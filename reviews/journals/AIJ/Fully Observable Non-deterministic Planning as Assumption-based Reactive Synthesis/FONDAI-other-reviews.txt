
View Letter
Date: 	Sep 16, 2016
To: 	****
From: 	"Artificial Intelligence" aij.office@googlemail.com
Subject: 	Your Submission ARTINT-D-16-00179 -- ****


Ms. Ref. No.:  ARTINT-D-16-00179
Title: Fully Observable Non-deterministic Planning as Assumption-based Reactive Synthesis
Artificial Intelligence

Dear ****,

This paper you submitted to Artificial Intelligence has been reviewed and I am sorry that it has been rejected.

The reviews are attached. Thank you for submitting your work to the Journal.


Yours sincerely

Rina Dechter
Editor-in-Chief
Artificial Intelligence- Now free access - See aij.ijcai.org

From the AE:

Dear Sebastian, Nicolas and Natalia,

We now have three reviews on your submission. In my opinion, the reviewers made a really good jobs reading and understanding your work, and producing detailed and in-depth evaluations. The main criticism, that I fully share, is that the contribution of the paper is too marginal for the journal Artificial Intelligence.

First, the assumptions and notion of strong-cyclic policies for FOND planning are currently well understood as described in many recent works in the area, and even in textbooks (such as Geffner & Bonet''s book entitled "A Concise Introduction to Models and Methods for Automated Planning"): a policy pi is strong-cyclic for task P iff pi achieves the goal along all the fair executions generated by pi, where an execution T (interleaved sequence of states and actions) is fair iff for every pair (s,a) that appears infinitely often in T and possible outcome s'' of a on s, T also contains the triplet (s,a,s'') infinitely often. As Reviewer #3 points out, this concept is also very well known and clear on MDPs (the probabilistic version of FONDs) where strong-cyclic policies are known as proper policies. As Reviewer #3 also points out, in MDPs one can go even further, given the probabilities involved, and show that the set of trajectories that aren''t fair (for policy pi and the definition of fairness given above) has measure zero.

Second, the paper gets quite technical and complicated in expressing in logic this concept that is formally expressed in a paragraph (but not in logic, of course). This succinctness is achieved because the definition is made from "outside" the system whereas the characterisation given in the paper is "within" the system. As the first reviewer points out, What''s the value/utility of making this logical characterisation of fairness? Does it permit simpler or more efficient approaches for the synthesis of strong cyclic plans or controllers? This is not clear at all and, indeed, it doesn''t sound plausible (I would be pleasantly surprised if proved wrong, though). On the other hand, as argued above, such definition is certainly not making the concept of strong-cyclic policy or the assumptions on the environment more clear or "more formal". On the contrary, I think it may confuse non-experts in the area, while providing few useful knowledge to the experts.

Third, there are important pieces of related work, pertaining to different areas such as KR, planning and probabilistic planning that are not cited or analysed in a more deeper way. In my opinion, the paper excessively builds on early work and not with the most recent work where the right and in-sync notions (with your work) of strong-cyclic policies and fairness are used/given. These latter works are quickly mentioned in the related work section.

So, even though the article is a sound and complex elaboration, its significance and important appears at the moment to be small. Observe also that we are not talking about fixing or expanding a section of the paper. The criticism of the reviewers go much deeper and enclose the whole work. I''m sorry to inform you that your paper has not been accepted in AIJ. Please read the reviews carefully to fully understand this decision and to find very insightful information about your work.

==========================================================================================
Reviewer #1: AIJ Review Form

Part A
------

Please answer the following questions "yes/no" and provide appropriate justification as appropriate.

CONTENT
                           
Is the paper technically sound? Yes

Is the work described original? YEs

Does it show sufficient applicability to AI? Yes

Does it place new results in appropriate context with earlier work?
Marginal, with a few gaps (see detailed review below)

Is the paper sufficiently novel? (A paper is novel if the results it describes
were not previously published by other authors, and were not previously published
by the same authors in any archival journal.) Yes

Is the paper complete? (Generally, a paper is complete if it includes all relevant proofs
and/or experimental data, a thorough  discussion of connections with the existing literature,
and a convincing discussion of the motivations and implications of the
presented work.)
No, as the utility of the proposed solution approach needs to be
justified (see detailed review below)

Does anything need to be added or deleted?
Yes (see detailed review below)

Is the result important enough to warrant publication?
Potentially important with some more work


Accesibility
--
Is the paper accessible to the broad readers of AIJ?
Yes

Specifcally:

Is the problem addressed in the paper, described in an accessible
manner to readers of the journal?
Yes

Is it possible for an AI researcher, outside the specific area,  to
assess its relevance to  AI in general and  to their own research
area, in particular?
A good attempt is made to make it broadly accessible, but key points
about the utility of the results need to be addressed.


Is enough background given (e.g., prior work, preliminaries,
methodology) so an AI researcher outside the specific area can
appreciate the paper''s contribution?
Yes

----

FORM
                                                       
Does the abstract adequately reflect the contents?
Yes

Does it contain adequate references to previous work?
Yes. However, the value provided beyond prior work is not clear

Does it explain clearly what was done that is new?
Yes

Does it clearly indicate why this work is important?
No, more analysis is required

Is the English satisfactory?
Yes

Is the presentation otherwise satisfactory?
Yes

Are there an appropriate number of figures?
Yes

Do the figures help clarify the concepts in the paper?
Yes


Part B: DETAILED COMMENTS
-------------------------


This paper presents two theoretical results. The first is a formal
identification of conditions under which strong cyclic plans are
useful. In my opinion, currently this is the more clear contribution.
The authors show that the condition of state-strong fairness on the
environment is sufficient for a strong cyclic plan to eventually reach
the goal state in a FOND problem. Furthermore, a solution to a FOND
problem is a strong cyclic plan iff it achieves the goal whenever the
environment satisfies the state-strong fairness condition.  

The second contribution consists of reductions that (a) translate FOND
problems to 2-player Buchi games and (b) represent them using LTL
formulas so that LTL synthesis approaches could be used for solving
the original problem. This part of the paper has a relatively weaker
motivation.  It is not clear that the reductions presented will
actually be more helpful than existing techniques for solving FOND
problems. No empirical or theoretical analysis is presented to make
this case. Given that the languages that they reduce to are propositional  
and have the same computational complexity classes (as would be
expected), the utility of the reduction needs to be justified. Perhaps
empirical results can be obtained using solvers for LTL synthesis
problems or 2-player Buchi games. Otherwise, it is not clear that the
presented reductions would be useful.

Overall, I think the paper makes a valuable contribution in
formalizing the notion of fairness under which strong cyclic plans
achieve their goals.  The paper is very well written and the quality
of presentation is uniformly very good. The authors take care to
present running examples and figures clarifying the technical points.

However, I would encourage the authors to come up with
convincing arguments justifying the value of the remainder of the
paper.


Detailed comments:

p3: "inspired on that in [5]" --> inspired by that in [5]

"remaining of this article" --> remainder of this paper



p8:

"use the key,... turn the knob" --> flip coin 1; flip coin2


This section is good. It is clear that one needs all possible
combinations of effects to occur infinitely often for a given policy''s
execution and the state-strong fairness condition ensures this.

p12:
The text just after Eq. 2 confuses operator moves and environment
moves. I suggest replacing "operator selector controller"
with "operator", or "the agent" and mentioning in the background that
the agent controls the selection of operators.

"as a mean for" --> "as a means for"

The connection to LTL synthesis and declarative approaches is good.
However, the authors should also note in the paper that unlike
planning domains, even specifying a problem using LTL/CTL can be
cumbersome due to the propositional nature of these languages. The
number of propositions is O(n^k) for a problem with n objects and
predicates of arity k (Imagine specifying a "simple" blocks world
problem with 10 blocks in such a language). The point is that
complexity of synthesis is 2EXPTIME or polynomial in a representation
that is already exponential in the arity of a first-order/parametric
representation typically used in planning. Further, the polynomial-time
version (GR(1)) is polynomial in the state-space, which gives a
more sober perspective that is also consistent with complexity theory.
It is good to balance the excitement about connections with synthesis
with these aspects to convey an accurate understanding of the field to
the reader. The authors remark on this caveat briefly much later in
the paper but this discussion needs to be promoted, and addressed more
carefully. What is the utility of the presented reduction? How is the
proposed solution technique better than existing algorithms for strong
cyclic planning?


The reduction to games needs to connect with prior work in the area of
MDPs with LTL constraints (essential FONDs with stochastic
non-determinism), e.g. the work of Etessami, Vardi and their
collaborators. A good starting point is Brazdil et al., FSTTCS ''10.
Although they address slightly different problems of model checking,
the game formulation is similar.

Section 4.2: the statement about being the first controller-synthesis
based approach is a bit vague and but worth refining. What are
"controller-synthesis based approaches"? Arguably, the algorithms for
strong-cyclic planning solve the same problems and are also optimal
w.r.t computational complexity. One could instead make a stronger
claim by using specifics of the method used.


p14: As noted above, the O(n^2), is actually not too impressive from
the point of view of planning. It is in fact the same as EXP for the
complexity of FOND planning in general, where EXP comes due to the
fact that one has to do an exponential time operation to construct the
state space. While it is good to see that the complexity classes line
up, indicating that the reductions being used are not wasteful, the
"polynomial" complexity alone is not a good reason to use the proposed
technique. The same clarification applies to conclusion in p21, that
the problem of finding a strong-cyclic policy is in PTIME.

Related work:

The authors tend to equate FOND with strong cyclic planning. However,
the origins and formulations for FOND go further back. See for example
Conditional Nonlinear Planning, Peot & Smith, AIPS 1992.

George Pappas, Kress Gazit and others have been doing planning for
robots using the results of Pnueli et al. for synthesis of reactive
behaviors for GR(1) specs. While this is not a formal connection to
strong cyclic planning, the use of reactive synthesis techniques for
planning is not new.  

The relationship to synthesis for GR(1) formulas is not clear. The
authors state:

"Unfortunately, though, the assumption-requirement shape of GR(1)
specifications is not suitable: the assumption part is too simple and
cannot accommodate a reactivity condition itself."    

The conclusion of this statement is essential to the paper, but the
justification is too informal. Since the poor complexity of synthesis
for LTL formulas forms a strong motivation for the paper, and GR(1)
formulas have efficient synthesis, this point needs to be discussed in
the technical section (not just in the related work). Please make this
a formal result about non-expressiblity in GR(1).


The paper would benefit with a greater connection with the literature
in planning for "synthesis" as the term is used in this paper. Older
work by Waldinger is mentioned, but there''s rising interest. Some of
the work in the area of generalized planning (Srivastava et al., ICAPS
''11) and (Segovia-Aguas et al., IJCAI ''16) also uses program synthesis
problems as test cases.





==========================================================================================
Reviewer #2: SUMMARY

The paper discusses the relationship between Fully Observable
Non-Deterministic Planning (FOND Planning) and Reactive Synthesis. The
paper first introduces an LTL formalization of the requirements that
the environment must satisfy in order for a strong cyclic policy to
invariably lead to the goal eventually. This formalizes a concept that
in the literature was often kept informal. Thanks to this formulation
it would be possible (although) impractical to solve FOND planning as
an LTL synthesis problem. Secondly, the authors discuss a dedicate
construction of a 2-player game such that any winning strategy for the
existential player corresponds to a solution to the FOND planning
problem.  The authors prove that this construction meets the
computational complexity lower bound of FOND planning.


OVERALL EVALUATION

I think the material presented in the paper is in general interesting
and worthy of publication.

My major critique to the paper is that there is little connection
between the first part (from Section 2 to Section 4.1), that is about
LTL formalization and synthesis, and the second part, that is focused
on the 2-player game construction. In fact, the second part almost
never uses the ideas from the LTL formalization (apart for the proofs)
and seems like a separate paper to me. I do understand that the second
part represent most of the novel part with respect to [44], and is
somehow a progression on the same research line, but the connection
between the two parts is quite stretched in my opinion.

Concerning the technical quality, I think some more effort for
clarifying the proofs is needed as they are pretty obscure: maybe a
sketch of the proof giving some intuition to the reader would be
helpful. Moreover, there are some (minor) technicalities (listed
below) that I think are wrong and might need to be fixed.


TECHNICAL ACCURACY

There are some technicalities in the paper that are unconvincing to
me, I list them below.

- In page 5 you defined the Kripke structure without the initial
 states (in the MC literature, K is usually a quadruple embedding the
 initial states) and later you say that K \models \phi usually
 denotes K, w \models \phi for all w \in W (Pg 6 Ln 16). This is very
 odd to me, usually, K \models \phi means that K, w \models \phi for
 all the INITIAL STATES w of K. I believe that this writing is
 misleading and in fact, the K, w \models \phi version is almost
 always used. The other form is in my opinion wrong as in Pg 9 Ln 29
 where I K_P^\pi \models A[\gamma -> F \phi_goal] should be K_P^\pi,
 <S_I, O_I> \models ... as in the definition of theorem 1.

- I do not understand why the authors present the semantics of LTL and
 CTL for structures with terminating states if in Pg 3 Ln 32 they
 restrict themselves to deadlock-free problems.

- The second bullet of the LTL semantics is wrong, as \neg \phi should
 be covered instead of \neg p.
 It should read as follows:
 * \lambda \models \neg \phi iff \lambda \not models \phi

- The given definition of the semantics of LTL does not cover the
 whole presented syntax: W, G and F operators are missing. Here the
 authors should either give their semantics or present the rewritings
 of these operators in the ones for which the semantics is given.

- the seventh bullet of the CTL semantics is also wrong, it should
 read as follows:
 * K, w \models AF \phi iff for all maximal runs \lambda = w0,w1,w2,... with w0 = w THERE EXISTS a k >= 0 such that K, wk \models \phi.

- Section 2 presents the semantics of CLT and LTL but not the one of
 CTL*. However, CTL* is used in the paper and thus its semantics
 should be presented. For example, theorem 1 (that is one of the
 major contributions of the paper) is stated as a CTL* formula even
 if the formula really is LTL, but the proof leverages the LTL
 semantics, but the fact that an LTL formula is a CTL formula of the
 form A(\phi) with \phi not containing path quantifiers is never
 introduced before footnote 5 in Pg 11.

- In definition 8 the # sign is undefined, the reader must wait till
 line 47 (outside of the definition) to understand its meaning.

- Definition 8 is overly complex due to the syntax change of states
 that can be pairs or triples. I think that uniforming the signature
 would be better.



PRESENTATION

The paper is generally well-written and understandable with few,
easily fixable typos. I just have few minor suggestions:

- I think that the motivations for the work could be emphasized a bit

- The background on the 2-player games could be moved to section 2 to
 better merge the two parts of the paper.

- The authors could add a bit of background on the reactive synthesis
 techniques in section 2



MINOR POINTS

Pg 2 Ln 9: can be reach. -> reached.
Pg 2 Ln 24: some quite -> quite some
Pg 2 Ln 46: between the assumption on the -> assumptions
Pg 3 Ln 43: is a (deterministic effect) condition -> better state that you use the same syntax for condition and effects, and remove the confusing parenthesis
Pg 3 Ln 50: Formula A \Psi (E \Psi) -> use word "respectively" to avoid confusion, at first sight it seemed a single formula... Moreover, in the grammar you used \phi instead of \Psi...
Pg 9 Ln 45: in \lambda infinite many times -> infinitely
Pg 12 Ln 28: behaves fair w.r.t -> fairly
Pg 15 Ln 58: the * in <s, *, \box> is misleading because it can be confused with s*. Why not using o_# as in the definition?
Pg 16 Ln 30: AFor instance -> For
Pg 16 Ln 36: o is a adequate -> an
Pg 16 Ln 36: planing -> planning
Pg 16 Ln 53: a FOND planning problems -> problem
Pg 23 Ln 21 and 36: The GR(1) fragment is introduced twice with similar wording
Pg 24 Ln 53: planning under with action -> something is missing here


==========================================================================================

Reviewer #3: This is a review of manuscript number ARTINT-D-16-00179. All numbered
references, e.g., [10], refer to the bibliography in the manuscript. Additional
references are listed below.

CONTEXT

The main objects of study are (finite-state) fully-observable non-deterministic
planning problems (FOND) and a particular solution concept, i.e., strong-cyclic
policies.  These are policies that satisfy the branching property AG(EF(goal)),
or a variation in which the EF(goal) obligation is dropped once goal has been
reached.

Such solution concepts are interesting because they capture iterative
trial-and-error strategies such as "pick up a block until succeed" that might
loop forever if a certain effect ("succeed") is not guaranteed [10].

Consequently, as the authors point out, the FOND literature assumes that
policies be run in "fair" environments, and that this assumption had not been
sufficiently formalised.

The purpose of this paper is to formalise this assumption, and leverage it to
show that one can reduce FOND with strong-cyclic policies to reactive synthesis
on fair environments, and achieve the known optimal complexity, i.e., 1EXPTIME.

The connection between planning and synthesis is known to be a tight one.  FOND
planning is nothing else than synthesising winning strategies in 2-player
graph-games of perfect information.  However, there are two important
distinctions between the formalisms.
- Planning typically induces an exponentially large graph (i.e., n variables
 induce 2^n states), and thus the complexities are typically one exponent
 larger (e.g., reachability games are PTIME-complete, while strong FOND
 planning is EXPTIME-complete).
- The manuscript focuses on non-randomised deterministic policies, which
 correspond to deterministic memoryless strategies. In many games such
 strategies suffice, i.e., if there is no deterministic memoryless strategy
 achieving an objective, then there is no strategy at all.

CONTRIBUTION

The authors define a linear-temporal property over executions called
"state-strong fairness" that says that if the same action is made in the same
state infinitely often, then every possible effect also appears infinitely
often.

State-strong fair executions (of a given policy) have the following fundamental
property: if a state s is seen infinitely often then every state s'' reachable
(using the policy) from s is also seen infinitely often.

They prove that a policy is strong-cyclic if and only if every state-strong fair
execution of the policy reaches the goal (Theorems 1 and 2).  Informally, the
reason this is true is the following:
- only if: if a state s is seen infinitely often then, by state-strong fairness,
 every state s'' reachable from s (in P using the policy) is also seen
 infinitely often; so by strong-cyclic, at least one of these states satisfies
 the goal.
- if: if a state s is reachable (in P using the policy) and the goal is not
 reachable from s, then no execution from s (in particular the state-strong
 fair ones) reaches the goal, contradicting the assumption.

The authors show that another natural fairness property does not capture
strong-cyclic policies, i.e., "if an action is executed infinitely many times,
every non-deterministic outcome will occur infinitely many times".

They then provide a reduction from finding strong-cyclic policies in FOND
problems to solving Buchi-games, i.e., graph-games with repeated reachability
objectives. The authors state that the reduction is inspired by one from the
stochastic games literature [5].

EVALUATION

I unreservedly commend the authors for their goal of identifying and cleaning-up
loose and misleading assumptions from the literature. Too much time is wasted on
extending ideas with poor foundations. I especially appreciate the statements of
Theorems 1 and 2.

However, I have serious concerns about the novelty of the technical details.  

In short, Theorems 1 and 2 follow from standard properties of MDPs; and, the
fact that there is a natural reduction of strong-cyclic FOND to game-solving
follows from important connections between fix-point algorithms and parity
games.

Here are my justifications.

State-strong fairness is a well-known notion in the planning and verification
communities.

For instance, it was formally defined in [34, Section 2.1] where it is shown how
to reduce planning for LTL objectives under state-strong fairness to
strong-cyclic planning. The exact relationship between the manuscript and [34]
is not clearly established (see OTHER COMMENTS).

Let me focus on the setting in which state-strong fairness is fundamental, i.e.,
the probabilistic setting, and in particular Markov Decision Processes with the
solution concept "the goal is reached with probability 1".

The connection with probability is implicit in the manuscript, e.g., Example 1
gives a FOND representation for the problem of flipping coins until heads
appear, and the stated inspiration for the reduction is a paper on stochastic
parity games [5].

However, much more is known. A policy on an MDP induces a Markov Chain. The
set of executions in a Markov Chain that are state-strong fair has measure
equal to one. Thus:

FACT 1. A policy ensures the goal with probability 1 if and only if it ensures
the goal on state-strong executions.

What is the connection with strong-cyclic policies? It turns out that one can
reduce the problem "does there exist a strategy that achieves the goal with
probability 1" to the problem "does there exists a strategy that induces a
Markov chain whose underlying graph satisfies AG(EF(goal))", see for instance
[FKNP11, Algorithm 4]. In other words, the algorithm reduces the problem to
checking if there exists a strong cyclic strategy. So, given a policy, apply the
algorithm to the induced Markov chain of that policy, and get:

FACT 2. A policy ensures the goal with probability 1 if and only if it is
strong-cyclic.

Putting FACTS 1 and 2 together, we get Theorems 1 and 2.

Actually, the algorithm in [FKNP11] can be thought of as a parity game.  Here
are some details.  The algorithm calculates the set of states for which there is
a policy ensuring that the goal is reached with probability 1. The algorithm is
a nesting of two fix-points computations, a least inside a greatest, over the
underlying transition-system of the MDP.  This amounts to model-checking a
certain mu-calculus formula over this transition-system.  Moreover, model
checking mu-calculus is equivalent to solving parity games [GTW02].  In fact,
the corresponding parity game has 3 colours, and so can be solved in quadratic
time in the number of states (of the MDP).

Thus there is a natural reduction of strong-cyclic FOND to solving 3 colour
parity games, resulting in an EXPTIME procedure.

OTHER COMMENTS

- There is some confusion about the differences and similarities between reactive
synthesis and game solving.

The authors state that they demonstrate "how efficient approaches to controller
synthesis can be used so solve FOND planning tasks" (pg 2.)

What they mean, I think, is that they plan to show how to reduce strong-cyclic
FOND to solving games of one kind or another (and achieve optimal complexity
with this reduction). Indeed, they don''t reduce to reactive synthesis (as also
the title suggests), but to certain games on graphs.

Why does this distinction between reactive synthesis and games on graphs matter?
It has ramifications on the complexity of synthesis.

LTL games (i.e., games on graphs with LTL objectives, such as Buchi games) are
distinct from reactive synthesis. The former have an explicit arena while in the
latter the arena is implicit and compactly encoded in the formula. As a result,
the complexity of solving LTL games is 2EXPTIME in the formula and polynomial in
the arena, while the complexity of reactive synthesis is 2EXPTIME in the
formula.

- The title uses the phrase "assumption-based reactive synthesis". An explanation
of "assumption-based" means would be helpful.

- The definitions in the preliminary section (sec 2.1) should be tightened.
- "condition" is undefined
- the definition of state, although correct, is clunky.
- you allow non-deterministic strategies but then focus on deterministic ones for
  most of the paper.
- the definition of "possible executions" uses the notion of "execution". again,
  although correct, it makes for hard reading.
- in the definition of "possible executions" it seems that the condition s_
  \models Pre_{o_i} is superfluous since you already stated that o_i \in
  \pi(s_i).
- are "possible executions" infinite, as suggested by the notation?
- the definition of "closed" does not match the explanation after it.
- the definition of "strong cyclic plan" is too informal.
- the statement about "strong policies" says that all executions are finite and
  acyclic; doesn''t the fact that policies are memoryless mean that finite
  implies acyclic?
- please define "classical planning".

- Definition 4. "strong-cyclic plan solution". Isn''t "solution" superfluous?

- More generally, "plan", "policy" and "solution" are all used in the
 manuscript; are these interchangeable?

- I found the main purpose of the paper obscurely described, until I read the
 theorems. For instance, the abstract states "We study conditions that the
 environments must entail so that the plans guarantee achieving the goals...
 [we] show that strong-cyclic plans are correct solution concepts for fair
 environments", and later (pg. 7) "it is ... important to understand and
 formalize the contexts under which these type of plans will indeed achieve the
 objectives".  The notions "correct solution concept" and "contexts" are too
 vague to be useful.

- The discussion in the related work about the current state of the literature
 regarding the meaning of "fair environment" would be a most valuable addition.
 E.g., what is the exact relationship between the present work and [34]. There
 they show how to reduce state-strong fair realisability to strong-cyclic
 planning. Although it says (pg. 10) "The theorem is related to Theorem 5 in
 [34], though ours crystallize the fairness assumption explicitly within
 Traverso et al.''s FOND planning logical foundational framework (see Section 5
 for further discussion).", I found neither this statement nor the discussion
 in Section 5 clear.

- The citation in "While feasible, synthesis under fairness assumptions is
 computationally very demanding (Vardi [46]...)" is not appropriate. That paper
 covers a much more general setting, i.e., LTL objectives and imperfect
 information.

- Pg 24. CTL synthesis is mentioned. This seems out of context.

REFERENCES

[FKNP11] V. Forejt, M.Z. Kwiatkowska, G. Norman, D. Parker.  Automated
Verification Techniques for Probabilistic Systems. SFM 11, 53-113, 2011.

[GTW02] Automata, Logics, and Infinite Games:A Guide to Current Research.
E. Grädel, W. Thomas and T. Wilke, Thomas (Eds.), 2002.

[GV15] G. de Giacomo and M. Vardi. Synthesis for LTL and LDL on Finite Traces.
IJCAI 15, 1558-1564, 2015.


REVIEWER

Sasha Rubin (I am not in favour of single-blind reviews).




******************************************
For further information on AIJ reviewing processes, please visit www.aijd.org.
Free Access now to AIJ -- see aij.ijcai.org

For further assistance, please visit our customer support site at http://help.elsevier.com/app/answers/list/p/7923. Here you can search for solutions on a range of topics, find answers to frequently asked questions and learn more about EES via interactive tutorials. You will also find our 24/7 support contact details should you need any further assistance from one of our customer support representatives.

