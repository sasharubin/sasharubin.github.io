
<!DOCTYPE html>


<html>
<head>
    <title>AAMAS2018</title>
    
<link rel="icon" href="https://cdn.confmaster.net/tenants/default/images/favicon-cm.ico" type="image/x-icon"/>
<link rel="shortcut icon" href="https://cdn.confmaster.net/tenants/default/images/favicon-cm.ico"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link href="//netdna.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" media="all" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.1/css/font-awesome.min.css" rel="stylesheet">
    <script src="//code.jquery.com/jquery-2.1.1.min.js"></script>

<link href="https://cdn.confmaster.net/css/extra.css" rel="stylesheet">
    
    <link href="//cdnjs.cloudflare.com/ajax/libs/select2/4.0.3/css/select2.min.css" type="text/css" media="screen" rel="stylesheet" />
    
        <link href="//cdnjs.cloudflare.com/ajax/libs/x-editable/1.5.0/bootstrap3-editable/css/bootstrap-editable.css"
              rel="stylesheet"/>
    

    <script>
        $(function () {
            $("#modalMessage").modal({backdrop: 'static'});
        });
    </script>

</head>
<body>



<script>
    $(document).ready(function (e) {
        search_for = '' || 'Person';
        search_for = search_for.substr(0, 1).toUpperCase() + search_for.substr(1);
        $('.search-panel span#search_concept').text(search_for);
        $('.search-panel .dropdown-menu').find('a').click(function (e) {
            e.preventDefault();
            var param = $(this).attr("href").replace("#", "");
            var concept = $(this).text();
            $('.search-panel span#search_concept').text(concept);
            $('.input-group #search_for').val(param);
        });
    });

</script>

<nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse"
                    data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://celweb.vuse.vanderbilt.edu/aamas18/home/">AAMAS2018</a>
        </div>
        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse navbar-justified" id="bs-example-navbar-collapse-1">
            
            <ul class="nav navbar-nav navbar-right">
                <li><a href="/user/home"><i class="fa fa-home"></i> Home</a></li>
                
                    
                    
                    
                        
                    
                        
                    
                        
    <li class=" dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">PC Member <b class="caret"></b></a>
        <ul class="dropdown-menu">
            
                <li><a class="nav" href="/rev_3/paper/bid/list/">Bidding</a></li>
            
        </ul>
    </li>

                    
                        
                    
                    
    <li class=" dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Submissions <b class="caret"></b></a>
        <ul class="dropdown-menu">
            
                <li><a class="nav" href="/author/paper/list/">View own papers</a></li>
            
        </ul>
    </li>

                    
                    
    <li class=" dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-user"></i> Sasha Rubin <b class="caret"></b></a>
        <ul class="dropdown-menu">
            
                <li><a class="nav" href="/personalData/edit/">Edit Personal Data</a></li>
            
                <li><a class="nav" href="/user/accounts/email/">Manage Email Addresses</a></li>
            
                <li><a class="nav" href="/user/accounts/password/change/">Change Password</a></li>
            
                <li><a class="nav" href="/user/accounts/social/connections/">Manage Social Logins</a></li>
            
                <li><a class="nav" href="/person/keywords/edit/">Edit Personal Keywords</a></li>
            
                <li><a class="nav" href="/invitation/answer/">Answer Open Invitations</a></li>
            
        </ul>
    </li>

                    <li><a href="/accounts/logout/">
                        <strong><i class="fa fa-sign-out"></i> Logout</strong>
                    </a>
                    </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</nav>



    <div class="container hidden-print">
        <a href="http://celweb.vuse.vanderbilt.edu/aamas18/home/"><img class="img-responsive img-rounded banner" src="https://cdn.confmaster.net/tenants/aamas/aamasBanner.png"
                                      alt="AAMAS2018"></a>
    </div>

<div class="visible-print-block">
    <h5>ConfMaster@AAMAS2018 printed for Sasha Rubin
        (sasharubin) at 2017-11-17 20:28:36 </h5>
</div>

<div class="container-fluid page-header">
    <h1>
        
    Bid on Submissions
    <span class="label label-default lb-xl" title="Saved bids (update on page reload)">
                        
                            <span class="badge lb-lg badge-gold"
                                  title="Top Choice"
                                  data-ctr="0" id="bid_type_50">
                                0
                            </span>
                        
                            <span class="badge lb-lg badge-green"
                                  title="Very Interested"
                                  data-ctr="0" id="bid_type_45">
                                0
                            </span>
                        
                            <span class="badge lb-lg badge-blue"
                                  title="Interested"
                                  data-ctr="0" id="bid_type_40">
                                0
                            </span>
                        
                            <span class="badge lb-lg badge-gray-darker"
                                  title="Not Interested"
                                  data-ctr="0" id="bid_type_25">
                                0
                            </span>
                        
                            <span class="badge lb-lg badge-red"
                                  title="Conflict of Interest"
                                  data-ctr="0" id="bid_type_20">
                                0
                            </span>
                        
                     </span>

    </h1>
</div>

<div class="container-fluid">
    




    

    <style>
        .lb-lg {
            font-size: 15px;
        }

        .lb-xl {
            font-size: 20px;
        }
    </style>
    
    <div class="hidden-print">
        


    <!-- Modal -->
    <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <form enctype="multipart/form-data" action="" role="form" method="get"
                      class="form-horizontal hidden-print">
                    <div class="modal-header">
                        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                            <span aria-hidden="true">&times;</span>
                        </button>
                        <h4 class="modal-title" id="myModalLabel">Set Filter</h4>
                    </div> <!-- modal-header -->
                    <div class="modal-body">
                        <div class="form-group"><label class="col-md-2 control-label" for="id_title__icontains">Title</label><div class="col-md-8"><input type="text" name="title__icontains" title="" id="id_title__icontains" class="form-control" placeholder="Title" /></div></div>
<div class="form-group"><label class="col-md-2 control-label" for="id_keywords__pk__in">Keywords</label><div class="col-md-8"><select name="keywords__pk__in" title="" data-width="100%" data-minimum-input-length="0" data-placeholder="" id="id_keywords__pk__in" class="form-control django-select2" data-allow-clear="true" multiple="multiple">
  <optgroup label="Agent-based Simulation">
  <option value="530">Analysis of agent-based simulations</option>

  <option value="527">Emergent behaviour</option>

  <option value="531">Interactive simulation</option>

  <option value="532">Modelling for agent based simulation</option>

  <option value="639">Simulation of complex systems</option>

  <option value="529">Simulation techniques, tools and platforms</option>

  <option value="638">Social simulation</option>

  <option value="640">Validation of simulation systems</option>

  <option value="649">Other</option>

  </optgroup>
  <optgroup label="Agent Cooperation">
  <option value="563">Biologically-inspired approaches and methods</option>

  <option value="561">Coalition formation (non-strategic)</option>

  <option value="564">Collective intelligence</option>

  <option value="562">Distributed problem solving</option>

  <option value="633">Multi-robot systems</option>

  <option value="632">Multi-user/multi-virtual-agent interaction</option>

  <option value="565">Teamwork, team formation, teamwork analysis</option>

  <option value="651">Other</option>

  </optgroup>
  <optgroup label="Agents and Mainstream Computing">
  <option value="620">Autonomic computing</option>

  <option value="623">Mobile agents</option>

  <option value="624">P2P, web services, grid computing, IoT, HPC</option>

  <option value="621">Service-oriented architectures</option>

  <option value="652">Other</option>

  </optgroup>
  <optgroup label="Agent Societies and Societal Issues">
  <option value="517">Architectures for social reasoning</option>

  <option value="635">Coordination and control models for multiagent systems</option>

  <option value="516">Monitoring agent societies</option>

  <option value="514">Normative systems</option>

  <option value="513">Organisations and institutions</option>

  <option value="510">Policy, regulation and legislation</option>

  <option value="518">Self-organization</option>

  <option value="634">Social networks</option>

  <option value="515">Socio-technical systems</option>

  <option value="512">Trust and reputation</option>

  <option value="511">Values in MAS (privacy, safety, security, transparency, etc)</option>

  <option value="653">Other</option>

  </optgroup>
  <optgroup label="Agent Theories and Models">
  <option value="555">Belief-Desire-Intention theories and models</option>

  <option value="557">Cognitive models</option>

  <option value="554">Logic and Game Theory</option>

  <option value="558">Logics for agents and multi-agent systems</option>

  <option value="556">Logics for norms and normative systems</option>

  <option value="631">Logics for norms and normative systems</option>

  <option value="559">Models of emotions</option>

  <option value="654">Other</option>

  </optgroup>
  <optgroup label="Communication and Argumentation">
  <option value="524">Argumentation-based dialogue and protocols</option>

  <option value="520">Commitments</option>

  <option value="521">Communication languages and protocols</option>

  <option value="523">Deductive, rule-based and logic-based argumentation</option>

  <option value="522">Speech act theory</option>

  <option value="655">Other</option>

  </optgroup>
  <optgroup label="Economic Paradigms">
  <option value="545">Auctions and mechanism design</option>

  <option value="544">Bargaining and negotiation</option>

  <option value="548">Behavioral game theory</option>

  <option value="549">Cooperative games: computation</option>

  <option value="547">Cooperative games: theory &amp; analysis</option>

  <option value="550">Game Theory for practical applications</option>

  <option value="551">Noncooperative games: computation</option>

  <option value="552">Noncooperative games: theory &amp; analysis</option>

  <option value="546">Social choice theory</option>

  <option value="656">Other</option>

  </optgroup>
  <optgroup label="Engineering Multiagent Systems">
  <option value="573">Development techniques, tools and platforms</option>

  <option value="578">Innovative agents and multiagent applications</option>

  <option value="576">Methodologies for agent-based systems</option>

  <option value="575">Modelling and specification languages</option>

  <option value="574">Programming languages and frameworks for agents and multi-agent systems</option>

  <option value="657">Other</option>

  </optgroup>
  <optgroup label="Humans and Agents">
  <option value="647">Agent-based analysis of human interactions</option>

  <option value="646">Agents competing against humans</option>

  <option value="648">Agents for improving human cooperative activities</option>

  <option value="644">Human-robot/agent interaction</option>

  <option value="645">Multi-user/multi-virtual-agent interaction</option>

  <option value="658">Other</option>

  </optgroup>
  <optgroup label="Knowledge Representation and Reasoning">
  <option value="568">Ontologies for agents</option>

  <option value="571">Reasoning about action, plans and change in multi-agent systems</option>

  <option value="570">Reasoning about knowledge, beliefs, goals and norms in multiagent systems</option>

  <option value="569">Reasoning in agent-based systems</option>

  <option value="567">Single and multi-agent planning and scheduling</option>

  <option value="659">Other</option>

  </optgroup>
  <optgroup label="Learning and Adaptation">
  <option value="637">Adversarial machine learning</option>

  <option value="584">Co-evolutionary algorithms</option>

  <option value="636">Deep learning</option>

  <option value="581">Evolutionary algorithms</option>

  <option value="585">Learning agent capabilities (agent models, communication, observation)</option>

  <option value="580">Learning agent-to-agent interactions (negotiation, trust, coordination)</option>

  <option value="583">Multiagent learning</option>

  <option value="582">Reward structures for learning</option>

  <option value="660">Other</option>

  </optgroup>
  <optgroup label="Verification and Validation of Agent-based Systems">
  <option value="641">Fault tolerance and resilience of multi-agent systems</option>

  <option value="629">Synthesis of agent-based systems</option>

  <option value="642">Testing and debugging multiagent programs</option>

  <option value="628">Testing of agent-based systems, including model-based testing</option>

  <option value="627">Verification techniques for multiagent systems, including model checking</option>

  <option value="661">Other</option>

  </optgroup>
</select></div></div>
<div class="form-group"><label class="col-md-2 control-label" for="id_bid__bid__in">Bid</label><div class="col-md-8"><select name="bid__bid__in" title="" data-width="100%" data-minimum-input-length="0" data-placeholder="" id="id_bid__bid__in" class="form-control django-select2" data-allow-clear="true" multiple="multiple">
  <option value="50">Top Choice</option>

  <option value="45">Very Interested</option>

  <option value="40">Interested</option>

  <option value="35">Neutral</option>

  <option value="30">No Bid</option>

  <option value="25">Not Interested</option>

  <option value="20">Conflict of Interest</option>

</select></div></div>
<input type="hidden" name="track__pk" value="4" id="id_track__pk" />
                        
                            <input type="hidden" name="limit" value="all"/>
                        
                        
                    </div> <!-- modal-body -->
                    <div class="modal-footer">
                        <button type="submit" class="btn btn-primary" id="form-submit">Search</button>
                       
                    </div> <!-- modal-footer -->
                </form>
            </div> <!-- modal-content -->
        </div> <!-- modal-dialog -->


    </div> <!-- modal -->
    <div class="btn-group vspace2">
        <a class="btn btn-primary" data-toggle="modal" data-target="#myModal">Filter</a>
    </div>


    </div>

    




<ul class="list-inline list-filter">
    
        
    
        
    
</ul>



    
        <table class="table table-striped table-bordered table-condensed table-hover table-responsive">
            <thead>
            <tr>
                <th  ><a href="/rev_3/paper/bid/list/?page=1&limit=all&order_by=-id"># ▲</a></th>
                <th  ><a href="/rev_3/paper/bid/list/?page=1&limit=all&order_by=title">Title </a></th>
                
                <th  ><a href="/rev_3/paper/bid/list/?page=1&limit=all&order_by=paperType">Paper type </a></th>
                <th  ><a href="/rev_3/paper/bid/list/?page=1&limit=all&order_by=track">Paper track </a></th>
                <th>
                    Keywords
                </th>
                
                    <th  ><a href="/rev_3/paper/bid/list/?page=1&limit=all&order_by=annotated_external_matching_value">Suggestion </a></th>
                
                <th  ><a href="/rev_3/paper/bid/list/?page=1&limit=all&order_by=annotated_bid">Bid </a></th>
                <th class="hidden-print">&nbsp;</th>
                <th class="visible-print-inline-block">Abstract</th>
            </tr>
            </thead>
            
                <tr>
                    <td>541</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-541">Controller Synthesis for Hierarchical Agent Interactions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Verification and Validation of Agent-based Systems] Synthesis of agent-based systems<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.980</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_541" class="editable_bid" data-pk="541" data-value="30"
                    data-url="/rev_3/paper/bid/set/541/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-541"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="p1">We introduce a formalism and algorithm for synthesizing controllers to coordinate interactions among hierarchically organized agents. Typical applications are, for example, in harbor or warehouse automation. The formalism models agents as hierarchical input/output automata, and models a system of interacting agents as the parallel composition of the automata. It extends the usual parallel composition operation of I/O automata with a hierarchical composition operation for refining abstract tasks into lower-level subtasks. We provide algorithms to synthesize hierarchically organized control components to coordinate the agents’ interactions in order to drive the system toward desired states. We formally define the representation and prove that the two operations of parallel and hierarchical composition are distributive, which is essential for the correctness and completeness of the synthesis algorithm.</p><style type="text/css">
p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 9.0px Helvetica}
</style></td>
                </tr>
            
                <tr>
                    <td>604</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-604">Testing Phase Space Properties of Synchronous Dynamical Systems with Nested Canalyzing Local Functions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.890</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_604" class="editable_bid" data-pk="604" data-value="30"
                    data-url="/rev_3/paper/bid/set/604/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-604"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">Discrete dynamical systems serve as effective formal models in many</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">contexts, including simulations of agent-based models, propagation</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">of contagions in social networks and study of biological phenomena.</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">A class of Boolean functions, called nested canalyzing functions</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">(NCFs), have been found as good models of certain biological</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">phenomena.&nbsp; Motivated by these biological applications, we study a</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">variety of analysis problems for synchronous dynamical systems</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">(SyDSs) over the Boolean domain, where each local function is a</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">nested canalyzing function. Each analysis problem involves testing</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">whether the phase space of a given SyDS satisfies a certain property.</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">Problems considered include reachability, predecessor existence,</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">fixed point existence and garden of Eden existence.&nbsp; We present</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">computational intractability results for some problems as well as efficient</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">algorithms for other problems.&nbsp; In many cases, our results provide</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">a clear delineation between intractable and efficiently </span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">solvable&nbsp;</span>versions of problems.</p></td>
                </tr>
            
                <tr>
                    <td>603</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-603">Sensor synthesis using genetic programming</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Monitoring agent societies<br>[Agent Societies and Societal Issues] Other</td>
                    
                        <td>0.860</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_603" class="editable_bid" data-pk="603" data-value="30"
                    data-url="/rev_3/paper/bid/set/603/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-603"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'CMR9'">In this paper we consider the problem of sensor synthesis within an environment to determine whether some behaviour has occurred. Our model is based on the semantics
of planning, and we provide a simple formalism for describing sensors and behaviours in such a model. We investigate
heuristic techniques for performing sensor synthesis, demonstrating that such techniques perform well in complex domains.&nbsp;</span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>655</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-655">Parity-energy ATL for qualitative and quantitative reasoning in MAS</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Agent Cooperation] Multi-robot systems<br>[Verification and Validation of Agent-based Systems] Verification techniques for multiagent systems, including model checking</td>
                    
                        <td>0.860</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_655" class="editable_bid" data-pk="655" data-value="30"
                    data-url="/rev_3/paper/bid/set/655/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-655"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we introduce a new logic suitable to reason about strategic</p><p>abilities of multi-agent systems where (teams of) agents are subject to</p><p>qualitative (parity) and quantitative (energy) constraints and where goals are</p><p>represented, as usual, by means of temporal properties.</p><p>We formally define such a logic, named parity-energy-ATL (pe-ATL, for short),</p><p>and we study its model checking problem, which we prove to be decidable<span style="line-height: 1.42857;">&nbsp;with</span></p><p>different complexity upper bounds, depending on different choices for the</p><p>energy range.</p><p><br></p></td>
                </tr>
            
                <tr>
                    <td>627</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-627">How Implicit Communication Emerges during Conversation Game</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Communication languages and protocols<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Humans and Agents] Agent-based analysis of human interactions</td>
                    
                        <td>0.860</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_627" class="editable_bid" data-pk="627" data-value="30"
                    data-url="/rev_3/paper/bid/set/627/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-627"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="Abstract"><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:
&quot;Linux Libertine&quot;;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:
minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:
AR-SA">Humans can achieve implicit communication based on the ability to
predict an opponent’s response. This ability helps human coordination. Implicit
communication is also used in uncooperative tasks for detecting deception. The
emergent process of cooperation and detection of deception for agent
communication is a popular topic in multi-agent simulations. In this study, we conduct
a multi-agent evolutionary simulation to analyze how implicit communication
emerges and its effects on agent communication during a conversation game. We
use a simplified three-player Werewolf game, including two cooperative roles
called villager and seer, and one deceptive role called werewolf. In the Werewolf
game, deceptions have a significant impact on the state of the game; the strong
relationship between lie-based coordination and winning rate, and the rule of
hidden identity in the game indicate that implicit communication may be
concealed in the players’ irrational strategies. </span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:minor-latin;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">In
this paper</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:
&quot;Linux Libertine&quot;;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:
minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:
AR-SA">,</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;
line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;
mso-fareast-theme-font:minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA"> we define implicit communication as a player using
irrational strategies and predicting its cooperator telling implicit lies. Therefore,
we</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;
line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:&quot;Linux Libertine&quot;;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">
analyze the results by labeling the agents’ strategies as rational, irrational,
and ambiguous. Our analysis suggests that implicit communication appears when
at least two roles are evolved, and communication only emerges between evolved </span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;
font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">cooperative
</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;
line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:&quot;Linux Libertine&quot;;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">agents.
If the evolved agents are a villager and a seer, </span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:minor-latin;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">implicit
communication emerges and the </span><span lang="EN-US" style="font-size:9.0pt;
mso-bidi-font-size:11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;
mso-fareast-font-family:&quot;Linux Libertine&quot;;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA">seer keeps telling lies while the villager
persists in irrational strategies, to maintain their group’s victory. In the case
of evolution of both the villager and werewolf, the </span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:minor-latin;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">villager
rarely uses irrational strategies</span><span lang="EN-US" style="font-size:9.0pt;
mso-bidi-font-size:11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;
mso-fareast-font-family:&quot;Linux Libertine&quot;;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA">, and implicit communication does not </span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;
font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">emerge.</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;
font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:&quot;Linux Libertine&quot;;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">
For the condition with three agents with evolutional processes, implicit
communication </span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:
Calibri;mso-fareast-theme-font:minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA">emerges in several patterns.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>715</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-715">Agents for Video Game Understanding Modeled with Hybrid Markov Logic Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Simulation techniques, tools and platforms<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.830</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_715" class="editable_bid" data-pk="715" data-value="30"
                    data-url="/rev_3/paper/bid/set/715/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-715"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>General game-playing agents often learn environment models by optimizing a reward function, but recent work has focused instead on simulating the underlying game engine. This new work hopes to further the idea of automated game understanding by developing agents with a conceptual understanding of a game world, not just an optimized execution policy learned in non-interpretable models. We address the strengths and weaknesses of current approaches through an agent-centric survey and introduce <i>Hybrid Markov Logic Networks</i>&nbsp;as a potential tool for game engine simulation. HMLNs afford greater representational power than pure logical action based systems. We show that by abstracting the rules over numeric features a game engine can be represented with a more interpretable and compact model. We also show that ordinary <i>Markov Logic Networks</i> subsume logic based approaches and additionally can handle the stochastic processes inherent in many environments.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>478</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-478">Reasoning about Nash Equilibria with Parity Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logic and Game Theory<br>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Verification and Validation of Agent-based Systems] Synthesis of agent-based systems<br>[Verification and Validation of Agent-based Systems] Verification techniques for multiagent systems, including model checking</td>
                    
                        <td>0.830</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_478" class="editable_bid" data-pk="478" data-value="30"
                    data-url="/rev_3/paper/bid/set/478/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-478"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Nash equilibrium is, arguably, the best known and most widely used solution concept for multi-player general-sum games. In this paper, we present a new technique to check if a concurrent and multi-agent system, modelled as a multiplayer game, has a Nash equilibrium. We consider multi-agent systems (games) where each agent (player) in the system desires to achieve a given goal expressed using a formula of Linear Temporal Logic (LTL). From a theoretical point of view, our technique can check if a given game has a Nash equilibrium in 2EXPTIME, matching the optimal upper bound of the problem. The technique relies on a reduction of the problem of checking for the existence of a Nash equilibrium to the solution of a parity game, which is then solved using Streett automata. From a practical perspective, we describe an implementation of our technique and apply it to the analysis of concurrent and multi-agent systems modelled as games in the Simple Reactive Modules Language (SRML).</p><p><br></p></td>
                </tr>
            
                <tr>
                    <td>492</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-492">Detection of Intelligent Agent Behaviors using Markov Chains</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.830</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_492" class="editable_bid" data-pk="492" data-value="30"
                    data-url="/rev_3/paper/bid/set/492/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-492"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider the problem of detecting the behavior of intelligent agents operating in stochastic environments. In particular, we focus on a scenario where we are given two models for agent behaviors and we are interested in detecting whether one model is contained in the other model. This problem has applications on several domains, such as for example Active Malware Analysis (AMA) for cyber-security, where malware analyzers need to determine whether a known malware behavior appears in an application. We use Markov chains to represent the behavioral models of the agents and we propose a novel technique based on a transformation of the Markov chain that allows to apply standard methods to extract features that can be used to detect if one model is contained in the other. We empirically evaluate our approach in two scenarios: in the first one we consider well known examples of classical games with the aim of detecting known strategies in the behavior of players; in the second one, we aim at detecting known malicious behaviors or injected code for real malware samples. Results show that our approach is capable of detecting small malware injected into bigger applications, overcoming a limitation of the current AMA techniques. Moreover, the proposed algorithm can search for the existence of known behaviors both in malware models and in models of agents interacting within a general game.<br></p></td>
                </tr>
            
                <tr>
                    <td>288</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-288">Adaptive virtual organisms made by self-assembling heterogeneous components within regular 2D patterns</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Programming languages and frameworks for agents and multi-agent systems<br>[Engineering Multiagent Systems] Modelling and specification languages<br>[Agents and Mainstream Computing] Autonomic computing<br>[Agents and Mainstream Computing] P2P, web services, grid computing, IoT, HPC</td>
                    
                        <td>0.830</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_288" class="editable_bid" data-pk="288" data-value="30"
                    data-url="/rev_3/paper/bid/set/288/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-288"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The relation between a structure and the function running on that structure is of central interest in many fields, including computer science, biology (organ vs. function), psychology (brain vs. mind), architecture (designs vs. functionality), etc. Our paper addresses this question with reference to computer science recent hardware/software advances, particularly in areas as IoT, robotics, self-systems, CPS, AI-hardware, etc.&nbsp; &nbsp;<br><br>At the modeling, conceptual level, our main contribution is the introduction of the concept of ``virtual organism'', to populate the intermediary level between rigid, slightly reconfigurable, hardware agents and abstract, intelligent, adaptive software agents. A virtual organism has a structure, resembling the hardware capabilities, and it runs low-level functions, implementing the software requirements. Roughly speaking, it is an adaptive, reconfigurable, distributed, interactive, open system, consisting of a network of heterogeneous computing nodes, with a constrained structural shape, and running a bunch of overlapping functions.<br><br>Technically, the virtual organisms studied here are in two dimensions (2D) and their structures are described by regular 2D pattens. By reconfiguration, an organism may change its structure to another structure belonging to the same 2D pattern. Two classes of reconfigurations are particularly important: conservative reconfigurations (preserving the nodes, but changing the structure) and elastic reconfigurations (allowing for adding or removing nodes).<br><br>While the potential of choosing interesting structures and functions to define virtual organisms is basically unlimited, in this paper we describe only three simple organisms: (1) a tree collector organism (TC-organism); (2) a feeding cell organism, consisting of a membrane, with collecting/releasing trees attached on its external/internal side; and (3) an organism consisting of a collection of connected feeding cell organisms.<br><br>To test the benefits of reconfiguration, we implemented a simulator for TC-organisms and tested TC-organisms' behavior. A TC-organism has a tree structure and collect items from multiple sources with a flow from leafs to root, under the following constraints:&nbsp; (i) there is an upper bound on the allowed flow per node; and (ii) leafs collecting capabilities depend on their distances to sources. We tested the behavior of TC-organisms under appropriate scenarios and the quantitative results confirm the intuition that: (1) reconfigurable structures are better suited than fixed structures in dynamically changing environments; and (2)&nbsp; elastic reconfiguration is better suited than conservative reconfiguration when considering the cost of node renting and of the unit flow collected.<br><br></p></td>
                </tr>
            
                <tr>
                    <td>373</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-373">Path Planning Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.820</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_373" class="editable_bid" data-pk="373" data-value="30"
                    data-url="/rev_3/paper/bid/set/373/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-373"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Path planning is a fundamental problem in robotic control. While it has received a significant amount of attention from an algorithmic perspective, there has been little research investigating the issue of multiple path planners facing a possible strategic conflict. We investigate strategic interactions among several path planning agents using a game theoretic path planning framework. Our focus is on tension between two important objectives: efficiency in the agents' achieving their goals, and safety in navigating towards these. We begin by developing a novel mathematical formulation for computing a best response path for an agent given a fixed path plan of others in a stochastic environment. We use this formulation for approximating Nash equilibria in path planning games through a best response dynamics algorithm. Finally, we develop a novel multi-agent path planning formulation for computing a social welfare optimizing multi-agent path plans. Through several case studies, we show that in a path planning game, tension between efficiency and safety can be resolved in a socially suboptimal way, with safety often significantly compromised even when all agents have a strong interest in avoiding collisions.</p></td>
                </tr>
            
                <tr>
                    <td>448</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-448">SMT-Based Diagnosis of Multi-Agent Temporal Plans</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.820</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_448" class="editable_bid" data-pk="448" data-value="30"
                    data-url="/rev_3/paper/bid/set/448/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-448"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The paper proposes a model and methodology for diagnosing action<br>failures in the execution of Temporal Multi-Agent Plans (TMAPs).<br>Contrary to previous proposals in the literature, we characterize<br>actions with a finite set of possible execution modes, where each<br>mode prescribes not only the logic post-conditions of the actions,<br>but also a continuous interval of possible durations.<br>Diagnoses are defined as assignments of modes to the actions that<br>are consistent with the received observations and have the highest<br>rank. We study two different algorithms that exploit a Satisfiability<br>Modulo Theories (SMT) solver for the efficient computation of<br>diagnoses. An implementation of the algorithms and experimental<br>results comparing their performance are also discussed.<br></p></td>
                </tr>
            
                <tr>
                    <td>221</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-221">Repeated Triangular Trade: Sustaining Circular Cooperation with Observation Errors</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Noncooperative games: theory &amp; analysis<br>[Economic Paradigms] Other</td>
                    
                        <td>0.820</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_221" class="editable_bid" data-pk="221" data-value="30"
                    data-url="/rev_3/paper/bid/set/221/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-221"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We introduce a new fundamental problem called triangular trade, which is a natural extension of the well-studied prisoner's dilemma for three (or more) players but a player cannot directly punish a seemingly defected player. More specifically, this problem deals with a situation where the power/influence of players is one-way, players would be better off if they maintain circular cooperation, but each player has an incentive to defect. We analyze whether players can sustain such circular cooperation when they repeatedly play this game and each player observes the action of another player with some observation errors (imperfect private monitoring). We confirm that no simple strategy can constitute an equilibrium within any reasonable parameter settings when there are only two actions: ``Cooperate'' and ``Defect.'' Thus, we introduce two additional actions: ``Whistle'' and ``Punish,'' which can be considered as a slight modification of ``Cooperate.'' Then, players can achieve sustainable cooperation using a simple strategy called Remote Punishment strategy (RP), which constitutes an equilibrium for a wide range of parameters. Furthermore, we show the payoff obtained by a variant of RP is optimal within a very general class of strategies that covers virtually all meaningful strategies.<br></p></td>
                </tr>
            
                <tr>
                    <td>246</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-246">The Curse of Ties in Congestion Games with Limited Lookahead</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.810</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_246" class="editable_bid" data-pk="246" data-value="30"
                    data-url="/rev_3/paper/bid/set/246/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-246"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We introduce a novel framework to model limited lookahead in congestion games. Intuitively, the players enter the game sequentially and choose an optimal action under the assumption that the <i>k</i>-1 subsequent players play subgame-perfectly. Our model naturally interpolates between outcomes of greedy best-response (<i>k</i>=1) and subgame-perfect outcomes (<i>k</i>=<i>n</i>, the number of players). We study the impact of limited lookahead (parameterized by <i>k</i>) on the stability and inefficiency of the resulting outcomes. As our results reveal, increased lookahead does not necessarily lead to better outcomes; in fact, its effect crucially depends on the existence of ties and the type of game under consideration.</p><p><br></p><p>More specifically, already for very simple network congestion games we show that subgame-perfect outcomes (full lookahead) can be unstable, whereas greedy best-response outcomes (no lookahead) are known to be stable. We show that this instability is due to player indifferences (ties). If the game is generic (no ties exist) then all outcomes are stable, independent of the lookahead <i>k</i>. In particular, this implies that the price of anarchy of <i>k</i>-lookahead outcomes (for arbitrary <i>k</i>) equals the standard price of anarchy. For special cases of cost-sharing games and consensus games we show that no lookahead leads to stable outcomes. Again this can be resolved by removing ties, though for cost-sharing games only full lookahead provides stable outcomes. We also identify a class of generic cost-sharing games for which the inefficiency decreases as the lookahead <i>k</i> increases.</p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>516</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-516">Pooling or Sampling: Collective Dynamics for Electrical Flow Estimation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Agent Cooperation] Collective intelligence<br>[Agent Cooperation] Biologically-inspired approaches and methods</td>
                    
                        <td>0.810</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_516" class="editable_bid" data-pk="516" data-value="30"
                    data-url="/rev_3/paper/bid/set/516/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-516"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The computation of electrical flows is a crucial primitive for many 
recently proposed optimization algorithms on weighted networks. While 
typically implemented as a centralized subroutine, the ability to 
perform this task in a fully decentralized way is implicit in a number 
of biological systems. Thus, a natural question is whether this task can 
provably be accomplished in an efficient way by a network of agents 
executing a simple protocol.
</p><p>We provide a positive answer, proposing two distributed approaches to 
electrical flow computation on a weighted network: a deterministic 
process mimicking Jacobi's iterative method for solving linear systems, 
and a randomized token diffusion process, based on revisiting a 
classical random walk process on a graph with an absorbing node.
We show that both processes converge to a solution of Kirchhoff's node 
potential equations, derive bounds on their convergence rates in terms 
of the weights of the network, and analyze their time and message 
complexity.&nbsp;</p><p><br></p></td>
                </tr>
            
                <tr>
                    <td>602</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-602">Industrial Symbiotic Networks as Coordinated Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Policy, regulation and legislation<br>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Economic Paradigms] Game Theory for practical applications<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.800</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_602" class="editable_bid" data-pk="602" data-value="30"
                    data-url="/rev_3/paper/bid/set/602/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-602"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style="margin-bottom:12.0pt"><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>AR-SA</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="371">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin-top:0cm;
	mso-para-margin-right:0cm;
	mso-para-margin-bottom:8.0pt;
	mso-para-margin-left:0cm;
	line-height:107%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;}
</style>
<![endif]-->

We present a framework for implementing a
specific form of collaborative industrial practices called "Industrial
Symbiotic Networks (ISNs)'' as cooperative games. The game-theoretic formulation
of ISNs enables systematic reasoning about what we call the ISN implementation problem.
Specifically, the characteristics of ISNs may lead to inapplicability of fair and
stable benefit allocation methods even if the collaboration is a collectively
desired one (from a socioeconomic and&nbsp;environmental point of view).
Inspired by realistic ISN scenarios and following the literature on normative
multi-agent systems, we consider regulations and normative socioeconomic policies
as two elements that in combination with ISN games resolve the situation and
result in the introduction of the novel concept of “Coordinated ISNs (C-ISNs)".
Applied&nbsp;regulations are mainly monetary incentive allocation rules to
enforce the desired industrial collaborations with respect to an established
policy. In our framework, employing Marginal Contribution Nets (MC-Nets) as
rule-based cooperative game representations fosters&nbsp;the combination of
regulations and ISN games with no loss in expressiveness. We develop
algorithmic methods for generating regulations that ensure the implementability
of ISNs and as a policy support, show the policy requirements that ensure the
implementability of all the desired ISNs in a balanced-budget way. </p><p>

</p></td>
                </tr>
            
                <tr>
                    <td>498</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-498">GANGs: Generative Adversarial Network Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Co-evolutionary algorithms<br>[Learning and Adaptation] Deep learning<br>[Learning and Adaptation] Adversarial machine learning</td>
                    
                        <td>0.800</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_498" class="editable_bid" data-pk="498" data-value="30"
                    data-url="/rev_3/paper/bid/set/498/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-498"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Generative Adversarial Networks (GAN) have become one of the most successful frameworks for unsupervised generative modeling. As GANs are difficult to train much research has focused on this. However, very little of this research has directly exploited game-theoretic techniques. We introduce Generative Adversarial Network Games (GANGs), which explicitly model an (implicitly defined) finite zero-sum game between a generator (G) and classifier (C), where the two players use mixed strategies (probability distributions over neural networks). Due to the extremely large size of these games, we cannot expect to compute exact best responses. Thus, we define resource-bounded best responses (RBBRs), and a resource-bounded Nash Equilibrium (RB-NE) as a pair of mixed strategies such that neither G or C can find a better RBBR. The RB-NE solution concept is richer than the notion of ‘local Nash equilibria’ in that it captures not only failures of escaping local optima of gradient descent, but applies to any approximate best response computations, including methods with random restarts. To validate our approach, we solve GANGs with the Parallel Nash Memory algorithm, which provably monotonically converges to an RB-NE. We compare our results to standard GAN setups, and demonstrate that our method deals well with typical GAN problems such as mode collapse, partial mode coverage and forgetting.<br></p></td>
                </tr>
            
                <tr>
                    <td>296</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-296">A Courteous Learning Rule for Ad-hoc Anti-coordination</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.800</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_296" class="editable_bid" data-pk="296" data-value="30"
                    data-url="/rev_3/paper/bid/set/296/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-296"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we investigate the problem of anti-coordination under rationality constraints in ad-hoc resource allocation settings. Inspired by human behavior, we propose a framework (CA<sup>3</sup>NONY) that enables fast convergence to efficient and fair allocations based on a simple convention of courtesy. We prove that following such convention induces a strategy which constitutes an approximate subgame-perfect equilibrium of the repeated resource allocation game with discounting. Simulation results highlight the effectiveness of CA<sup>3</sup>NONY as compared to state-of-the-art bandit algorithms, since it achieves more than two orders of magnitude faster convergence, higher efficiency, fairness, and average payoff for the agents.<br></p></td>
                </tr>
            
                <tr>
                    <td>356</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-356">Incentivizing Collaboration in a Competition</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.800</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_356" class="editable_bid" data-pk="356" data-value="30"
                    data-url="/rev_3/paper/bid/set/356/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-356"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Research and design competitions aim to promote innovation or creative production, which is often best achieved through collaboration. The nature of a competition, however, typically necessitates sorting by individual performance. This presents tradeoffs for the competition designer, between incentivizing global performance and distinguishing individual capability. We model this situation in terms of an abstract collaboration game, where individual effort also benefits neighboring agents. We formally define a distinguishability property that captures the essence of distinguishing player capability. We propose a scoring mechanism called LSWM that rewards agents based on localized social welfare. We show that LSWM indeed promotes global performance, in that social optima are equilibria of the mechanism. Moreover, we establish conditions under which the mechanism leads to increased collaboration, and under which it ensures distinguishability. Finally, through experiments we evaluate convergence equilibrium through best-response dynamics, and the degree of distinguishability achieved whether or not the conditions hold.</p></td>
                </tr>
            
                <tr>
                    <td>657</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-657">Measuring Simulation Effort for Brahms Models</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Simulation techniques, tools and platforms<br>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Verification and Validation of Agent-based Systems] Testing and debugging multiagent programs</td>
                    
                        <td>0.800</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_657" class="editable_bid" data-pk="657" data-value="30"
                    data-url="/rev_3/paper/bid/set/657/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-657"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The most common testing mechanism for Multi-Agent Systems (MAS) is simulation. Simulation is useful insofar as interesting test cases are used that enable the simulation to explore different behaviors of the system, but simulation alone cannot be fully relied upon to adequately cover the test space, especially in the case of non-deterministic concurrent systems. We use ideas from software testing to define a coverage metric that quantifies the test effort during simulation, and aids in creating scenarios that better cover the behavior space of the system. The coverage metric is defined in terms of the Brahms language, an agent-oriented language that models MAS, and is composed of three parts: workframe coverage, communication coverage, and schedule coverage. We performed a case study on NASA's Small Aircraft Transportation System (SATS) to gauge the usefulness of the metric.</p></td>
                </tr>
            
                <tr>
                    <td>56</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-56">The Dynamic Maximum Coverage Problem, Towards Multi-Agent Coverage Systems Capable of Goal-Driven Planning and Tight Coordination</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Agent Cooperation] Multi-robot systems<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.800</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_56" class="editable_bid" data-pk="56" data-value="30"
                    data-url="/rev_3/paper/bid/set/56/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-56"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper introduces a new problem for integrating altogether four key features within coverage problems: coordination, detailed environmental model, planning, and goal-driven optimization. We called this problem the Dynamic Maximum Coverage Problem (DMCP). The DMCP expands the classic Maximum Coverage Problem by introducing two time dynamics: the points to cover and related rewards can change over time; environmental dynamics can constrain the evolution of the probes in charge of setting up the coverage (e.g. robots with limited speed need time to reach rewarding positions). The problem consists in finding trajectories that maximize the total accumulated reward over time, while respecting environmental constraints. This paper formalizes the DMCP, introduces generic algorithms for efficiently solving it, evaluates these algorithms, and applies the DMCP on a multi-robot application.<br></p></td>
                </tr>
            
                <tr>
                    <td>483</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-483">Local Equilibria in Logic-Based Multi-Player Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logic and Game Theory<br>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Verification and Validation of Agent-based Systems] Synthesis of agent-based systems<br>[Verification and Validation of Agent-based Systems] Verification techniques for multiagent systems, including model checking</td>
                    
                        <td>0.800</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_483" class="editable_bid" data-pk="483" data-value="30"
                    data-url="/rev_3/paper/bid/set/483/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-483"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Game theory provides a well-established framework for the analysis and verification of concurrent and multi-agent systems. In such a framework, typically, the analysis of a multi-agent system involves computing the set of equilibria in the associated multi-player game representing the behaviour of the system. In this setting, as systems grow larger, it becomes harder to find equilibria in the game -- which represent the rationally stable behaviours of the multi-agent system (the solutions of the game). To address this issue, in this paper, we study the concept of local equilibria in which we are interested in (maximal) stable coalitions of agents with<br>respect to which an equilibrium can be found. We focus on solutions given by Nash equilibria, and base our study in Boolean games and iterated Boolean games, two logic-based models of concurrent and multi-agent systems where players' goals are given by formulae in, respectively, propositional logic and LTL.<br></p></td>
                </tr>
            
                <tr>
                    <td>512</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-512">Collective vs Selfish Adaptation: The Case of Sustainable Urban Mobility</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Socio-technical systems<br>[Agent Cooperation] Collective intelligence<br>[Engineering Multiagent Systems] Modelling and specification languages</td>
                    
                        <td>0.800</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_512" class="editable_bid" data-pk="512" data-value="30"
                    data-url="/rev_3/paper/bid/set/512/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-512"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Software systems have evolved from being 'stand-alone systems' to 'systems of systems' to meet the challenging needs of societies. Contemporary software systems such as socio-technical systems are composed of distributed and heterogeneous agents, the embedded environment, and software components. Addressing the disruptions caused due to the unprecedented behaviors of people, and exogenous changes in the environment while designing software systems remains a challenging task in practice. The literature reviewed failed to meet all the requirements in characterizing the type of systems demanded by the research problem.</p><p>In this paper, we address the challenges that impede collective adaptation in smart mobility systems by proposing a notion of ensemble. Ensembles enable systems with collective adaptability to be built as emergent aggregations of autonomous and self-adaptive agents. Adaptation in these systems is triggered by a run-time occurrence, which is known as an `issue'. The phenomenal aspect of our approach is, it allows agents affected by an issue in the context of a smart mobility scenario to adapt collaboratively with minimal impact on their own preferences through an issue resolution process. Finally, as the management of coalition is decentralized, it eliminates the single point of failure, and the potential bottleneck in the system.<br></p></td>
                </tr>
            
                <tr>
                    <td>35</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-35">Maximizing Social Welfare while Minimizing Regret in Multi-Agent Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Behavioral game theory<br>[Economic Paradigms] Cooperative games: computation</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_35" class="editable_bid" data-pk="35" data-value="30"
                    data-url="/rev_3/paper/bid/set/35/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-35"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In multi-agent systems (MASs), the complex interactions among selfish agents can be modelled as stochastic games, characterized by the need for cooperation and preservation of self-interest at the same time, in which the environment changes in response to agents' behaviours. Existing decision support approaches in multi-agent systems focus on minimizing individual agent's regret, but overlook maximizing social welfare. To bridge this gap, we propose the regret-minimization-social-welfare-maximization (RMSM) approach. It quantifies the magnitude and concentration of regret within an MAS population over time, and produces actionable recommendations in polynomial time to encourage agent cooperation while protecting self-interest. Through theoretical analysis, we establish a lower bound on time-averaged social welfare and an upper bound on time-averaged regret when agents follow RMSM. Extensive simulations demonstrate significant advantage of RMSM over two state-of-the-art approaches.<br></p></td>
                </tr>
            
                <tr>
                    <td>229</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-229">Concurrent Game Structures for Temporal STIT Logic</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logic and Game Theory<br>[Agent Theories and Models] Logics for agents and multi-agent systems</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_229" class="editable_bid" data-pk="229" data-value="30"
                    data-url="/rev_3/paper/bid/set/229/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-229"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">The paper introduces a new semantics for STIT logic (the logic of "seeing to it that") </span><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">based on concurrent game structures (CGSs), thereby strengthening the connection </span><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">between STIT and existing logics for MAS including coalition logic, alternating-time </span><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">temporal logic and strategy logic, whose languages are usually interpreted over CGSs. Moreover, it </span><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">provides a complexity result for a rich temporal STIT language interpreted over these structures. </span><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">The language extends that of full computation tree logic CTL* by individual agency operators, </span><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">allowing to express sentences of the form ``agent i sees to it that phi is true, as a consequence her choice''.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>554</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-554">Fake News in Social Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Agent Societies and Societal Issues] Social networks<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_554" class="editable_bid" data-pk="554" data-value="30"
                    data-url="/rev_3/paper/bid/set/554/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-554"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We model the spread of news as a social learning game on a network. Agents can either endorse or oppose a claim made in a piece of news, which itself may be either true or false. Agents base their decision on a private signal and their neighbors' past actions. Given these inputs, agents follow strategies derived via deep multi-agent reinforcement learning and receive utility from acting in accordance with the veracity of claims. Our framework yields strategies with agent utility close to a theoretical, Bayes optimal benchmark, while remaining flexible to model re-specification. Optimized strategies allow agents to correctly identify most false claims, when all agents receive unbiased private signals. However, an adversary's attempt to spread fake news by targeting a subset of agents with a biased private signal can be successful. Even more so when the adversary has information about agents' network position or private signal. When agents are aware of the presence of an adversary they re-optimize their strategies in the training stage and the adversary's attack is less effective. Hence, exposing agents to the possibility of fake news can be an effective way to curtail the spread of fake news in social networks. Our results also highlight that information about the users' private beliefs and their social network structure can be extremely valuable to adversaries and should be well protected.<br></p></td>
                </tr>
            
                <tr>
                    <td>347</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-347">Resisting Exploitation Through Rewiring In Social Networks: How Parity, Sympathy and Reciprocity Can Increase Social Welfare</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent Societies and Societal Issues] Self-organization<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_347" class="editable_bid" data-pk="347" data-value="30"
                    data-url="/rev_3/paper/bid/set/347/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-347"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We are interested in understanding how socially desirable traits like sympathy, reciprocity and fairness can survive in environments that include aggressive and exploitative agents.&nbsp; Social scientists have long observed and theorized about ingrained motivational factors as explanations for departures from self-seeking behaviors by human subjects. Some of these factors, namely reciprocity, have also been studied extensively in the context of agent systems as tools for promoting cooperation and improving social welfare in stable societies.&nbsp; In this paper, we evaluate how other factors like sympathy and parity can be gainfully used by agents to seek out cooperation possibilities while avoiding exploitation traps in more dynamic societies.&nbsp; We evaluate the relative effectiveness of agents influenced by different social considerations when they can choose who to interact with in their environment.&nbsp; Such rewiring of social networks not only allows apparently vulnerable agents to avoid exploitation but also allows them to form gainful coalitions to leverage mutually beneficial cooperation, thereby significantly improving social welfare.<br></p></td>
                </tr>
            
                <tr>
                    <td>253</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-253">Real-Time Detection and Learning of Behavioural Anomalies for Elderly People</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Other<br>[Learning and Adaptation] Multiagent learning<br>[Agent Societies and Societal Issues] Self-organization<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_253" class="editable_bid" data-pk="253" data-value="30"
                    data-url="/rev_3/paper/bid/set/253/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-253"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In a context of a rapidly growing population of elderly people, this paper introduces a novel method for behavioural anomaly detection by multi-agent system learning using medical staff feedback. This method first models the Circadian Activity Rythm of a set of sensors and compares it to a nominal profile to determine variations in patients' activities. The anomalies are detected by a multi-agent system as a linear relation of those variations, weighted by influence parameters. The problem of adaptation to a particular patient then becomes the problem of learning the adequate influence parameters. This approach is evaluated on a synthetic environment and results show both the capacity to effectively learn influence parameters and the resilience of this system to parameter size.</p></td>
                </tr>
            
                <tr>
                    <td>496</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-496">Agent Strategies for Hide and Seek Game</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_496" class="editable_bid" data-pk="496" data-value="30"
                    data-url="/rev_3/paper/bid/set/496/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-496"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We are given an environment with some objects (park with trees, a city block area) and mobile agents moving in the environment. An agent (hider) can hide behind an object to be not seen by other agents (seekers) through their line of sight (visibility). These hider agents (that are hiding behind objects) can be found by seekers who explore the environment. A pragmatic example of the problem is a warehouse environment with no drones or cameras, and some culprit agents are hiding from the police agents. The aim of hiders is not to be caught for the longest time, and the aim of the seekers is catch all of them in the shortest period of time. We formulate the problem by using visibility based map abstractions. Our hiders and seeker plan their moves by utilizing multi-armed bandits UCB reward update model. We built a simulator to create environments for multiple hiders and multiple seekers to test their strategies in a hide and seek game. Simulation results indicate that our abstractions and reward models enable better exploration for seeker agents and better obstruction for hider agents. Seeker agents take lesser time to find hider agents and hider agents take more time to be discovered, on average.</p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>133</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-133">On the time Inconsistency of Monetary Policy Game: A Differential Game Theory Approach</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Behavioral game theory<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_133" class="editable_bid" data-pk="133" data-value="30"
                    data-url="/rev_3/paper/bid/set/133/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-133"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The time consistency problem in an open loop Nash equilibrium is investigated by applying a differential monetary policy game model between the central bank and the public sector. By categorizing the time consistency problem into two types, behavioral and structural, we found that under variation of parameters (Lucas critique) even the open loop Nash equilibrium concept, which is generally well known as a time consistent game, degenerates into some sort of the feedback equilibrium concept. Results also show that due to controllability of both players the structural time inconsistency of monetary policy is almost always unavoidable.<br></p></td>
                </tr>
            
                <tr>
                    <td>470</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-470">Q-Learning Based, Value Driven Action Recommender to Retain Agents in Online Q&amp;A Forums</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_470" class="editable_bid" data-pk="470" data-value="30"
                    data-url="/rev_3/paper/bid/set/470/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-470"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><pre style="margin-bottom: 0px;"><span style=" color:#000000;">People participate actively in an online Q</span><span style=" color:#800000;">&amp;A</span><span style=" color:#000000;"> community such as </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">StackOverflow</span><span style=" color:#000000;"> for different reasons ranging from altruism to building a professional resume. Each of these reasons provide a certain value for the community members. Thinking of a user's behavior in the community as a reflection of acquired value of each participant, we introduce a novel measure, Reflected Value (RV), to quantify the intensity of the acquired value. The higher commitment of a member to participate in a community indicates that he/she has acquired a higher value from the community. In a community-based question and answering (</span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">CQA</span><span style=" color:#000000;">) forum like </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">StackOverflow</span><span style=" color:#000000;">, the success of the </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">CQA</span><span style=" color:#000000;"> is heavily dependent to the regular participation of its users. Having knowledge of such user values can provide many advantages to both, the community users and the </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">CQA</span><span style=" color:#000000;">. In this paper, we first build a Hidden Markov Model (HMM) to measure RV. We then propose a novel, Q-learning based </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">recommender</span><span style=" color:#000000;"> system, Value Driven Action </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">Recommender</span><span style=" color:#000000;"> (VAR), to recommend the users the most promising strategies (action choices) to maximize their expectation of RV over time. Finally, on the real data from </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">StackOverflow</span><span style=" color:#000000;">, we conduct a statistical test to illustrate the efficacy of VAR. For every active user on </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">StackOverflow</span><span style=" color:#000000;">, we measure a </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">jaccard</span><span style=" color:#000000;"> divergence between our recommendation to the user and the actual strategy used and illustrate that higher the divergence, the higher the posterior probability of a user leaving </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">StackOverflow</span><span style=" color:#000000;">. Thus, we believe VAR is a very useful </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">recommender</span><span style=" color:#000000;"> system to increase life-span of users on the </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">CQA</span><span style=" color:#000000;">.</span></pre></td>
                </tr>
            
                <tr>
                    <td>239</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-239">Multi-Step Multiagent Expert Advice</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_239" class="editable_bid" data-pk="239" data-value="30"
                    data-url="/rev_3/paper/bid/set/239/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-239"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Complex tasks (e.g. in natural language processing (NLP) or computer vision) often require to solve a sequence of unique steps. Usually, there exist numerous exchangeable ''learners'' for the individual tasks, each being an ''expert'' for data with certain characteristics. Different frameworks have emerged to approach the problem of learning which expert to choose for which step, such as Contextual Decision Processes (CDPs) or Expert Processes (EPs), which assume a single agent to take actions. A resulting problem is dealing with expert correlation, which reduces predictive performance.</p><p>In this work, we thus study the setup of a cooperative Multiagent System (MAS) where experts are controlled by several agents. We first extend EPs to Multiagent Expert Processes (MEPs) and define the expert coordination process (ECP). We then model relational agent features for agents to exploit learned pairwise behavior in domain-dependent neighborhoods. Our policy-based reinforcement learning (RL) approach for coordinating agents enables agents to learn non-stationary coordination policies based on action error residuals with regards to the joint action. The eventual MEP policy is adapted with regards to robustness of the ECP.</p><p>We empirically evaluate our approach on a Named Entity Recognition and Disambiguation task with real-world services as experts and standard benchmark data sets. The results suggest that we are able to compete or even outperform centralized approaches, while keeping flexibility to distribute the MEP to multiple stakeholders or coordinate redundant copies of experts to avoid system failure.</p></td>
                </tr>
            
                <tr>
                    <td>361</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-361">A Computationally Grounded Model of Emotional BDI-Agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Agent Theories and Models] Models of emotions<br>[Verification and Validation of Agent-based Systems] Verification techniques for multiagent systems, including model checking</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_361" class="editable_bid" data-pk="361" data-value="30"
                    data-url="/rev_3/paper/bid/set/361/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-361"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal" style="line-height:115%"><span lang="EN-US">This
paper extends the KBDI logic by incorporating well-being emotion modalities
(joy</span><span lang="EN-US"> and </span><span lang="EN-US">distress) as described in Ortony,
Clore and Collins’s (OCC) theory and obtain an emotional KBDI logic called
KBDIE logic. We propose a new computational model of emotion triggers for BDI
agents, called the observation-based KBDIE-system model (or KBDIE-model for
short). The key point of this KBDIE-model is to express agent’s emotion</span><span lang="EN-US">s</span><span lang="EN-US">, such as joy and distress, as a set of runs
(computing paths), which is exactly a system in the interpreted system model, a
well-known agent-model due to Halpern </span><span lang="EN-US">et al</span><span lang="EN-US">. </span><span lang="EN-US">We present a sound and complete proof
system with respect to our KBDIE-model and explore how symbolic model checking
techniques can be applied to model checking emotional BDI-agent. We show that
the technique is amenable to symbolic implementation via binary decision
diagram. We introduce MCKBDIE, a toolkit based on the open-source model checker
MCKBDI which presently supports KBDI logic only, implementing the technique.
The experimental results obtained confirm that MCKBDIE can verify
specifications of finite-state multi-agent systems involving agents’ emotion</span><span lang="EN-US">al</span><span lang="EN-US"> state</span><span lang="EN-US">s</span><span lang="EN-US">.</span><span lang="EN-US"><o:p></o:p></span></p></td>
                </tr>
            
                <tr>
                    <td>318</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-318">Eliminating Opportunism using an Epistemic Mechanism</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Economic Paradigms] Auctions and mechanism design<br>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_318" class="editable_bid" data-pk="318" data-value="30"
                    data-url="/rev_3/paper/bid/set/318/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-318"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Opportunism is a behavior that takes advantage of knowledge asymmetry and results in promoting agents' own value and demoting other agents' value. It is important to eliminate such a selfish behavior in multi-agent systems, as it has undesirable results for the participating agents. However, as the context we study here is multi-agent systems, system designers actually might not be aware of the value system for each agent thus they have no idea whether an agent will perform opportunistic behavior. Given this fact, this paper designs an epistemic mechanism to eliminate opportunism given a set of possible value systems for the participating agents: an agent's knowledge gets updated so that the other agent is not able to perform opportunistic behavior, and there exists a balance between eliminating opportunism and respecting agents' privacy.<br></p></td>
                </tr>
            
                <tr>
                    <td>566</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-566">A Formalism and an Algorithm for HTN Acting</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_566" class="editable_bid" data-pk="566" data-value="30"
                    data-url="/rev_3/paper/bid/set/566/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-566"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Hierarchical Task Network (HTN) planning is a practical and efficient
approach to planning when 'standard operating procedures' for a domain are available. Like Belief-Desire-Intention (BDI) agent
reasoning, HTN planning performs hierarchical and context-based
refinement of goals into subgoals and basic actions. However, while
HTN planners 'lookahead' over the consequences of choosing one
refinement over another, BDI agents interleave refinement with acting
in the real world. There has been a renewed interest in making
HTN planners behave more like BDI agent systems, e.g. to have a
unified representation for acting and planning. However, past work
on the subject has remained informal or implementation-focused.
Thus, this paper is a formal account of HTN acting, which supports
interleaved deliberation, action, and failure recovery. To this end,
we use the syntax of the most general HTN planning formalism and
build on its core machinery, and we provide an algorithm which
combines our new formalism with the continual processing of exogenous
events. We also study the properties of HTN acting and
its relation to HTN planning.<br></p></td>
                </tr>
            
                <tr>
                    <td>511</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-511">Hunting Algorithm Performance Evaluation Environment</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Agent Cooperation] Biologically-inspired approaches and methods</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_511" class="editable_bid" data-pk="511" data-value="30"
                    data-url="/rev_3/paper/bid/set/511/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-511"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:RelyOnVML></o:RelyOnVML>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:DoNotShowRevisions></w:DoNotShowRevisions>
  <w:DoNotPrintRevisions></w:DoNotPrintRevisions>
  <w:DoNotShowMarkup></w:DoNotShowMarkup>
  <w:DoNotShowComments></w:DoNotShowComments>
  <w:DoNotShowInsertionsAndDeletions></w:DoNotShowInsertionsAndDeletions>
  <w:DoNotShowPropertyChanges></w:DoNotShowPropertyChanges>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>EN-CA</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:DontVertAlignCellWithSp></w:DontVertAlignCellWithSp>
   <w:DontBreakConstrainedForcedTables></w:DontBreakConstrainedForcedTables>
   <w:DontVertAlignInTxbx></w:DontVertAlignInTxbx>
   <w:Word11KerningPairs></w:Word11KerningPairs>
   <w:CachedColBalance></w:CachedColBalance>
   <w:UseFELayout></w:UseFELayout>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="true"
  DefSemiHidden="true" DefQFormat="false" DefPriority="99"
  LatentStyleCount="267">
  <w:LsdException Locked="false" Priority="0" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="59" SemiHidden="false"
   UnhideWhenUsed="false" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" QFormat="true" Name="TOC Heading"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-qformat:yes;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
</style>
<![endif]--><span style="font-size:9.0pt;mso-bidi-font-size:11.0pt;
line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;
mso-fareast-theme-font:minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-CA;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA">While new hunting algorithms are being developed
to model pack animal hunting behaviours, these are being assessed with centralized,
algorithmic computing methods rather than decentralized, agent based ones. To
address this deficiency, this research proposed, designed, and developed a
Hunting Algorithm Performance Evaluation Environment (HAPEE) using Multi-Agent
System (MAS). Further, this research proposed to use the NetLogo MAS
environment (to implement the HAPEE) but adapt it to the Belief, Desire, and
Intent (BDI) architecture. Netlogo was customized to a number of
two-dimensional scenarios with both Hunting Agents (HA) and Prey Agents (PA)
interacting with each other and with the obstacles within the scenarios. The HAs
and PAs were developed with the flexibility to instantiate many types of
hunters and prey. The differences in both the HAs and PAs was with their skills
(communications, perception, speed, etc.) and their cognitive abilities. To
evaluate the viability of the HAPEE, it <span style="mso-spacerun:yes">&nbsp;</span>was used to evaluate two hunting algorithms:
the Lion Optimization Algorithm (LOA) and the Grey Wolf Optimization (GWO)
algorithm. The experimental results showed that the LOA was more resilient to
obstacles than was the GWO. In the presence of obstacles, the lionesses were
more reliable in completing joint convergence onto the prey. While the wolves
had a lower convergence rate, they displayed an ability to recover from the
confusion caused by obstacles to finally close in on their prey. The research thus
concluded that the NetLogo programming environment was successfully adapted to
the BDI architecture and was very effective at structuring a large MAS
(consisting of thousands of lines of code). </span><br></p></td>
                </tr>
            
                <tr>
                    <td>122</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-122">Sentient Self-organisation -- Infinite Dimensional Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent Cooperation] Biologically-inspired approaches and methods<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.790</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_122" class="editable_bid" data-pk="122" data-value="30"
                    data-url="/rev_3/paper/bid/set/122/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-122"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Theoretical arguments and empirical evidence in neuroscience suggest that organisms represent or model their environment by minimizing a variational free-energy bound on the surprise associated with sensory signals from the environment. In this paper, we study phase transitions in coupled dissipative dynamical systems (complex Ginzburg-Landau equations) under a variety of coupling conditions to model the exchange of a system (agent) with its environment. We show that arbitrary coupling between sensory signals and the internal state of a system -- or those between its action and external (environmental) states -- do not enable synchronous dynamics between external and internal states: the spatial structure and the temporal dynamics of sensory signals and action (that comprise the system's Markov blanket) have to be pruned to produce synchrony. This synchrony is necessary for an agent to infer environmental states -- a pre-requisite for survival. Therefore, such sentient dynamics&nbsp; relies primarily on approximate synchronization between the agent and its niche.<br></p></td>
                </tr>
            
                <tr>
                    <td>530</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-530">Hierarchical Task Model Learning from Demonstration</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Ontologies for agents<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Humans and Agents] Agent-based analysis of human interactions</td>
                    
                        <td>0.780</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_530" class="editable_bid" data-pk="530" data-value="30"
                    data-url="/rev_3/paper/bid/set/530/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-530"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Hierarchical reactive planning frameworks require operator libraries and domain models to be authored. These approaches suffer from the knowledge acquisition bottleneck in complex domains where it is not feasible to predetermine preconditions and context conditions for operators. ABL (A Behavior Language) is one such agent authoring language designed to create believable and reactive agents. It requires expert human input to encode their planning strategies into the agent's behavior library. This is a challenging and time-consuming task. Moreover, the deterministic nature of ABL's planning algorithm makes it difficult to apply machine learning techniques for unsupervised knowledge acquisition in domains where sufficient expert demonstrations are available. We present pABL, a probabilistic modification of the ABL modeling language, and demonstrate its usefulness in the pursuit domain that has been investigated in the agents community for cognitive architectures and multi-agent teamwork problems. We then present initial results on improving ABL models with human demonstrations in a more complex domain, StarCraft:Brood War, which is a real-time strategy game. This work contributes to development of agent authoring languages that are both more interpretable in terms of decision making and powerful in terms of representation of stochastic features of complex domains.<br></p></td>
                </tr>
            
                <tr>
                    <td>784</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-784">Automatic Construction of SPS Reconfiguration Supervisors</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for norms and normative systems<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.780</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_784" class="editable_bid" data-pk="784" data-value="30"
                    data-url="/rev_3/paper/bid/set/784/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-784"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>A reliable Shipboard Power System must be able to detect a fault, isolate it and, possibly, restore the power supply to other devices. An agent based solution has the responsibility to monitor and control the underlying electrical layer to apply changes to the electrical scheme thus to interrupt and to isolate sections of the electrical layer maintaining vessel survivability. This paper proposes a Petri Net based model for supervising LTL requirements able to detect possible violations and enact the proper reconfiguration strategy. This approach leads to the automatic construction of supervising agents.</p><p>Keywords:&nbsp;Shipboard Power System Reconfiguration, Supervisor Agent, Linear Temporal Logic</p></td>
                </tr>
            
                <tr>
                    <td>749</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-749">Three body problems in evolutionary game dynamics: Convergence, Periodicity and Limit Cycles</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Learning and Adaptation] Multiagent learning<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.780</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_749" class="editable_bid" data-pk="749" data-value="30"
                    data-url="/rev_3/paper/bid/set/749/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-749"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px;">We study the asymptotic behavior of replicator dynamics in settings of network interaction. We&nbsp;focus on three agent graphical games where each edge/game is either a 2x2 zero-sum or a 2x2 coordination/partnership&nbsp;game. Using tools from dynamical systems such as Lyapunov functions and&nbsp;invariant functions we establish that this simple family of games can exhibit an interesting range of behaviors such as global convergence, periodicity for all initial conditions as well as limit cycles.&nbsp;</span><font color="#222222" face="arial, sans-serif"><span style="font-size: 12.8px;">In contrast, we do not observe more complex behavior such as toroids or chaos whilst it is possible to reproduce them in slightly more complicated settings.</span></font><br></p></td>
                </tr>
            
                <tr>
                    <td>293</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-293">Do all tournaments admit irrelevant matches?</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.780</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_293" class="editable_bid" data-pk="293" data-value="30"
                    data-url="/rev_3/paper/bid/set/293/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-293"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider tournaments played by a set of agents in order to establish a ranking among them.<br>We introduce the notion of irrelevant match, as a match that does not influence the ultimate ranking of the involved parties.<br>After discussing the basic properties of this notion, we seek out tournaments that have no irrelevant matches, focusing on the class of tournaments where each agent challenges each other exactly once.<br>We prove that tournaments with a static schedule and at least 5 agents always include <br>irrelevant matches. Conversely, dynamic schedules can be devised in ways that avoid irrelevant matches, at least for one of the involved agents.<br></p></td>
                </tr>
            
                <tr>
                    <td>59</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-59">A Logical Theory for Memory Management with Explicit Time in Resource-Bounded Agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Engineering Multiagent Systems] Methodologies for agent-based systems<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.780</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_59" class="editable_bid" data-pk="59" data-value="30"
                    data-url="/rev_3/paper/bid/set/59/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-59"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In intelligent agents memory plays a crucial role in the choice of future course of action, as it is progressively formed by means of agent's interactions with the external environment. So, a flexible though formal approach to memory management is in order. Previous work exists concerning logical formalization of reasoning about the formation of beliefs in non-omniscient agents. In this paper we address an aspect which has been hardly considered so far, namely the notion of \as explicit time'', by introducing timed beliefs and timed inferences. This aspect is fundamental since perceptions and inferences in agents' realistic applications are inherently timed. We propose an approach which extends existing ones, and provide an example of application. <br></p></td>
                </tr>
            
                <tr>
                    <td>759</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-759">Constrained Swap Dynamics over a Social Network in Distributed Resource Reallocation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.780</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_759" class="editable_bid" data-pk="759" data-value="30"
                    data-url="/rev_3/paper/bid/set/759/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-759"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We examine a resource allocation problem in which each agent is to be assigned exactly one object. Agents are initially endowed with a resource that they can swap with one another. However, not all exchanges are plausible: we represent required connections between agents with a social network, and we model their rationality via an individual preference relation over items and by assuming a greedy behaviour. Thus, agents may only perform pairwise exchanges with a limited set of neighbors and only if it brings them preferred objects. We propose to analyze this distributed process with the study of two dual questions. Is it possible for an agent to obtain a certain object if the swaps occur favourably? Can an agent be guaranteed a certain level of satisfaction irrespective of the actual exchanges? These questions are investigated under the lense of classical and parameterized complexity, focusing on budget constraints such as the number of exchanges an agent may be involved in as well as the total duration of the process.</p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>686</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-686">Characterizing the Limits of Autonomous Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Other<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.780</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_686" class="editable_bid" data-pk="686" data-value="30"
                    data-url="/rev_3/paper/bid/set/686/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-686"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block">One of the goals of AI is to develop and deploy autonomous systems that are capable of operating successfully and independently in complex and uncertain environments. While much progress has been made towards this goal, human interventions still play a fundamental role in many real-world settings. In practice, however, we still do not fully understand under what conditions human input is necessary, and for when it is, we do not fully comprehend the principles for incorporating this input into an AI system such that better performance is achieved. In this paper, we answer these two questions -- when human input is needed and, if so, how it should be incorporated into an AI system. We use the language of structural causal models (Pearl, 2000) to formalize these questions and delineate the limits between fully- and semi-autonomous systems. We design two types of agents which correspond to different levels of autonomy: the first we call experimental agent, which does not consider any human input in its decision-making process, and the second we call counterfactual agent that does take human input into consideration. We study algorithms for optimizing the experimental and counterfactual agents in canonical settings. We prove that a counterfactual agent dominates an experimental agent in terms of performance. We further characterize under which conditions experimental and counterfactual agents can reach the same level of performance, which elicits the settings where full autonomy can, at least in principle, be achieved. These results suggest a trade-off between autonomy and optimality -- while full autonomy is certainly preferred, using human input could potentially improve the performance of the system. To resolve this tension, we formulate a constrained reinforcement learning problem with the goal of maximize the performance of a semi-autonomous system subject to a budget constraint over available human input. We reduce this problem to polynomial programming problem in Markov environments that can be solved efficiently. Finally,&nbsp; extensive simulations and experiments support our findings. <br></td>
                </tr>
            
                <tr>
                    <td>47</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-47">Second-Order Know-How Strategies</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logic and Game Theory<br>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Agent Cooperation] Collective intelligence<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems</td>
                    
                        <td>0.770</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_47" class="editable_bid" data-pk="47" data-value="30"
                    data-url="/rev_3/paper/bid/set/47/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-47"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The fact that a coalition has a strategy does not mean that the coalition knows what the strategy is. If the coalition knows the strategy, then such a strategy is called a know-how strategy of the coalition. The paper proposes the notion of a second-order know-how strategy for the case when one coalition knows what the strategy of another coalition is. The main technical result is a sound and complete logical system describing the interplay between the distributed knowledge modality and the second-order coalition know-how modality.<br></p></td>
                </tr>
            
                <tr>
                    <td>469</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-469">The generalized N&amp;K value, an axiomatic mechanism for electricity trading</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.770</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_469" class="editable_bid" data-pk="469" data-value="30"
                    data-url="/rev_3/paper/bid/set/469/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-469"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We introduce a solution concept for non-cooperative games, called the generalized N&amp;K value, and apply it as a mechanism for determining appropriate financial transfers over an optimal power flow (OPF) instance in an electrical network. Specifically, we derive the generalized N&amp;K value axiomatically, for non-cooperative games with constraints on the players joint action spaces. We then develop a bi-level programming method for computing it on OPF instances, in which the joint action space couplings arise from the players' use of a shared power network. The generalized N&amp;K value rewards electrical network participants (e.g.,~generators and loads) in proportion to their competitive position for monetary compensation within the network. Given this, we highlight the merits of the generalized N&amp;K value over locational marginal pricing in the context of a test instance of an electrical network under DC approximation. This shows the generalized N&amp;K value to be significantly different in its nature, reflecting the relative bargaining power of the electrical network participants, as well as exhibiting budget-balancedness and continuity with network parameters.</p></td>
                </tr>
            
                <tr>
                    <td>610</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-610">Multi-Agent Systems and Blockchain: Results from a Systematic Literature Review</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Agent Societies and Societal Issues] Trust and reputation<br>[Agent Societies and Societal Issues] Other</td>
                    
                        <td>0.770</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_610" class="editable_bid" data-pk="610" data-value="30"
                    data-url="/rev_3/paper/bid/set/610/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-610"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Human beings are increasingly connected through uncountable interlinked electronic devices that perform ubiquitous computing. As a consequence, scientific research is pushing towards the design and development of autonomous and collaborative systems and devices that interact and compete with each other, often emulating humankind dynamics.&nbsp;&nbsp;</p><p>Multi-Agent Systems (MAS) technology is widely used for the development of intelligent distributed systems, including cases that deal with highly sensitive data (e.g., ambient assisted living, healthcare, energy trading). To foster accountability and trusted interactions, recent trends advocate the inclusion of blockchain technologies (BCT) for multi-agent systems.</p><p>Although most of these approaches have only started exploring the topic, there is an impending need for establishing a research roadmap, as well as identifying both scientific and technological challenges in this scope.</p><p>As a first necessary step towards this goal, this paper presents a systematic literature review of studies involving MAS and BCT as reconciling solutions.</p><p>Aiming at providing a comprehensive overview of their application domains, we analyze motivations, assumptions, requirements, strengths, and limitations presented in the current state of the art. Moreover, discussing the future challenges, we introduce our vision on how MAS and BCT could be combined in different application scenarios.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>423</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-423">Automatic Synthesis of Efficient Regular Strategies in Adversarial Patrolling Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.770</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_423" class="editable_bid" data-pk="423" data-value="30"
                    data-url="/rev_3/paper/bid/set/423/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-423"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We give a polynomial-time algorithm for synthesizing efficient regular strategies in patrolling games with general topology. Regular strategies use finite-state automata to gather some information about the history of defender's moves, which results in substantially better protection of the targets. So far, the scope of automatic strategy synthesis was limited to positional strategies (which ignore the history) or to regular strategies where the underlying finite-state automata had to supplied manually. In this paper, we show how to synthesize the underlying finite-state automata <i>algorithmically</i>, and we also design a novel <i>gradient-based</i><b> </b>strategy improvement method which runs in polynomial time and produces high-quality strategies for patrolling games of realistic size. To evaluate the quality of these strategies, we also develop an algorithm for computing an <i>upper</i> <i>bound</i> on the best achievable protection, and compare the quality of the constructed strategies against this bound. <br></p></td>
                </tr>
            
                <tr>
                    <td>137</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-137">An SMT Encoding for Parsing of LL(1) Grammars</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Verification and Validation of Agent-based Systems] Other<br>[Verification and Validation of Agent-based Systems] Synthesis of agent-based systems<br>[Verification and Validation of Agent-based Systems] Verification techniques for multiagent systems, including model checking<br>[Verification and Validation of Agent-based Systems] Testing and debugging multiagent programs</td>
                    
                        <td>0.770</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_137" class="editable_bid" data-pk="137" data-value="30"
                    data-url="/rev_3/paper/bid/set/137/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-137"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="font-family: verdana, arial, helvetica; font-size: small;">In this work, we propose an end-to-end symbolic algorithm for parsing LL(1) grammars. We implement our ideas into our tool, Athena, and demonstrate its usefulness by building two applications over it: automated repair of syntax errors in Tiger programs and automated parser synthesis to automatically synthesize LL(1) parsers. Athena is able to successfully repair 80% of our benchmarks (675 buggy Tiger programs), clocking an average of 30 seconds per repair and synthesize parsers for interesting languages from examples. Like it verification conditions (encoding a program in logic) has found widespread applications in program analysis, we believe that Athena can serve as a foundation for interesting applications in parsing.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>93</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-93">Least Distance Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Agent Theories and Models] Logic and Game Theory<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.770</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_93" class="editable_bid" data-pk="93" data-value="30"
                    data-url="/rev_3/paper/bid/set/93/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-93"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="font-family: verdana, arial, helvetica; font-size: small;">In many scenarios, agents are related to one another by different forms of groups. One prevalent situation is when players try to make a choice from a set, while those in the same group try to make choices as different as possible. Such strategical interactions turn out to be key challenges in many real-world applications, including allocating wireless spectrums, scheduling advertisements or even the daily choice of which clothes to wear. We model this kind of interactions as a type of non-cooperative games on a social hypergraph, coined least distance games, where the players (vertices) utility are measured by the least distance in each hyperedge. Reducing the game to a congestion game, we prove the existence of pure Nash equilibrium and show that the price of anarchy of this game is exactly 2. These results motivate us to further investigate the problem of designing the optimal hypergraph structure. We conclude with two theorems, one finds the optimal graph structure under some conditions while the other finds an approximately optimal structure in the general case.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>282</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-282">Distributed Collaborative Reasoning for Human Activity Recognition in Smart Homes</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.770</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_282" class="editable_bid" data-pk="282" data-value="30"
                    data-url="/rev_3/paper/bid/set/282/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-282"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Human Activity Recognition (HAR) is an important research issue for pervasive computing that aims to identify human activities in smart homes. In previous works, most reasoning approaches for HAR are based on centralized approach where a central system is responsible for processing and reasoning about sensor data in order to recognize activities. Since smart homes are open environments deploying heterogenous sensors, reasoning process for HAR needs to be distributed over a group of heterogeneous, autonomous and interacting entities in order to be more efficient. This paper proposes a fully distributed multi-agent reasoning approach where learning agents, with diverse classifiers, observe sensor data, make local predictions, communicate and collaborate to identify current activities. Experimental tests on Aruba dataset indicate an enhancement in terms of accuracy and F-measure metrics compared to the centralized approach and also compared to a distributed approach existing in the literature.</p></td>
                </tr>
            
                <tr>
                    <td>770</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-770">Optimal Multiphase Investment Strategies for Influencing Opinions in a Social Network</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.770</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_770" class="editable_bid" data-pk="770" data-value="30"
                    data-url="/rev_3/paper/bid/set/770/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-770"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We study the problem of optimally investing in nodes of a social network in a competitive setting, where two camps aim to maximize adoption of their opinions by the population. In particular, we consider the possibility of campaigning in multiple phases, where the final opinion of a node in a phase acts as its initial biased opinion for the following phase. Using an extension of the popular DeGroot-Friedkin model, we formulate the utility functions of the camps, and show that they involve what can be interpreted as multiphase Katz centrality. Focusing on two phases, we analytically derive Nash equilibrium investment strategies, and the extent of loss that a camp would incur if it acted myopically. Our simulation study affirms that nodes attributing higher weightage to initial biases necessitate higher investment in the first phase, so as to influence these biases for the terminal phase. We then study the setting in which a camp's influence on a node depends on its initial bias. For single camp, we present a polynomial time algorithm for determining an optimal way to split the budget between the two phases. For competing camps, we show the existence of Nash equilibria under reasonable assumptions, and that they can be computed in polynomial time.</p></td>
                </tr>
            
                <tr>
                    <td>515</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-515">Shaping Opinion Dynamics in Social Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Methodologies for agent-based systems<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.770</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_515" class="editable_bid" data-pk="515" data-value="30"
                    data-url="/rev_3/paper/bid/set/515/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-515"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>A networked opinion diffusion process that usually involves extensive spontaneous discussions between connected users, is often propelled by external sources of news or feeds recommended<br>to them. In many applications like marketing design, or product<br>launch, etc., corporations often post curated news or feeds on social<br>media in order to steer the users’ opinions in a desired way. We<br>call such scenarios as opinion shaping or opinion control whereby<br>a few select users called control users post opinionated messages<br>to drive the others’ opinion to reach a given state. In this paper,<br>we propose SmartShape, an opinion control package that jointly<br>selects the control users, as well as computes the optimum rate of<br>control messages, thereby driving the networked opinion dynamics<br>to the desired direction. Furthermore, our proposal also includes a<br>robust shaping suit which makes our control framework resilient<br>to stochastic fluctuations of opinion dynamics, orginating from<br>several sources of randomness. Experiments on several synthetic<br>and real datasets gathered from Twitter, show that SmartShape<br>can accurately determine the quality of a set of control users as<br>well as shape the opinion dynamics more effectively than several<br>baselines.</p></td>
                </tr>
            
                <tr>
                    <td>164</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-164">Modelling Theory of Mind and Deception in Agent-Oriented Programming Languages</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Cognitive models<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems</td>
                    
                        <td>0.770</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_164" class="editable_bid" data-pk="164" data-value="30"
                    data-url="/rev_3/paper/bid/set/164/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-164"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">Since the emergence of BDI architectures for agent-based systems, the AI community&nbsp;</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">has</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">given</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;a lot of attention to Theory of Mind. Theory of Mind&nbsp;</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">provides us with the opportunity</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;to create intelligent machines that are able to model other agents' minds (machines and humans). Another important topic in AI research,&nbsp;</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">which</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;stems from problems such as negotiation, is the ability&nbsp;</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">for a machine</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;to deceive. In this paper</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">,</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;we propose an approach for modelling deception and Theory of Mind in an Agent-Oriented Programming Language inspired by the BDI architecture. Our work aims to show the compatibility between Theory of Mind and the BDI architecture. It also aims to extend an AOPL in order to allow agents to model other agents' minds by enabling&nbsp;</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">those</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;agents to use Theory of Mind in their reasoning and decision-making</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">. Using an approach for modelling deception based on dynamic epistemic logic, we show how agents can use Theory of Mind to deceive other agents. To the best of our knowledge, this work is one of the first attempts to model deception in multi-agent systems.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>708</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-708">A Geometric Least Squares Method for Peer Assessment</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_708" class="editable_bid" data-pk="708" data-value="30"
                    data-url="/rev_3/paper/bid/set/708/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-708"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><font face="verdana, arial, helvetica" size="2">In the peer assessment problem, a set of agents give evaluations to each other, and we are going to combine these peer assessments together to construct an overall evaluation. In contrast with the normal score aggregation problem, the peer assessment problem has incomplete information about the scores: each agent has a missing score that should be given by itself. &nbsp;In this paper, we propose a geometric least squares method (GLS) to find an aggregate scoring overall agents for the peer assessment problem. Our method is based on the following observation. Since each agent has a missing score, we consider the missing score as a variable and then each agent can be regarded as a line in an $n$-dimensional vector space. The final aggregate scores can also be regarded as points on a line vector, called the \emph{projection vector}.&nbsp;</font><span style="font-family: verdana, arial, helvetica; font-size: small;">Thus, we treat the peer assessment problem as an optimization problem of selecting a projection vector with minimum total squared distance to all the $n$ lines. This method will not only find an `optimal' aggregate evaluation of the agents, but also recover a value for each missing score accordingly. We will see that this aggregate method has some advantages compared with the simple average method. One advantage is that, when the scores given by each agent (even ignoring the magnitude of the agent) are close to a groundtruth, the new method finds the groundtruth with the highest expectation.</span></p></td>
                </tr>
            
                <tr>
                    <td>710</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-710">A Multi-agent Bayesian Decision Model for Multiple Environments</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_710" class="editable_bid" data-pk="710" data-value="30"
                    data-url="/rev_3/paper/bid/set/710/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-710"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="font-size:14.5pt;line-height:107%;
font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family:&quot;Times New Roman&quot;;
color:#222222;mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:
AR-SA">Multi-games and their uniform variant have been previously introduced as
a class of Bayesian games to model simultaneous competition in a number of
different environments or basic games.&nbsp; Each agent invests a portion of
its resources, regarded as private information or type, in each basic
game.&nbsp;&nbsp;We show that a mixed Bayesian Nash equilibrium (BNE) can be
computed from any set of Nash equilibria for all the basic games. For uniform
multi-games, where each agent plays the same strategy in all the basic games,
we introduce a notion of regularity and show that if the multi-game is regular
on the extreme types of the agents then a BNE can be constructed for it in
constant time.&nbsp;&nbsp;We also derive an algorithm, constant with respect to
the number of types, that checks if a multi-game is regular on its extreme
types. In the second part, we develop a design mechanism for the type space of
a double game and provide an algorithm to compute its BNE in linear time with
respect to the number of types of the agents. Finally, we show that our results
for MGs can be extended to networks.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>594</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-594">Planning with Dead-Ends via Model Checking</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_594" class="editable_bid" data-pk="594" data-value="30"
                    data-url="/rev_3/paper/bid/set/594/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-594"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In probabilistic planning, states with no trajectory to the goal, called <i>dead-end states</i>, can compromise the termination of a planner. Usually, the planner needs to infer if a state is a dead-end while planning which has a tremendous impact on planning performance.&nbsp; In this paper, we formally characterize via model checking: (i) the complete set of dead-end states of a planning task and (ii) different classes of probabilistic planning tasks with dead-ends. This is done by using a temporal logic whose semantics takes into account the actions. We also show how this formal characterization can be used to implement an efficient dead-end detection method via symbolic preimage operations. To evaluate the proposed dead-end detection method, we adapt LRTDP and HMDPP, state-of-the-art probabilistic planners, to&nbsp; run experiments over domains from the IPPC 2008 and their extended versions with dead-ends harder to be detected. The empirical results show a significant reduction in planning time, specially on domains with hard to detect dead-end states.<br></p></td>
                </tr>
            
                <tr>
                    <td>39</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-39">Managing Communication Costs under Temporal Uncertainty</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_39" class="editable_bid" data-pk="39" data-value="30"
                    data-url="/rev_3/paper/bid/set/39/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-39"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In multi-agent temporal planning, individual agents cannot know a priori when other agents will execute their actions and so treat those actions as uncertain. Only when others communicate the results of their actions can that uncertainty be resolved. If a full communication protocol is specified ahead of time, then delay controllability can be used to assess the feasibility of the temporal plan. However, agents often have flexibility in choosing when to communicate the results of their action. In this paper, we address the question of how to choose communication protocols that guarantee the feasibility of the original temporal plan subject to some cost associated with that communication. To do so, we introduce a means of extracting delay controllability conflicts and show how we can use these conflicts to more efficiently guide our search. We then present three conflict-directed search algorithms and explore the theoretical and empirical tradeoffs between the different approaches.<br></p></td>
                </tr>
            
                <tr>
                    <td>392</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-392">Playing Stackelberg Opinion Optimization with Randomized Algorithms for Combinatorial Strategies</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_392" class="editable_bid" data-pk="392" data-value="30"
                    data-url="/rev_3/paper/bid/set/392/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-392"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>From a perspective of designing or engineering for opinion formation games in social networks, the opinion maximization (or minimization) problem has been studied mainly for designing subset selecting algorithms.We furthermore define a two-player zero-sum Stackelberg game of competitive opinion optimization by letting the player under study as the first-mover minimize the sum of expressed opinions by doing so-called "internal opinion design", knowing that the other adversarial player as the follower is to maximize the same objective by also conducting her own internal opinion design.</p><p>We propose for the min player to play the follow-the-perturbed-leader algorithm in such Stackelberg game, obtaining losses depending on the other adversarial player’s play. Since our strategy of subset selection is combinatorial in nature, the probabilities in a distribution over all the strategies would be too many to be enumerated one by one. Thus, we design a randomized algorithm to produce a (randomized) pure strategy. We show that the strategy output by the randomized algorithm for the min player is essentially an approximate equilibrium strategy against the other adversarial player.</p></td>
                </tr>
            
                <tr>
                    <td>584</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-584">Succeeding in Complex Domains by Learning to Delegate</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Teamwork, team formation, teamwork analysis<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_584" class="editable_bid" data-pk="584" data-value="30"
                    data-url="/rev_3/paper/bid/set/584/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-584"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Large state and action spaces present many challenges to reinforcement learning. <br>In order to succeed on complex domains, a decision-maker may rely on a team of agents, selecting a team member to act on her behalf in each environment state.<br>Thus, she must learn to delegate, by finding a performance-maximizing mapping from states to agents. <br>In this paper we investigate several aspects of this model, showing the conditions under which learning to delegate outperforms directly learning to act. <br>We present synthetic experiments to further study such systems. <br>Finally, we demonstrate learning to delegate in a very complex domain: real time strategy games, where we significantly outperform state-of-the-art approaches. <br><br></p></td>
                </tr>
            
                <tr>
                    <td>585</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-585">Vocabulary Alignment for Collaborative Agents:  a Study with Real-World Multilingual How-to Instructions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Communication languages and protocols<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_585" class="editable_bid" data-pk="585" data-value="30"
                    data-url="/rev_3/paper/bid/set/585/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-585"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Collaboration between heterogeneous agents typically requires the ability to communicate meaningfully. This can be challenging in open environments where participants may use different languages. Previous work proposed a technique to infer alignments between different vocabularies that uses only information about the tasks&nbsp; being executed, without any external resource. Until now, this approach has only been evaluated with artificially created data. <br>We propose an adaptation of this technique to protocols written by humans in natural language, which we extract from instructional webpages. In doing so, we not only are able to evaluate these techniques on real human-crafted protocols but also show how to take into account challenges that arise when working with natural language labels.<br>The quality of the alignments obtained with our technique is evaluated in terms of their precision and of their effectiveness in enabling successful collaborations, using a translation dictionary as a baseline. We show how our technique outperforms the dictionary when used to interact.<br><br><br></p></td>
                </tr>
            
                <tr>
                    <td>359</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-359">Interpretable Robust Decision Making</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_359" class="editable_bid" data-pk="359" data-value="30"
                    data-url="/rev_3/paper/bid/set/359/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-359"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Interpretable decision making frameworks allow us to easily imbue agents with specific goals, risk tolerances, and understanding. Existing decision making systems either forgo interpretability, or pay for it with severely reduced efficiency and large memory requirements. In this paper, we outline DeepID, a neural network approximation of Influence Diagrams, that avoids such pitfalls. We further demonstrate how the framework allows for the introduction of robustness in a very transparent and interpretable manner, without increasing the complexity class of the decision problem.<br></p></td>
                </tr>
            
                <tr>
                    <td>125</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-125">Towards Partial Order Reductions for Strategic Ability</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Verification and Validation of Agent-based Systems] Verification techniques for multiagent systems, including model checking</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_125" class="editable_bid" data-pk="125" data-value="30"
                    data-url="/rev_3/paper/bid/set/125/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-125"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We propose a general semantics for strategic abilities of agents in asynchronous systems, with and without perfect information. Based on the semantics, we show some general complexity results for verification of strategic abilities in asynchronous interaction. More importantly, we develop a methodology for <i>partial order reduction</i> in verification of agents with imperfect information, based on the notion of <i>traces</i>. We show that the reduction preserves an important subset of strategic properties, both with and without the fairness assumption. Interestingly, the reduction does not work for strategic abilities under perfect information.<br><br><br></p></td>
                </tr>
            
                <tr>
                    <td>580</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-580">Autonomous Decision Making for Search and Tracking with Multiple Coordinated UAVs</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_580" class="editable_bid" data-pk="580" data-value="30"
                    data-url="/rev_3/paper/bid/set/580/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-580"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Search-and-tracking is the problem of locating a moving target and following it to its destination. In this work, we consider a scenario in which the target moves across a large geographical area by following a road network and the search is performed by multiple unmanned aerial vehicles (or drones) with limited endurance. We address the problem of distributed autonomous search-and-tracking by leveraging generic high-level decision-making techniques: AI task planning and constraint programming. In exploiting a model-and-solve paradigm, these techniques grant access to a range of high-performance optimisation solvers, while offering a flexible extension of the model according to different mission specifications. We give a formulation of the problem that lends itself to both planning and constraint programming encodings and then use off-the-shelf solvers to find solutions. We explore two alternative approaches to coordinate our team of observers: a centralised architecture, in which one agent solves the problem centrally and assigns tasks to the other agents in the team, and a decentralised architecture, in which each agent decides its own behaviour. We prove that the objective function of the problem is submodular and implement a greedy algorithm that, thanks to this property, presents remarkably good performance. Given the rapid increase of the problem size with the number of observers, our experimental evaluation studies the scalability of the different techniques and identifies the conditions under which a decentralised approach becomes preferable to a centralised one.<br></p></td>
                </tr>
            
                <tr>
                    <td>341</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-341">Maximizing Impact in an Agent Reputation Network under Uncertainty</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Trust and reputation<br>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Agent Theories and Models] Other</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_341" class="editable_bid" data-pk="341" data-value="30"
                    data-url="/rev_3/paper/bid/set/341/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-341"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style=" color:#000000;">Many multi-agent systems (</span><span style=" text-decoration: underline; color:#000000;">MASs</span><span style=" color:#000000;">) are situated in stochastic environments. Some such systems that are based on the partially observable Markov decision process (</span><span style=" text-decoration: underline; color:#000000;">POMDP</span><span style=" color:#000000;">) do not take the benevolence of other agents for granted. We propose a new </span><span style=" text-decoration: underline; color:#000000;">POMDP</span><span style=" color:#000000;">-based framework which is general enough for the specification of a variety of stochastic MAS domains involving the impact of agents on each other's reputations. A unique feature of this framework is that actions are specified as either undirected (regular) or directed (towards a particular agent), and a new directed transition function is provided for </span><span style=" text-decoration: underline; color:#000000;">modeling</span><span style=" color:#000000;"> the effects of reputation in interactions. Assuming that an agent must maintain a good enough reputation to survive in the network, a planning algorithm is developed for an agent to select optimal actions in stochastic </span><span style=" text-decoration: underline; color:#000000;">MASs</span><span style=" color:#000000;">. Preliminary evaluation is provided via an example specification and by determining the algorithm's complexity.</span></p></td>
                </tr>
            
                <tr>
                    <td>608</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-608">Event-Based and Scenario-Based Causality for Computational Ethics</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Agent Theories and Models] Other</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_608" class="editable_bid" data-pk="608" data-value="30"
                    data-url="/rev_3/paper/bid/set/608/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-608"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper makes use of high-level action languages to investigate aspects of causality that are central to ethical reasoning. We identify properties that causal relations assume and that determine how, as well as to what extent, we may ascribe ethical responsibility on their basis. The paper is structured in three parts. First, we present an extension of the Event Calculus that enables the agent to generate plans of actions, with the particularity that they integrate both actions and omissions. Second, we present an account of \textit{event-based} causality that is grounded in the architecture of event preconditions and effects, and that distinguishes four types of causal relations contingent on the nature of the entities that compose them. Namely, it discriminates actions and omissions from automatic events, and produced outcomes from avoided ones. Third, we examine notions of \textit{scenario-based} causality whose role it is to scrutinise and buttress the causal relations previously identified. Inquiring into the other possible versions of modelled scenarios, we account for simple counter-factual validity ("Had I not acted so, would this outcome still be true?"), criticality ("Could anything else have led to this outcome?"), extrinsic necessity ("Had I not produced it, was this outcome even avoidable?"), and elicited necessity ("Have I made this outcome unavoidable?"). The model is implemented in Answer Set Programming.<br></p></td>
                </tr>
            
                <tr>
                    <td>694</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-694">Onboard Mission Planning for an Autonomous Satellite</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_694" class="editable_bid" data-pk="694" data-value="30"
                    data-url="/rev_3/paper/bid/set/694/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-694"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Satellite autonomy can help overcome the limitations imposed by the ground segment and enhance the responsiveness that attracts much attention from researchers in the last decades. In reality, the limited computational resource presents a challenge for the onboard mission planning. In this paper, we study the onboard mission planning problem for an autonomous satellite. A continuous planning architecture and a dynamic graph model are developed, then an improved label-setting algorithm with three acceleration strategies is proposed to maximize the total profit. The experimental result demonstrates that our method can solve the onboard mission planning problem in much less time.<br></p></td>
                </tr>
            
                <tr>
                    <td>434</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-434">Resource Logics with a Diminishing Resource</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Verification and Validation of Agent-based Systems] Verification techniques for multiagent systems, including model checking</td>
                    
                        <td>0.760</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_434" class="editable_bid" data-pk="434" data-value="30"
                    data-url="/rev_3/paper/bid/set/434/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-434"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style="margin-bottom: 0px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">Model-checking resource logics with production and consumption of resources is a computationally hard and often undecidable problem. We introduce a simple and realistic assumption that there is at least one diminishing resource, that is, a resource that cannot be produced and every action has a non-zero cost on this resource. An example of such resource is time. We show that, with this assumption, problems that are undecidable even for the underlying Alternating Time Temporal Logic, such as model-checking under imperfect information and perfect recall, become decidable for resource logics with a diminishing resource.</span></p><div><span style="font-variant-ligatures: no-common-ligatures"><br></span></div></td>
                </tr>
            
                <tr>
                    <td>430</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-430">Balanced outcomes in wage bargaining</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Economic Paradigms] Cooperative games: computation</td>
                    
                        <td>0.750</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_430" class="editable_bid" data-pk="430" data-value="30"
                    data-url="/rev_3/paper/bid/set/430/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-430"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Balanced outcomes are a subset of core outcomes that take into consideration fairness and agents’ power in bargaining networks. In this paper, following the seminal works by (Cook and Yamagishi 1992) and (Kleinberg and Tardos 2008) on modeling and computing balanced outcomes in unit-capacity trading networks, we explore this concept further by considering its generalization in the so-called wage bargaining network where agents on one side (the employers side) may have multiple capacity. It turns out that previous definitions do not trivially extend to this setting. Our first contribution is to incorporate insights from the bargaining theory and define a generalized notion of balanced outcomes in wage bargaining networks.</p><p>We then consider computational aspects of this newly proposed solutions. We show that there are polynomial-time combinatorial algorithms to compute such solutions in both unweighted and weighted graphs. Our algorithms and proofs are enabled by novel generalizations of techniques proposed by Kleinberg and Tardos and an original technique proposed in this paper called “loose chain”.</p></td>
                </tr>
            
                <tr>
                    <td>726</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-726">Minimax-Regret Querying on Side Effects for Safe Optimality in Factored Markov Decision Processes</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.750</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_726" class="editable_bid" data-pk="726" data-value="30"
                    data-url="/rev_3/paper/bid/set/726/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-726"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><font color="#222222" face="arial, sans-serif"><span style="font-size: 12.8px;">When a robot is tasked by a human operator to change some state features of the environment&nbsp;to achieve a goal (e.g., making a room clean), the actions the robot must or should take may also change other state features (e.g., moving furniture). When the human operator has not, or cannot, specify for every feature whether changing it is permissible, the robot risks causing negative side effects (e.g., breaking a vase while cleaning).&nbsp; A robot that can be trusted to safely operate in its environment should err on never causing negative side effects.&nbsp; We formalize this problem and develop an algorithm that avoids negative side effects based on what the robot knows about the operator's preferences.&nbsp; Furthermore, we formulate a minimax-regret querying strategy for the robot to selectively ask the operator about potential side effects.&nbsp; Our empirical results show that our strategy has computational advantages over a more exhaustive approach, and poses better queries than using a heuristic.</span></font><br></p></td>
                </tr>
            
                <tr>
                    <td>140</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-140">Multi-agent simulation with heuristic optimization of air pollution dynamics in a city</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Learning and Adaptation] Evolutionary algorithms<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.750</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_140" class="editable_bid" data-pk="140" data-value="30"
                    data-url="/rev_3/paper/bid/set/140/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-140"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span lang="EN-GB" style='font-family: "Times New Roman",serif; font-size: 10pt; mso-fareast-font-family: "Times New Roman"; mso-ansi-language: EN-GB; mso-fareast-language: EN-US; mso-bidi-language: AR-SA;'><font color="#000000">The synthesis of
environmental control systems which allow the best ecological trade-offs to be
identified on rational greening of a city for reducing the daily concentration
of air pollution is an important problem that has not been solved hitherto. We have
developed a multi-agent simulation of air pollution dynamics for optimal tree
cluster allocation in a city and applied it using the city of Yerevan, Armenia
as a case study. The Pareto optimal solutions on greening in the city were computed
with the help of the suggested heuristic optimization algorithm taking into
account the complex absorptive-diffusive interaction between agent-trees and
air pollutants produced by agent-enterprises and agent-vehicles located in the
city.</font></span><br></p></td>
                </tr>
            
                <tr>
                    <td>534</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-534">Reciprocal Strategies in Repeated Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Agent Theories and Models] Logic and Game Theory</td>
                    
                        <td>0.750</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_534" class="editable_bid" data-pk="534" data-value="30"
                    data-url="/rev_3/paper/bid/set/534/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-534"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In repeated play against a single opponent, an agent must address the fact that, in addition to immediate effects, its actions may also affect the opponent's future behavior. We have developed a class of sequential extensive form games, in which participants take turns acting, for studying the effects of one agent's action on an opponent's future actions.The main reasons for an agent to make its strategy conditional on the opponents previous actions is to learn the opponent's strategy, or to teach the opponent to play a preferred outcome. We describe a class of reciprocal strategies for this environment that can perform well against a learning opponent.&nbsp; We also demonstrate a method for finding the optimal reciprocal strategy for a given opponent.</p></td>
                </tr>
            
                <tr>
                    <td>656</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-656">Distributed Strategy Adaptation with a Prediction Function in Multi-Agent Task Allocation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.750</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_656" class="editable_bid" data-pk="656" data-value="30"
                    data-url="/rev_3/paper/bid/set/656/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-656"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Coordinating multiple agents to complete a set of tasks under time constraints is a complex problem. Distributed consensus-based task allocation algorithms address this problem without the need for human supervision. With such algorithms, agents add tasks to their own schedule according to specified allocation strategies. Various factors, such as the available resources and number of tasks, may affect the efficiency of a particular allocation strategy. The novel idea we suggest is that each individual agent can predict the best task inclusion strategy locally, based on the limited task assignment information communicated among networked agents. Using supervised classification learning, a function is trained to predict the most appropriate strategy between two well known insertion heuristics. Using the proposed method, agents are shown to correctly predict and select the optimal insertion heuristic to achieve the overall highest number of task allocations. The adaptive agents consistently match the performances of the best non-adaptive agents across a variety of scenarios. This study aims to demonstrate the possibility and potential performance benefits of giving agents greater decision making capabilities to independently adapt the task allocation process in line with the problem of interest.</p></td>
                </tr>
            
                <tr>
                    <td>388</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-388">Please be an Influencer? Contingency-Aware Influence Maximization</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.750</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_388" class="editable_bid" data-pk="388" data-value="30"
                    data-url="/rev_3/paper/bid/set/388/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-388"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Most previous work on influence maximization in social networks assumes that the chosen influencers (or seed nodes) can be influenced with certainty (i.e., with no contingencies). In this paper, we focus on using influence maximization in public health domains for assisting low-resource communities, where contingencies are common. It is very difficult in these domains to ensure that the seed nodes are influenced, as influencing them entails contacting/convincing them to attend training sessions, which may not always be possible.&nbsp; Unfortunately, previous state-of-the-art algorithms for influence maximization are unusable in this setting. This paper tackles this challenge via the following four contributions: (i) we propose the Contingency Aware Influence Maximization problem and analyze it theoretically; (ii) we cast this problem as a Partially Observable Markov Decision Process and propose CAIMS (a novel POMDP planner) to solve it, which leverages a natural action space factorization associated with real-world social networks; and (iii) we provide extensive simulation results to compare CAIMS with existing state-of-the-art influence maximization algorithms. Finally, (iv) we provide results from a real-world feasibility trial conducted to evaluate CAIMS, in which key influencers in homeless youth social networks were influenced in order to spread awareness about HIV.<b></b><i></i><u></u><sub></sub><sup></sup><strike></strike><br></p></td>
                </tr>
            
                <tr>
                    <td>83</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-83">Coordination of Mobile Agents for Wireless Sensor Network Maintenance</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Agent Cooperation] Multi-robot systems<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems<br>[Agents and Mainstream Computing] Mobile agents</td>
                    
                        <td>0.750</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_83" class="editable_bid" data-pk="83" data-value="30"
                    data-url="/rev_3/paper/bid/set/83/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-83"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we study the problem of wireless sensor network (WSN)</p><p>maintenance using a team of collaborative autonomous mobile agents.</p><p>The agents are deployed in the area of the WSN in such a way that would minimize the time it takes them to reach a failed sensor and repair it. </p><p>The team must constantly optimize its collective deployment to account for occupied agents.</p><p>The objective is to define the optimal deployment and task allocation strategy, that minimize the solution cost.</p><p>The solution cost is a linear combination of the weighted sensors' downtime, the agents' traveling distance and penalties incurred due to unrepaired sensors within a certain time limit.</p><p>A constrained variation of the problem where agents are subject to capacity constrains is also considered.</p><p>Our solutions are inspired by research in the field of computational geometry and the design of our algorithms is based on state of the art approximation algorithms for the classical problem of facility location.</p><p>We empirically compare and analyze the performance of several proposed algorithms.<br></p><p>The sensitivity of the algorithms' performance to the following parameters is analyzed: agents to sensors ratio, sensors' sparsity, frequency of failures and repair duration.</p></td>
                </tr>
            
                <tr>
                    <td>129</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-129">Understanding Social Capital in an Intra-Organizational Dependency Network</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Agent Societies and Societal Issues] Organisations and institutions<br>[Agent Societies and Societal Issues] Socio-technical systems<br>[Agent Cooperation] Collective intelligence</td>
                    
                        <td>0.750</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_129" class="editable_bid" data-pk="129" data-value="30"
                    data-url="/rev_3/paper/bid/set/129/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-129"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In a complex open multi-agent system, agents' interactions as well as their actions are not predictable. They collaborate beneficently with one another for mutual actions that are beyond the ones current capabilities. Repeated pattern of interactions shape a feature of their organizational structure when those agents self-organize themselves for a long-term objective. We aim to understand <i>social capital</i> in organizations that are open membership multi-agent systems with an emphasis in our formulation on the dynamic network of social interactions that, in part, elucidate evolving structures and impromptu topologies of networks. We provide analysis of how social capital can be created within this type of organizations and drive to a measurement for its value. We empirically evaluate the proposed model through an example of an open-source project development.<br></p></td>
                </tr>
            
                <tr>
                    <td>787</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-787">Autonomy Reconsidered: Toward Developing Multi-Agent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Teamwork, team formation, teamwork analysis<br>[Agent Cooperation] Multi-robot systems</td>
                    
                        <td>0.750</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_787" class="editable_bid" data-pk="787" data-value="30"
                    data-url="/rev_3/paper/bid/set/787/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-787"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The Church-Turing thesis suggests that the notion of autonomy, applied to robots or artificial agents, must be encoded as an algorithm or set of algorithms. The thesis of this paper is that autonomy is algorithms.&nbsp;&nbsp; More specifically, an agent's autonomy is the set of physically and computationally grounded algorithms that can be performed by that agent.&nbsp;&nbsp;A precise definition of this thesis leads to two useful notions related to autonomy, namely&nbsp;behavior potential and success potential. These two notions lead to a measure of how well an agent fulfills its&nbsp; potential, which we call fulfillment.&nbsp; &nbsp;Fulfillment and success potential induce partial and total orderings of possible algorithms, leading to algorithm-based, capability-centered definitions of levels of autonomy that complement common uses of this phrase.&nbsp;&nbsp;We argue that (a) because the success potential of a&nbsp;multi-agent system can exceed the success potentials of individual&nbsp;agents through synergy effects and (b) the fulfillment of an&nbsp;&nbsp;individual can be augmented through interactions with others,&nbsp;though (c) possibly interfering in the fulfillment of the&nbsp;other agents. Interaction algorithms enable multiple agents to coordinate, communicate, or exchange information; these algorithms enable and constrain tradeoffs between augmenting and diminishing other agents. Short case studies are presented to illustrate how the algorithm-based definitions can be used to understand existing systems.<br></p></td>
                </tr>
            
                <tr>
                    <td>151</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-151">The Power of Context in Networks: Ideal Point Models with Social Interactions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Agent Theories and Models] Logic and Game Theory<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.750</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_151" class="editable_bid" data-pk="151" data-value="30"
                    data-url="/rev_3/paper/bid/set/151/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-151"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Game theory has been widely used for modeling strategic behaviors in networked multiagent systems. However, the context within which these strategic behaviors take place has not received much attention. We present a model of strategic behavior in networks that incorporates the behavioral context. We focus on the contextual aspects of Senate voting. A senator's decision to vote <i>yea</i>&nbsp;or <i>nay</i>&nbsp;on a bill comes as a result of their ideologies, agendas, and their interactions with other senators. One salient model in political science is the <i>ideal point model</i>, which assigns each senator and each bill a number on the real line of political spectrum. These points then allow for prediction of future voting behavior. We extend the classical ideal point model with network-structured interactions among senators. In contrast to the ideal point model's prediction of individual voting behavior, we predict <i>joint voting behaviors</i>&nbsp;in a game-theoretic fashion. Our model also includes the characteristics of a bill. This allows it to outperform previous models that solely focus on the networked interactions among senators with no bill-specific parameters. We focus on two fundamental questions: learning the model using real-world data and computing <i>stable outcomes</i>&nbsp;of the model in order to predict joint voting behaviors. We demonstrate the effectiveness of our model through experiments using data from the 114th U.S. Congress.</p></td>
                </tr>
            
                <tr>
                    <td>466</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-466">Planning Using a Portfolio of Reduced Models with Cost Adjustments</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.750</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_466" class="editable_bid" data-pk="466" data-value="30"
                    data-url="/rev_3/paper/bid/set/466/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-466"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Reduced models such as determinization help autonomous agents cope with the complexity of planning under uncertainty. Existing reduced model techniques employ a uniform outcome selection principle for all state-action pairs to simplify a problem. But it is often hard to identify which outcome selection principle will work well across all problems in a domain. In this paper, we aim to create robust reduced models that can yield near-optimal solutions. First, we introduce<i> planning using a portfolio of reduced models</i>, a framework that provides flexibility in reduced model formulation by using a portfolio of outcome selection principles. Secondly, we propose <i>planning using cost adjustment</i>, a technique to improve solution quality by accounting for the outcomes ignored in the reduced model, and analyze conditions under which it can achieve optimal action selection. Finally, we demonstrate the benefits of the approach on three different domains that include an electric vehicle charging problem with stochastic parking duration, using real-world data from a university campus, and two benchmark problems from the planning literature.</p></td>
                </tr>
            
                <tr>
                    <td>662</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-662">BDI Model of Connected and Autonomous Vehicles</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.750</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_662" class="editable_bid" data-pk="662" data-value="30"
                    data-url="/rev_3/paper/bid/set/662/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-662"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;" id="docs-internal-guid-de50807b-a835-4ccf-a721-63b0d2f0f566"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;">It is expected that connected and autonomous vehicles (CAVs) will become a regular mean of transportation by the year 2022. To fully leverage the potential of this new technology it is necessary to equip such cars with efficient algorithms permitting them to drive in a safe and possibly optimal manner. Thereby we aim to design and implement tools for evaluation of strategies for driving and interactions in various settings.</span><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;">In this paper we present results of the first stage of our research on a simulation framework of CAVs.</span></p><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;" id="docs-internal-guid-de50807b-a835-4ccf-a721-63b0d2f0f566"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;"><br></span></p><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;">A search for balance between huge complexity of representing of real-world CAVs and comprehensibility of the solution led us to the paradigm of multi-agent systems. In particular, the concept of BDI, Beliefs-Desires-Intentions, offers useful abstractions for activities of a single self-driving car and a whole systems of such vehicles. However the existing BDI-systems either do not address certain problems related to simulation of CAVs or introduce significant overhead in programming resources.</span></p><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;"><br></span></p><p><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;">Our approach, on the other hand, in a simple way combines two distinct natures of a self-driving car: its reactiveness and proactiveness. Moreover, modularity of the resulting architectures for an individual CAV and urban traffic induced by these cars makes the design easily extensible and resilient. Finally, we also consider technical aspects of implementation even on a large scale of hundreds and thousands vehicles and verify its feasibility by preparing a prototype of a CAV simulating tool.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>160</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-160">Preference-Guided Planning: An Active Elicitation Approach</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.750</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_160" class="editable_bid" data-pk="160" data-value="30"
                    data-url="/rev_3/paper/bid/set/160/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-160"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Planning with preferences has been employed extensively to quickly generate high-quality plans.&nbsp;</p><p>However, it may be difficult for the human expert to supply this information without knowledge of the reasoning employed by the planner and the distribution of planning problems. We consider the problem of actively eliciting preferences from a human expert during the planning process. Specifically, we study this problem in the context of the Hierarchical Task Network (HTN) planning framework as it allows easy interaction with the human.</p><p>Our experimental results on several diverse planning domains show that the preferences gathered using the proposed approach improve the quality and speed of the planner, while reducing the burden on the human expert.</p></td>
                </tr>
            
                <tr>
                    <td>325</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-325">Imitation Learning of Optimal Strategies in Differential Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Noncooperative games: computation<br>[Agent Theories and Models] Logic and Game Theory<br>[Agent Cooperation] Multi-user/multi-virtual-agent interaction<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.740</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_325" class="editable_bid" data-pk="325" data-value="30"
                    data-url="/rev_3/paper/bid/set/325/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-325"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The ability of a vehicle to navigate safely through any environment relies on its driver having an accurate sense of the future positions and goals of other vehicles on the road. A driver does not navigate around where an agent is, but where it is going to be. To avoid collisions, autonomous vehicles should be equipped with the ability to to derive appropriate controls using future estimations for other vehicles, pedestrians, or otherwise intentionally moving agents in a manner similar to or better than human drivers. Differential game theory provides one approach to generate a control strategy by modeling two players with opposing goals. Environments faced by autonomous vehicles, such as merging onto a freeway, are complex, but they can be modeled and solved as a differential game using discrete approximations; these games yield an optimal control policy for both players and can be used to model adversarial driving scenarios rather than average ones, so that autonomous vehicles will be safer on the road in more situations. Further, discrete approximations of solutions to complex games that are computationally tractable and provably asymptotically optimal have been developed, but may not produce usable results in an online fashion. To retrieve an efficient, continuous control policy, we use deep imitation learning to model the discrete approximation of a differential game solution. We successfully learn the policy generated for two games of different complexity, a fence escape and merging game, and show that the imitated policy generates control inputs faster than the differential game generated policy.<br></p></td>
                </tr>
            
                <tr>
                    <td>727</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-727">A Stitch in Time - Autonomous Model Management via Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.740</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_727" class="editable_bid" data-pk="727" data-value="30"
                    data-url="/rev_3/paper/bid/set/727/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-727"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><pre style="margin-bottom: 0px;"><span style=" color:#000000;">Concept drift - a change, either sudden or gradual, in the underlying</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">properties of data - is one of the most prevalent challenges to</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">maintaining high-performing learned models over time in autonomous</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">systems.  In the face of concept drift, one can hope that the old model</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">is sufficiently representative of the new data despite the concept</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">drift, one can discard the old data and retrain a new model with (often</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">limited) new data, or one can use transfer learning methods to combine</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">the old data with the new to create an updated model.  Which of</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">these three options is chosen affects not only near-term decisions, but</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">also future needs to transfer or retrain.  In this paper, we thus model</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">response to concept drift as a sequential decision making problem and</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">formally frame it as a Markov Decision Process.  Our reinforcement</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">learning approach to the problem shows promising results on one</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">synthetic and two real-world </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">datasets</span><span style=" color:#000000;">.</span></pre><p>













</p><pre style="margin-bottom: 0px;"><br></pre></td>
                </tr>
            
                <tr>
                    <td>465</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-465">Evolving Coverage Behaviours For MAVs Using NEAT</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Evolutionary algorithms<br>[Agent Cooperation] Multi-robot systems</td>
                    
                        <td>0.740</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_465" class="editable_bid" data-pk="465" data-value="30"
                    data-url="/rev_3/paper/bid/set/465/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-465"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>There has been an increasing interest in the use of robotic swarms for the purpose of surveillance and mapping of complex environments. This is mainly due to the fact that swarm systems have a number of desirable properties over single agent systems: robustness, scalability and the ability to solve a problem in parallel. Although progress has been made in this area, there is still a long way to go before these technologies are deployed in a real world environment. This paper offers a real world, robotic solution to an important sub-task in surveillance: dynamic coverage - the problem of covering an area evenly and continuously in order to visit all areas of interest. This work provides a novel solution in that it achieves this in a completely decentralised manner with no reliance on GPS, meaning it is achieved using a relative positioning system as opposed to a global positioning system. This is especially important for deployment in hazardous, uncertain environments where GPS may be unavailable and communication links stand a high chance of being severed. Previous works either rely on a centralised command unit, require the use of GPS or simply do not realise the simulation results on real robots. This work uses NEAT, which is a neuroevolutionary algorithm that evolves neural network structure as well as the synapse weights through the use of a genetic algorithm. The robotic controllers are first realised via accurate simulation and then transferred to Micro-Aerial Vehicles (MAVs). The MAVs are modified to include a Ultra-Wideband Frequency (UWB) chip which use radio waves to communicate inter drone distances to one another.<br></p></td>
                </tr>
            
                <tr>
                    <td>73</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-73">Distributed Multi-resource Allocation with Little Communication Overhead</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.740</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_73" class="editable_bid" data-pk="73" data-value="30"
                    data-url="/rev_3/paper/bid/set/73/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-73"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="white-space:pre">	</span>We propose a distributed algorithm to solve a special&nbsp;distributed multi-resource allocation problem with no direct&nbsp;inter-agent communication. We do so by extending a recently introduced&nbsp;additive-increase multiplicative-decrease (AIMD) algorithm, which only&nbsp;uses very little communication between the system and agents. Namely,&nbsp;a control unit broadcasts a one-bit signal to agents whenever one of&nbsp;the allocated resources exceeds capacity. Agents then respond to this&nbsp;signal in a probabilistic manner. In the proposed algorithm, each&nbsp;agent is unaware of the resource allocation of other agents. We also&nbsp;propose a version of the AIMD algorithm for multiple binary&nbsp;resources (e.g., parking spaces). Binary resources are indivisible&nbsp;unit-demand resources, and each agent either allocated one unit of the&nbsp;resource or none.&nbsp; In empirical results, we observe that in both&nbsp;cases, the average allocations converge over time to optimal allocations.</p></td>
                </tr>
            
                <tr>
                    <td>637</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-637">Coordination and Common Knowledge on Communication Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Economic Paradigms] Behavioral game theory<br>[Economic Paradigms] Noncooperative games: computation<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.740</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_637" class="editable_bid" data-pk="637" data-value="30"
                    data-url="/rev_3/paper/bid/set/637/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-637"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Protest is a collective action problem and can be modeled as a coordination game in which two or more people each take an action with the potential to achieve shared mutual benefits, only if their actions coincide. In the context of protest participation, successful coordination requires that people know each others' willingness to participate, and that this information is common knowledge.&nbsp; Social networks can facilitate the creation of common knowledge through the flow of messages.&nbsp; Although there is a rich experimental literature that documents behavior in coordination games with and without communication, little is known about how people coordinate behaviors within a social network and how different types of communication structures affect behavior.</p><p>In this paper, we develop a theoretically based on-line experiment with Amazon Mechanical Turk participants to characterize the emergence of common knowledge and coordination through interactions within a network. Our experiment is designed to identify the effects of both social network topology and communication and to falsify the game-theoretic predictions.&nbsp; Our data reveal that choices are affected by the network structure and they move towards the theoretical predictions with communication. We use our behavioral findings to simulate dynamics in more complex networks through agent-based modeling. Thus, we combine human behaviors identified in experiments with realistic social network structures to reveal patterns not previously observed.<br></p></td>
                </tr>
            
                <tr>
                    <td>213</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-213">Information Exchanging and Non-Cooperative Computation among Rational Agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.740</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_213" class="editable_bid" data-pk="213" data-value="30"
                    data-url="/rev_3/paper/bid/set/213/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-213"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We study mechanism design in the setting where agents are rewarded using information only. This is an interesting setting motivated, among other things, by the increasing interest in secure multi party computation techniques. Moreover this is a very challenging setting, since information (as opposed to money) can be easily replicated and is not \emph{fungible} i.e., the same piece of information might have different values for different agents. More specifically, we consider the setting of a joint computation where different agents have inputs of different \emph{quality} or \emph{value}, and their utility incorporates both&nbsp; \emph{correctness} and \emph{exclusiveness}, i.e. every agent is interested in improving the quality of his own piece of information while preventing other agents from doing so.</p><p>Then we ask the question of whether we can design mechanisms that motivate all agents (even those with high-quality input) to participate in the computation. We begin answering this fascinating question by proposing mechanisms for natural joint computation tasks such as intersection, union, and average.</p></td>
                </tr>
            
                <tr>
                    <td>87</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-87">Belief Shadowing</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.740</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_87" class="editable_bid" data-pk="87" data-value="30"
                    data-url="/rev_3/paper/bid/set/87/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-87"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Belief change/update/revision typically requires deep and/or complex modifications of belief bases.</p><p>In this paper we present a novel, lightweight and tractable approach to a new kind of belief change which we call&nbsp;<i>belief shadowing</i>. It can be seen as a transient swap of beliefs. Namely, a belief base can be shadowed by another belief base representing new observations and/or beliefs of superior agents/teams. However, no changes to belief bases are required. Therefore, this approach can substantially improve the performance of agent systems relying on doxastic reasoning.</p><p>In order to address important phenomena, also those related to adequate modeling of dynamic environment, our approach is based on a carefully chosen four-valued paraconsistent logic with truth values representing truth, falsity, incompleteness and inconsistency.&nbsp; Moreover, potentially undesired or forbidden conclusions are prevented by integrity constrains together with their shadowing machinery.&nbsp;&nbsp;</p><p>As an implementation environment we have chosen a recently developed four-valued query language, based on the same logic and providing necessary reasoning tools. Importantly, the presented shadowing techniques are general enough to be embedded in any reasoning environment&nbsp; addressing related phenomena.&nbsp;</p><p>The approach is illustrated by a medical emergency room scenario exhibiting a fair level of dynamism and complexity.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>420</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-420">A Coordination Mechanism to Replicate Large-Scale Multi-Agent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Agent Cooperation] Distributed problem solving<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.740</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_420" class="editable_bid" data-pk="420" data-value="30"
                    data-url="/rev_3/paper/bid/set/420/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-420"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Distributed cooperative applications are now increasingly designed as Multi-Agent Systems (MASs). Such applications may be open, very dynamic, large scale and, being decentralized, exhibit heterogeneous and dynamic agent criticalities.These characteristics create new challenges to the traditional approaches of fault-tolerance. We focus on replication-based preventive approaches. The aim is to dynamically and automatically adapt the agent replication strategy (number of replicas and their location), in order to maximize the MAS reliability (guarantee of continuity of computation w.r.t the agents criticalities) while not significantly impacting the system performances. In this paper, we describe a decentralized coordination mechanism for dynamically optimizing&nbsp; the replication strategy of a large-scale and open MAS. We then provide theoretical validation and report on experimental validation by comparing to a top-of-the-art DCOP algorithm.</p></td>
                </tr>
            
                <tr>
                    <td>419</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-419">Reinforcement Learning based on Sequential Information in the Iterated Prisoner&#39;s Dilemma</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Noncooperative games: computation<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.740</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_419" class="editable_bid" data-pk="419" data-value="30"
                    data-url="/rev_3/paper/bid/set/419/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-419"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The Iterated Prisoner's Dilemma (IPD) has been studied for exploring human social interactions, and many strategies have been designed for it to achieve better total payoffs. However, there is no single strategy suitable for playing against all other agents since the performance of an IPD strategy depends largely on the opponent's strategy. We develop a new strategy for the IPD that uses lifelong Reinforcement Learning (RL) and is based on the novel concept of sequential information of recent moves, which is able to find optimal responses against different opponents. In our RL framework, the Markov Decision Process (MDP) is built upon the history of the IPD, and the lifelong training SARSA is used to select the actions. The state of the Q-table employs, for the first time, the number of sequential cooperation in recent rounds, which evaluates the response of the opponent to the agent's recent moves and stores its features. Meanwhile, the Q-table acquires knowledge throughout the agent's lifetime in which playing against each new opponent strategy is considered as a new RL task associated with a new MDP. Our RL strategy is the new state-of-the-art which wins both the round-robin and the ecological tournaments. Moreover, it enhances the performance of the opponents, and has similar top scores in other repeated games.<br></p></td>
                </tr>
            
                <tr>
                    <td>227</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-227">Solving the Capacitated Open Vehicle Routing Problem, Based on Probability Distribution Analysis of Saving Matrix Values</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Agents and Mainstream Computing] Mobile agents</td>
                    
                        <td>0.740</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_227" class="editable_bid" data-pk="227" data-value="30"
                    data-url="/rev_3/paper/bid/set/227/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-227"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal" style="margin-top:6.0pt;margin-right:0cm;margin-bottom:0cm;
margin-left:0cm;margin-bottom:.0001pt">











<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1107305727 0 0 415 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin-top:0cm;
	margin-right:0cm;
	margin-bottom:4.0pt;
	margin-left:0cm;
	text-align:justify;
	mso-pagination:widow-orphan;
	font-size:9.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-bidi-language:AR-SA;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-size:10.0pt;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;}
@page WordSection1
	{size:612.0pt 792.0pt;
	margin:72.0pt 72.0pt 72.0pt 72.0pt;
	mso-header-margin:36.0pt;
	mso-footer-margin:36.0pt;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>






Same day last mile parcels delivery services
are recently gaining a great deal of attention in the autonomous agents
community. In the Tel-Aviv metropolitan area, Gett and other companies provide
delivery services for small parcels using a scooters fleet.<span style="mso-spacerun:yes">&nbsp; </span>Scooter couriers deliver the parcels from the
local post offices to the final customers. Since a scooter has limited capacity
and is paid with respect to the total traveling distance, the problem can be
formulated as a Capacitated Open Vehicle Routing Problem (COVRP). The proposed
approach is based on the high sparseness of the Clarke-Wright (CW) saving matrix for
COVRP in case of parcels delivery from post offices. In this case the CW algorithm
can be separated to construction of all feasible Hamiltonian paths at the first
phase and its optimal combination at the second phase. Computational results
show that the proposed algorithm is competitive, over performs classical CW in the
Tel-Aviv metropolitan area by 42% on average and improves known benchmark
results on some instances.</p><p>





<br></p></td>
                </tr>
            
                <tr>
                    <td>636</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-636">Dynamic Traveling Repairmen Bounty Hunters</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Agent Cooperation] Multi-robot systems</td>
                    
                        <td>0.740</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_636" class="editable_bid" data-pk="636" data-value="30"
                    data-url="/rev_3/paper/bid/set/636/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-636"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Vehicle routing problems such as the multiagent Dynamic Traveling Repariman Problem (DTRP) are of interest to many fields and of increasing practical importance in light of advances in autonomous vehicles.&nbsp; DTRP is NP-hard, making approximation methods attractive.&nbsp; However current heuristic approaches do not adequately consider issues special to DTRP, such as fairness and variance, discontiguous-space scenarios, or approaches to equitably partitioning the task space.&nbsp; We tackle this problem in a novel way, using a multiagent task allocation technique loosely called <i>bounty hunting</i>.&nbsp; In bounty hunting, agents compete to perform tasks non-exclusively in return for reward, and rapidly learn which agents are more adept at various tasks than others, divvying up the task space.&nbsp; &nbsp; We demonstrate that bounty hunting can perform efficiently in discontiguous environments, and can improve the bias and variance of the system while minimally affecting average waiting time.&nbsp; We show that Bounty Hunting consistently performs as well as or statistically better than the current state-of-the-art heuristic, and is particularly good in large-scale scenarios.<br></p></td>
                </tr>
            
                <tr>
                    <td>476</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-476">A Generalised Method for Empirical Game Theoretic Analysis</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Behavioral game theory<br>[Economic Paradigms] Game Theory for practical applications<br>[Learning and Adaptation] Multiagent learning<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.740</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_476" class="editable_bid" data-pk="476" data-value="30"
                    data-url="/rev_3/paper/bid/set/476/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-476"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper provides theoretical bounds for empirical game theoretical analysis of complex multi-agent interactions. More precisely, we provide insights on the empirical, or meta game, showing that a Nash equilibrium of the meta-game is an approximate Nash equilibrium of the true underlying game. We provide insights on how many data samples are required to obtain a close enough approximation of the underlying game. Additionally, we extend the meta-game analysis methodology to asymmetric games. The state-of-the-art has only considered empirical games in which agents have access to the same strategy sets and the payoff structure is symmetric, implying that agents are interchangeable. Finally, we carry out an empirical illustration of the generalised method in several domains, illustrating the theory and evolutionary dynamics of several versions of the \textit{AlphaGo} algorithm (symmetric), the dynamics of the Colonel Blotto game played by human players on Facebook (symmetric), and an example of a meta-game in Leduc Poker (asymmetric), generated by the PSRO multi-agent learning algorithm.<br></p></td>
                </tr>
            
                <tr>
                    <td>577</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-577">Combating Behavioral Deviance via User Behavior Control</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Agent Theories and Models] Logic and Game Theory<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_577" class="editable_bid" data-pk="577" data-value="30"
                    data-url="/rev_3/paper/bid/set/577/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-577"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Compared to traditional behavioral deviance, online deviant behavior (like cyberbullying) is more likely to spread over online social communities since it is not restricted by time and space, and can occur more frequently and intensely. To control risks associated with the spread of deviant and anti-normative behavior, it is essential to understand online users’ reaction when they interact with other users. In this paper, we model online users’ behavior interaction as an evolutionary game on a graph and analyze users’ behavior dynamics under different network conditions. Based on this theoretical framework, we then investigate behavior control strategies that aim to eliminate behavioral deviance. Finally, we use a real world dataset from a social network to verify the accuracy of our model’s hypothesis.We also and test the performance of our behavior control strategy through simulations based on both real and synthetically generated data. The experimental results demonstrate that our behavior control methods can effectively eliminate the impact of bullying behavior even when the proportion of bullying messages is higher than 60%.</p></td>
                </tr>
            
                <tr>
                    <td>148</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-148">HIGHLIGHTS: Summarizing Agent Behaviors to People</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_148" class="editable_bid" data-pk="148" data-value="30"
                    data-url="/rev_3/paper/bid/set/148/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-148"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span id="docs-internal-guid-845b1209-9c0c-9dd0-f805-d5c9b062b001"></span></p><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><font face="Arial"><span style="font-size: 14.6667px; white-space: pre-wrap;">People increasingly interact with autonomous agents. This paper introduces and formalizes the problem of automatically generating a summary of an agent's behavior with the goal of increasing people's familiarity with the agent's capabilities and limitations. In contrast with prior approaches&nbsp; which developed methods for explaining a single decision made by an agent, our approach aims to provide users with a summary that describes the agent's behavior in different situations. We hypothesize that reviewing such summaries could help people in tasks such as choosing between agents or determining the level of autonomy to grant to an agent. We develop ``HIGHLIGHTS'', an algorithm that produces a summary of an agent's behavior by extracting important trajectories from simulations of the agent.&nbsp;</span></font><span style="font-size: 14.6667px; white-space: pre-wrap; font-family: Arial;">We conducted a human-subject experiment to evaluate whether HIGHLIGHTS summaries help people assess the capabilities of agents. Our results show that participants were more successful at evaluating the capabilities of agents when presented with HIGHLIGHTS summaries compared to baseline summaries, and rated them as more helpful. We also explore a variant of the HIGHLIGHTS algorithm which aims to increase the diversity of states included in the summary, and show that this modification further improves people's ability to assess agents' capabilities.</span></p></td>
                </tr>
            
                <tr>
                    <td>198</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-198">Diversity Constraints in Public Housing Allocation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_198" class="editable_bid" data-pk="198" data-value="30"
                    data-url="/rev_3/paper/bid/set/198/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-198"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The state of Singapore operates a national public housing program, accounting for over $80\%$ of its residential real estate. Singapore uses its housing allocation program to ensure ethnic diversity in its neighborhoods; it does so by imposing ethnic quotas: every ethnic group must not own more than a certain percentage in a housing project, thus ensuring that every neighborhood contains members from each ethnic group. However, imposing diversity constraints naturally results in some welfare loss. Our work studies the tradeoff between diversity and social welfare from the perspective of computational economics. We model the problem as a an extension of the classic assignment problem, with additional diversity constraints. While the classic assignment program is poly-time computable, we show that adding diversity constraints makes the problem computationally intractable; however, we identify a $\tfrac{1}{2}$-approximation algorithm, as well as reasonable agent utility models which admit poly-time algorithms. In addition, we study the {\em price of diversity}: this is the loss in welfare incurred by imposing diversity constraints; we provide upper bounds on the price of diversity as a function of natural problem parameters; next, we analyze public data from Singapore's Housing Development Board, and create a simulated framework testing the welfare loss due to diversity constraints in realistic large-scale scenarios.</p></td>
                </tr>
            
                <tr>
                    <td>676</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-676">Adaptive Stress Testing for Autonomous Vehicles</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Simulation techniques, tools and platforms<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Verification and Validation of Agent-based Systems] Testing of agent-based systems, including model-based testing<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_676" class="editable_bid" data-pk="676" data-value="30"
                    data-url="/rev_3/paper/bid/set/676/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-676"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="font-size:12.8px">A critical problem for autonomous 
vehicles is efficient safety validation in simulation. Naively sampling 
scenarios to find failures is intractable. This paper uses adaptive 
stress testing, a method for validating the safety of autonomous 
vehicles that perturbs stochastic elements in the environment in a 
directed way until the vehicle is involved in a collision. The problem 
of finding the most likely failure scenario can be modeled as a Markov 
decision process, and reinforcement learning algorithms can be used to 
efficiently solve the problem. We use Monte Carlo tree search (MCTS), 
which has been used previously to test aircraft collision avoidance 
systems. We also present a more scalable deep reinforcement learning 
approach and show that it can find more likely failure scenarios than 
MCTS while requiring fewer calls to the simulator. A simulation scenario
 involving a vehicle approaching a crosswalk is used to demonstrate the 
validity of the framework and the approaches used. However, the 
framework presented in this paper can be generalized to other scenarios,
 given appropriate models of the vehicle and the environment.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>369</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-369">Action Selection for Transparent Planning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Communication languages and protocols<br>[Agent Theories and Models] Cognitive models</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_369" class="editable_bid" data-pk="369" data-value="30"
                    data-url="/rev_3/paper/bid/set/369/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-369"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We introduce a novel framework to formalise and solve <i>transparent planning tasks</i>&nbsp;by executing actions selected in a suitable and timely fashion. A <i>transparent planning task</i>&nbsp;is defined as task where the objective of the agent is to communicate its true goal to observers, thereby making its intentions and its action selection <i>transparent</i>. We formally define and model these tasks as <i>Goal POMDP</i> where the state space is the Cartesian product of the states of the world and a given set of hypothetical goals. Action effects are deterministic in the world states of the problem but probabilistic in the observer's beliefs. Transition probabilities are obtained from making a call to a model-based plan recognition algorithm, which we refer to as an <i>observer stereotype</i>. We propose an action selection strategy via on-line planning that seeks actions to quickly convey the goal being pursued to an observer assumed to fit a given stereotype. In order to keep run-times feasible, we propose a novel model-based plan recognition algorithm that approximates well-known probabilistic plan recognition methods. The resulting on-line planner, after being evaluated over a diverse set of domains and three different observer stereotypes, is found to convey goal information faster than purely goal-directed planners.<br></p></td>
                </tr>
            
                <tr>
                    <td>700</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-700">New Algorithms for Inference in Graph Sequence Models</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Social networks<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_700" class="editable_bid" data-pk="700" data-value="30"
                    data-url="/rev_3/paper/bid/set/700/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-700"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Although the computational and statistical trade-offs for modeling single graphs are relatively well understood, extending such results to sequences of graphs is difficult. In this work, we propose two models for such sequences that capture: link persistence between nodes across time, and community persistence of each node across time. In the first model, we assume that the latent community of each node does not change, and in the second model we relax this assumption. For both models, we propose computationally efficient inference algorithms, which leverage community detection methods that work on single graphs. We provide simulation results validating their performance.<br></p></td>
                </tr>
            
                <tr>
                    <td>481</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-481">Diversified Strategies in Games: Learning and Properties</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logic and Game Theory<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_481" class="editable_bid" data-pk="481" data-value="30"
                    data-url="/rev_3/paper/bid/set/481/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-481"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><pre id="code" class="brush: ; plain-text" style="margin-bottom: 0px; padding: 10px;"><font color="#000000"><span style="font-size: 12px; white-space: pre-wrap;">In this work we consider online decision-making settings in which players have an additional constraint that at each time step they must play a diversified mixed strategy: one that does not put too much weight on any one action. This constraint is motivated by applications such as finance, routing, and resource allocation, in which one would like to limit the chance of catastrophic failure while still performing well in typical cases. We explore properties of diversified strategies in both zero-sum and general-sum games, and provide algorithms for minimizing regret within the family of diversified strategies as well as methods for using taxes or fees to guide standard regret-minimizing players towards diversified strategies. We also analyze equilibria produced by diversified strategies in general-sum games. We show that surprisingly, requiring diversification can actually lead to higher-quality equilibria, and give strong guarantees on both price of anarchy and the social welfare produced by regret-minimizing diversified agents. We additionally give algorithms for finding optimal diversified strategies in distributed settings where one must limit communication overhead.<br></span></font></pre></td>
                </tr>
            
                <tr>
                    <td>243</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-243">A normal modal logic for trust in the sincerity</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Trust and reputation<br>[Agent Theories and Models] Logics for agents and multi-agent systems</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_243" class="editable_bid" data-pk="243" data-value="30"
                    data-url="/rev_3/paper/bid/set/243/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-243"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In the field of multi-agent systems, as some agents may be not reliable or honest, a particular attention is paid to the notion of trust. There are two main approaches for trust: trust assessment and trust reasoning. Trust assessment is often realized with fuzzy logic and reputation systems which aggregate testimonies -- individual agents' assessments -- to evaluate the agents' global reliability. In the domain of trust reasoning, a large set of works focus also on trust in the reliability as for instance Liau's BIT modal logic where trusting a statement means the truster can believe it. However, very few works focus on trust in the sincerity of a statement -- meaning the truster can believe the trustee believes it. Consequently, we propose in this article a modal logic to reason about an agent's trust in the sincerity towards a statement formulated by another agent. We firstly introduce a new modality of trust in sincerity and then we prove that our system is sound and complete. Finally, we extend our notion of individual trust about the sincerity to shared trust and we show that it behaves like a KD system. <br><br></p></td>
                </tr>
            
                <tr>
                    <td>591</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-591">FActCheck: Keeping Activation of Fake News at Check</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Social networks<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_591" class="editable_bid" data-pk="591" data-value="30"
                    data-url="/rev_3/paper/bid/set/591/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-591"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The diffusion of fake news has become a crucial problem in recent years as social media have become prime sources of news, and the preferred mechanism for dissemination of&nbsp; opinions and ideas. To improve the reliability of content shared on social media, effective strategies for mitigating the diffusion of fake news are increasingly necessary. One way to battle the dissemination of fake news is to propagate the corresponding real news, since people who receive the real news in tandem with the fake news are less likely to believe in fake news. To achieve this goal, we propose to find a set of individuals of a pre-defined size to pass the real news to the maximum number of nodes in the network. They are likely to receive the fake news so that they can test its credibility, and when they propagate the corresponding real news, it is likely to reach a large number of individuals. This problem, termed Fake News Activation Checking (FActCheck), is fundamentally different from works for (i) preventing the spread of rumors by removing nodes or blocking edges, and (ii) competitive influence maximization in social networks, that have been well studied in the literature. We prove that FActCheck is NP-Hard with a monotone and submodular objective, leading to a polynomial time greedy algorithm (AFC) which provides (1-1/e-\epsilon)-approximation. We further optimize the runtime of AFC by developing a fast graph-pruning heuristic (RAFC) that performs as well as AFC in checking the spread of fake news. Our experiments on real-world networks demonstrate that our approach outperforms popular methods in social network analysis literature.</p></td>
                </tr>
            
                <tr>
                    <td>587</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-587">Combining Opinion Pooling and Evidential Updating for Multi-Agent Consensus</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Other<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_587" class="editable_bid" data-pk="587" data-value="30"
                    data-url="/rev_3/paper/bid/set/587/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-587"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The evidence available to a multi-agent system can take at least two distinct forms. There can be direct evidence from the environment resulting, for example, from sensor measurements or from running tests or experiments. In addition, agents also gain evidence from individuals in the population with whom they are interacting. We, therefore, envisage agents' beliefs as a probability distribution over a set of hypotheses of interest, which are update either on the basis of direct evidence using Bayesian updating, or by taking account of the probabilities of other agents using opinion pooling. This paper investigates the relationship between these two processes in a multi-agent setting. We show that pooling operators can provide a mechanism by which a limited amount of direct evidence can be efficiently propagated through a population of agents so that an appropriate consensus is reached. A number of axioms are introduced relating to the evidence preservation properties of pooling operators. In particular, we show that evidence preservation characterises the product pooling operator. We also consider possible Bayesian justifications for pooling operators in this context. Finally, we present simulation experiments which investigate the convergence properties of a parameterised family of operators with a range of evidence propagation strengths.<br></p></td>
                </tr>
            
                <tr>
                    <td>312</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-312">Data-driven Multiagent Email Generators</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Methodologies for agent-based systems<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_312" class="editable_bid" data-pk="312" data-value="30"
                    data-url="/rev_3/paper/bid/set/312/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-312"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Multi-agent simulation of communication is often required by network traffic generation systems for application testing and user training.&nbsp; This domain creates a set of constraints on the simulation components: the decision models must be distributed, the agent decisions must be data-driven, explainable, and configurable, and the resulting communication graphs must be measurably realistic.&nbsp; The methodology described here works within these constraints, and is developed on email communications.&nbsp; Topic modeling and named entity recognition on an email corpus create reusable templates for individual emails; topic inference and thread extraction creates email thread graphs which are then compiled into a distributed thread model; the email templates and thread models are then used by agents.&nbsp; Then, social network analysis measures compare system-generated with human-generated email data.<br></p></td>
                </tr>
            
                <tr>
                    <td>86</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-86">A Differential Privacy Mechanism with Network Effects for Crowdsourcing Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_86" class="editable_bid" data-pk="86" data-value="30"
                    data-url="/rev_3/paper/bid/set/86/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-86"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">In crowdsourcing systems, it is important for the crowdsource campaign initiator to incentivize users to share their data to produce
results of the desired computational accuracy. This problem becomes especially challenging when users are concerned about the
privacy of their data. To overcome this challenge, existing work
often aims to provide users with differential privacy guarantees to incentivize privacy-sensitive users to share their
data. However, this work neglects the network effect that a user
enjoys greater privacy protection when he aligns his participation behaviour with that of other users. To explore the network effect
and provide a differential privacy guarantee, we design PINE (Privacy Incentivization with Network Effects). PINE is a mechanism
that maximizes the initiator’s payoff while providing participating
users with privacy protections. Numerical simulations show that
PINE improves the initiator’s expected payoff by up to </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">40%</span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">, compared to a differential privacy mechanism that does not consider
this effect.&nbsp;</span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>445</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-445">An Optimal Rewiring Strategy for Reinforcement Social Learning in Cooperative Multiagent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_445" class="editable_bid" data-pk="445" data-value="30"
                    data-url="/rev_3/paper/bid/set/445/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-445"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">Multiagent coordination in cooperative multiagent systems <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">(MASs) has been widely studied in both fixed-agent repeated <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">interaction setting and the static social learning framework. <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">However, two aspects of dynamics in real-world multiagent <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">scenarios are currently missing in existing works. First, the <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">network topologies can be dynamic where agents may change <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">their connections through rewiring during the course of interactions. Second, the game matrix between each pair of agents <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">may not be static and usually not known as a prior. Both the <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">network dynamics and game uncertainty increase the coordination difficulty among agents. In this paper, we consider<br><span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">a multiagent dynamic social learning environment in which <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">each agent can choose to rewire potential partners and interact with randomly chosen neighbors in each round. We propose an optimal rewiring strategy for agents to select most <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">beneficial peers to interact with for the purpose of maximizing the accumulated payoff in repeated interactions. We empirically demonstrate the effectiveness and robustness of our <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">approach through comparing with benchmark strategies. The <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">performance of three representative learning strategies under <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">our social learning framework with our optimal rewiring are <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">investigated as well.</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><br style=" font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: -webkit-auto; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; "></span><br></p></td>
                </tr>
            
                <tr>
                    <td>311</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-311">Preference Elicitation with Interdependency and User Bother Cost</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Humans and Agents] Human-robot/agent interaction<br>[Humans and Agents] Agent-based analysis of human interactions<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_311" class="editable_bid" data-pk="311" data-value="30"
                    data-url="/rev_3/paper/bid/set/311/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-311"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Agent-based scheduling systems, such as automated systems that schedule meetings for users and systems that schedule smart devices in smart homes, require the elicitation of user preferences in order to operate in a manner that is consistent with user expectations. Unfortunately, interactions between such systems and users can be limited as human users prefer to not be overly bothered by such systems. As such, a key challenge is for the system to efficiently elicit key preferences without bothering the users too much.&nbsp;</p><p>To tackle this problem, we propose a cost model that models the cognitive or bother cost associated with asking a question. We incorporate this model into our iPLEASE system, an interactive preference elicitation system. iPLEASE represents a user's preferences as a matrix, called preference matrix, and uses heuristics to select, from a given set of questions, an efficient sequence of questions to ask the user such that the total bother cost incurred to the user does not exceed a given bother cost budget. The user's response to those questions will partially populate the preference matrix. It then performs an exact matrix completion via convex optimization to approximate the remaining preferences that are not directly elicited. We empirically apply iPLEASE on randomly-generated problems as well as on a real-world dataset for the smart device scheduling problem to demonstrate that our approach outperforms other non-trivial benchmarks in eliciting user preferences.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>722</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-722">Clustering Behavior to Recognize Subjective Beliefs in Human-Agent Teams</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Trust and reputation<br>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_722" class="editable_bid" data-pk="722" data-value="30"
                    data-url="/rev_3/paper/bid/set/722/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-722"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Trust is critical to the success of human-agent teams, and one of the critical antecedents to trust is transparency. To best interact with human teammates, an agent must be able to explain itself so that they understand its decision-making process. However, individual differences among human teammates require that the agent dynamically adjust its explanation strategy based on their current unobservable subjective beliefs. We therefore need methods by which an agent can recognize its teammates' subjective beliefs relevant to trust-building (e.g., their understanding of the agent's capabilities and process). We leverage a nonparametric method to enable an agent to use its history of prior interactions as a means for recognizing and predicting a new teammate's subjective beliefs. We first gather data combining observable behavior sequences with survey-based observations of typically unobservable perceptions. We then use a nearest-neighbor approach to identify the prior teammates most similar to the new one. We use these neighbors' responses to infer the likelihood of possible beliefs, as in collaborative filtering. The results provide insights into the types of beliefs that are easy (and hard) to infer from purely behavioral observations.</p></td>
                </tr>
            
                <tr>
                    <td>772</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-772">On the Shapley Value of Boolean Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Coalition formation (non-strategic)<br>[Economic Paradigms] Cooperative games: computation</td>
                    
                        <td>0.730</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_772" class="editable_bid" data-pk="772" data-value="30"
                    data-url="/rev_3/paper/bid/set/772/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-772"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The Shapley value is a fair method for dividing the payoff of a cooperative game. Computing the Shapley value is a \#P-complete problem; however, in few games, we can overcome this exponential time complexity and obtain efficient algorithms. Here, we study boolean function games, where the characteristic function of the cooperative game is a boolean function. For a read-once function game, we give an $O(n^4)$ time algorithm to find the Shapley value of all players. We also study the Banzhaf index of this problem, which is another method for dividing the payoff. Furthermore, we show that a slight relaxation of the read-once assumption leads to a \#P-complete problem, including a boolean game with a twice-read monotone function or a thrice-read monotone bipartite planar boolean function. We also study the parameterized complexity of boolean games. We define a new parameter called rooted treewidth and we find the Shapley value of a boolean game in time $O(2^r n^4)$, which is a generalization our previous algorithm. The model of boolean games is a general framework which is useful for many cooperative games in various fields.<br></p><p>Moreover, we assume the issue that sometime the boolean function is unknown at first, and we want to find it by looking at the payoff of some coalitions. For a depth three monotone read-once function, we present an algorithm that looks at the payoff of $O(n\log n)$ coalitions to reconstruct the function.</p></td>
                </tr>
            
                <tr>
                    <td>704</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-704">Real-time Prediction of Intermediate-horizon Automotive Collision Risk</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Simulation techniques, tools and platforms<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_704" class="editable_bid" data-pk="704" data-value="30"
                    data-url="/rev_3/paper/bid/set/704/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-704"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><font face="Arial"><span style="font-size: 14.6667px; white-space: pre-wrap;">Advanced collision avoidance and driver hand-off systems can benefit from the ability to accurately predict, in real time, the probability a vehicle will be involved in a collision within an intermediate horizon of 10 to 20 seconds. The rarity of collisions in real-world data poses a significant challenge to developing this capability because, as we demonstrate empirically, intermediate-horizon risk prediction depends heavily on high-dimensional driver behavioral features. As a result, a large amount of data is required to fit an effective predictive model. In this paper, we assess whether simulated data can help alleviate this issue. Focusing on highway driving, we present a three-step approach for generating data and fitting a predictive model capable of real-time prediction. First, high-risk automotive scenes are generated using importance sampling on a learned Bayesian network scene model. Second, collision risk is estimated through Monte Carlo simulation. Third, a neural network domain adaptation model is&nbsp; trained on real and simulated data to address discrepancies between the two domains. Experiments indicate that simulated data can mitigate issues resulting from collision rarity, thereby improving risk prediction in real-world data.</span></font><br></p></td>
                </tr>
            
                <tr>
                    <td>507</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-507">A New Algorithm for Allocating Temporally Constrained Tasks with Collision-Free Trajectories in Multi-Robot Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Agent Cooperation] Multi-robot systems</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_507" class="editable_bid" data-pk="507" data-value="30"
                    data-url="/rev_3/paper/bid/set/507/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-507"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><i>Multi-robot systems (</i>MRS<i>)</i> are a reference solution for many real-world applications of crucial practical importance, e.g. management of warehouses. Efficiently and dynamically assigning to robots tasks having deadlines, i.e. constraints on when the execution must take place, in such a way that some objective functions of interest (e.g. makespan, number of performed tasks, distance traveled) are optimized is perhaps one of the most fundamental primitives of such systems. Although the corresponding computational problem is known to be both NP–Hard and hard to approximate, few effective and practical solutions are known in the literature. However, none of them guarantees that collision-free trajectories are used by the robots under relatively general hypotheses.</p><p>In this paper, we present a new algorithm that is able to allocate tasks having deadlines while, at the same time, providing collision-free trajectories under more general assumptions. We provide an extensive experimental evaluation, conducted on meaningful synthetic datasets, to assess the effectiveness of the new approach and to show that it outperforms state-of-the-art methods in terms of quality of the computed solutions.</p></td>
                </tr>
            
                <tr>
                    <td>385</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-385">Opponent Modeling in Data Collection Game using Deep Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_385" class="editable_bid" data-pk="385" data-value="30"
                    data-url="/rev_3/paper/bid/set/385/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-385"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Data-collection Game (DCG) is proposed to model the scenario where a robotic agent needs to collect digital data in an environment containing an opponent. The opponent can disable the data-collecting agent and may use various strategies. Deep reinforcement learning is employed to train the data-collecting agent, where deep neural networks are used both to encode the agent's policy and to model the opponent's strategy. Four networks that model the opponent in various ways are proposed and evaluated. Experiments show explicit opponent modeling using a separate network greatly improves the performance of the data-collecting agent.</p></td>
                </tr>
            
                <tr>
                    <td>199</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-199">Gossip Gradient Descent</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Learning and Adaptation] Multiagent learning<br>[Agents and Mainstream Computing] P2P, web services, grid computing, IoT, HPC</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_199" class="editable_bid" data-pk="199" data-value="30"
                    data-url="/rev_3/paper/bid/set/199/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-199"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we consider a problem of learning a linear regression model distributively with a network of $N$ interconnected agents which receive private streaming data. Each agent (e.g., a mobile sensor) can deploy an online learning algorithm, e.g. stochastic gradient descent, to learn adaptively the regression model using its receiving private data. The goal is to devise an algorithm for each agent, under the constraint that each of them can communicate only with its neighboring agents based on a communication graph, to enable each agent converge to the true model with a performance comparable to that of the traditional centralized solution. We propose an algorithm called \emph{gossip gradient descent}, and establish $O\bigl ( \sqrt{\frac{\log t}{(1-\lambda_2)N t}}\bigr)$ convergence in expectation and mean square, where $\lambda_2$ is the second largest eigenvalue of the expected gossip matrix corresponding to the underlying communication graph, and $t$ is the time step of the algorithms. For the case when agents are privacy sensitive, we propose a differentially private variant of the algorithm, which achieves $\epsilon$-differential privacy and $O\bigl (\sqrt{\frac{\log^2 t }{\epsilon \cdot (1-\lambda_2)N t}}\bigr)$ convergence speed.</p></td>
                </tr>
            
                <tr>
                    <td>226</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-226">Learning Temporal Strategic Relationships using Generative Adversarial Imitation Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Deep learning<br>[Learning and Adaptation] Adversarial machine learning</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_226" class="editable_bid" data-pk="226" data-value="30"
                    data-url="/rev_3/paper/bid/set/226/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-226"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">This paper presents a novel framework for automatic learning of
complex strategies in human decision making. We observe temporal
relationships at the subtask level of expert demonstrations, and
determine the different strategies employed in order to successfully
complete a task. To capture the relationship between the subtasks
and the overall goal, we utilise two external memory modules, one
for capturing dependencies within a single expert demonstration,
such as the sequential relationship among different sub tasks, and
a global memory module for modelling task level characteristics
such as best practice employed by different humans based on their
domain expertise. Furthermore, we demonstrate how the hidden
state representation of the memory can be used as a reward signal
to smooth the state transitions, eradicating subtle changes. We
evaluate the effectiveness of the proposed model for an autonomous
highway driving application, where we demonstrate its capability
to learn different expert policies and outperform state-of-the-art
methods.&nbsp;</span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>422</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-422">Formalising Oughts and Practical Knowledge without Resorting to Action Types</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Agent Theories and Models] Logics for norms and normative systems<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_422" class="editable_bid" data-pk="422" data-value="30"
                    data-url="/rev_3/paper/bid/set/422/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-422"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We show how the logical modelling of puzzles concerning epistemic oughts, such as the ones put forward by Horty &amp; Pacuit and the Miner's Scenario by Parfit, are solved without introducing action types in the logical language. The problem of epistemic oughts is a fundamental one. Without exaggeration, we can say that the nature of the relation between agency, action, knowledge, and normativity is central to the understanding of responsibility, a main topic in Artificial Intelligence nowadays. In the setting we propose here, bringing together these four components of responsibility requires that we blend (1) a theory of action and agency, (2) a theory of knowledge / epistemic indistinguishability in action, and (3) deontic orderings along which we distinguish right from wrong. We will accomplish this by using <i>stit</i> theory and by lifting a deontic ordering over histories to the level of actions that an agent can knowingly perform. We compare the resulting definition for subjective (epistemic) oughts with Horty's definition of objective oughts. We will demonstrate our findings by modelling the Miner's Scenario and other examples.<br></p></td>
                </tr>
            
                <tr>
                    <td>40</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-40">Extending the Efficiency Improvement Advisor Concept to Deal with Certain Knowledge</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_40" class="editable_bid" data-pk="40" data-value="30"
                    data-url="/rev_3/paper/bid/set/40/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-40"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The efficiency improvement advisor can improve the quality of the emergent solutions created by self-organizing emergent multi-agent systems by identifying recurring tasks that the agents in the self-organizing system do not solve well. This knowledge is used to create exception rules for the appropriate agents that improve their task-fulfilling behaviour. In this paper, we present an extension to the advisor that allows it to use certain knowledge about future tasks in addition to the (somewhat uncertain) knowledge gained from the system history. By now creating groups of exception rules for each expected task, the self-organizing emergent system can achieve near optimal solutions for static problem instances and good solutions for a range of expected tasks, while still being able to deal with dynamic (and unpredicted) tasks, as shown by experiments in a pickup-and-delivery scenario.</p></td>
                </tr>
            
                <tr>
                    <td>769</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-769">StarCraft as a Testbed for Engineering Complex Distributed Systems Using Cognitive Agent Technology</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Engineering Multiagent Systems] Programming languages and frameworks for agents and multi-agent systems<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_769" class="editable_bid" data-pk="769" data-value="30"
                    data-url="/rev_3/paper/bid/set/769/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-769"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Multi-agent systems and cognitive agent technologies have been advocated as the next generation model for engineering complex, distributed systems, but there is no testbed available to demonstrate the added value of such systems. It has been argued that the evaluation of cognitive agent systems requires richer benchmark problems. We think that real-time strategy (RTS) games like StarCraft can offer such a testbed, as AI for RTS requires the design of complicated strategies for coordinating hundreds of units that need to solve a range of challenges (incl. long-term high-level planning but also short-term control of individual units). It also allows us to evaluate whether current agent technologies (infrastructures, tools, languages) are sufficient to live up to this challenge. RTS games moreover offer an opportunity to show the potential of cognitive agent technologies for addressing the challenges such environments provide, as multi-agent systems offer a combination of advanced reasoning and decision making capabilities with built-in communication mechanisms for coordination.</p><p>In this paper, we report on the design and development of the first multi-agent connector that provides full access to StarCraft (Brood War). We provide a new interface that is dedicated to a multi-agent approach by connecting each unit in the game to a cognitive agent. Our aim with such an interface is to provide a tool to the agent community for demonstrating the added value of cognitive technologies.</p><p>Two main challenges are addressed in this work. First, we decide on the right level of abstraction for unit control by means of agents, designing for instance the percepts that are available to units. Second, a sufficient level of performance needs to be ensured in order to allow a large variety of multi-agent implementations to be successful at tackling challenges of RTS AI. The resulting open-source connector readily supports the hundreds of agents that can come and go during the game. Based on the development of the connector and its initial use by 200 students, we already gained valuable insights such as the benefits of using publish-subscribe based messaging and the challenges of debugging large sets of agents.</p></td>
                </tr>
            
                <tr>
                    <td>364</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-364">Towards a &quot;Master Algorithm&quot; for Forming Faster Conventions On Various Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Self-organization<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agent Cooperation] Multi-robot systems<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_364" class="editable_bid" data-pk="364" data-value="30"
                    data-url="/rev_3/paper/bid/set/364/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-364"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p class="MsoNormal"><span style="font-size:10.5pt;font-family:&quot;Helvetica Neue&quot;;
mso-fareast-font-family:&quot;Times New Roman&quot;;mso-bidi-font-family:&quot;Times New Roman&quot;;
color:black;background:white">In this paper, we argue the importance of
developing a “Master Algorithm” that forms a faster social convention among
software agents on any network topology. We hypothesize that one possible
approach for building this “Master Algorithm” is to embed network awareness in
agent’s decision-making process. As a first step towards this algorithm, we
present a novel network aware convention formation (NACF) algorithm that equips
agents with network awareness to create faster conventions. In NACF, agents
have access to a battery of algorithms suitable for different network
topologies. We enrich this battery of convention algorithms by including some
existing state-of-the-art algorithms as well as by designing two new algorithms
for scale-free and planar topologies. NACF enables agents to use only local
information to predict the global network structure and choose the appropriate
convention algorithm to converge into a single convention at a faster rate. An
extensive simulation is done on different network topologies, both static and
dynamic, with varying network configurations. The results show that NACF
successfully forms convention on various network scenarios. We also identify
the limitations of NACF and provide insights for improvement.&nbsp;</span><span style="font-size:10.0pt;font-family:Times;mso-fareast-font-family:&quot;Times New Roman&quot;;
mso-bidi-font-family:&quot;Times New Roman&quot;"><o:p></o:p></span></p><p>






<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Revision>0</o:Revision>
  <o:TotalTime>0</o:TotalTime>
  <o:Pages>1</o:Pages>
  <o:Words>187</o:Words>
  <o:Characters>1071</o:Characters>
  <o:Company>University of Nebraska-Lincoln</o:Company>
  <o:Lines>8</o:Lines>
  <o:Paragraphs>2</o:Paragraphs>
  <o:CharactersWithSpaces>1256</o:CharactersWithSpaces>
  <o:Version>14.0</o:Version>
 </o:DocumentProperties>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>JA</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
   <w:UseFELayout/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="true"
  DefSemiHidden="true" DefQFormat="false" DefPriority="99"
  LatentStyleCount="276">
  <w:LsdException Locked="false" Priority="0" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 9"/>
  <w:LsdException Locked="false" Priority="35" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" Priority="10" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" Priority="11" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" Priority="22" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" Priority="59" SemiHidden="false"
   UnhideWhenUsed="false" Name="Table Grid"/>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" QFormat="true" Name="TOC Heading"/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:Times;
	panose-1:2 0 5 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"ＭＳ 明朝";
	mso-font-charset:78;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1791491579 18 0 131231 0;}
@font-face
	{font-family:"ＭＳ 明朝";
	mso-font-charset:78;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1791491579 18 0 131231 0;}
@font-face
	{font-family:Cambria;
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073743103 0 0 415 0;}
@font-face
	{font-family:"Helvetica Neue";
	panose-1:2 0 5 3 0 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-452984065 1342208475 16 0 1 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:Cambria;
	mso-ascii-font-family:Cambria;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:"ＭＳ 明朝";
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:Cambria;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-family:Cambria;
	mso-ascii-font-family:Cambria;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:"ＭＳ 明朝";
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:Cambria;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.25in 1.0in 1.25in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:Cambria;
	mso-ascii-font-family:Cambria;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Cambria;
	mso-hansi-theme-font:minor-latin;}
</style>
<![endif]-->



<!--StartFragment-->





<!--EndFragment--></p><p class="MsoNormal"><o:p>&nbsp;</o:p></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>258</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-258">Design of Coalition Resistant Credit Score Functions for  Online Discussion Forums</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_258" class="editable_bid" data-pk="258" data-value="30"
                    data-url="/rev_3/paper/bid/set/258/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-258"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Motivated by the need to design robust, trustworthy online discussion forums (ODFs), we design a manipulation resistant credit scoring function to assign scores to agents interacting on a typical ODF.<br>The setting we consider is that of an ODF where the agent utilities are determined by credit scores obtained by the agents in the form of popularity indicators such as upvotes, ratings, shares, and likes. Agents can potentially manipulate the credit scores by strategically awarding the popularity indicators to other agents in order to maximize their own credit score. We focus on a specific but very common form of manipulation, namely, coalition formation. We propose a credit function that discourages formation of coalition(s) by the<br>agents. Our idea is to design such a credit function with the use of community detection algorithms that find an agent set partition by maximizing a community detection metric. Our contribution is to find a characterization for coalition identifying community detection metrics and to show that one can design coalition resistant credit<br>functions with such a metric. In particular, we investigate the modularity metric and show that it is coalition identifying, and show that the proposed credit function with modularity metric is coalition resistant. We validate our theoretical findings with simulations on illustrative datasets.<br></p></td>
                </tr>
            
                <tr>
                    <td>527</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-527">Learning Policy Representations in Multiagent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_527" class="editable_bid" data-pk="527" data-value="30"
                    data-url="/rev_3/paper/bid/set/527/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-527"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">Modeling agent behavior is central to understanding the emergence of complex phenomena in multiagent systems. Prior work in
agent modeling has largely been task-specific and driven by hand-engineering domain-specific prior knowledge. In this work, we
propose a general learning framework for modeling agent behavior
in any multiagent system using only a few episodes of interaction data. Our framework casts agent modeling as a representation
learning problem. Consequently, we design a novel objective based
on imitation learning and agent identification for unsupervised
learning of representations of agent policies. We introduce criteria
for evaluating the generalization performance of the learned representations and design methods for using these representations in a
wide range of downstream tasks. We demonstrate empirically the
utility of the proposed representation learning algorithm on (i) a
challenging high-dimensional competitive environment for continuous control and (ii) a cooperative environment for communication
on supervised predictive tasks, unsupervised clustering, and policy
optimization using deep reinforcement learning.&nbsp;</span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>616</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-616">Timing Reliability for Local Schedulers in Multi-Agent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Simulation techniques, tools and platforms<br>[Agent-based Simulation] Other<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent-based Simulation] Validation of simulation systems</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_616" class="editable_bid" data-pk="616" data-value="30"
                    data-url="/rev_3/paper/bid/set/616/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-616"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In the last decades, the use of Multi-Agent Systems (MAS) resulted in being the most relevant approach to foster the development of systems performing distributed reasoning, automated/autonomous actions, and regulating component interactions in unpredictable and uncertain scenarios. The scientific community provided numerous innovative contributions about resource and task allocation seeking for optimal/sub-optimal solutions. The adoption of MAS in Cyber-Physical Systems (CPS) is producing outstanding results.</p><p>However, in current MAS, the actual task execution is still delegated to traditional general-purpose scheduling algorithms running within the agent (local scheduler of behaviors). The main consequence is the incapability to enforce compliance with strict timing constraints (i.e., the impossibility of providing any guarantee about the system's behavior in the worst-case scenario).&nbsp;</p><p>Therefore, the adoption of MAS is hampered, excluding significant application scenarios such as safety-critical environments. </p><p>This paper proposes the schedulability analysis of various tasks-sets, that are feasible using real-time schedulers, on top of traditional general-purpose solutions.&nbsp;</p><p>In particular, the study of deadline-missing rate occurring in general-purpose setups, evaluated on an agent-based simulator developed on OMNET++, is presented.</p><p>The obtained results strengthen the motivations for adopting and adapting real-time scheduling mechanisms as the local scheduler within agents.</p></td>
                </tr>
            
                <tr>
                    <td>666</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-666">Tractable Reasoning about Agent Programming in Dynamic Preference Logic</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Engineering Multiagent Systems] Modelling and specification languages</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_666" class="editable_bid" data-pk="666" data-value="30"
                    data-url="/rev_3/paper/bid/set/666/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-666"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>An interpretation of mental attitudes of a BDI programming language is given as a mapping of program states to a BDI logic. This mapping help us to understand how<br>the semantics of the constructs of the language relate to the<br>concepts of the BDI paradigm. While several BDI logic have been proposed for this effect, it is not clear how models in some of these logics can be connected to the agent programs they are supposed to specify. More yet, being based on modal logic, the reasoning problems in theses logics are not tractable in general, limiting their usage to tackle real-world problems. In this work, we use of Dynamic Preference Logic to provide a semantic foundation to BDI agent programming languages and investigate tractable expressive fragments of this logic to reason about agent programs. With that, we aim to provide a way of implementing semantically grounded agent programming languages with tractable reasoning cycles.<br></p></td>
                </tr>
            
                <tr>
                    <td>745</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-745">Privacy-preserving social choice methods for multiagent systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Economic Paradigms] Other</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_745" class="editable_bid" data-pk="745" data-value="30"
                    data-url="/rev_3/paper/bid/set/745/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-745"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Social choice provides methods for collective decisions. They include methods for voting and for aggregating rankings. These methods are used in multiagent systems for similar purposes when decisions are to be made by agents. Votes and rankings are sensitive information. Because of that, privacy mechanisms are needed to avoid the disclosure of sensitive information. <br><br>Cryptographic techniques can be applied in centralized environments to avoid the disclosure of sensitive information. A trusted third party can then compute the outcome. In distributed environments we can use a secure multiparty computation approach for implementing a collective decision method. Other privacy models exist as e.g. differential privacy and k-anonymity. They provide models that are complementary to multiparty computation approaches, and solutions that can be combined with the crytographic ones thus providing additional privacy guarantees. <br><br>In this paper we propose the use of probabilistic social choice methods to achieve differential privacy. We use the method called random dictatorship and prove that under some circumstances differential privacy is satisfied and propose a variation that is compliant with this privacy model. <br><br><br></p></td>
                </tr>
            
                <tr>
                    <td>272</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-272">Online Coalition Structure Generation in Graph Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Coalition formation (non-strategic)<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_272" class="editable_bid" data-pk="272" data-value="30"
                    data-url="/rev_3/paper/bid/set/272/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-272"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider the online version of the coalition structure generation in graph games problem, where agents are vertices in a graph. After each step $t$, in which the $t$-th agent appears in an online fashion, agents are partitioned into $c(t)$ coalitions $\clust(t)=\{\C_1^t, \C_2^t, \ldots, \C_{c(t)}^t \}$, such that every agent belongs to exactly one coalition $C_i^t$. When an agent appears, it may either join an existing coalition or form a new one having it as the only agent. The profit of a such a coalition structure $\clust(t)$ is the sum of the profits of its coalitions. We consider two cases for the profit of a coalition: (1) the sum of the weights of its edges (which represents the total profit of the agents in the coalition), and (2) the sum of the weights of its edges divided by its size (which represents the average profit of the agents in the coalition). Such coalition structures appear in a variety of application in AI, multi-agent systems, networks, as well as in social networks, data analysis, computational biology, game theory, and scheduling.</p><p>For each of the profit functions we consider the bounded and unbounded cases depending on whether or not the size of a coalition can exceed a given value $\alpha$. Furthermore, we consider the case of limited number of coalitions and various weight functions for the edges, namely the cases of unrestricted, positive and constant weights. We show tight or nearly tight bounds for the competitive ratio in each case.<br></p></td>
                </tr>
            
                <tr>
                    <td>306</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-306">Multi-Agent Norm Learning from Observations</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Normative systems<br>[Agent Cooperation] Multi-robot systems</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_306" class="editable_bid" data-pk="306" data-value="30"
                    data-url="/rev_3/paper/bid/set/306/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-306"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We study the problem of automatically identifying and learning a set of norms from observations in a multi-agent environment. We currently lack effective methods that (a) allow for an explicit context-sensitive norm representation, and (b) avoid making onerous assumptions about the individuals being observed. In this paper, we propose a Dempster-Shafer-based learning approach to address these challenges and evaluate the approach using multi-agent simulations.</p></td>
                </tr>
            
                <tr>
                    <td>41</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-41">Motor Fault Detection Based on Multi-Agent Classifier System</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Trust and reputation<br>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Verification and Validation of Agent-based Systems] Synthesis of agent-based systems</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_41" class="editable_bid" data-pk="41" data-value="30"
                    data-url="/rev_3/paper/bid/set/41/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-41"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal" style="text-align:justify;line-height:normal"><span style="font-size:12.0pt;font-family:&quot;Times New Roman&quot;,&quot;serif&quot;;mso-ascii-theme-font:
major-bidi;mso-hansi-theme-font:major-bidi;mso-bidi-theme-font:major-bidi">An
early detection of component faults is crucial for motors. In this paper, we
present a novel framework to detect and identify fault conditions of
three-phase induction motors using an ensemble of classifiers. The Q-Learning
Multi-Agent Classifier System (QMACS) is a multi-agent system, which uses the
trust-negotiation-communication (TNC) reasoning scheme. Hybrid models of the
Q-learning and online neural networks (NNs) are used as learning agents of the
multi-agent system. The effectiveness of QMACS for detecting and identifying
motor faults is evaluated through experiments. Time-domain statistical features
are extracted and fed into QMACS for classification. Experiment results
demonstrate that QMACS is able to achieve a superior performance with a
decision fusion of its constituents.<o:p></o:p></span></p></td>
                </tr>
            
                <tr>
                    <td>709</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-709">Recognizing Plans by Learning Embeddings from Observed Action Distributions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_709" class="editable_bid" data-pk="709" data-value="30"
                    data-url="/rev_3/paper/bid/set/709/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-709"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>

</p><p style="margin:0in;font-family:Calibri;font-size:11.0pt">Recent advances in
visual activity recognition have raised the possibility of applications such as
video surveillance. Effective approaches for such problems however require the
ability to recognize the plans of the agents from video information. Although
traditional plan recognition algorithms depend on access to sophisticated
domain models, one recent promising direction involves learning shallow models
directly from the observed activity sequences, and using them to
recognize/predict plans. One limitation of such approaches is that they expect
observed action sequences as training data. In many cases involving vision or
sensing from raw data, there is considerably uncertainty about the specific
action at any given time point. The most we can expect in such cases is
probabilistic information about the action at that point. The training data
will then be sequences of such observed action distributions. In this paper, we
focus on doing effective plan recognition with such uncertain observations. Our
contribution is a novel extension of word vector embedding techniques to
directly handle such observation distributions as input. This involves
computing embeddings by minimizing the distance between distributions (measured
as KL-divergence). We will show that our approach has superior performance when
the perception error rate (PER) is higher, and competitive performance when the
PER is lower. We will also explore the possibility of using importance sampling
techniques to handle observed action distributions with traditional word vector
embeddings. We will show that although such approaches can give good
recognition accuracy, they take significantly longer training time and their
performance will degrade significantly at higher perception error rate.</p><p>

<b></b><i></i><u></u><sub></sub><sup></sup><strike></strike><br></p></td>
                </tr>
            
                <tr>
                    <td>729</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-729">Collaborative Planning for Mixed-Autonomy Lane Changing</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Humans and Agents] Human-robot/agent interaction<br>[Humans and Agents] Agent-based analysis of human interactions</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_729" class="editable_bid" data-pk="729" data-value="30"
                    data-url="/rev_3/paper/bid/set/729/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-729"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span id="docs-internal-guid-f275bb16-a99d-6cc2-6a7e-e93911adf0ff"><span style="font-size: 10.5pt; font-family: Arial; vertical-align: baseline; white-space: pre-wrap;">Driving in traffic can be viewed as a challenging multi-agent non-zero-sum game. In this paper we consider mixed-autonomy traffic where autonomous and human-driven vehicles drive together. For this, we propose a planning framework to navigate the Autonomous Vehicle (AV) where its degree of cooperation with the other agents can be controlled. This degree determines the effect of the other agent’s goals on its actions. We test this approach in a finite length two-lane highway where the AV and human car attempt to merge into each other’s lanes. Our algorithm, with six cooperation factors, was evaluated in a user-study involving 21 participants in a simulation environment. The study showed that our approach was successful in the lane-changing task for most of the factors. We also found that the overall system performed better when the cooperation factor was used that fairly considered the goals of both the AV's and the human car.</span></span><br></p></td>
                </tr>
            
                <tr>
                    <td>499</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-499">An Other Regarding Preference Model for Group Recommendation: an Empirical Evaluation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Humans and Agents] Agent-based analysis of human interactions<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_499" class="editable_bid" data-pk="499" data-value="30"
                    data-url="/rev_3/paper/bid/set/499/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-499"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>		 	 	 		</p><div class="page" title="Page 1">			<div class="layoutArea">				<div class="column">					<p>		 	 	 		</p><div class="page" title="Page 1">			<div class="layoutArea">				<div class="column">					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">Group Recommendation Systems (GRSs) provide support to a group decision-making process by trying to suggest items that can be of interest to each group member. General approaches for GRSs start from the individual recommendations and merge them in a way to determine the best choice for the whole group. The results presented in the literature showed that traditionally aggregation techniques do not seem to capture all the features of real-world scenarios. Furthermore, recent studies in Behavioral Economics evidence the necessity to define utility models that are not compatible with the self-interested utility maximizing behavior of the traditional economic paradigm. In this work, starting from an Other-Regarding Preference model, we extend it in order to deal with the strength of the relationship and the presence of interpersonal conflicts. Furthermore, in order to define the magnitude of the two aspects on the proposed model, we conducted an experiment on the Amazon Mechanical Turk platform, using the results to derive the values of the model’s parameters. The conducted study evidenced that the agent’s utility, when in the presence of another agent, is strictly correlated with its utility, when it is considered alone, and also to the utility of the other agent. The model showed different behaviors in relation to the strength and the status of the relationship. This suggests that we can use different parameters for the model in relation to such factors characterizing the relationship.&nbsp;</span></p>				</div>			</div>		</div>				</div>			</div>		</div></td>
                </tr>
            
                <tr>
                    <td>100</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-100">Socially Friendly and Group Protecting Coalition Logics</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logic and Game Theory<br>[Agent Theories and Models] Logics for agents and multi-agent systems</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_100" class="editable_bid" data-pk="100" data-value="30"
                    data-url="/rev_3/paper/bid/set/100/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-100"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider extensions of Coalition Logic (CL) which can express statements about inter-related powers of coalitions to achieve their respective goals. In particular, we introduce and study two new extensions of CL. One of them is the ``Socially Friendly Coalition Logic'' SFCL, which is also a multi-agent extension of the recently introduced ``Instantial Neighborhood Logic'' INL. The logic SFCL can express the claim that a coalition has a collective strategy to guarantee achieving its explicitly stated goal while acting in a `socially friendly way', by enabling the remaining agents to achieve other (again, explicitly stated) goals of their choice. The other new extension is the ``Group Protecting Coalition Logic'' GPCL which enables reasoning about entire coalitional goal assignments, in which every group of agents has its own specified goal. &nbsp;GPCL can express &nbsp;claims to the effect that there is an action profile of the grand coalition such that, by playing it, every sub-coalition of agents can guarantee satisfaction of its own private goal (and thus, protect its own interests) while acting towards achievement of the common goal of the grand coalition. For each of these logics, we discuss its expressiveness, introduce the respective notion of bisimulation and prove bisimulation invariance and Hennessy-Milner property. We then also present sound and complete axiomatic systems and prove decidability for both logics.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>323</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-323">A Unified Framework for Opinion Dynamics</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Verification and Validation of Agent-based Systems] Synthesis of agent-based systems<br>[Agent-based Simulation] Social simulation<br>[Humans and Agents] Agent-based analysis of human interactions</td>
                    
                        <td>0.720</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_323" class="editable_bid" data-pk="323" data-value="30"
                    data-url="/rev_3/paper/bid/set/323/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-323"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span class="im"><p><span class="im">Opinion dynamics is the study of how large groups 
interact with one another and reach consensus, with applications to 
various areas such as computer networks, politics, and sociology. It is 
typically explored using agent-based modeling, with a wide variety of 
available models.</span></p><p><span class="im"><br></span><span class="im">Numerous opinion dynamics models have been 
proposed, but it has been pointed out that there is a lack of a shared 
framework. We extend earlier attempts and provide a unified framework. 
The advantages of such a framework include the reduction of duplication 
and the identification of unexplored parameter space.</span></p><p><span class="im"><br></span>Our framework is implemented in a modular simulator which is then used to verify the validity of the framework. We show that the modular approach we propose is able to perfectly replicate results from purpose-built, stand-alone simulators for two widely used models, namely Relative Agreement and CODA.</p></span></p><p><br></p></td>
                </tr>
            
                <tr>
                    <td>345</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-345">Incorporating Chorus Line Effect into A Cucker-Smale System for Fast Manoeuvre Tracking</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent Cooperation] Collective intelligence<br>[Agent Societies and Societal Issues] Self-organization<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_345" class="editable_bid" data-pk="345" data-value="30"
                    data-url="/rev_3/paper/bid/set/345/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-345"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>It has been observed empirically that a flock of birds is able to turn and change direction rapidly as a single unit.</p><p>The "chorus-line hypothesis'' was proposed in 1984 by Potts to explain this phenomenon.</p><p>It puts forward the idea that those birds that are further down the line from the initiator can predict the</p><p>movement from those nearer the initiator, thereby reducing their response time.</p><p>The same effect is observed in a human chorus-line.&nbsp;&nbsp;</p><p>This paper proposes an implementation of the chorus-line effect in a Cucker-Smale multiple agent system.</p><p>We study the time it takes for the rest of the agents to follow an abrupt change in direction executed by one of the flock members.</p><p>Through mathematical analysis and computer simulation, we found that the time required for this</p><p>kind of maneouvre tracking is indeed reduced compared with the standard Cucker-Smale model.&nbsp;</p><p>Moreover, it is more effective than using a finite-time controlled Cucker-Smale system that has been studied earlier.</p></td>
                </tr>
            
                <tr>
                    <td>378</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-378">C-C-C control strategy for systematic teamwork in multi-robot systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis<br>[Agent Cooperation] Multi-robot systems</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_378" class="editable_bid" data-pk="378" data-value="30"
                    data-url="/rev_3/paper/bid/set/378/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-378"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal" style="text-align:justify"><span style="font-size:12.0pt;
mso-bidi-font-size:11.0pt;line-height:115%">There is a considerable demand for
the use of multi-robot systems, due to characteristics such as flexibility,
robustness, scalability, parallelism, these systems are projected as novel
tools to help humans in hazardous activities such as humanitarian demining,
search and rescue, handling of dangerous materials, and others. However,
controlling the motion and behavior of large teams of robots is not a trivial
task. This paper presents a distributed control strategy based in
Consent-Coordination-Cooperation (CCC) to let robots describe teamwork
collective behaviours that could be useful in different applications. In the
current state of art there is no clear distinction between the role played by
coordination and cooperation, or the importance of conformity in the system,
but all these elements are essential to achieve collective teamwork. The
propose considers the so called consent variables whose values are defined for
the group of robots in a consensus way, then, those values are used for a
coordination mechanism to achieve commons means and efforts, and finally, the
cooperation is realized using local interactions and sharing information, in
consequence, the robots work together for the same purpose, by this way, the
team of robots work in a sistematic way&nbsp;
to solve a task. To validate the proposal, the <i>Robotarium</i> platform has
been used, showing the teamwork achieved in an orderly manner, by a group of
robots.<o:p></o:p></span></p></td>
                </tr>
            
                <tr>
                    <td>222</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-222">Pricing lottery outcomes via conditional posted prices -- evidences from ride-sharing and beyond</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Behavioral game theory<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_222" class="editable_bid" data-pk="222" data-value="30"
                    data-url="/rev_3/paper/bid/set/222/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-222"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>How to price a lottery, i.e., a randomized outcome, has been one of the central research agendas in economics and decision theory. Recently, the problem has become even more important due to the emergence of sharing economies. For example, in a typical ride-sharing context, a passenger may end up with riding a car alone or sharing the car with another passenger, with a posted price paid upfront to the trip. Such an ex ante posted price is simple in design and thus prevalently adopted by most ride-sharing applications. In this paper, we explore the possibility of pricing a lottery using the so-called conditional posted pricing, a pricing scheme that prices separately each possible realization of the lottery. Independent of the ride-sharing context, we first show in theory that the conditional posted pricing strictly dominates the ex ante posted pricing in the sense that it increases the expected utility of the agents without decreasing their expected payments, under certain reasonable conditions. We then validate our theory both in a questionnaire survey and in an online field experiment based on a major ride-sharing platforms. Both the survey and the online field experiment confirm our proposed theory. In addition, we show how to find the conditional posted price in order to achieve the maximum expected utility of each agent, under some further conditions.<br></p></td>
                </tr>
            
                <tr>
                    <td>193</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-193">Pushing the Frontier in Exploratory Learning for Extending the Range of Delivery Drones</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Verification and Validation of Agent-based Systems] Other<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agent Cooperation] Multi-robot systems</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_193" class="editable_bid" data-pk="193" data-value="30"
                    data-url="/rev_3/paper/bid/set/193/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-193"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Delivery drones have a fairly short range due to their lim- ited battery life. We propose to use learning techniques to ex- tend the range of drones by taking advantage of buildings and structures in urban environments. This paper describes new exploration strategies to generate paths for a drone to reach its destination while learning about the energy consumption on each edge on its path in order to optimize its range for future missions. We evaluated the performance of our exploration strategies in finding the set of all reachable destinations in a city, and found that exploring locations near the boundary of the reachable sets according to the current energy model can speed up the learning process.<br></p></td>
                </tr>
            
                <tr>
                    <td>209</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-209">Smoother bidding strategy for dynamic reservation values</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_209" class="editable_bid" data-pk="209" data-value="30"
                    data-url="/rev_3/paper/bid/set/209/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-209"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="color: rgb(51, 51, 51); font-family: monospace; font-size: 14.16px; text-size-adjust: auto; background-color: rgb(253, 252, 250);">Negotiation is an important component of interaction process among humans. With increasing automation, autonomous agents are expected to take over a lot of this interaction process. Much of automated negotiation literature focuses on agents having static and known reservation values. In many situations involving dynamic environments e.g., an agent negotiating on behalf of human regarding a meeting or a pair of automated vehicles in traffic negotiating for a section of road can have reservation values that vary with time. This throws up a different set of challenges that may need additional reasoning about the concession behavior. In this paper, we build upon the ONAC (Optimal Non-Adaptive Concession) strategy which uses amount of time to deadline as a primary criteria to influence the concession behavior of a negotiating agent. The ONAC strategy works on settings where the reservation value of the agent is fixed and known. Although the ONAC strategy can encode dynamic reservation values as we demonstrate in this paper, it may not make for a smoothly conceding agent. We therefore propose the ONAC-S (Optimal Non-Adaptive Concession with Smoothing) strategy that attenuates the fluctuations in bidding i.e. smoothens the bidding strategy so negotiators (esp. human negotiators) can feel that they are part of a rational negotiation. In particular, we propose to use one of Counter, Exponential or Bayesian Learning with Regression Analysis on top of ONAC to develop the ONAC-S strategy. We then use a poly-fit function to identify the best fit curve and compute the RSS as a measure of smoothness. Using this procedure, our experiments could show that ONAC-S indeed provides a much smoother negotiation compared to ONAC.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>271</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-271">An Observation Dimension-Weighted U-Tree Algorithm</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_271" class="editable_bid" data-pk="271" data-value="30"
                    data-url="/rev_3/paper/bid/set/271/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-271"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span lang="EN-US" style='margin: 0px; font-family: "Calibri",sans-serif; font-size: 10.5pt;'>Instance-based
methods are a class of effective algorithms for solving reinforcement learning
problems. U-Tree algorithm presents the state space from instance chains
effectively, which is very beneficial to solve the reasonable Q-value of
actions. However, the complexity of the construction of suffix tree in U-Tree
algorithm is exponential. A new observation dimension-weighted algorithm
ODWU-Tree for optimizing the expansion of fringe of suffix tree is presented in
the paper. ODWU-Tree algorithm obtains the heuristic information of
environments by simple heuristic exploration, evaluates the weight coefficient
of observation dimensions, and expands the fringes by the most important
observation dimensions for reasonable leaf state. Experiment results of New
York Driving show that both the efficiency and the effect have been improved significantly
by ODWU-Tree algorithm compared to U-Tree algorithm.</span><b></b><i></i><u></u><sub></sub><sup></sup><strike></strike><br></p></td>
                </tr>
            
                <tr>
                    <td>68</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-68">A Kinetic Model of the Dynamics of Compromise in Large Multi-Agent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent Societies and Societal Issues] Social networks<br>[Agent-based Simulation] Social simulation<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_68" class="editable_bid" data-pk="68" data-value="30"
                    data-url="/rev_3/paper/bid/set/68/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-68"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><div>Compromise is one of the primary phenomena that govern the dynamics of the opinion in multi-agent systems. In this paper, compromise is isolated from other phenomena, and it is studied using a statistical framework designed to investigate collective properties of large multi-agent systems. The proposed framework is completed with the details needed to model compromise, and differential problems that describe the dynamics of the opinion under suitable hypotheses are presented. Long-time asymptotic solutions of obtained differential problems are discussed to confirm that compromise makes multi-agent systems tend to reach consensus. It is proved that compromise make all agents tend to share the same opinion, and that the value of the asymptotic opinion can be expressed in terms of the initial distribution of the opinion and of other characteristics of the multi-agent system. Obtained analytic results are confirmed by independent simulations in exemplificative cases.</div></td>
                </tr>
            
                <tr>
                    <td>494</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-494">Design of Influencing Agents to Aid Flock Formation in Low-Density Settings</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent Cooperation] Biologically-inspired approaches and methods</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_494" class="editable_bid" data-pk="494" data-value="30"
                    data-url="/rev_3/paper/bid/set/494/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-494"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Flocking is a coordinated collective behavior that results from local sensing between individual agents who have a tendency to orient towards each other. Flocking is common amongst animal groups and could also be useful in robotic swarms. In the interest of learning how to control flocking behavior, several pieces of recent work in the multiagent systems literature have explored the use of influencing agents for guiding flocking agents to face a target direction. However, the existing work in this domain has focused on simulation settings of small areas with toroidal shapes. In such settings, agent density is high, so interactions are common, and flock formation occurs easily. In our work, we study new environments with lower agent density, wherein interactions are more rare. We study the efficacy of placement strategies and influencing agent behaviors drawn from the literature, and find that the behaviors that have been shown to work well in high-density conditions tend to be much less effective in the environments we introduce. The source of this ineffectiveness is a tendency of influencing agents explored in prior work to face directions intended for maximal influence that actually separate the influencing agents from the flock. We find that in low-density conditions maintaining a connection to the flock is more important than rushing to orient towards the desired direction. We use these insights to propose new placement strategies and influencing agent behaviors that overcome the difficulties posed by our new environments. The best influencing agents we identify act like normal members of the flock to achieve positions that allow for control, and then exert their influence. We dub this strategy "follow-then-influence."</p></td>
                </tr>
            
                <tr>
                    <td>725</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-725">Population-based incremental learning for optimal coalition generation on smart grids</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Coalition formation (non-strategic)<br>[Agent Cooperation] Collective intelligence<br>[Economic Paradigms] Cooperative games: computation<br>[Agent Cooperation] Multi-robot systems</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_725" class="editable_bid" data-pk="725" data-value="30"
                    data-url="/rev_3/paper/bid/set/725/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-725"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="color: rgb(33, 33, 33); font-size: 10pt;">Coalition structure
generation&nbsp;has long been a&nbsp;challenging problem in multi-agent systems
and cooperative game theory because of its&nbsp;NP-hardness in computational
complexity. In this paper, we propose a stochastic optimization approach using
a modified&nbsp;Population Based Incremental Learning (PBIL) algorithm with
top-k merit weighting to find&nbsp;the&nbsp;optimal coalition structure for
smart grids. Empirical results show that the proposed algorithm gives
competitive performance compared with state-of-the-art&nbsp;solutions such
as&nbsp;genetic algorithm and&nbsp;dynamic programming.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>365</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-365">A Learning and Masking Approach to Secure Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Deep learning<br>[Learning and Adaptation] Adversarial machine learning</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_365" class="editable_bid" data-pk="365" data-value="30"
                    data-url="/rev_3/paper/bid/set/365/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-365"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Deep Neural Networks (DNNs) have been shown to be vulnerable against adversarial examples, which are data points cleverly constructed to fool the classifier. Such attacks can be devastating in practice, especially as DNNs are being applied to ever increasing critical tasks like image recognition in autonomous driving. In this paper, we introduce a new perspective on the problem. We do so by first defining robustness of a classifier to adversarial exploitation. Next, we show that the problem of adversarial example generation can be posed as learning problem. We also categorize attacks in literature into high and low perturbation attacks; well-known attacks like FGSM and also out attack produce higher perturbation adversarial examples while the more potent but computationally inefficient Carlini-Wagner (CW) attack is low perturbation. Next, we show that the dual approach of the attack learning problem can be used as a defensive technique that is effective against high perturbation attacks. Last but not the least, we show that a classifier masking method achieved by adding noise to the a neural network's logit output protects against low distortion attacks such as the Carlini-Wagner attack. We also show that both our learning and masking defense can work simultaneously to protect against many attacks. We demonstrate the efficacy of our techniques by experimenting with the MNIST and CIFAR-10 datasets.<br></p></td>
                </tr>
            
                <tr>
                    <td>48</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-48">Privacy Sensitive Environment Re-Decomposition for Junction Tree Agent Organization Construction</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Agent Societies and Societal Issues] Organisations and institutions<br>[Agent Societies and Societal Issues] Self-organization<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_48" class="editable_bid" data-pk="48" data-value="30"
                    data-url="/rev_3/paper/bid/set/48/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-48"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>A number of frameworks for decentralized probabilistic reasoning, constraint reasoning,&nbsp;</p><p>and decision theoretic reasoning assume a junction tree (JT) agent organization.</p><p><span style="white-space:pre">	</span>A natural decomposition of agent environment may not admit a JT organization.</p><p><span style="white-space:pre">	</span>Hence, re-decomposition of the environment is necessary.</p><p><span style="white-space:pre">	</span>Unfortunately, re-decomposition incurs loss of agent privacy&nbsp;</p><p>that ultimately translates to loss of intellectual property of agent suppliers.</p><p><span style="white-space:pre">	</span>Few work is known to protect agent privacy during JT organization construction.</p><p><span style="white-space:pre">	</span>We propose a novel algorithm suite DAER that re-decomposes the environment</p><p>to enable a JT organization, while minimizing agent privacy loss by a greedy approach.</p><p><span style="white-space:pre">	</span>Advantage of DAER over alternative methods includes that it does not suffer from&nbsp;</p><p>any privacy loss on private variables.<span style="white-space:pre">	</span></p><p><span style="white-space:pre">	</span>Formal analysis as well as empirical evaluation of DAER are reported.</p></td>
                </tr>
            
                <tr>
                    <td>501</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-501">Learning and Updating User Models for Subpopulations in Persuasive Argumentation Using Beta Distributions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Argumentation-based dialogue and protocols<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_501" class="editable_bid" data-pk="501" data-value="30"
                    data-url="/rev_3/paper/bid/set/501/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-501"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Persuasion is an activity that involves one party (the persuader) trying to induce another party (the persuadee) to believe or do something. It is an important and multifaceted human facility both in professional life (e.g., a doctor persuading a patient to give up smoking) and everyday life (e.g., some friends persuading another to join them in seeing a film). Recently, some proposals in the field of computational models of argument have been made for probabilistic models of what the persuadee knows about, or believes. However, they cannot efficiently model uncertainty on the belief of individuals and cannot represent populations. We propose to use mixtures of beta distributions and apply them on real data gathered by linguists. We show that we can represent the belief and its uncertainty using beta mixtures and that we can predict the evolution of this belief after an argument is given. We also present examples of how to use the mixtures in practice to replace general belief update functions.</p></td>
                </tr>
            
                <tr>
                    <td>410</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-410">The Dynamics of Opinion Evolution in Gossiper-Media Model with WoLS-CALA Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_410" class="editable_bid" data-pk="410" data-value="30"
                    data-url="/rev_3/paper/bid/set/410/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-410"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="font-family: verdana, arial, helvetica; font-size: small;">In social networks, media outlets such as TV, newspapers, blogs adjust their opinions to cater to the public's interest to increase the number of followers. Meanwhile, the evolution of the public's opinions are affected by both the media and the peers they interact with. In this work, we investigate how the interactions between mainstream media affect the dynamics of the public's opinions in social networks. We propose a reinforcement learning framework to model the interactions between the public (aka gossipers) and the media agents. We model each gossiper as an individually rational agent, which updates its opinion using the Bounded Confidence Model (BCM). Each media agent is interested in maximizing the number of following gossipers competitively, and an adaptive WoLS-CALA (Win or Learn Slow Continuous Action Learning Automaton) algorithm is proposed to achieve that goal. We theoretically prove that WoLS-CALA can guarantee convergence towards Nash equilibria for any two-agent games with continuous action space. Besides, the opinion dynamics of both gossipers and media are theoretically analyzed. Extensive empirical simulation reveals the opinion dynamics of our framework facilitates the consensus of opinions and confirms the theoretical analysis.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>630</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-630">Capacity-aware Sequential Recommendations</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_630" class="editable_bid" data-pk="630" data-value="30"
                    data-url="/rev_3/paper/bid/set/630/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-630"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Personalized recommendations are increasingly important to engage users and guide them through large systems, for example when recommending points of interest to tourists visiting a popular city. To maximize long-term user experience it is imperative to consider issuing a sequence of recommendations, given that by observing the user's response to a recommendation, the recommender system can update its estimate of the user's (latent) interests. However, when considering a large number of users and capacity limits (e.g., maximum attendance of a museum), the recommender system should not only consider the users' interests, but also the effect of recommendations on the available capacity.<br><br>The structure in such a constrained, multi-agent, partially observable decision problem can be exploited by a novel belief-space sampling algorithm which bounds the size of the state space by a limit on regret. This algorithm is significantly more scalable than state-of-the-art approximate POMDP planners. Moreover, by explicitly considering the information value of actions, this algorithm significantly improves the quality of recommendations over an extension of Thompson sampling to the multi-agent, constrained case. We show how&nbsp; constraint satisfaction can be decoupled from sequential recommendation policies, resulting in algorithms that compute recommendations for thousands of agents while respecting capacity limits.<br><br></p></td>
                </tr>
            
                <tr>
                    <td>544</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-544">But-for causality revisited</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Verification and Validation of Agent-based Systems] Testing and debugging multiagent programs</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_544" class="editable_bid" data-pk="544" data-value="30"
                    data-url="/rev_3/paper/bid/set/544/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-544"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Using the Halpern-Pearl framework for causal modelling, the paper formalises the generalised but-for test, according to which X is a cause of Y if Y would not have happened <i>in the way it did</i> but for X. The resulting notion of causality is shown to be more permissive about what counts as a contributing cause than existing definitions of causality in the HP framework. The paper then proposes some natural restrictions on counterfactual reasoning within the HP framework, which prevent the generalised but-for test from becoming too permissive when applied to structural equations. A unique causal theory that can be computed effectively is shown to satisfy the restrictions. The paper argues that this theory does better than existing definitions of causality on problematic examples, especially when the theory is used to assign causal responsibility to individuals for effects brought about by a collective.</p></td>
                </tr>
            
                <tr>
                    <td>124</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-124">Optimal Constraint Collection for Core-selecting Path Mechanism</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Cooperative games: computation</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_124" class="editable_bid" data-pk="124" data-value="30"
                    data-url="/rev_3/paper/bid/set/124/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-124"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p abs_visibility="true">
		
	
	
		</p><div title="Page 1" class="page">
			<div class="layoutArea">
				<div class="column">
					<p><span style='font-family: "LinLibertineT"; font-size: 9pt;'>In path auctions, strategic bidders make bids for commodities. Each
edge of the graph stands for a commodity and the weight on the
edge represents the prime cost. Auctioneer needs to purchase a
sequence of edges in order to get a path from one vertex to another at a low cost. Path auctions can be considered as a kind of
combinatorial reverse-auctions. Computing prices in core-selecting
combinatorial auctions is a computationally hard problem, the same
is true in core-selecting path auctions. This problem can be solved
by core constraint generation(CCG) algorithm. However, we  nd
that there are many redundant constraints and the constraint col-
lection can be conciser in core-selecting path mechanism. In this
paper, </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>1</span><span style='font-family: "txsys"; font-size: 9pt;'>) </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>we put forward a new approach to get the constraint collection, and reduce the constraint number from exponential </span><span style='font-family: "LinLibertineI"; font-size: 9pt;'>O </span><span style='font-family: "txsys"; font-size: 9pt;'>(</span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>2</span><span style='font-family: "LinLibertineI7"; font-size: 7pt; vertical-align: 3pt;'>n </span><span style='font-family: "txsys"; font-size: 9pt;'>)
</span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>to polynomial </span><span style='font-family: "LinLibertineI"; font-size: 9pt;'>O</span><span style='font-family: "txsys"; font-size: 9pt;'>(</span><span style='font-family: "LinLibertineI"; font-size: 9pt;'>n</span><span style='font-family: "LinLibertineT"; font-size: 7pt; vertical-align: 3pt;'>2</span><span style='font-family: "txsys"; font-size: 9pt;'>)</span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>, where </span><span style='font-family: "LinLibertineI"; font-size: 9pt;'>n </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>is the network diameter; </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>2</span><span style='font-family: "txsys"; font-size: 9pt;'>) </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>we prove
that the new constraint collection is not only equivalent to the original collection, but also has no redundant constraint in the worst
case; </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>3</span><span style='font-family: "txsys"; font-size: 9pt;'>) </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>we validate our approach on real-world datasets and obtain
excellent results. Furthermore, we provide new insights to think
over the core-selecting mechanism in combinatorial auctions.&nbsp;</span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>149</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-149">A Natural Language Text Interface for Increased Situation Awareness of Remote Autonomous Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Humans and Agents] Human-robot/agent interaction<br>[Humans and Agents] Other</td>
                    
                        <td>0.710</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_149" class="editable_bid" data-pk="149" data-value="30"
                    data-url="/rev_3/paper/bid/set/149/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-149"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Autonomous systems are designed to carry out activities without the need for operators to micro-manage them. It is, however, essential that operators maintain situation awareness in order to monitor vehicle status and unforeseen circumstances that may affect their intended behaviour, such as a change in the environment. The Anon-Brand autonomy framework is a vehicle-agnostic platform supporting multi-vehicle missions, primarily for Autonomous Underwater Vehicles (AUVs). We have combined this C2 interface with a novel approach of interacting with the vehicle through a natural language chat interface. ANON-NEW-SYS offers a fluid and natural way for operators to gain information on vehicle status and faults, mission and objectives status and to set reminders. We describe the system and an evaluation study providing evidence that such an interactive multimodal interface can assist in maintaining situation awareness for operators of autonomous systems.<br></p></td>
                </tr>
            
                <tr>
                    <td>701</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-701">Execution Skill Estimation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_701" class="editable_bid" data-pk="701" data-value="30"
                    data-url="/rev_3/paper/bid/set/701/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-701"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In domains with continuous action spaces, one important characteristic of an agent is their precision in executing intended actions. An agent's execution skill has a large impact on their success as it determines how much executed actions deviate from intended actions. We introduce the problem of estimating an agent's execution skill level in domains with continuous action spaces, given only observations of their executed actions. The main difficulty is that while executed actions are observed, the intended actions are not observed, and therefore the amount of action deviation due to imperfect execution skill is not obvious. We explore this problem in a simple experimental domain with continuous actions that contains the essential features that make the problem challenging. We first introduce a naive method for this domain that focuses on estimating the long-term average reward of the agent which can then be used to estimate the agent's execution skill level. We then present a novel method that is able to accurately estimate the execution skill of a perfectly rational agent and show experimentally that it is more accurate than the naive estimator with limited observations. Finally, these results are experimentally validated in an actual domain that features imperfect execution skill, the game of computational billiards.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>277</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-277">Faster Policy Adaptation in Environments with Exogeneity: A State Augmentation Approach</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_277" class="editable_bid" data-pk="277" data-value="30"
                    data-url="/rev_3/paper/bid/set/277/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-277"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The reinforcement learning literature typically assumes fixed state transition functions for the sake of tractability. However, in many real-world tasks, the state transition function changes over time, and this change may be governed by exogenous variables outside of the control loop. This can make policy learning difficult. In this paper, we propose a new algorithm to address the aforementioned challenge by embedding the state transition functions at different timestamps into a Reproducing Kernel Hilbert Space; the exogenous variable, as the cause of the state transition evolution, is estimated by projecting the embeddings into the subspace that preserves maximum variance. By augmenting the observable state vector with the estimated exogenous variable, standard RL algorithms such as Q-learning are able to learn faster and better. Experiments with both synthetic and real data demonstrate the superiority of our proposed algorithm over standard and advanced variants of Q-learning algorithms in dynamic environments.<br></p></td>
                </tr>
            
                <tr>
                    <td>684</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-684">Multiagent Bidirectionally-Coordinated Nets in Playing Startcraft Micro Combat Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_684" class="editable_bid" data-pk="684" data-value="30"
                    data-url="/rev_3/paper/bid/set/684/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-684"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Many artificial intelligence (AI) applications often require multiple intelligent agents to work in a collaborative effort. Efficient learning for intra-agent communication and coordination is an indispensable step towards general AI. In this paper, we take StarCraft combat game as a case study, where the task is to coordinate multiple agents as a team to defeat their enemies. To maintain a scalable yet effective communication protocol, we introduce a Multiagent Bidirectionally-Coordinated Network (BiCNet) with a vectorised extension of actor-critic formulation.&nbsp; We show that BiCNet can handle different types of combats with arbitrary numbers of AI agents for both sides. Our analysis demonstrates that without any supervisions such as human demonstrations or labelled data, BiCNet could learn various types of advanced coordination strategies that have been commonly used by experienced game players. In our experiments, we evaluate our approach against multiple baselines under different scenarios; it shows state-of-the-art performance, and possesses potential values for large-scale real-world applications.<br></p></td>
                </tr>
            
                <tr>
                    <td>166</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-166">Information Design in Crowdfunding under Thresholding Policies</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Behavioral game theory</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_166" class="editable_bid" data-pk="166" data-value="30"
                    data-url="/rev_3/paper/bid/set/166/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-166"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In crowdfunding,&nbsp; an entrepreneur often has to decide how to disclose the campaign status in order to collect as many contributions as possible.&nbsp; We propose information design as a tool to help the entrepreneur to improve revenue by influencing backers' beliefs. We introduce a heuristic algorithm to dynamically compute information-disclosure policies for the entrepreneur, followed by an empirical evaluation to demonstrate its competitiveness over the widely-adopted immediate-disclosure policy. Our results demonstrate that despite its ease of implementation, the immediate-disclosure policy is not optimal when backers follow thresholding policies. With appropriate heuristics, an entrepreneur can benefit from dynamic information disclosure. Our work sheds light on information design in a dynamic setting where agents make decisions using thresholding policies.<br></p></td>
                </tr>
            
                <tr>
                    <td>90</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-90">Modeling behaviours to extend contextual goal models for self-adaptive systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Engineering Multiagent Systems] Modelling and specification languages<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_90" class="editable_bid" data-pk="90" data-value="30"
                    data-url="/rev_3/paper/bid/set/90/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-90"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><span style=" color:#000000;">The adaptation of self-adaptive systems is caused by context changes, leading to changes of the software behaviours. The missing control of context may lead to unforeseen changes of system. Many proposals rely on variants of goal models to support monitoring and adaptation functions. Contextual goal models consider the effect of context on reconfiguring system to reach requirements and quality measures. They serve as mechanisms in terms of how systems decide to make strategy and rationale of adaptive system. We argue that existing proposals do not consider the influence the runtime system behaviours on context. In this paper, we provide a different description of software behaviours for extending goal model that may be applied to self-adaptive systems. Software behaviours are </span><span style=" text-decoration: underline; color:#000000;">modeled</span><span style=" color:#000000;"> and </span><span style=" text-decoration: underline; color:#000000;">analyzed</span><span style=" color:#000000;"> along with changes and uncertainty of self-adaptive systems. We develop an operations semantics corresponding to the extend model and demonstrate on a detailed smart airport manage scenario.</span><span style=" color:#000000;"></span></td>
                </tr>
            
                <tr>
                    <td>108</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-108">Controlling Elections through Social Influence</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_108" class="editable_bid" data-pk="108" data-value="30"
                    data-url="/rev_3/paper/bid/set/108/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-108"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Election control considers the problem of an adversary who attempts to tamper with a voting process, in order to either ensure that their favored candidate wins (constructive control) or another candidate loses (destructive control). As online social networks have become significant sources of information for potential voters, a new tool in an attacker's arsenal is to effect control by harnessing social influence, for example, by spreading fake news and other forms of misinformation through online social media.</p><p>We consider the computational problem of election control via social influence, studying the conditions under which finding good adversarial strategies is computationally feasible. We consider two objectives for the adversary in both the constructive and destructive control settings: probability and margin of victory (POV and MOV, respectively). We present several strong negative results, showing, for example, that the problem of maximizing POV is inapproximable for any constant factor. On the other hand, we present approximation algorithms which provide somewhat weaker approximation guarantees, such as bicriteria approximations for the POV objective and constant-factor approximations for MOV. Finally, we present mixed integer programming formulations for these problems. Experimental results show that our approximation algorithms often find near-optimal control strategies, indicating that election control through social influence is a salient threat to election integrity.</p></td>
                </tr>
            
                <tr>
                    <td>572</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-572">MTDeep: Boosting the Security of Deep Neural Nets Against Adversarial Attacks with Moving Target Defense</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Learning and Adaptation] Deep learning<br>[Learning and Adaptation] Adversarial machine learning</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_572" class="editable_bid" data-pk="572" data-value="30"
                    data-url="/rev_3/paper/bid/set/572/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-572"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Recent works on gradient based attacks and universal perturbations can adversarial modify images to bring down the accuracy of state-of-the-art classification techniques based on deep neural networks to as low as 10% on popular data-sets like MNIST and ImageNet. The design of general defense strategies against a wide range of such attacks remains a challenging problem. In this paper, we derive inspiration from recent advances in the fields of cybersecurity and multi-agent systems and propose to use the concept of <i>Moving Target Defense (MTD)</i>&nbsp;for increasing the robustness of a set of deep networks against such adversarial attacks. To this end, we formalize and exploit the notion of <i>differential immunity</i> of an ensemble of networks to specific attacks. To classify an input image, a trained network is picked from this set of networks by formulating the interaction between a Defender (who hosts the classification networks) and their (Legitimate and Malicious) Users as a repeated <i>Bayesian Stackelberg Game (BSG)</i>. We empirically show that our approach, MTDeep reduces misclassification on perturbed images for MNIST and ImageNet data-sets while maintaining high classification accuracy on legitimate test images. Lastly, we demonstrate that our framework can be used in conjunction with any existing defense mechanism to provide more resilience to adversarial attacks than those defense mechanisms by themselves.</p></td>
                </tr>
            
                <tr>
                    <td>304</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-304">An interactive multi-agent computational semiotic model for sentiment analysis</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Architectures for social reasoning<br>[Agent Cooperation] Collective intelligence<br>[Agent Cooperation] Multi-user/multi-virtual-agent interaction<br>[Agent Theories and Models] Other</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_304" class="editable_bid" data-pk="304" data-value="30"
                    data-url="/rev_3/paper/bid/set/304/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-304"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>For Peircean semiotics, a sign is not a dyadic entity, composed of a word and its meaning. Instead, meaning-making is a process of signification borne of a strictly triadic relationship; in which a representative of a sign (word(s)) stands for its object (or meaning,) but never in a vacuum, and always for an interpretant, with respect to a ground (convention or context.) For Peirce, it is this third, this interpretant through which the sign displays its meaning. What is even more important is that this rational process of signification is never being carried out by a single Mind, it requires a community of reasoners. In semiotic terms this article translates the sentiment analysis problem as follows: A sentence/comment is a representamen which has a sentiment value (its object) for an evolving community of agents (interpretant) with respect to their dynamic memories (ground.) This article presents an interactive multi-agent model for this semiotic based approach towards sentiment analysis, tests it on an original student evaluation of teachers dataset, and aims to establish semiotics as a reparative alternative to the dominant dichotomies - rule-based and data-based camps within computational linguistics.<br style=" font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: -webkit-auto; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; "><br></p></td>
                </tr>
            
                <tr>
                    <td>391</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-391">Empathy in artificial intelligence leads to intrinsic moral behaviors</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Cognitive models<br>[Agent Theories and Models] Models of emotions<br>[Agent Cooperation] Biologically-inspired approaches and methods<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_391" class="editable_bid" data-pk="391" data-value="30"
                    data-url="/rev_3/paper/bid/set/391/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-391"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:RelyOnVML/>
  <o:AllowPNG/>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>ZH-CN</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
   <w:UseFELayout/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:宋体;
	mso-font-charset:134;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:3 680460288 22 0 262145 0;}
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1107305727 0 0 415 0;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073786111 1 0 415 0;}
@font-face
	{font-family:等线;
	mso-font-charset:134;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:-1610612033 953122042 22 0 262159 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:等线;
	mso-ascii-font-family:等线;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:宋体;
	mso-hansi-font-family:等线;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-size:10.5pt;
	mso-ansi-font-size:10.5pt;
	mso-bidi-font-size:11.0pt;
	font-family:等线;
	mso-ascii-font-family:等线;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:等线;
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:等线;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-font-kerning:1.0pt;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.5pt;
	mso-bidi-font-size:11.0pt;
	font-family:等线;
	mso-ascii-font-family:等线;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:等线;
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:等线;
	mso-hansi-theme-font:minor-latin;
	mso-font-kerning:1.0pt;}
</style>
<![endif]-->



<!--StartFragment-->



<!--EndFragment--></p><p class="MsoNormal"><span style="font-family:&quot;Calibri&quot;,sans-serif;mso-fareast-language:
ZH-CN">Ethical concerns of artificial intelligence have recently drawn
extensive interest in both academia and industry. Building an intrinsic sense
of morality is one potential way of regulating and promoting desirable
prosocial behaviors and reduce unethical behaviors. Incorporating ideas found
in social neuroscience, we hardwired a theoretical model of empathy in rational
reinforcement learning-based agents. Empathy was modeled to enable affective
state sharing between agents and their behavioral dynamics were tested and
analyzed in multiple game settings. Empathetic agents showed increased
cooperation compared to rational agents in iterated prisoner dilemma. They also
exhibited sympathetic concern in the altruism games, in which agents had to
either sacrifice its own reward in order to rescue its partner’s loss or gain
reward while its partner was punished. Moreover, they showed a sense of
fairness and primitive targeted helping behavior in the ultimatum game that
tests fairness and its multiagent variant. In summary, our model illustrates
that empathy can act as a fundamental affective drive underlying moral and
prosocial behaviors including cooperation, altruism, sympathy and fairness.
This provides novel methods and insights in regulating AI behaviors in
multiagent systems, as well as artificial subjects in psychology and behavioral
economics experiments. <o:p></o:p></span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>346</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-346">Strategy Generation for Multi-Unit Real-Time Games via Voting</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_346" class="editable_bid" data-pk="346" data-value="30"
                    data-url="/rev_3/paper/bid/set/346/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-346"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Real-time strategy (RTS) games are a challenging application for Artificial Intelligence (AI) methods. This is because they involve simultaneous play and adversarial reasoning that is conducted in real time in large state spaces. Many AI methods for playing RTS games rely on hard-coded strategies designed by human experts. The drawback of using such strategies is that they are often unable to adapt to new scenarios during gameplay. The contribution of this paper is a new approach, called &nbsp;Strategy Creation via Voting (SCV), that uses a voting method to generate a large set of novel strategies from existing expert-based ones. Then, SCV uses during the game an opponent modeling scheme to choose which strategy from the generated pool of possibilities to use. By repeatedly choosing which strategy to use, SCV is able to adapt to different scenarios that might arise during the game. The approach is applied to MicroRTS, which is a recognized RTS testbed used to evaluate AI methods. The results of a detailed empirical study show that our approach is able to outperform all approaches tested. Although we applied SCV to an RTS game, the method is in principle applicable to any domain in which one controls a group of units to jointly solve tasks.</p></td>
                </tr>
            
                <tr>
                    <td>297</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-297">Comparing Multi-Armed Bandit Algorithms and Q-learning for Multiagent Action Selection: a Case Study in Route Choice</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_297" class="editable_bid" data-pk="297" data-value="30"
                    data-url="/rev_3/paper/bid/set/297/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-297"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The multi-armed bandit (MAB) problem is concerned with an agent choosing which arm of a slot machine to play seeking to optimize its reward.</p><p>A family of reinforcement learning algorithms exists to tackle this problem, including a few variants that consider more than one agent (thus, characterizing a repeated game) and non-stationary variants.</p><p>In this paper, we seek to evaluate the performance of some of these MAB algorithms and compare them with Q-learning when applied to a non-stationary repeated game, where commuter agents have the task of learning how to choose a route that minimizes their travel times.</p></td>
                </tr>
            
                <tr>
                    <td>528</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-528">Foundations of MASTDEAL : A new MultiAgent application for Islamic finance</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Simulation techniques, tools and platforms<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_528" class="editable_bid" data-pk="528" data-value="30"
                    data-url="/rev_3/paper/bid/set/528/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-528"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="AbstractText" style="margin-top:0cm;margin-right:284.25pt;margin-bottom:
0cm;margin-left:0cm;margin-bottom:.0001pt"><span lang="EN-US">This paper
describes the foundations of a new Multi-Agent platform in the Islamic Banking
field that can be integrated with any Bank platform. This platform is based on
a collection of agents collaborating to support the decision making of many
actors in the banking field, such as customers, companies and bank agency’s
<gs id="c0aae7de-5211-4e5c-8068-942bde633dce" ginger_software_uiphraseguid="5b1823eb-3aea-4798-9c15-1a2ce443cf4e" class="GINGER_SOFTWARE_mark">responsibles</gs>. The platform is described and the belief and behavior of each
agent are highlighted.<o:p></o:p></span></p></td>
                </tr>
            
                <tr>
                    <td>326</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-326">Deep Pseudo-Convolutional Reinforcement Learning for Spatial Decision Making</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_326" class="editable_bid" data-pk="326" data-value="30"
                    data-url="/rev_3/paper/bid/set/326/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-326"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="font-size: 10.5pt; font-family: &quot;Helvetica Neue&quot;;">In many applications, such as in forest management, road network design, and ecosystem management, decision makers are required to plan actions over large spatial domains and long time periods. These spatial planning problems are often characterized by a large state space, with a large discrete action space, and therefore, directly applying conventional reinforcement learning approaches quickly becomes intractable. We introduce a novel reinforcement learning framework –&nbsp;</span><span style="font-size: 10.5pt; font-family: &quot;Helvetica Neue&quot;;"><span style="font-size: 10.5pt;">Deep&nbsp;<i>Pseudo-Convolutional Reinforcement learning</i></span>&nbsp;-- which generalizes the use of translational invariance from CNNs more broadly to policy networks such as those concerning spatial planning. The key observation underlying our method is that effects of actions in spatial planning problems typically are local, and hence, sharing one deep policy network across spatial dimensions allows for extremely compact network parametrization. We evaluate our framework on an important problem in computational sustainability -- biological control of an invasive&nbsp; species&nbsp;&nbsp;across an ecosystem spanning eastern North America. Our method consistently outperforms competing reinforcement learning methods and a heuristic combinatorial method in terms of learning speed and performance, showing how our framework successfully can be used for large-scale spatial planning problems.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>69</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-69">Safe transfer learning for risk-sensitive applications.</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Agent Theories and Models] Other</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_69" class="editable_bid" data-pk="69" data-value="30"
                    data-url="/rev_3/paper/bid/set/69/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-69"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><font color="#212121" face="sans-serif"><span style="font-size: 13px;">This paper tackles the problem of transfer learning for risk-sensitive applications. The goal is to quickly adapt to a new environment acknowledging the risk dimension of the interactions done with it. Previous works do not use a safe strategy during the cold-start phase of the learning process. We believe that for most real life applications, in the first interactions, it's more important to be risk-aware than being average. For that, we propose to transfer a safe strategy learned among different source environments thanks to epsilon-safe a novel algorithm. The safe strategy is learnt with CFTQ a novel algorithm for Constrained Markov decision processes. Benchmarks show that the safe strategies are more efficient in the very first steps of the learning but also speed up significantly the learning process.</span></font><br></p></td>
                </tr>
            
                <tr>
                    <td>631</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-631">Reinforcement Learning for Heterogeneous Teams with PAC Bounds</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Teamwork, team formation, teamwork analysis<br>[Learning and Adaptation] Reward structures for learning</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_631" class="editable_bid" data-pk="631" data-value="30"
                    data-url="/rev_3/paper/bid/set/631/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-631"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><div>We explore reinforcement learning for heterogeneous teams in which rewards for an agent are decomposed into local costs, stimuli unique to each agent, and global rewards, those shared by all agents in the domain. Such domains include heterogeneous teams of robots, where each robot may incur different costs for the same action, but share an overall goal. We introduce two templates for learning in this setting with factored rewards: a straightforward extension of Perkins' Monte Carlo exploring starts for POMDPs to canonical MPOMDPs, with a single policy mapping joint observations of all agents to joint actions (MCES-MP); and another with each agent individually mapping joint observations to their own action (MCES-FMP). We use probably approximately correct (PAC) bounds to analyze sample complexity, instantiating these templates to PAC learning. We promote scalability by including a policy search space pruning technique, and evaluate the two approaches on three domains with heterogeneous agents demonstrating that MCES-FMP yields comparable policies in less time and samples.</div></td>
                </tr>
            
                <tr>
                    <td>111</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-111">GEESE: Grammatical Evolution Algorithm for Evolution of Swarm Behaviors</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Learning and Adaptation] Evolutionary algorithms</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_111" class="editable_bid" data-pk="111" data-value="30"
                    data-url="/rev_3/paper/bid/set/111/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-111"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Animals such as bees, ants, birds, fish, and others are able to perform complex coordinated tasks like foraging, nest-selection, flocking, and escaping predators efficiently without centralized control or coordination. Conventionally, mimicking these behaviors with robots requires researchers to study actual behaviors, derive mathematical models, and implement these models as algorithms. We purpose a distributed algorithm, Grammatical Evolution algorithm for Evolution of Swarm bEhaviors (GEESE), that extends the literature on using genetic methods to generate collective behaviors for robot swarms. GEESE uses grammatical evolution to evolve a primitive set of human-provided rules into productive individual behaviors. The GEESE algorithm is evaluated in two different ways. First, GEESE is compared to state-of-the-art genetic algorithms on the canonical Santa Fe Trail problem. Results show that GEESE outperforms the state-of-the-art by (a) providing better solution quality given sufficient population size while (b) utilizing fewer evolutionary steps. Second, we compare GEESE output with hand-coded solutions and solutions generated by conventional Grammatical Evolution to show that GEESE can be used successfully for evolving collective swarm behavior for a foraging task.</p></td>
                </tr>
            
                <tr>
                    <td>308</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-308">Eliciting Truthful Unverifiable Information</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Economic Paradigms] Auctions and mechanism design</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_308" class="editable_bid" data-pk="308" data-value="30"
                    data-url="/rev_3/paper/bid/set/308/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-308"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In many situations, an uninformed agent (UA) needs to elicit information from an informed agent (IA), typically when the latter has some unique expertise or knowledge related to some opportunity available to the UA. In many of those situations, the correctness of the information cannot be verified by the UA, and therefore it is important to guarantee that the information-elicitation mechanism incentivizes the IA to report truthfully.&nbsp; </p><p>This paper presents and studies several information-elicitation mechanisms that guarantee truthful reporting, differing in the type of costs the IA incurs in producing and delivering the information. We show that with no such costs truthful information elicitation is possible with a positive but arbitrarily small expense for the UA.&nbsp; When information-delivery is costly, truthful information elicitation is possible where the extra expense for the UA (above the unavoidable cost of delivery) is arbitrarily small.&nbsp; Finally, when the information-production is costly, under some realistic condition related to the ratio between the expected gain of the IA from true reporting and the information-production cost, truthful information elicitation is possible where the extra expense for the UA (above the unavoidable cost of production) is arbitrarily small. <br></p></td>
                </tr>
            
                <tr>
                    <td>531</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-531">A Fairness Criterion for Identifying Illegal Market Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.700</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_531" class="editable_bid" data-pk="531" data-value="30"
                    data-url="/rev_3/paper/bid/set/531/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-531"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>According to U.S. and U.K. law, corporate directors must use their power for the commercial benefit of their company and its members. Yet some business leaders, in trying to maximize their benefits, may operate market systems that cross a moral, ethical, or legal line. For example, Ponzi schemes are fraudulent and illegal, even if they maximize a company's benefit. In contrast, other market systems, like fist-price auctions with transaction fees, are considered appropriate business mechanisms.</p><p><br></p><p>Between these clear endpoints, a number of market systems fall into a gray area. Penny auctions, lotteries, and gambling games, for example, are outlawed in some jurisdictions, legal in others, and have controversial rules of questionable fairness. We know of no overarching criteria to distinguish legitimate market systems from deceptive tricks; each is treated separately and often inconsistently in the law. Betting on sports, betting on elections, and betting on financial stocks are all logically equivalent, yet treated differently in the court of law. Rather than examining every market system case by case, we propose a simple, general criterion for measuring fairness of a market system, allowing society to consistently identify which market systems to allow and which to ban. Our fairness criterion measures how rewards are distributed among market participants. If each participant on average gets back from the market a constant factor of the information, skill, time, and/or money that she puts in, then the market is fair. If, on the other hand, one or more participants consistently earn rewards that far outpace what they put in, then the market is unfair and, in our opinion, should be considered for legal sanction.</p></td>
                </tr>
            
                <tr>
                    <td>178</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-178">Integrated Hybrid Planning and Programmed Control for Real–Time UAV Maneuvering</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Verification and Validation of Agent-based Systems] Synthesis of agent-based systems<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_178" class="editable_bid" data-pk="178" data-value="30"
                    data-url="/rev_3/paper/bid/set/178/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-178"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The automatic generation of realistic behaviour such as tactical intercepts for <i>Unmanned Aerial Vehicle</i>s (<b>UAV</b>) in air combat is a&nbsp;challenging problem. State-of-the-art solutions propose hand--crafted&nbsp;algorithms and heuristics whose performance depends heavily on the initial&nbsp;conditions and aerodynamic properties of the UAVs involved. This&nbsp;paper shows how to employ domain--independent planners, embedded into professional&nbsp;multi--agent simulations, to implement <i>Model Predictive Control</i> (<b>MPC</b>) two--level&nbsp;hybrid control systems for UAVs. Width-based search techniques,&nbsp;taken off-the-shelf from the literature in <i>classical planning over simulators</i>,&nbsp;are used to generate <i>real--time control signals</i> that steer&nbsp;<span style="white-space: pre;">	</span>simulated aircraft as best suits the situation. We compare experimentally the controllers&nbsp;using planners with a behaviour tree that implements tactics widely&nbsp;accepted and used in the real world. Our results indicate hybrid planners derive novel and effective tactics from <i>first principles</i> inherent to the dynamical constraints UAVs are subject to.</p></td>
                </tr>
            
                <tr>
                    <td>560</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-560">Interactive Agent that Understands the User</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Speech act theory<br>[Agent Theories and Models] Cognitive models</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_560" class="editable_bid" data-pk="560" data-value="30"
                    data-url="/rev_3/paper/bid/set/560/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-560"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Our work uses the notion of theory of mind to enable<br>an interactive agent to keep track of the state of knowledge,<br>goals and intentions of the human user, and to<br>engage in and initiate sophisticated interactive behaviors<br>using decision-theoretic paradigm of maximizing<br>expected utility. Currently, systems like Google Now<br>and Siri mostly react to user’s requests and commands<br>using hand-crafted responses, but they cannot initiate<br>intelligent communication and plan for longer term interactions.<br>The reason is that they lack a clearly defined<br>general objective of the interaction. Our main premise is<br>that communication and interaction are types of action,<br>so planning for communicative and interactive actions<br>should be based on a unified framework of decision theoretic<br>planning. To facilitate this, the system’s state<br>of knowledge (a mental model) about the world has to<br>include probabilistic representation of what is known,<br>what is uncertain, and how things change as different<br>events transpire. Further, the state of user’s knowledge<br>and intentions (the theory of the user’s mind) needs to<br>include precise specification of what the system knows,<br>and how uncertain it is, about the user’s mental model,<br>and about her desires and intentions. The theories of<br>mind may be further nested to form interactive beliefs.<br>Finally, decision-theoretic planning proposes that desirability<br>of possible sequences of interactive and communicative<br>actions be assessed as expected utilities of alternative<br>plans. We describe our preliminary implementation<br>using the Open CYC system, called MARTHA,<br>and illustrate it in action using two simple interactive<br>scenarios.<br></p></td>
                </tr>
            
                <tr>
                    <td>141</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-141">Assigning Tasks to Workers based on Historical Data: Online Task Assignment Problem with Two-sided Arrivals</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Other</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_141" class="editable_bid" data-pk="141" data-value="30"
                    data-url="/rev_3/paper/bid/set/141/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-141"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Efficient allocation of tasks to workers is a central problem in crowdsourcing. In this paper, we consider a special setting inspired from spatial crowdsourcing platforms where both workers and tasks arrive dynamically. Additionally, we assume all tasks are&nbsp; heterogeneous&nbsp; and each worker-task assignment brings a distinct reward. The natural challenge lies in how to incorporate the uncertainty in the arrivals from both workers and tasks into our online allocation policy such that the total expected rewards are maximized. To attack this challenge,&nbsp; we assume the arrival patterns of worker "types" and task "types" are not erratic and can be predicted from historical data. To be more specific, we consider a finite time horizon T and assume in each time-step, a single worker and task are sampled (i.e., "arrive") from two respective distributions independently, and this sampling process repeats identically and independently for the entire T online time-steps.</p><p><br></p><p>Our model, called Online Task Assignment Problem with Two-Sided Arrival (OTAP-TSA), is a significant generalization of the classical online task assignment problem where the set of tasks is assumed to be available offline.&nbsp; For the general version of OTAP-TSA, we present an optimal non-adaptive algorithm which achieves an online competitive ratio of 0.295. For the special case of OTAP-TSA&nbsp;where the reward is a function of just the worker type, we present an improved algorithm (which is adaptive) and achieves a competitive ratio of at least 0.345. On the hardness side, along with showing that the ratio obtained by our non-adaptive algorithm is the best possible among all non-adaptive algorithms, we further show that no (adaptive) algorithm can achieve a ratio better than 0.581 (unconditionally), even for the special case of OTAP-TSA&nbsp;with homogenous tasks (i.e., all rewards are same). At the heart of our analysis lies a new technical tool (which is a refined notion of the birth-death process), called the two-stage birth-death process, which may be of independent interest. Finally, we perform numerical experiments on two real-world datasets obtained from crowdsourcing platforms to complement our theoretical results.</p></td>
                </tr>
            
                <tr>
                    <td>536</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-536">Expressive Power of Coalition Announcement Logic</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Agent Theories and Models] Other</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_536" class="editable_bid" data-pk="536" data-value="30"
                    data-url="/rev_3/paper/bid/set/536/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-536"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">Coalition Anouncement Logic (CAL) studies the strategic interaction between public announcements</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">made by agents, and its effect on agents' knowledge. The main modality of CAL stands for</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">`agents in group $G$ have an announcement such that whatever other announcements agents from outside $G$</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">make at the same time,&nbsp;</span><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">property $\phi$ holds after this joint announcement'.</span><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">&nbsp;CAL is similar to the</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">Group Announcement Logic (GAL), which can express that `agents in group $G$ have an announcement such that</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">property $\phi$ holds after this announcement</span><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">'. It has been an open problem for some time whether CAL</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">modalities are definable in GAL. We answer this question positively for the case of</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">finite models. We also investigate expressive power of fragments of CAL.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>184</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-184">Optimizing network structure for preventative health</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_184" class="editable_bid" data-pk="184" data-value="30"
                    data-url="/rev_3/paper/bid/set/184/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-184"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Diseases such as heart disease, stroke, or diabetes affect hundreds of millions of people. Such conditions are strongly impacted by obesity, and establishing healthy lifestyle behaviors is a critical public health challenge with many applications. Changing health behaviors is inherently a multiagent problem since people's behavior is strongly influenced by those around them. Hence, practitioners often attempt to modify the social network of a community by adding or removing edges in ways that will lead to desirable behavior change. To our knowledge, no previous work considers the algorithmic problem of finding the optimal set of edges to add and remove. We propose the RECONNECT algorithm, which efficiently finds high-quality solutions for a range of different network intervention problems. We evaluate RECONNECT in a highly realistic simulated environment based on the Antelope Valley region in California which draws on demographic, social, and health-related data. We find the RECONNECT outperforms an array of baseline policies, in some cases yielding a 150% improvement over the best alternative.<br></p></td>
                </tr>
            
                <tr>
                    <td>165</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-165">Empirically Evaluating the Application of POMDP vs. MDP Towards the Induction of Pedagogical Strategies</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Humans and Agents] Human-robot/agent interaction<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_165" class="editable_bid" data-pk="165" data-value="30"
                    data-url="/rev_3/paper/bid/set/165/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-165"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Intelligent Tutoring Systems (ITSs) have been shown to be highly
effective at improving student learning in real classrooms, approaching
that of human tutors, through scaffolding and intelligent contextualized
feedback adapted to individual learners. Despite the high
payoffs of ITSs, significant barriers remain. To design an effective
ITS, developers must form the basic core of the system and then
determine what to teach and how to teach it. Pedagogical strategies
are policies used by the system to decide what tutorial action to take
when multiple actions are available given user input and the current
learning context. Prior research has shown that when the content
(what) is controlled to be equivalent, there is little evidence that pedagogical
decisions (how) will affect students’ learning. In this work,
however, we applied Reinforcement Learning (RL) to induce effective
pedagogical policies directly from pre-existing student-system
interaction data. When applying RL to ITSs, we face two major challenges:
first, measurements of student learning (reward) are often
delayed; and second, there are many factors that may affect learning
which are not well understood (state representation). We report two
empirical studies in which we compare two frameworks: Markov
Decision Processes (MDPs) vs. Partially Observable Markov Decision
Processes (POMDPs) for policy induction and deterministic
vs. stochastic for the policy execution. Our results show that when
the contents are controlled to be equivalent, effective pedagogical
strategies will improve students’ learning. More specifically, the
POMDP framework is more suitable for the task of pedagogical
policy induction than the MDP framework and stochastic policy
executions can outperform deterministic executions.<br></p></td>
                </tr>
            
                <tr>
                    <td>524</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-524">The Rationale behind Bounded Rational Agents in Retail Markets</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Economic Paradigms] Behavioral game theory<br>[Economic Paradigms] Noncooperative games: computation</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_524" class="editable_bid" data-pk="524" data-value="30"
                    data-url="/rev_3/paper/bid/set/524/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-524"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In retail markets, sellers offer competitive prices to attract buyers and increase profits. Reacting to these prices human buyers are not rational, i.e., they do not always choose the optimal available option (cheapest price). In practice, the rationality of buyers is bounded due to cognitive limitations or time constraints. Recent advancements in artificial intelligence and e-commerce enable market participation by agents that are (almost) perfectly rational due to their computational capacity. However, receding characteristics of human buyers, such as bounded rationality, might have unfavorable effects on markets with regards to the stability of competition and prices. In this paper, we study the consequences of varying degrees of buyers' rationality on markets where sellers compete in price for identical items. We model the level of buyers' rationality using the multinomial logit function. We use hierarchical reasoning to model the competition of sellers, where each seller computes its best response strategy (price) with regards to its belief over opponent sellers of lower levels of reasoning. We derive the best response strategy of a reasoning seller with regards to the degree of buyers' rationality, and show the existence of an optimal degree of rationality for buyers. We use evolutionary dynamics over reasoning levels to show that perfect rationality allows higher reasoning sellers to eliminate competition, and thus results in monopolistic behavior. Our results suggest that perfect rationality leads to unstable evolutionary dynamics and price spikes, decreasing the utility of buyers in retail markets. In contrast to perfect rationality, we show that bounded rationality stimulates competition among sellers of varying reasoning levels, yielding benefits for buyers.</p></td>
                </tr>
            
                <tr>
                    <td>570</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-570">Adversarial Classification on Social Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Economic Paradigms] Game Theory for practical applications<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_570" class="editable_bid" data-pk="570" data-value="30"
                    data-url="/rev_3/paper/bid/set/570/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-570"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The spread of unwanted or malicious content through social me-<br>dia has become a major challenge. Traditional examples of this<br>include social network spam, but an important new concern is the<br>propagation of fake news through social media. A common ap-<br>proach for mitigating this problem is by using standard statistical<br>classification to distinguish malicious (e.g., fake news) instances<br>from benign (e.g., actual news stories). However, such an approach<br>ignores the fact that malicious instances propagate through the<br>network, which is consequential both in quantifying consequences<br>(e.g., fake news diffusing through the network), and capturing de-<br>tection redundancy (bad content can be detected at different nodes).<br>An additional concern is evasion attacks, whereby the generators of<br>malicious instances modify the nature of these to escape detection.<br>We model this problem as a Stackelberg game between the defender<br>who is choosing parameters of the detection model, and an attacker,<br>who is choosing both the node at which to initiate malicious spread,<br>and the nature of malicious entities. We develop a novel bi-level<br>programming approach for this problem, as well as a novel solution<br>approach based on implicit function gradients, and experimentally<br>demonstrate the advantage of our approach over alternatives which<br>ignore network structure.<br></p></td>
                </tr>
            
                <tr>
                    <td>78</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-78">Service-Oriented Robot Software Development Framework for Distributed Heterogeneous Platforms</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Programming languages and frameworks for agents and multi-agent systems<br>[Engineering Multiagent Systems] Modelling and specification languages</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_78" class="editable_bid" data-pk="78" data-value="30"
                    data-url="/rev_3/paper/bid/set/78/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-78"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In the near future, it will be common that a variety of robots are cooperating to perform a mission in various fields. A key technical challenge to realize this vision is software challenge on how to specify the mission at the user level and how to program each robot separately. In this paper, we propose a novel software development framework that separates mission specification and robot behavior programming. For mission specification, a novel script language is proposed with the expression capability of dynamic mode change and multi-tasking. For robot behavior programming, an extended dataflow model is used for task-level behavior specification that does not depend on the robot hardware platform. In the proposed framework, the actual robot software is automatically generated from the model. The viability of the proposed framework is demonstrated with two real-life experiments.&nbsp;&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>174</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-174">Quasi-random Agents for Image Transition and Animation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent-based Simulation] Modelling for agent based simulation</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_174" class="editable_bid" data-pk="174" data-value="30"
                    data-url="/rev_3/paper/bid/set/174/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-174"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Quasi-random walks show similar features as standard random walks, but with much less randomness. We utilize this established model from discrete mathematics and show how agents carrying out quasi-random walks can be used for image transition and animation. The key idea is to generalize the notion of quasi-random walks and let a set of autonomous agents perform quasi-random walks painting an image. Each agent has one particular target image that they paint when following a sequence of directions for their quasi-random walk. The sequence can easily be chosen by an artist and allows them to produce a wide range of different transition patterns and animations.<br></p></td>
                </tr>
            
                <tr>
                    <td>475</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-475">Stable Planning Mechanisms for Self Interested Agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_475" class="editable_bid" data-pk="475" data-value="30"
                    data-url="/rev_3/paper/bid/set/475/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-475"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper considers a multi-agent planning setting where actions
are owned by self interested agents, and the agents have
private information about their action costs. Given a planning
task, our goal is to buy a cost-optimal plan for the task from
these self-interested agents. The well-known Vickery-ClarkGroves
(VCG) mechanism is the unique solution that guarantees
both truthfulness and efficiency. However, we show
that all truthful planning mechanisms including VCG can be
forced to pay an \Omega(n) factor more than the cost of the second
cheapest plan, where n is the number of agents. This overpayment
can often lead to coalition manipulations and false
name manipulations. To address these problems, we present
stable planning mechanisms in this paper. The stable planning
mechanism is based on the core solution concept and
can eliminate coalition manipulations and false name manipulations.
We then give a novel core formulation which needs
only O(k^2) constraints for a cost optimal plan with k actions.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>161</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-161">Online Replanning in Dec-POMDPs for Model Error</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_161" class="editable_bid" data-pk="161" data-value="30"
                    data-url="/rev_3/paper/bid/set/161/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-161"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The Decentralized Partially Observable Markov Decision Process (Dec-POMDP) is a powerful framework for decentralized planning under uncertainty. While there are many methods for solving Dec-POMDPs, they all assume the model is correct. In practice, it is very difficult to generate a complete and correct model. Therefore, our approach deals with model error by allowing each agent to replan separately when model differences are detected. This decentralized replanning approach considers two methods for updating solutions and communicating model knowledge. In both cases, we consider the effect of these updates and communications on the other agents’ behavior. We demonstrate these contributions in a search and rescue domain where agents use incorrect a priori environment models for planning. Our methods represent the first Dec-POMDP-based approaches for dealing with model error and the first Dec-POMDP-based replanning methods.<br></p></td>
                </tr>
            
                <tr>
                    <td>338</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-338">Gavel: A Sanctioning Enforcement Framework</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Policy, regulation and legislation<br>[Agent Societies and Societal Issues] Normative systems<br>[Agent Societies and Societal Issues] Monitoring agent societies<br>[Engineering Multiagent Systems] Programming languages and frameworks for agents and multi-agent systems</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_338" class="editable_bid" data-pk="338" data-value="30"
                    data-url="/rev_3/paper/bid/set/338/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-338"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Sanctioning is one of the most adopted enforcement mechanisms in the governance&nbsp;</p><p>of multiagent systems. Current enforcement frameworks, however, restrict agents&nbsp;</p><p>to reason about and make sanctioning decisions. We developed the Gavel framework,&nbsp;</p><p>an adaptive sanctioning enforcement framework that enables agents to decide for&nbsp;</p><p>the most appropriate sanction to apply depending on various decision factors. The&nbsp;</p><p>potential benefits and use of the framework is shown using a Public Goods Game</p><p>in which agents are endowed with different strategies combining material and</p><p>reputational sanctions.</p></td>
                </tr>
            
                <tr>
                    <td>188</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-188">A Tree Traverse Algorithm To Compute Distance Between Lexicographic Preferences</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Knowledge Representation and Reasoning] Other<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_188" class="editable_bid" data-pk="188" data-value="30"
                    data-url="/rev_3/paper/bid/set/188/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-188"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Very often, we have to look into more than one agents' preferences and compare or aggregate them. In a simple situation, the agents may go through and consider each possible alternative. However, this approach becomes impractical when it involves a combinatorial domain, where the number of alternatives grows exponentially as the number of decision attributes increases. In this paper, we consider a well-known compact model, namely, lexicographic preference trees (LP-trees), for representing agents' preferences. We tackle the problem of computing the dissimilarity/distance between agents' preferences represented by LP-trees. In particular, we investigate how the differences on attribute importance and local attribute preferences between agents would affect the distance in their final ranking over the outcome space. We propose an efficient algorithm LpDis to compute the number of disagreed pairwise preferences between agents by traversing their LP-trees. The proposed algorithm can be applied to any classes of LP-trees and allows agents to have different importance structures and preference dependencies. Furthermore, it neither needs to generate any outcome nor to query agents' LP-trees over outcome pairs. Experimental results show that the proposed algorithm hugely reduced the computation time compared to an exhaustive query method.</p></td>
                </tr>
            
                <tr>
                    <td>712</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-712">Designing Incentives to Maximize the Adoption of Rooftop Solar Technology</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_712" class="editable_bid" data-pk="712" data-value="30"
                    data-url="/rev_3/paper/bid/set/712/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-712"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Household level rooftop solar technology adoption has increased rapidly in many regions, driven by a multitude of factors, including falling prices and incentives such as tax breaks. It has also been shown in recent research that peer effects have an important role in the spread of solar adoption. The existence of peer effects leads to a natural problem of how to design incentives to maximize adoption in such a model. While this is an instance of an "influence maximization" problem, prior results from the influence maximization literature cannot be used directly. In this work, we extend prior results from the literature on the use of submodularity to obtain a greedy approximation. We use this new result to do optimal "seed set" selection for a highly detailed data-driven agent-based model of household rooftop solar adoption.<br></p></td>
                </tr>
            
                <tr>
                    <td>145</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-145">Multiplex Network Structure Enhances the Role of Generalized Reciprocity in Promoting Cooperation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent Cooperation] Biologically-inspired approaches and methods<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.690</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_145" class="editable_bid" data-pk="145" data-value="30"
                    data-url="/rev_3/paper/bid/set/145/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-145"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Recent studies suggest that the emergence of cooperative behavior can be explained by <i>generalized reciprocity</i>, a behavioral mechanism based on the principle of "help anyone if helped by someone". In multi-agent systems, the cooperative dynamics is largely determined by the network structure which dictates the interactions among neighboring agents. These interactions often exhibit multidimensional features, either as relationships of different types or temporal dynamics, both of which may be modeled as a "multiplex" network. Against this background, here we advance the research on cooperation models inspired by generalized reciprocity by considering a multidimensional networked society. Our results reveal that a multiplex network structure effectively enhances the role of generalized reciprocity in promoting cooperation by acting as a latent support, even when the network parameters in some of the separate network dimensions suggest otherwise (i.e. favor defection). As a result, generalized reciprocity forces the cooperative contributions of the individual agents to concentrate in the dimension which is most favorable for the existence of cooperation.<br></p></td>
                </tr>
            
                <tr>
                    <td>370</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-370">Toward Understanding the Impact of User Participation in Dynamic Ridesharing</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Simulation techniques, tools and platforms<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_370" class="editable_bid" data-pk="370" data-value="30"
                    data-url="/rev_3/paper/bid/set/370/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-370"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Understanding the impact of user participation in ridesharing systems is crucial for stakeholders to take appropriate actions toward achieving desired outcomes. To date, however, a careful study that quantifies the impact and its extent of user participation on the efficiency of dynamic ridesharing systems is missing. One of the main obstacles is that there is lack of modular approaches for simulating dynamic ridesharing systems at scale. To bridge the gap, we present&nbsp; SpaceTime for Dynamic Ridesharing (STDR) - a platform for large-scale dynamic ridesharing simulations. By conducting experiments on the platform with over three million ride requests extracted from the New York City taxi trip dataset, we present the first empirical study to investigate how and to what extent user participation influences the efficiency of dynamic ridesharing systems. We demonstrate how specific configurations (e.g., fleet size, vehicle capacity, and the maximum waiting time) of dynamic ridesharing systems can be identified to counter the effect of user participation on the system efficiency. Stakeholders should base decisions regarding system configurations on insights from data-driven simulations and make tradeoffs between system efficiency and price of anarchy for desired outcomes.<br></p></td>
                </tr>
            
                <tr>
                    <td>677</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-677">Discovering Blind Spots in Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_677" class="editable_bid" data-pk="677" data-value="30"
                    data-url="/rev_3/paper/bid/set/677/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-677"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Agents trained in simulation often make errors in the real world, due to mismatches between training and testing environments. These mistakes can be dangerous and difficult to discover because the agent cannot a priori predict them. In this work, we propose using oracle feedback to learn a predictive model of these blind spots to reduce costly errors in real world execution. We focus on blind spots in reinforcement learning that occur due to incomplete state representation: The agent does not have the appropriate features to represent the true state of the world and thus cannot distinguish many states from each other. We formalize the problem of discovering blind spots in RL as a noisy supervised learning problem with class imbalance. Our learning methodology combines techniques for label aggregation, calibration, and supervised learning to reason explicitly about various forms of noise emerging from different forms of oracle feedback, including oracle demonstrations and corrections, to predict blind spots in unseen regions of the state space. We evaluate our approach on two domains and show that its predictive performance achieves higher performance than baseline approaches, and that the learned model can be used to selectively query the oracle at execution time to prevent errors. We also empirically analyze the biases of various forms of oracle feedback, including demonstrations and corrections, and how they impact the discovery of blind spots.<br></p></td>
                </tr>
            
                <tr>
                    <td>564</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-564">On Structures and Stabilities of Weighted Allocations and Linear Network Flows</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Economic Paradigms] Cooperative games: computation</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_564" class="editable_bid" data-pk="564" data-value="30"
                    data-url="/rev_3/paper/bid/set/564/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-564"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider a more general case of the stable allocation problem in which workers and firms have positive weights over contracts. A weighted allocation is stable if there are no worker-firm pairs can mutually benefit by privately signing an unsaturated contract. We show that weighted stable allocations (WSA) possess a natural lattice structure. We also study the structure of a variant of stable network flow, the linear mapping stable flow (LMSF). Instead of the traditional Kirchhoff's law, requiring the outflow is equal to the inflow, there is a linear relation between the outflow and the inflow for each agent. A flow is stable if no group of vertices can mutually benefit by&nbsp; rerouting the flow along a path contained in the group. By the bidirectional reducibility between WSA and LMSF, not only can we find a WSA in polynomial time, but we also investigate the roll of each agent in a market network and the structure of LMSF. Furthermore, we study the structure of monotone piecewise linear mapping stable flow (MPLMSF), where the relation between inflow and outflow is piecewise linear for each agent. Eventually, we present a fast path augmenting algorithm for LMSF and MPLMSF by using dynamic trees.<br></p></td>
                </tr>
            
                <tr>
                    <td>70</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-70">Distributed, Private, and Derandomized Allocation Algorithm for EV Charging</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Cooperation] Distributed problem solving</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_70" class="editable_bid" data-pk="70" data-value="30"
                    data-url="/rev_3/paper/bid/set/70/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-70"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Efficient resource allocation is challenging when privacy of users is important. Distributed solution approaches have recently been used extensively to find a solution for such problems. In this work, we study the efficiency of distributed AIMD algorithm for allocation of subsidized goods. To this end, we assign each user a suitable utility function describing the amount of satisfaction that it has from allocated resource. We define the resource allocation as a total utilitarianism problem that is an optimization problem of sum of users utility functions subjected to capacity constraint. Recently, a stochastic state-dependent variant of AIMD algorithm is used for allocation of common goods among users with strictly increasing and concave utility functions. We improve this algorithm to allocate subsidized goods to users with concave and nonmonotonous utility functions as well as users with Sigmoidal utility functions. We also derandomize the AIMD algorithm and compare its efficiency with the stochastic version. To illustrate the effectiveness of the proposed solutions, we present simulation results for a public renewable-energy powered charging station in which the electric vehicles (EV) compete to be recharged.<br></p></td>
                </tr>
            
                <tr>
                    <td>384</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-384">A Deep Policy Inference Q-Network for Multi-Agent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_384" class="editable_bid" data-pk="384" data-value="30"
                    data-url="/rev_3/paper/bid/set/384/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-384"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We present DPIQN, a deep policy inference Q-network that targets multi-agent systems composed of controllable agents, collaborators, and opponents that interact with each other. We focus on one challenging issue in such systems---modeling agents with varying strategies---and propose to employ "policy features" learned from raw observations (e.g., raw images) of collaborators and opponents by inferring their policies. DPIQN incorporates the learned policy features as a hidden vector into its own deep Q-network (DQN), such that it is able to predict better Q values for the controllable agents than the state-of-the-art deep reinforcement learning models. We further propose an enhanced version of DPIQN, called deep recurrent policy inference Q-network (DRPIQN), for handling partial observability. Both DPIQN and DRPIQN are trained by an adaptive training procedure, which adjusts the network's attention to learn the policy features and its own Q-values at different phases of the training process. We present a comprehensive analysis of DPIQN and DRPIQN, and highlight their effectiveness and generalizability in various multi-agent settings. Our models are evaluated in a classic soccer game involving both competitive and collaborative scenarios. Experimental results performed on 1 vs. 1 and 2 vs. 2 games show that DPIQN and DRPIQN demonstrate superior performance to the baseline DQN and deep recurrent Q-network (DRQN) models. We also explore scenarios in which collaborators or opponents dynamically change their policies, and show that DPIQN and DRPIQN do lead to better overall performance in terms of stability and mean scores.<br></p></td>
                </tr>
            
                <tr>
                    <td>460</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-460">Epistemic Foundations for Generalised Planning with Nondeterminism</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_460" class="editable_bid" data-pk="460" data-value="30"
                    data-url="/rev_3/paper/bid/set/460/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-460"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In an influential paper, Levesque proposed a formal specification for analysing the correctness of program-like plans, such as conditional plans, iterative plans, and knowledge-based plans. He motivated a logical characterisation within the situation calculus that included binary sensing actions. While the characterisation does not immediately yield a practical algorithm, the specification serves as a general skeleton to explore the synthesis of program-like plans for reasonable, tractable fragments.&nbsp;</p><p><br></p><p>Increasingly, classical plan structures are being applied to stochastic environments such as robotics applications. This raises the question as to what the specification for correctness should look like, since Levesque's account makes the assumption that sensing is exact and actions are deterministic. Building on a situation calculus theory for reasoning about</p><p>degrees of belief and noise, we revisit the execution</p><p>semantics of generalized plans. The specification is then used to</p><p>analyse the correctness of example plans.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>665</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-665">Learning to Trade: Exploiting Market Forces to Increase Social Welfare in Multi-Agent Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_665" class="editable_bid" data-pk="665" data-value="30"
                    data-url="/rev_3/paper/bid/set/665/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-665"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">Recent work on learning in multi-agent systems (MAS) is concerned
with questions on the ability to learn social interaction skills like
learning to communicate, learning to cooperate or the preservation
of cooperation. These are key challenges to make MAS applicable
in real world settings that possibly include interaction with other
systems and also humans. In this work, we contribute an algorithm
for </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineTI'">learning to trade</span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">. We consider trade to be a central feature in
domains where a given amount of resources needs to be allocated
to a group of agents. We motivate this from the first fundamental
theorem of welfare economics according to which competitive
markets tend towards Pareto efficient allocations. To study the
emergence of trading behavior in MAS, we use Deep Reinforcement
Learning with independent, self-interested learners and provide
them with the ability of exchanging resources to realize trading. We
propose ’Action Traders’, which refers to agents that can trade their
atomic actions in exchange for environmental reward. For empirical
evaluation we implemented action trading in the Coin Game - and find that trading significantly increases social efficiency in terms of
overall reward compared to agents without action trading.&nbsp;</span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>77</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-77">Selfish Behavior is Ubiquitous: Maximize Selfish Group’s Income in Multi-agent Pursuit-Evasion Problem</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_77" class="editable_bid" data-pk="77" data-value="30"
                    data-url="/rev_3/paper/bid/set/77/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-77"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span lang="EN-US">We are </span><span lang="EN-US">interested</span><span lang="EN-US"> in multi-agent pursuit-evasion
problem, where the pursuers’ goal is to round up the evader, and the evader’s goal
is to avoid being captured by the pursuers. Existing related studies usually
consider the condition that all the pursuers are not self-interested and
willing to cooperate closely. However, the reality is that selfish behavior is ubiquitous in multi-agent
systems, and some selfish agents collude together to maximize their group’s
income. Therefore, the analysis of selfish pursuers’
strategy is meaningful and may be conductive to the follow-up research on promoting
cooperation. As we all know, the pursuers’ selfish behavior
is influenced by the reward allocation mechanism that developed for awarding pursuers
after the process of pursuit, thus we propose a problem: what is the suitable
strategy that the selfish group will take when faced with different reward allocation
mechanism. To the best of our knowledge, this is the
first paper that studies this problem. Our contributions are as follows: First,
we formally define this problem. Second, we analyze this problem, and propose two
suitable algorithms based on the analyses: one is an algorithm
designed according to the main idea of the greedy strategy; the other one is a novel
heuristic algorithm that tears a gap in the encircled formation deliberately
with the purpose of attracting the evader to move towards the gap. Finally, we extensively
evaluate our algorithms in simulation,</span><span lang="EN-US"> demonstrating that the
efficacy of our algorithm in improving selfish group’s total income. Our
results in this paper can facilitate the follow-up research on how to design
reward allocation mechanism to promote cooperation and detect the selfish
behavior.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>207</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-207">A Homophily-Free Community Detection Framework for Roaming Taxis</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent Societies and Societal Issues] Social networks<br>[Humans and Agents] Agent-based analysis of human interactions<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_207" class="editable_bid" data-pk="207" data-value="30"
                    data-url="/rev_3/paper/bid/set/207/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-207"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Taxi service is the best candidate for replacing private vehicles in most cities; however, finding customers by roaming the street is a major source of inefficiency. To obtain information about customer demand and/or surge pricing at different locations, taxi drivers typically form communities (through messaging applications and phone conversations). Taxi companies can exploit the knowledge of such communities to pass on demand or price information effectively and efficiently. Given the continuous and constant presence of such surges in major cities like Singapore, this can serve to significantly reduce wait times for customers or increase revenue for taxi drivers.</p><p>As it is difficult to get data about observable interactions such as messages or calls among individuals, this paper provides an innovative application where in we infer all relationships from visitations to physical locations. However, such inferences are subject to spatial homophily (similar location preferences will be inferred as relationships), and detection of the actual community structure can thus be extremely challenging. To that end, we make the following key contributions: (1) We introduce a four-phase framework, which by way of using quantified impacts excludes homophily. We execute this framework on a real-world data set of more than 6,000 taxis in Singapore; (2) To validate the framework, we first generate a synthetic dataset based on an input community structure and then infer that community structure; (3) Finally, we also implement a baseline approach without the homophily-elimination design and show that our framework can extract communities at much finer scale.</p></td>
                </tr>
            
                <tr>
                    <td>354</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-354">Variational BEJG Solvers for Marginal-MAP Inference with Accurate Approximation of B-conditional Entropy</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_354" class="editable_bid" data-pk="354" data-value="30"
                    data-url="/rev_3/paper/bid/set/354/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-354"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Previously proposed variational techniques for approximate MMAP inference in complex graphical models of high-order factors relax a dual variational objective function to obtain its tractable approximation, and further perform MMAP inference in the resulting simplified graphical model, where the sub-graph with decision variables is assumed to be a disconnected forest. In contrast, we developed novel variational MMAP inference algorithms and proximal convergent solvers, where we can improve the approximation accuracy while better preserving the original MMAP query by designing such a dual variational objective function that an upper bound approximation is applied only to the entropy of decision variables. We evaluate the proposed algorithms on both simulated synthetic datasets and diagnostic Bayesian networks taken from the UAI inference challenge, and our solvers outperform other variational algorithms in a majority of reported cases. Additionally, we demonstrate the important real-life application of the proposed variational approaches to solve complex tasks of policy optimization by MMAP inference, and performance of the implemented approximation algorithms is compared.<br></p></td>
                </tr>
            
                <tr>
                    <td>589</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-589">Probabilistic Auction for Distributed, Robust Resource Optimization (PADRE)</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_589" class="editable_bid" data-pk="589" data-value="30"
                    data-url="/rev_3/paper/bid/set/589/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-589"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-family: LinLibertineT; font-size: 12px;">Large scale resource allocation problems occur in military information collection, air campaign planning, logistics networks, energy grids, etc.. Optimal solutions require that demand, resource status, and allocation decisions are shared via messaging between geographically distributed nodes in the network, whether allocation decisions are made by one or a few auctioneer nodes or negotiated via distributed winner determination. Jamming of wireless links and cyber attacks on the network interfere with messaging and, thus, the quality of the allocation decisions. Therefore, optimizing decision quality requires selecting the appropriate decision network architecture. Our contribution described in the paper is a decentralized resource allocation architecture and algorithm that is robust to significant message loss and to uncertain demand arrival, and provides fine-grained, many-to-many combinatorial task allocation. Most importantly, it enables a conscious choice of the best level of decentralization under the expected degree of communications denial and quantifies the benefits of approximating status of peer nodes using proxy agents during temporary communications loss. Current solutions address one or two, but not all of these concerns. We present an auction-based resource allocation algorithm whose winner determination includes a constrained clustering algorithm. Hard and soft constraints ensure temporal and spatial requirements are met, while also honoring task priorities and dependencies, anticipating future needs, and minimizing ripple effects of allocation changes. We derive theoretical performance bounds for various degrees of decentralization. We show via extensive empirical analysis that our algorithmic implementation compares well to these theoretical bounds. Our results reveal the optimal degree of decentralization for any level of communications denial.&nbsp;</span><br></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>412</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-412">SCC-rFMQ learning in Cooperative Markov Games with Continuous Actions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Learning and Adaptation] Multiagent learning</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_412" class="editable_bid" data-pk="412" data-value="30"
                    data-url="/rev_3/paper/bid/set/412/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-412"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="font-family: verdana, arial, helvetica; font-size: small;">Although many reinforcement learning algorithms have been proposed for learning the optimal solutions in single-agent continuous action domains, multiagent coordination domains with continuous action have received relatively few investigations. Coordination problems in traditional multiagent domains, such as non-stationarity and stochasticity problem, still remain challenging for the continuous action multiagent domains. In this paper, we propose an independent learner hierarchical method, named Sample Continuous Coordination with recursive Frequency Maximum Q-Value (SCC-rFMQ), which divides the coordination problem in the continuous action cooperative Markov games into two layers. One layer samples a finite set of actions from the continuous action spaces by a sampling mechanism with variable exploratory rate, and the other layer evaluates the actions in the sampled action set and updates the policy using a reinforcement learning coordination method. By constructing coordination mechanisms at both levels, SCC-rFMQ can avoid the nonstationarity and stochasticity problem in continuous action cooperative Markov games effectively. The effectiveness of SCC-rFMQ is demonstrated on two well-designed games experimentally, i.e., a continuous version of the climbing game and a cooperative version of the boat problem. And the experimental results show that SCC-rFMQ outperforms other reinforcement learning algorithms in terms of dealing with the coordination problem in continuous action cooperative Markov games.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>683</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-683">An Election Game with a Polynomial-time Algorithm for Equilibrium Computation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_683" class="editable_bid" data-pk="683" data-value="30"
                    data-url="/rev_3/paper/bid/set/683/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-683"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We present a game-theoretic model for issue-based elections when voter opinions form natural clusters, approximating the continuous multi-dimensional solution space (as in the classic Hotelling-Downs model) to a finite discrete one. We show that this game can be reduced to a variation of network cost-sharing game with additional non-shareable costs. The flexibility offered by this reduction permits our model to capture several variations of the Hotelling-Downs model simultaneously, including ones with limited attraction, ability of candidates to enter and exit any time during the campaign or abstain from the race, the restriction on candidates to access certain stance positions, and the operational cost considerations of running a campaign. We show that a pure Nash equilibrium (PNE) always exists in our model, and we provide a polynomial-time algorithm for computing a PNE, which is in general PLS-Hard for network cost-sharing games. The results can also be extended to spatio-temporal games with similar structure, such as in location games with placement of commercial facilities.</p></td>
                </tr>
            
                <tr>
                    <td>234</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-234">On Collusion and Coercion: Agent Interconnectedness and In-Group Behaviour</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Socio-technical systems<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_234" class="editable_bid" data-pk="234" data-value="30"
                    data-url="/rev_3/paper/bid/set/234/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-234"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The interconnectedness of actors is an antecedent for collective corruption, which in turn can lead to endemic corruption in a society. As a testbed for studying the effects of social interconnectedness on corrupt behaviours, we examine the domain of maritime customs. Taking an extant agent-based simulation, we add to the simulation a nuanced model of actor relatedness, consisting of clan, in-group (sect), and town of origin, and encode associated behavioural norms. We examine the effects of social interconnectedness on domain performance metrics such as revenue, container outcomes, time, coercive demands, and collusion. Results confirm that, when corruption is widespread, localized punitive- or incentive-based policies are weakened, and that the effect of process re-engineering is frustrated when interconnectedness increases beyond a critical point, for two out of three forms of homophily connections. Our work connects with and provides a complementary methodology to works in the political economy literature.</p></td>
                </tr>
            
                <tr>
                    <td>336</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-336">A Decentralised Planning Framework for Multi-Agent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_336" class="editable_bid" data-pk="336" data-value="30"
                    data-url="/rev_3/paper/bid/set/336/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-336"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><font color="#222222" face="arial, sans-serif"><span style="font-size: 12.8px;">Multi-agent platforms typically provide various mechanisms for runtime coordination. In this context, decentralised multi-agent planning can be efficient as well as effective, especially in loosely-coupled domains, besides also ensuring important properties in agent systems such as privacy and autonomy. However, little work has been done to explore this in practice. In this paper, we address this issue by putting forward an approach to online multi-agent planning that combines goal allocation, individual planning, and coordination during runtime in order to support the achievement of social goals in multi-agent systems. In particular, we present a planning and execution framework called Decentralised Online Multi-Agent Planning (DOMAP). Experiments with two loosely-coupled planning domains, one classical and one novel, show that DOMAP outperforms four other state-of-the-art multi-agent planners with regards to both planning and execution time, particularly in the most difficult problems.</span></font><br></p></td>
                </tr>
            
                <tr>
                    <td>568</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-568">RAIL: Risk-Averse Imitation Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Deep learning<br>[Learning and Adaptation] Adversarial machine learning</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_568" class="editable_bid" data-pk="568" data-value="30"
                    data-url="/rev_3/paper/bid/set/568/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-568"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Imitation learning algorithms learn viable policies by imitating an expert's behavior when reward signals are not available. Generative Adversarial Imitation Learning (GAIL) is a state-of-the-art algorithm for learning policies when the expert's behavior is available as a fixed set of trajectories. We evaluate in terms of the expert's cost function and observe that the distribution of trajectory-costs is often more heavy-tailed for GAIL-agents than the expert at a number of benchmark continuous-control tasks. Thus, high-cost trajectories, corresponding to tail-end events of catastrophic failure, are more likely to be encountered by the GAIL-agents than the expert. This makes the reliability of GAIL-agents questionable when it comes to deployment in risk-sensitive applications like robotic surgery and autonomous driving. In this work, we aim to minimize the occurrence of tail-end events by minimizing tail risk within the GAIL framework. We quantify tail risk by the Conditional-Value-at-Risk (CVaR) of trajectories and develop the Risk-Averse Imitation Learning (RAIL) algorithm. We observe that the policies learned with RAIL show lower tail-end risk than those of vanilla GAIL. Thus the proposed RAIL algorithm appears as a potent alternative to GAIL for improved reliability in risk-sensitive applications.<br></p></td>
                </tr>
            
                <tr>
                    <td>358</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-358">Inverse Reinforcement Behavior Learning for the Decision-Making Model of Crowd Simulation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent-based Simulation] Simulation techniques, tools and platforms<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Learning and Adaptation] Reward structures for learning</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_358" class="editable_bid" data-pk="358" data-value="30"
                    data-url="/rev_3/paper/bid/set/358/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-358"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we present a behavior model of agent-base crowd simulation and a framework to adapt the model to re-generate observed real behaviors using inverse reinforcement learning (IRL). Crowd simulation has been recently the subject of study due to its application in the fields of disaster evacuation, smart town planning and business strategic placing. However as any type of simulation, the data obtained from it is as good as its degree of realism, so not only physics interactions but intelligent crowd behavior is needed to give meaningful results. However, to obtain patterns in order to model this behavior is not a trivial task, especially in case of crowds, as it requires an enormous quantity of observation data, something hardly feasible in many scenarios due to practical and legal reasons. A method to replicate human behavior is using machine learning techniques, using a small training data set to generate cues allowing crowd agents to react to similar situations accordingly. We implement a BDI-based behavioral agent model into CrowdWalk, a large-scale crowd simulator, and, apply IRL to obtain suitable reward values for each sub-goal in BDI. The goal of the system is to provide a reliable way for the agents to behave, based in learned patterns around environment features and also a way to orient themselves in the scenario without knowing its layout.<br></p></td>
                </tr>
            
                <tr>
                    <td>767</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-767">Ordered Preference Elicitation Strategies for Supporting Multi-Objective Decision Making</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Humans and Agents] Human-robot/agent interaction<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_767" class="editable_bid" data-pk="767" data-value="30"
                    data-url="/rev_3/paper/bid/set/767/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-767"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In multi-objective decision planning and learning, much attention is paid to producing optimal solution sets that contain an optimal policy for every possible user preference profile. We argue that the step that follows, i.e, determining which policy to execute by maximising the user's intrinsic utility function over this (possibly infinite) set, is under-studied. This paper aims to fill this gap. We build on previous work on Gaussian processes and pairwise comparisons for preference modelling, extend it to the multi-objective decision support scenario, and propose new ordered preference elicitation strategies based on ranking and clustering. Our main contribution is an in-depth evaluation of these strategies using computer and human-based experiments. We show that our proposed elicitation strategies outperform the currently used pairwise methods, and found that users prefer ranking most. Our experiments further show that utilising monotonicity information in GPs by using a linear prior mean at the start and virtual comparisons to the nadir and ideal points, increases performance. We demonstrate our decision support framework in a real-world study on traffic regulation, conducted with the city of [blinded for review].</p></td>
                </tr>
            
                <tr>
                    <td>739</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-739">Competitive Cloud Pricing for Long-Term Revenue Maximization</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agents and Mainstream Computing] P2P, web services, grid computing, IoT, HPC<br>[Agents and Mainstream Computing] Other</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_739" class="editable_bid" data-pk="739" data-value="30"
                    data-url="/rev_3/paper/bid/set/739/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-739"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We also develop approximation algorithms for immediate profit calculation so as to further improve the efficiency of our algorithms. Experimental results show that the MPE strategy leads to much higher profits for providers compared with existing policies and our algorithms are efficient for solving large-size problems.<br>We decompose the problem into two subtasks: (1) dividing the stochastic game into many normal-forma games and calculating their Nash equilibria, for which we design an algorithm ensuring to converge, and (2) computing the MPE of the original game, which is efficiently solved by an algorithm combining the Nash equilibria based on a mild assumption. We first propose a comprehensive model for the real-world cloud market and formulate it as a stochastic game. Then we apply the Markov Perfect Equilibrium (MPE) solution concept to describe providers' optimal pricing policies, which is difficult to compute due to the incomplete information, the large number of users, and the large state space of the stochastic game.<br>Pricing policy optimization is a very important problem for cloud providers. We study this problem while considering three properties of the real-world cloud market: (1) providers have only incomplete information about the market; (2) it is in evolution due to the increasing number of users and decreasing marginal cost of providers; (3) it is fully competitive because of providers' and users' revenue-driven nature. However, there is no existing work investigating providers' optimal pricing policies under such realistic settings.<span class="fontstyle0"></span></p></td>
                </tr>
            
                <tr>
                    <td>598</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-598">Propagating, Revising, and Updating Probabilistic Beliefs for Assertive Announced Changes</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Other<br>[Humans and Agents] Human-robot/agent interaction<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_598" class="editable_bid" data-pk="598" data-value="30"
                    data-url="/rev_3/paper/bid/set/598/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-598"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'">We consider a robot that learns knowledge about its environment through dialog
interaction. The robot needs to "understand" speech from humans, </span><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'; font-style: italic">i.e.</span><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'">, convert a
speech to a pre-defined frame with a set of natural language terms labeled with
frame elements and ground these labeled terms to robot’s internal values. Then
the robot requires a probabilistic model that grounds a variable, </span><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'; font-style: italic">i.e.</span><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'">, a labeled
natural language term, to the internal value. In this paper, we consider how to
learn and adjust such a probability model according to new speech, especially
when the speech assertively announces the changing of the environment. We
divide variables into two categories, </span><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'; font-style: italic">i.e.</span><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'">, multi-valued and singled-valued, and
treat them differently during the process. We respectively provide methods to
propagate probabilistic beliefs for multi-valued variables, revise beliefs for single-valued variables, and update beliefs when the environment has changed. At last,
we evaluate the performance of our approach in a rich human-robot interaction
setup. We show that, when the robot receives an assertive announced change, its
probabilistic beliefs should be modified radically.&nbsp;</span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>401</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-401">PICA: Proactive Intelligent Conversational Agent for Interactive Narratives</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_401" class="editable_bid" data-pk="401" data-value="30"
                    data-url="/rev_3/paper/bid/set/401/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-401"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>A narrative relies on imperfect knowledge to stimulate the interactions between the different characters and this imperfect knowledge is ultimately used as a plot device to drive the narrative. This motivates our exploration of ways to encode this information, provide means for a user to both query and influence the knowledge, and guide the user based on a model of their experience. We developed PICA: a proactive intelligent conversational agent for interactive narratives. Our hybrid sub-symbolic architecture allows for encoding belief models for multiple users and autonomous agents in addition to the actual story knowledge. We also developed a discourse module using behavior trees to intuitively design the proactive and reactive capabilities of PICA. We demonstrate PICA in the context of an existing interactive narrative system, and our results reveal the promise of using our approach to encode time and uncertainty to represent evolving belief models of both users and autonomous agents experiencing a narrative.</p></td>
                </tr>
            
                <tr>
                    <td>216</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-216">Optimal Resource Allocation inWork-flows: Crowds, Clouds and Beyond</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Architectures for social reasoning<br>[Agent Cooperation] Distributed problem solving<br>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Agents and Mainstream Computing] P2P, web services, grid computing, IoT, HPC</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_216" class="editable_bid" data-pk="216" data-value="30"
                    data-url="/rev_3/paper/bid/set/216/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-216"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In many applications such as crowd-sourcing or<br>cloud computing, a challenging problem for businesses<br>is to choose the right assignment of resources<br>to the various tasks so that the overall requirements<br>of the process (such as accuracy, deadlines<br>and cost) are satisfied. These tasks are part<br>of complex workflows, and even for simple workflows,<br>determining whether certain requirements<br>are feasible is NP-hard. We formalize the workflow<br>optimization problem (WOPT) for a set of<br>workflows that appear in real world problems. For<br>requirements that arise in such applications, we<br>provide a set of fast algorithms that guarantedly<br>achieve close to optimal solutions. We rigorously<br>compare our approach with plethora of previous efforts,<br>solutions to tackle these problems.<br></p></td>
                </tr>
            
                <tr>
                    <td>335</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-335">Learning System-Efficient Equilibria in Route Choice Using Tolls</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_335" class="editable_bid" data-pk="335" data-value="30"
                    data-url="/rev_3/paper/bid/set/335/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-335"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider the route choice problem using multiagent reinforcement learning. In this problem, each driver-agent individually learns which routes minimise its expected travel costs. Such a selfish behaviour results in the so-called User Equilibrium (UE), which is inefficient from the system's perspective. In order to reduce the impact of selfishness, a well-known alternative is the use of tolls. We employ the so-called marginal-cost tolling (MCT) scheme, in which each driver is charged according to the cost it imposes on others. The use of MCT leads agents to behave in a socially-desirable way so that the system optimum (SO) is achieved. In contrast to previous works, we formulate an MCT scheme in which drivers are charged <i>a posteriori</i>, i.e., at the end of their trips. In this sense, as compared to previous works, our mechanism is more flexible (it does not depend on specialised infrastructure), fairer (agents pay for their actual marginal costs), and avoids unrealistic assumptions (agents have limited knowledge). We provide a general formulation of the toll values for univariate, homogeneous polynomial cost functions, which comprise the most commonly-used cost functions in the literature. Furthermore, we deliver theoretical results, showing that our approach converges to the a system-efficient UE, i.e., the SO.<br></p></td>
                </tr>
            
                <tr>
                    <td>333</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-333">Efficient Cooperative Inverse Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Cooperative games: computation<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_333" class="editable_bid" data-pk="333" data-value="30"
                    data-url="/rev_3/paper/bid/set/333/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-333"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Our goal is for AI systems to correctly identify and act according to their human user's objectives. Cooperative Inverse Reinforcement Learning (CIRL) formalizes this <i>value alignment</i> problem as a two-player game between a human and robot, in which only the human knows the parameters of the reward function: the robot needs to learn them as the interaction unfolds. Previous work showed that CIRL can be solved as a POMDP, but with an action space size exponential in the size of the reward parameter space. In this work, we exploit a specific property of CIRL: the human is a full information agent. This enables us to derive an optimality-preserving modification to the standard Bellman update, which reduces the complexity of the problem by an exponential factor. Additionally, we show that our modified Bellman update allows us to relax CIRL's assumption of human rationality. We apply this update to a variety of POMDP solvers, including exact methods, point-based methods, and Monte Carlo Tree Search methods. We find that it enables us to scale CIRL to non-trivial problems, with larger reward parameter spaces, as well as larger action spaces for the robot and the human. In solutions to these larger problems, the human exhibits pedagogical (teaching) behavior, while the robot interprets it as such and attains higher value for the human.</p></td>
                </tr>
            
                <tr>
                    <td>592</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-592">Expertise Drift in Referral Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_592" class="editable_bid" data-pk="592" data-value="30"
                    data-url="/rev_3/paper/bid/set/592/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-592"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Learning-to-refer is a challenge in expert referral networks, wherein Active Learning helps experts (agents) estimate the skills of other connected experts for different categories of tasks that the initial expert cannot solve and therefore must seek referral to experts with more appropriate expertise. Prior research has investigated different reinforcement action selection algorithms to assess viability of the learning setting both with uninformative priors and with partially available noisy priors, where experts are allowed to advertise a subset of their skills to their colleagues. Prior to this work, time-varying expertise drift (e.g., experts learning with experience) has not been considered though it is an aspect that may often arise in practice. This paper addresses the challenge of referral learning with time-varying expertise, proposing&nbsp; Hybrid, a novel combination of Optimistic Thompson Sampling, Pessimistic Thompson Sampling and Distributed Interval Estimation Learning (DIEL). In our extensive empirical evaluation, considering both biased and unbiased drift, the proposed algorithm outperforms the previous state-of-the-art (DIEL) and approaches the drift-aware oracle upper bound.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>286</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-286">Constrained-Based Differential Privacy for Mobility Services</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Agent Societies and Societal Issues] Socio-technical systems</td>
                    
                        <td>0.680</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_286" class="editable_bid" data-pk="286" data-value="30"
                    data-url="/rev_3/paper/bid/set/286/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-286"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Ubiquitous mobile and wireless communication systems have the potential to revolutionize transportation systems, making accurate mobility traces and activity-based patterns available to optimize the design and operations of mobility systems. However, these rich data sets also pose significant privacy risks, potentially revealing highly sensitive information about individual agents.</p><p>This paper studies how to use <i>differential privacy</i> to release mobility data for transportation applications. It shows that existing approaches do not provide the desired fidelity for practical uses. To remedy this limitation, the paper proposes the idea of <i>Constraint-Based Differential Privacy</i> (CBDP) that casts the production of a private data set as an optimization problem that redistributes the noise introduced by a randomized mechanism to satisfy fundamental constraints of the original data set.</p><p>The CBDP has strong theoretical guarantees: It is a constant factor away from optimality and, when the constraints capture categorical features, it runs in polynomial time. Experimental results show that CBDP ensures that a city-level multi-modal transit system has similar performance measures when designed and optimized over the real and private data sets and improves state-of-art privacy methods by an order of magnitude.</p></td>
                </tr>
            
                <tr>
                    <td>405</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-405">A Game-Theoretic Approach for Overlapping Community Detection via Frequency Graphs</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_405" class="editable_bid" data-pk="405" data-value="30"
                    data-url="/rev_3/paper/bid/set/405/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-405"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We introduce an interaction-based game-theoretic approach to study the similarities between rational individuals in a complex network, and demonstrate how it can be used to reveal community and overlapping community structure of the network. In particular, we consider a simple network coordination game as a proxy for strategic interactions between individuals, and use the frequency that two agents adopt the same strategy in a Nash equilibrium of such game to reflect the likelihood that these two agents belong to the same community. The result is a frequency graph that highlights the similarities between agents through their coordination behaviors. Based on this frequency graph, we design simple and efficient algorithms for both community detection and overlapping community detection problems. We evaluate these algorithms on datasets of real-world networks and benchmark test networks. Results show that these algorithms are able to effectively identify both disjoint and overlapping communities, and are often more accurate than the other state-of-the-art methods when many people belong to multiple communities.<br></p></td>
                </tr>
            
                <tr>
                    <td>45</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-45">Group Conformity Model of Diffusion in Social Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_45" class="editable_bid" data-pk="45" data-value="30"
                    data-url="/rev_3/paper/bid/set/45/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-45"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Diffusion in social networks is a result of agent's natural desire to conform to the behavioral patterns of their peers. Unlike the existing models of diffusion, the more fine-grained model presented in this paper accounts for conformity to different social groups that the same agent might belong to, rather than conformity to society as whole. This new model of diffusion is one of the two major contributions of this paper.</p><p><br></p><p>The other contribution is a sound and complete logical system describing the properties of the influence relation in the proposed model. The logical system is an extension of Armstrong's axioms from database theory by one new axiom that captures the topological structure of the network.<br></p></td>
                </tr>
            
                <tr>
                    <td>578</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-578">When Rigging a Tournament, Let Greediness Blind You</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_578" class="editable_bid" data-pk="578" data-value="30"
                    data-url="/rev_3/paper/bid/set/578/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-578"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>A knockout (or single-elimination) tournament, being a standard format of competition, is ubiquitous in sports competitions, elections and decision making. Such a competition consists of several rounds. In each round, all players that have not yet been eliminated are paired up. Each pair entails a match, where losers are eliminated. Winners proceed to the next round, until only a single winner exists. Given that we can correctly predict the outcome of each potential match, a seeding of the tournament deterministically determines its winner. In this regard, having a favorite player v in mind, it is natural to ask whether there exists a seeding that will make v the winner, and if yes--find such a seeding. Aziz et al. [AAAI, 2014] showed that this problem, called Tournament Fixing Problem (TFP), is NP-hard, thus resolving a longstanding open problem in the area. As a natural next step, they initiated the study of the parameterized complexity of TFP with respect to the feedback arc set number $k$ of the tournament encoding outcomes of matches. As a first result, they presented an XP-algorithm, which is simple but extremely inefficient. Recently, Ramanujan and Szeider [AAAI, 2017] showed that the problem is FPT by developing a significantly better algorithm whose running time is bounded by $ 2^{\Oh(k^2\log k)}n^{\Oh(1)}$. At the heart of this algorithm, lies the translation of the problem into an algebraic system of equations that is solved in a black box fashion by an ILP solver. Having greediness in mind, we present a fresh, purely combinatorial solution to this problem. Our solution relies on new insights into TFP itself, and in fact even results in the better running time bound of $2^{\Oh(k\log k)}n^{\Oh(1)}$. While the analysis of our algorithm is intricate, the algorithm itself is surprisingly simple.<br></p></td>
                </tr>
            
                <tr>
                    <td>92</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-92">Greedy Algorithms for Maximizing Nash Social Welfare</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_92" class="editable_bid" data-pk="92" data-value="30"
                    data-url="/rev_3/paper/bid/set/92/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-92"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We study the problem of fairly allocating a set of indivisible goods among agents with additive valuations. The extent of fairness of an allocation is measured by its Nash social welfare, which is the geometric mean of the valuations of the agents for their bundles. While the problem of maximizing Nash social welfare is known to be APX-hard in general, we study the effectiveness of <i>simple</i>, <i>greedy </i>algorithms in solving this problem in two interesting special cases.<br><br>First, we show that a simple, greedy algorithm provides a 1.061-approximation guarantee when agents have <i>identical </i>valuations, even though the problem of maximizing Nash social welfare remains NP-hard for this setting. Second, we show that when agents have <i>binary </i>valuations over the goods, an exact solution (i.e., a Nash optimal allocation) can be found in polynomial time via a greedy algorithm. Our results in the binary setting extend to provide novel, exact algorithms for optimizing Nash social welfare under <i>concave </i>valuations. Notably, for the above mentioned scenarios, our techniques provide a <i>simple </i>alternative to several of the existing, more sophisticated techniques for this problem such as constructing equilibria of Fisher markets or using real stable polynomials.</p></td>
                </tr>
            
                <tr>
                    <td>411</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-411">Timing Rating Requests for Maximizing Obtained Rating</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Humans and Agents] Human-robot/agent interaction<br>[Humans and Agents] Other</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_411" class="editable_bid" data-pk="411" data-value="30"
                    data-url="/rev_3/paper/bid/set/411/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-411"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper studies methods for timing requests for user rating. The problem can be found in various domains, and has gained much importance in recent years as the accessibility of the public to the ratings received increased and became an important consideration affecting customers' decisions.&nbsp; The paper proposes a new method for issuing a rating request, based on optimal stopping principles, while assuming an exponentially diminishing effect of all prior user experiences with the system over the user satisfaction.&nbsp; We show that the expected-rating-maximizing timing strategy under this assumption is threshold-based and propose an efficient Monte-Carlo-based method which&nbsp; facilitates the thresholds extraction. The analysis of the ratings achieved through the use of the proposed method compared to issuing random rating requests (which is highly common in apps and by service companies nowadays) in two different experimental infrastructures reveals a significant improvement in the average rating received.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>212</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-212">Balancing the Pain and Gain of Hobnobbing: Utility-Based Network Building over Attributed Social Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Social networks<br>[Agent-based Simulation] Simulation of complex systems<br>[Humans and Agents] Agent-based analysis of human interactions</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_212" class="editable_bid" data-pk="212" data-value="30"
                    data-url="/rev_3/paper/bid/set/212/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-212"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span class="fontstyle0">The establishment of interpersonal ties is a pivotal problem in the structural analysis of social networks. In particular, link recommendation problem asks for valuable future links to establish by an individual. Existing methods for this problem rely on link prediction that evaluates the likelihood of successful tie creation between<br>two individuals. Such methods do not consider the social capital gained by agents, nor do they concern with the required cost of&nbsp;this process. In light of this limitation, we propose a utility-based network building problem, with an aim to strike a balance between the gained social capital – in the form of closeness centrality – and the cost of establishing ties. We propose algorithms to solve this problem over networks whose nodes may or may not be labelled with attributes, and test their performance on a range of synthesized and real-world social networks. By having multiple agents adopting utility-based network building strategies, we propose a suite of models of&nbsp; network formation and demonstrate empirically that the they capture important structural properties. In particular, we investigate the emergence of a core/periphery structure as a joint result of preferential attachment and network building strategies</span>&nbsp;.<br style="line-height: normal; text-align: -webkit-auto; text-size-adjust: auto;"></p></td>
                </tr>
            
                <tr>
                    <td>489</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-489">Leveraging Statistical Multi-Agent Online Planning with Emergent Value Function Approximation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Learning and Adaptation] Multiagent learning<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_489" class="editable_bid" data-pk="489" data-value="30"
                    data-url="/rev_3/paper/bid/set/489/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-489"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Making decisions is a great challenge in distributed autonomous environments due to enormous state spaces and uncertainty. Many online planning algorithms rely on statistical sampling to avoid searching the whole state space, while still being able to make acceptable decisions. However, planning often has to be performed under strict computational constraints making online planning in multi-agent systems highly limited, which could lead to poor system performance, especially in stochastic domains.</p><p>In this paper, we propose <i>Emergent Value function Approximation&nbsp;</i><i>for Distributed Environments (EVADE)</i>, an approach to integrate global experience into multi-agent online planning in stochastic domains to consider global effects during local planning. For this purpose, a value function is approximated online based on the emergent system behaviour by using methods of reinforcement learning.</p><p>We empirically evaluated EVADE with two statistical multi-agent online planning algorithms in a highly complex and stochastic smart factory environment, where multiple agents need to process various items at a shared set of machines. Our experiments show that EVADE can effectively improve the performance of multi-agent online planning, while offering efficiency w.r.t. the breadth and depth of the planning process.</p></td>
                </tr>
            
                <tr>
                    <td>766</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-766">State Abstraction Synthesis for Discrete Models of Continuous Domains</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_766" class="editable_bid" data-pk="766" data-value="30"
                    data-url="/rev_3/paper/bid/set/766/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-766"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><pre style="margin-bottom: 0px; padding: 0px; line-height: 1.4; background-color: rgb(255, 255, 255);"><pre style="padding: 0px; margin-bottom: 0px; line-height: 1.4; background-color: rgb(255, 255, 255);"><font color="#172b4d" face="SFMono-Medium, SF Mono, Segoe UI Mono, Roboto Mono, Ubuntu Mono, Menlo, Courier, monospace"><span style="font-size: 12px;">  Reinforcement Learning (RL) is a paradigm for enabling autonomous learning
  wherein rewards are used to influence an agent's action choices in various 
  states. As the number of states and actions available to an agent increases,
  so it becomes increasingly difficult for the agent to quickly learn the
  optimal action for any given state. One approach to mitigating the detrimental
  effects of large state spaces is to represent collections of
  states together as encompassing ``abstract states".

  State abstraction itself leads to a host of new challenges for an agent. One
  such challenge is that of automatically identifying new abstractions that
  balance generality and specificity; the agent must identify both the
  similarities and the differences between states that are relevant to its
  goals, while ignoring unnecessary details that would otherwise hinder the
  agent's progress. We call this problem of identifying useful abstract states
  the Abstraction Synthesis Problem (ASP). 

  State abstractions can provide a significant benefit to model-based agents by
  simplifying their models. T-UCT, a hierarchical model-learning algorithm
  for discrete, factored domains, is one such method that leverages state
  abstractions to quickly learn and control an agent's environment. Such
  abstractions play a pivotal role in the success of T-UCT; however, T-UCT's
  solution to ASP requires a fully discrete state space.

  In this work we develop and compare enhancements to T-UCT that relax its
  assumption of discreteness. We focus on solving ASP in domains with
  multidimensional, continuous state factors, using only the T-UCT agent's
  limited experience histories and minimal knowledge of the domain's structure.
  Finally, we present a new abstraction synthesis algorithm, RCAST, and compare
  this algorithm to existing approaches in the literature. We provide the
  algorithmic details of RCAST and its subroutines, and we show that RCAST
  outperforms earlier approaches to ASP by enabling T-UCT to accumulate
  significantly greater total reward with minimal expert configuration and
  processing time.</span></font>
</pre><div><br></div></pre></td>
                </tr>
            
                <tr>
                    <td>327</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-327">Multi-sided Advertising Markets: Dynamic Mechanisms and Incremental User Compensations</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Economic Paradigms] Auctions and mechanism design</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_327" class="editable_bid" data-pk="327" data-value="30"
                    data-url="/rev_3/paper/bid/set/327/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-327"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;"><!--StartFragment-->Online advertising has motivated has motivated companies to collect vast amounts of information about users, which increasingly creates privacy concerns. </p><p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;">One way to answer these concerns is by enabling end users to choose which aspects of their private information can be collected. Based on principles suggested by Feldman and Gonen (2016), we introduce a new online advertising market model which uses information brokers to give users such control.</p><p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;">Unlike (Feldman and Gonen 2016), our model is dynamic and involves multi-sided markets where all participating sides are strategic. We describe a mechanism for this model which is theoretically guaranteed to (approximately) maximize the gain from trade, avoid a budget deficit and incentivize truthfulness and voluntary participation. As far as we know, this is the first known dynamic mechanism for a multi-sided market having these properties.</p><p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;"><br></p><p>




</p><p style="margin-bottom: 0px;">We experimentally examine and compare our theoretical results by using real world advertising bid data. The experiments suggest that our mechanism performs well in practice even in input regimes for which our theoretical guarantee is weak or meaningless.<!--EndFragment--></p></td>
                </tr>
            
                <tr>
                    <td>99</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-99">A Scheduling-Based Approach to Multi-Agent Path Finding with Weighted and Capacitated Arcs</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Agent Cooperation] Multi-robot systems<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_99" class="editable_bid" data-pk="99" data-value="30"
                    data-url="/rev_3/paper/bid/set/99/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-99"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Multi-agent path finding (MAPF) deals with the problem of finding a collision-free path for a set of agents. The agents are located at nodes of a directed graph, they can move over the arcs, and each agent has its own destination node. It is not possible for two agents to be at the same node at the same time. The usual setting is that each arc has length one so at any time step, each agent either stays in the node, where it is, or moves to one of its neighboring nodes.</p><p><br></p><p>This paper suggests to model the MAPF problem using scheduling techniques, namely, nodes and arcs are seen as resources. The concept of optional activities is used to model which nodes and arcs an agent will visit. We first describe a model, where each agent can visit each node at most once. Then, we extend the model to allow agents re-visiting the nodes.</p><p><br></p><p>The major motivation for the scheduling model of MAPF is its capability to naturally include other constraints. We will study particularly the problems, where the capacity of arcs can be greater than one (more agents can use the same arc at the same time), and the lengths of arcs can be greater than one (moving between different pairs of nodes takes different times). These extensions make the model closer to reality than the original MAPF formulation. We compare the efficiency of models experimentally.</p></td>
                </tr>
            
                <tr>
                    <td>532</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-532">Adversarial Task Allocation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_532" class="editable_bid" data-pk="532" data-value="30"
                    data-url="/rev_3/paper/bid/set/532/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-532"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal">The problem of allocating tasks to workers is of
long-standing fundamental importance. Examples of this include the classical
problem of assigning computing tasks to nodes in a distributed computing
environment, as well as the more recent problem of crowdsourcing where a broad
array of tasks are slated to be completed
by human workers. Extensive research into this problem
generally addresses important issues such
as uncertainty and, in crowdsourcing, incentives. However, the problem of adversarial tampering with the task
allocation process has not received as much attention. <o:p></o:p></p><p>

</p><p class="MsoNormal">We are concerned with particular
adversarial setting in task allocation where an attacker may target a specific worker in order
to prevent the tasks assigned to this worker from being completed. &nbsp;We consider two attack models: one in which
the attacker observes the actual allocation decision, and the second in which
the adversary observes only the
allocation policy (which may be randomized). For the case when all tasks are
homogeneous, we provide efficient algorithms for both settings. When tasks are heterogeneous, however, we show the adversarial
allocation problem to be NP-Hard, Our
experiments show, surprisingly, that the difference between the level of
robustness in the two attack models is minimal: deterministic allocation can
achieve nearly as much utility as randomized.<o:p></o:p></p></td>
                </tr>
            
                <tr>
                    <td>442</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-442">Near-Optimal Mechanism for Ordinal Peer Assessment</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Monitoring agent societies<br>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Noncooperative games: computation<br>[Agent Theories and Models] Logics for agents and multi-agent systems</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_442" class="editable_bid" data-pk="442" data-value="30"
                    data-url="/rev_3/paper/bid/set/442/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-442"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Peer assessment serves as a major method for evaluating employee true performance, accessing the contributions of individuals within a group, making social decisions and many other scenarios.</p><p>The idea is to ask the individuals of the same group to assess the performance of others. Scores or ordering are determined based on these evaluations.</p><p>However, peer assessment can be biased and manipulated, especially when people have a conflict of interests. In this paper, we consider the problem of eliciting the underlying ordering of $n$ strategic agents with respect to their performances (e.g., quality of work, contributions, scores, etc.).</p><p>We first prove that there is no deterministic mechanism which obtains the underlying ordering in dominant-strategy implementation.</p><p>Then, we propose a \emph{Two-Stage Mechanism} in which truth-telling is the \emph{unique} strict Nash equilibrium yielding the underlying ordering, except that there is an arbitrarily small probability of the disorder between the last two agents.</p><p>Moreover, our mechanism needs only $n+1$ queries.</p><p>We prove a simple $\Omega(n)$ lower bound of query complexity for any mechanism,&nbsp;</p><p>which indicates that our mechanism is nearly optimal.</p><p>Besides, we conduct the experiments on several scenarios to demonstrate the proposed mechanism is robust.</p></td>
                </tr>
            
                <tr>
                    <td>51</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-51">Transformations from SARL Metamodel to Object Oriented Metamodel</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Programming languages and frameworks for agents and multi-agent systems<br>[Engineering Multiagent Systems] Modelling and specification languages</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_51" class="editable_bid" data-pk="51" data-value="30"
                    data-url="/rev_3/paper/bid/set/51/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-51"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>SARL is a general-purpose agent-oriented programming language.</p><p>This language aims at providing the fundamental abstractions for dealing with concurrency, distribution, interaction, decentralization, reactivity, autonomy and dynamic reconfiguration that are usually considered as essential for implementing agent-based applications.</p><p>Every programming language specifies an execution model.</p><p>In the case of SARL, this execution model is defined based upon the object-oriented paradigm, e.g. a run-time environment written in Java.</p><p>Accordingly, and by default, the SARL programs are transformed into their equivalent object-oriented programs.</p><p>The goal of this paper is the explanation of the mapping between the agent paradigm and the object-oriented paradigm, and the definition of transformations from the SARL constructs to the standard object-oriented constructs.</p><p>They enable the SARL developer understanding the SARL statements, and the mapping to executable entities.</p><p>The transformations in this paper could also serve as the basis for creating a compiler extension for targeting any object-oriented programming language.</p></td>
                </tr>
            
                <tr>
                    <td>262</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-262">Phase Transition of the 2-Choices Dynamics on Core-Periphery Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent Societies and Societal Issues] Social networks<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_262" class="editable_bid" data-pk="262" data-value="30"
                    data-url="/rev_3/paper/bid/set/262/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-262"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Consider the following process on a network: Each agent initially holds either opinion <i>blue</i>&nbsp;or <i>red</i>; then, in each round, each agent looks at two random neighbors and, if the two have the same opinion, the agent adopts it. This process is known as the <i>2-Choices</i>&nbsp;dynamics and is arguably the most basic non-trivial <i>opinion dynamics</i>&nbsp;modeling voting behavior on social networks. Despite its apparent simplicity, 2-Choices has been analytically characterized only on networks with a strong expansion property - under assumptions on the initial configuration that establish it as a fast <i>majority consensus</i> protocol.&nbsp;</p><p>In this work, we aim at contributing to the understanding of the 2-Choices dynamics by considering its behavior on a class of networks with Core-Periphery structure, a well-known topological assumption in social networks. In a nutshell, assume that a densely-connected subset of agents, the <i>core</i>, holds a different opinion from the rest of the network, the <i>periphery</i>. Then, depending on the strength of the cut between the core and the periphery, a phase-transition phenomenon occurs: Either the core's opinion rapidly spreads among the rest of the network, or a <i>metastability</i>&nbsp;phase takes place, in which both opinions coexist in the network for superpolynomial time. The interest of our result is twofold. On the one hand, by looking at the 2-Choices dynamics as a simplistic model of competition among opinions in social networks, our theorem sheds light on the <i>influence</i>&nbsp;of the core on the rest of the network, as a function of the core's connectivity towards the latter. On the other hand, to the best of our knowledge, we provide the first analytical result which shows a heterogeneous behavior of a simple dynamics as a function of structural parameters of the network. Finally, we validate our theoretical predictions with extensive experiments on real networks.</p></td>
                </tr>
            
                <tr>
                    <td>233</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-233">Multiagent Reinforcement Learning for Coordinated Autonomous Driving</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Learning and Adaptation] Multiagent learning</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_233" class="editable_bid" data-pk="233" data-value="30"
                    data-url="/rev_3/paper/bid/set/233/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-233"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Autonomous driving is a typical multi-agent setting where each vehicle must take into account its surrounding vehicles for taking specific driving maneuvers. Although a large number of studies have successfully applied reinforcement learning techniques in low-level control of driving maneuvers such as acceleration, deceleration and steering, or higher level of strategic decision makings such as lane changing and overtaking, little work has been done to investigate how co-existing autonomous vehicles would interact with each other and how reinforcement learning can be helpful in such situations. This paper tries to answer this question by applying multiagent reinforcement learning techniques for high-level strategic decision making of following or overtaking within a group of autonomous vehicles in highway situations. Learning in such situations is challenging due to the unique feature of vehicular mobility, which renders it infeasible to directly applying existing coordinated MARL approaches. To solve this problem, we propose two basic coordination models to enable distributed learning of coordinated maneuvers in a group of vehicles and then come up with several extended mechanisms to make these models workable in more complex and realistic settings with any number of vehicles. Experimental evaluation has verified the benefits of the proposed coordinated learning approach, compared to other approaches that learn without coordination or rely on some expert driving rules.</p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>261</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-261">The importance of fairness in increasing the adoption of autonomous group buying agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Humans and Agents] Human-robot/agent interaction<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_261" class="editable_bid" data-pk="261" data-value="30"
                    data-url="/rev_3/paper/bid/set/261/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-261"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><span id="docs-internal-guid-d2508946-aaef-7f18-3c97-e51b83a8208e"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span id="docs-internal-guid-d2508946-b678-915d-c109-9681653406cd"></span></p><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:#ffffff;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;">There has been growing interest in studying how people interact with autonomous agents and how to design interfaces for autonomous agents. We are interested in the opportunity to inform such design by concepts and research methods from behavioural economics, particularly around the idea of fairness amongst people. In this paper, we report on a lab study where participants experienced how autonomous shopping prototypes facilitate group buying, and where their shopping performance (i.e. savings) was linked to their experimental reward. In particular, we compared two different design choices for autonomous group buying agents:</span><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;"> one designed around fairness, and the other around economically rational utility maximisation. Our findings revealed that a fair agent is more likely to be accepted and trusted than a rational one, suggesting that</span><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:#ffffff;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;"> including fairness in the design of autonomous agents can increase the adoption and acceptance of such technology. </span></p></span></td>
                </tr>
            
                <tr>
                    <td>609</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-609">Architectural Middleware that Supports Building High-performance, Scalable, Ubiquitous, Intelligent Personal Assistants</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Agents and Mainstream Computing] Mobile agents<br>[Agents and Mainstream Computing] Service-oriented architectures</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_609" class="editable_bid" data-pk="609" data-value="30"
                    data-url="/rev_3/paper/bid/set/609/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-609"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Intelligent Personal Assistants (IPAs) are software agents that can perform tasks on behalf of individuals and assist them on many of their daily activities. IPAs capabilities are expanding rapidly due to the recent advances on areas such as natural language processing, machine learning, artificial cognition, and ubiquitous computing, which equip the agents with competences to understand what users say, collect information from everyday ubiquitous devices (including not only smartphones but also wearables, tablets, personal computers, cars, clothes, household appliances, etc.), learn user preferences, deliver data-driven search results, and make decisions based on user's context. Apart from the inherent complexity of building such IPAs, there are serious architectural and technical challenges (such as low-latency, high-performance, scalability, concurrency, interoperability, code mobility, support to the heterogeneity of objects and the diversity of communication protocols, among others) that need to be addressed since they divert developers and researchers from their main goal: building IPAs. Thus, our contribution in this paper is twofold: 1) we propose a platform-agnostic multi-session architecture that alleviates the burdensome task of dealing with low-level design details when building an IPA by adding multiple abstraction layers that hide the underlying complexity; and 2) we propose a high-performance middleware which concretizes the aforementioned architecture and allows the development of high-level capabilities while scaling the system up to hundreds of thousands of IPAs with no extra effort.&nbsp; We demonstrate the powerfulness of our framework by analyzing software metrics of its complexity, size, effort, performance, cohesion and coupling when developing a conversational IPA.<br></p></td>
                </tr>
            
                <tr>
                    <td>245</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-245">Opponent Modelling of Non-Stationary Agents with Deep Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_245" class="editable_bid" data-pk="245" data-value="30"
                    data-url="/rev_3/paper/bid/set/245/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-245"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Humans, like all animals, both cooperate and compete with each other. Through these interactions we learn to observe, act, and manipulate to maximise our utility function, and continue doing so as others learn with us. This is a decentralised non-stationary learning problem, where to survive and flourish an agent must adapt to the gradual changes of other agents as they learn, as well as capitalise on sudden shifts in their behaviour. To learn in the presence of such non-stationarity, we introduce the Switching Agent Model (SAM) that combines traditional deep reinforcement learning -- which typically performs poorly in such settings -- with opponent modelling, using uncertainty estimations to robustly switch between multiple policies. We empirically show the success of our approach in a multi-agent continuous action environment, demonstrating SAM's ability to identify, track, and adapt to both gradual and sudden changes in the behaviour of non-stationary agents<br></p></td>
                </tr>
            
                <tr>
                    <td>36</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-36">Modelling Multiple Influences Diffusion in On-line Social Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_36" class="editable_bid" data-pk="36" data-value="30"
                    data-url="/rev_3/paper/bid/set/36/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-36"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In on-line social networks, innovations in the presence of one or more influences disseminate through the topological structure of the networks rapidly. In reality, various influences normally coexist in the same context and have subtle relations, such as supportive, contradictory and competitive relations, affecting the users' decisions of adopting any innovations. Therefore, modelling diffusion process of multiple influences is an important, yet challenging research question. By employing the agent-based modelling, in this paper, a distributed approach has been proposed to model the diffusion process of multiple influences in social networks. The proposed model has been applied in the undesirable influence minimisation problem, where the time series is taken into consideration. The experimental results show our model can be utilised to minimise the adverse impact of a certain influence by injecting other influences. Furthermore, the proposed model also sheds light on understanding, investigating and analysing multiple influences in social networks<br></p></td>
                </tr>
            
                <tr>
                    <td>101</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-101">Gaussian process vector calculus for identifying sources and sinks in the presence of multiple agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_101" class="editable_bid" data-pk="101" data-value="30"
                    data-url="/rev_3/paper/bid/set/101/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-101"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block">We build a model using Gaussian processes to infer a spatio-temporal field from observed agent trajectories, representing a value, or influence, function. Significant landmarks or influence points in agent surroundings are jointly derived through vector calculus operations that indicate the presence of sources and sinks in the field. We evaluate these influence points by using the Kullback-Leibler divergence between the posterior and prior Laplacian of the inferred spatio-temporal field. Through locating significant features that influence trajectories, our model aims to give greater insight into underlying causal influence functions that help explain agent decision-making. A key feature of our model is that it infers a joint Gaussian process over the observed trajectories, the time-varying field of potential functions and corresponding canonical vector calculus operators. We apply our model to both synthetic data and GPS data of pelagic seabirds, demonstrating the applicability of our technique in the presence of multiple agents.</td>
                </tr>
            
                <tr>
                    <td>244</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-244">Design of  strategy proof market platforms with blockchain based, game theory inspired smart contracts</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Agent Societies and Societal Issues] Trust and reputation<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_244" class="editable_bid" data-pk="244" data-value="30"
                    data-url="/rev_3/paper/bid/set/244/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-244"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p abp="356">Trusted collaboration without revelation of business sensitive information is a key requirement for any business to business (B2B) platform. Platforms that satisfy these requirements of trust, privacy and collaboration have been difficult to build and therefore most B2B platforms are far more limited than business to customer (B2C) platforms. Our work investigates novel ways in which ideas from game theory, blockchain and cryptography can be harnessed to enable such trusted and privacy-preserving collaborative B2B platforms. As a prototypical example of the type of problems that our work aims to address, we consider an online welfare maximizing platform involving strategic enterprise buyers and sellers. </p><p abp="356">We model, using repeated games, the strategic interactions between buyers and sellers on such a collaborative B2B platform and deduce conditions under which&nbsp; high quality offerings constitute an equilibrium. Our proposed mechanism induces honest behavior by all the players. We also show that the technology of permissioned blockchains provides an excellent way of robustly implementing the proposed mechanism on an online platform. The blockchain deploys a smart contract that implements the business logic in a given mechanism and is supported by two cryptograpically sound regulation protocols to provide trust and privacy in all the collaborations. Thus, we believe, our work is a key step in the direction of building a powerful collaborative B2B platform.<br></p><p>&nbsp;</p><p abp="356"><br abp="357"></p></td>
                </tr>
            
                <tr>
                    <td>360</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-360">Facility Location with Variable and Dynamic Populations</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Social choice theory</td>
                    
                        <td>0.670</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_360" class="editable_bid" data-pk="360" data-value="30"
                    data-url="/rev_3/paper/bid/set/360/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-360"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><font face="Lucida Grande, Verdana, Arial, Helvetica, sans-serif"><span style="font-size: 13px; background-color: rgb(240, 254, 255);">Facility location is a well-studied problem in social choice literature, where agents' preferences are restricted to be singlepeaked. When the number of agents is considered as a variable (e.g., it is not observable a priori), a social choice function must be defined so that it can take any possible number of preferences as input. Furthermore, there exist cases where multiple choices must be made continuously while agents dynamically dynamically arrive/leave. Under such variable/ dynamic populations, a social choice function needs to give each agent an incentive to sincerely report her existence (e.g., participation/no-hiding). In this paper we consider facility location models with variable/dynamic populations. For a static (one-shot), variable population model, we provide a necessary and sufficient condition for a social choice function to satisfy participation, as well as truthfulness, anonymity, and Pareto efficiency. It is considered as a further restriction of median voter schemes. For a dynamic model, we first propose an online social choice function, which is optimal for the total sum of the distances between the choices in previous and current periods, among any Pareto efficient functions.We then define a generalized class of online social choice functions and compare their performance in both theoretical and experimental way.&nbsp;</span></font></p><p><br></p></td>
                </tr>
            
                <tr>
                    <td>321</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-321">CityScope Andorra: A multi-level interactive and tangible agent-based visualization</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Simulation techniques, tools and platforms<br>[Agent-based Simulation] Interactive simulation<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_321" class="editable_bid" data-pk="321" data-value="30"
                    data-url="/rev_3/paper/bid/set/321/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-321"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This study proposes a novel information visualization approach&nbsp; developed and deployed in the state of Andorra. We present a framework to analyze and represent individuals flow through a multi-level interactive and tangible agent-based visualization. The presented model, developed to simulate movement and behavior of visitors in Andorra, is embedded in the MIT CityScope framework, a Tangible User Interface platform used for civic engagement, urban development, and decision making. The model as well as other peripheral tools depicted here, were tested in concert during multiple real-life engagements.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>659</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-659">Teaching Multiple Tasks to an RL Agent using LTL</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Other<br>[Learning and Adaptation] Reward structures for learning<br>[Humans and Agents] Other</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_659" class="editable_bid" data-pk="659" data-value="30"
                    data-url="/rev_3/paper/bid/set/659/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-659"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper examines the problem of how to teach multiple tasks to an agent that learns using Reinforcement Learning (RL). To this end, we propose the use of Linear Temporal Logic (LTL) as a compelling language for teaching multiple tasks to an RL agent in a manner that supports composition of learned skills. We also propose a novel algorithm that exploits LTL progression and off-policy RL to speed up learning without compromising convergence guarantees. Experiments over randomly generated Minecraft-like grids illustrate our superior performance relative to the state of the art.<br></p></td>
                </tr>
            
                <tr>
                    <td>307</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-307">Collective Schedules: Scheduling Meets Computational Social Choice</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_307" class="editable_bid" data-pk="307" data-value="30"
                    data-url="/rev_3/paper/bid/set/307/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-307"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>When scheduling public works or events in a shared facility one needs to accomodate preferences of a population.&nbsp; We formalize this problem by introducing the notion of a collective schedule. We show how to extend fundamental tools from the social choice theory---the Kemeny rule and the Condorcet principle---to collective scheduling. We study the computational complexity of finding collective schedules. We also perform simulations demonstrating that optimal collective schedules can be found for instances with realistic sizes.</p></td>
                </tr>
            
                <tr>
                    <td>695</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-695">A Knowledge Engineering Methodology for Applications of Argumentation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Engineering Multiagent Systems] Methodologies for agent-based systems<br>[Agent Theories and Models] Other</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_695" class="editable_bid" data-pk="695" data-value="30"
                    data-url="/rev_3/paper/bid/set/695/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-695"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper proposes a general knowledge engineering methodology for developing real-life applications for dynamic decision making, expressible within Hierarchical Argumentation Frameworks (HAF). The methodology builds on a systematic analysis of application scenarios of increasing specificity. The application expert is able to express his/her preferences on the final desired outcome or behavior of the application system by considering the increasing specificity of the problem at different levels and resolving at a higher level, conflicts between arguments that appear at a lower level of specificity. The methodological process generates directly an argumentation theory that models declaratively the application at hand, with a high degree of modularity and flexibility. Several theoretical properties of the methodology, that depend only on the general properties of HAFs, are studied. An associated tool is presented and real world applications that have used our methodology and tool in different domains (i.e. data sharing, medical diagnosis support) are discussed.</p></td>
                </tr>
            
                <tr>
                    <td>80</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-80">Diffusion in Social Networks with Recalcitrant Agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_80" class="editable_bid" data-pk="80" data-value="30"
                    data-url="/rev_3/paper/bid/set/80/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-80"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The paper generalizes the standard threshold models of diffusion in social networks by introducing the notion of recalcitrant agents that are resistant to the diffusion. The focus of the paper is on a ternary influence relation between groups of agents: one group can indirectly influence another group in spite of the third group being recalcitrant. The main technical result is a sound and complete axiomatization of this relation.<br></p></td>
                </tr>
            
                <tr>
                    <td>139</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-139">ER-Agent Communication Languages and Protocol for Large-Scale Emergency Responses</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Communication languages and protocols<br>[Agents and Mainstream Computing] Mobile agents</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_139" class="editable_bid" data-pk="139" data-value="30"
                    data-url="/rev_3/paper/bid/set/139/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-139"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>MS</w:LidThemeOther>
  <w:LidThemeAsian>ZH-TW</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" Priority="0" SemiHidden="true"
   UnhideWhenUsed="true" Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" Priority="0" SemiHidden="true"
   UnhideWhenUsed="true" Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="0" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"/>
 </w:LatentStyles>
</xml><![endif]-->

<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin-top:0cm;
	mso-para-margin-right:0cm;
	mso-para-margin-bottom:8.0pt;
	mso-para-margin-left:0cm;
	line-height:107%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-ansi-language:MS;
	mso-fareast-language:EN-US;}
</style>
<![endif]-->



<!--StartFragment--><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;,serif;mso-fareast-font-family:
Calibri;mso-fareast-theme-font:minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA">We have introduced a new agent communication
language ​​(ER-ACL) and a corresponding protocol (ER-ACP) to be used in
multi-agent systems (MAS) to assist large-scale emergency responses as part of
an Emergency Response Communication Framework (Mobile Kit Disaster Assistance)</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;,serif;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">.
Four types of agent are assumed: victims, carers (medical &amp; social workers),
families &amp; friends, and ER-rescuers &amp; helpers (members of the public,
NGOs, government agencies etc.). The advantages of ER-ACL and ER-ACP are that
they provide a well-defined foundation to connect victims with potential
helpers, thereby enabling crowdsourcing via effective communication based on
precise semantics. The ER-ACL represents a significant extension and
specialisation of the FIPA ACL (2002)</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;,serif;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">&nbsp;for applications in emergency response scenarios now that great technical
advances have been made in telecommunication (including image and video
reporting). We have also added new message constructs from the Common Alerting
Protocol</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;,serif;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">.
In today’s uncertain world, we believe a well-managed and personalised
communication system is vital to organise unstructured resources and save
lives. Not having found one in existence to-date, we hope our efforts can help
close this gap.</span>&nbsp; &nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>270</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-270">SSCUSM: An Improved Algorithm for Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_270" class="editable_bid" data-pk="270" data-value="30"
                    data-url="/rev_3/paper/bid/set/270/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-270"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block">Instance-based methods are a class of effective algorithms for solving reinforcement learning problems. USM (Utile Suffix Memory) algorithm represents the state space from instance chains effectively, which is very beneficial to solve the reasonable Q-value of actions. However, the state space of USM is exponentially expanded and includes many redundant states. A new state space-compressed algorithm SSCUSM is presented in the paper. SSCUSM algorithm obtains the heuristic information of environments by blind exploration, improves the construction of suffix tree by limiting the maximum length of the observation-reward sequence and uses the frequency of observations to improve the efficiency of exploration. Experiment results of three well-known benchmarks show that both the efficiency and the effect have been improved a lot by SSCUSM algorithm compared to USM algorithm.</td>
                </tr>
            
                <tr>
                    <td>730</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-730">Leveraging Observational Learning for Exploration in Bandits</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent Cooperation] Multi-user/multi-virtual-agent interaction</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_730" class="editable_bid" data-pk="730" data-value="30"
                    data-url="/rev_3/paper/bid/set/730/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-730"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Imitation learning has been widely used to speed up learning of novice agents, by allowing them to leverage existing data from experts. In this paper, we study this problem in the context of bandits. More specifically, we consider that an agent, a learner, who is interacting with a bandit-style decision task,&nbsp; has access to a teacher, or target policy, interacting with the same environment. The learner is able to observe the actions that the teacher performs on the environment but not the rewards obtained. Our goal is to leverage the teacher data in order to guide the agent's exploration.</p><p>We propose a method that expands upon the Upper Confidence Bound algorithm by making use of conditional optimism contingent upon the actions of the teacher. We prove a regret upper-bound of order O(lnT) for problems with two-actions and derive the dependency on the expected regret of a general target policy. We provide empirical results showing both great benefits as well as certain limitations of using imitation in the multi-armed bandit setting.</p></td>
                </tr>
            
                <tr>
                    <td>320</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-320">Robust Deep Reinforcement Learning with Adversarial Attacks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Deep learning<br>[Learning and Adaptation] Adversarial machine learning</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_320" class="editable_bid" data-pk="320" data-value="30"
                    data-url="/rev_3/paper/bid/set/320/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-320"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper proposes adversarial attacks for Reinforcement Learning (RL) and then improves the robustness of Deep Reinforcement Learning algorithms (DRL) to parameter uncertainties with the help of these attacks. We show that even a naively engineered attack successfully degrades the performance of DRL algorithm. We further improve the attack using gradient information of an engineered loss function which leads to further degradation in performance. These attacks are then leveraged during training to improve the robustness of RL within robust control framework. We show that this adversarial training of DRL algorithms like Deep Double Q learning and Deep Deterministic Policy Gradients leads to significant increase in robustness to parameter variations for RL benchmarks such as Cart-pole, Mountain Car, Hopper and Half Cheetah environment.<br></p></td>
                </tr>
            
                <tr>
                    <td>190</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-190">Providing Smart Emergency Responses for Small-Scale Incidents Through Agent-Based Resource Management</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Collective intelligence<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_190" class="editable_bid" data-pk="190" data-value="30"
                    data-url="/rev_3/paper/bid/set/190/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-190"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In metropolitan regions, small-scale emergency incidents are characterised by their unpredictability, uncertainty and variability. Handling the emergency responses for these incidents usually require multiple emergency departments to collaborate with each other to generate efficient and effective resource allocation plans within a short time limit, which poses tremendous pressures and challenges on current emergency response systems. In this paper, an agent-based smart emergency response system is proposed to coordinate emergency departments to automatically and intelligently generate resources allocation plans to emergency incidents with the consideration of multiple objectives. In the experiment, an emergency resource allocation simulation system based on GoogleMaps is developed for testing the proposed system along with real-world rescue resource allocation data around the urban area of San Francisco.<br></p></td>
                </tr>
            
                <tr>
                    <td>403</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-403">Slim-DP: A Multi-Agent System for Communication-Efficient Distributed Deep Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_403" class="editable_bid" data-pk="403" data-value="30"
                    data-url="/rev_3/paper/bid/set/403/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-403"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>To afford the huge computational cost, large-scale deep neural networks (DNN) are usually trained on the distributed system, especially the widely-used parameter server architecture, consisting of a parameter server as well as multiple local workers with powerful GPU cards. During the training, local workers frequently pull the global model and push their computed gradients from/to the parameter server. Due to the limited bandwidth, such frequent communication will cause severe bottleneck for the training acceleration. As recent attempts to address this problem, quantization methods have been proposed to compress the gradients for efficient communication. However, such methods overlook the effects of compression on the model performance such that they either suffer from a low compression ratio or an accuracy drop. In this paper, to better address this problem, we investigate the distributed deep learning as a multi-agent system (MAS) problem. Specifically, 1) local workers and the parameter server are separate agents in the system; 2) the objective of these agents is to maximize the efficacy of the learned model through their cooperative interactions; 3) the strategy of the agents describes how they take actions, i.e. communicate their computed gradients or the global model, given the certain state; 4) rational agents always select the best-response strategy with the optimal utility. Inspired by this, we design a MAS approach for distributed training of DNN. In our method, the agents first estimate the utility (i.e., the benefit to help improve the model) of each action (i.e., transferring a subset of the gradients or the global model), and then take the best-response strategy based on their estimated utilities mixed with $\epsilon$-random exploration. We call our new method \emph{Slim-DP} as it, being different from the standard data-parallelism, only communicates a subset of the gradient or the global model. Our experimental results demonstrate that our proposed Slim-DP can reduce more communication cost and achieve better speedup without loss of accuracy than the standard data parallelism and its quantization version.<br></p></td>
                </tr>
            
                <tr>
                    <td>746</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-746">Fall if it lifts your team-mate: a novel type of candidate manipulation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_746" class="editable_bid" data-pk="746" data-value="30"
                    data-url="/rev_3/paper/bid/set/746/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-746"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We present a new interpretation of the traditional computational social choice<br>framework, where what are traditionally the candidates are considered as the<br>agents.<br>The particular implementation in mind is the proposed system for determining the<br>medal winners for Sports Climbing in the 2020 Olympic games.<br>We consider how this change in interpretation of who the agents are within the<br>model affects traditional questions, in particular the issue of manipulation by<br>agents within the system.<br><br></p></td>
                </tr>
            
                <tr>
                    <td>407</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-407">Modeling Assistant&#39;s Autonomy Constraints as a Means for Improving Autonomous Assistant-Agent Design</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Humans and Agents] Human-robot/agent interaction<br>[Humans and Agents] Other</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_407" class="editable_bid" data-pk="407" data-value="30"
                    data-url="/rev_3/paper/bid/set/407/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-407"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper we introduce and experimentally evaluate a new&nbsp; sub-optimal decision-making design to be used by autonomous agents acting on behalf of a user in repeated tasks, whenever the agent's autonomy level is continuously controlled by the user. This mode of operation is common and can be found whenever user's perception of the agent's competence is affected by the nature of the outcomes resulting from the agent's decisions rather than the optimality of the decisions made, e.g., in spam filtering, CV filtering, poker agents, and robotic vacuum cleaners as well as in newly arriving systems such as autonomous cars. Our proposed design relies on choosing the action that offers the best tradeoff between decision optimality and the influence over future allowed autonomy, where the latter is predicted using standard machine learning techniques. The design is found to be highly effective compared to following the theoretic-optimal decision rule, over various measures, through extensive experimentation with a virtual investment agent, making virtual investments on behalf of 679 subjects using Amazon Mechanical Turk.</p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>432</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-432">An Approach for Large-Scale Online Ridesharing</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Collective intelligence<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_432" class="editable_bid" data-pk="432" data-value="30"
                    data-url="/rev_3/paper/bid/set/432/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-432"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Ridesharing is a prominent collective intelligence application producing significant benefits both for individuals (reduced costs) and for the entire community (reduced pollution and traffic). We establish the online ridesharing (ORS) problem as an online stochastic combinatorial optimisation problem with the objective of forming cost-effective shared rides among commuters that submit requests to be served in a short time period (i.e., in a few minutes). We propose the first approach that can tackle large-scale ORS problems originating from real-world data (i.e., with ∼400 requests per minute). Specifically, we evaluate our approach on a real-world dataset, i.e., the New York City taxi dataset. Results show that our online approach computes solutions with an average competitive ratio of 90.9% (i.e., wrt the optimal offline solution assuming complete knowledge of the future) for problem sizes that allow to compute such an optimal solution in a feasible amount of time. On large-scale instances (i.e., when the optimal cannot be computed), our online approach provides solutions whose quality is comparable with those of our offline approach. Finally, our experiments show that our approach produces a 42% reduction in the car fleet.<br></p></td>
                </tr>
            
                <tr>
                    <td>488</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-488">Efficient Interdiction of Urban Criminals with the Aid of Real-time Information</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_488" class="editable_bid" data-pk="488" data-value="30"
                    data-url="/rev_3/paper/bid/set/488/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-488"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><span class="fontstyle0">Most violent crimes happen in urban and suburban cities. With emerging tracking techniques, law enforcement officers can have real-time location information of the escaping criminals and dynamically adjust the security resource allocation to interdict them. Unfortunately, existing work on urban network security games ignores such information. In this context, we make several key contributions. First, we show that ignoring the real-time information can have arbitrarily large loss of efficiency. To mitigate this loss, we propose a novel </span><span class="fontstyle2">Network Pursuit Game (NEST) </span><span class="fontstyle0">model to capture the interaction between an escaping adversary and a defender with real-time information available. Second, solving NEST is proven to be NP-hard. Third, to overcome the complexity barrier, several novel algorithms are provided, including (i) the </span><span class="fontstyle2">ﬂow representation </span><span class="fontstyle0">of the defender strategy which transforms the non-convex optimization to a linear program, and (ii) an iterative algorithm to repeatedly solve the restricted NEST with smaller scale and output the optimal solution. Fourth, to further improve the scalability, we propose a heuristic approach which solves a restricted NEST with only actions towards exit nodes and min-node-cut. Finally, extensive experimental evaluation shows that our solution significantly outperforms baselines in pursuit quality and can scale up to realistic-sized instances</span>&nbsp;.</td>
                </tr>
            
                <tr>
                    <td>60</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-60">A Site-Push Based Majority Winner Monitoring Algorithm for Distributed Elections</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Architectures for social reasoning<br>[Humans and Agents] Agent-based analysis of human interactions<br>[Humans and Agents] Other</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_60" class="editable_bid" data-pk="60" data-value="30"
                    data-url="/rev_3/paper/bid/set/60/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-60"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><br></p><div>The problem of distributed election majority-winner monitoring for 
checkpoint-based protocols has been under discussion from some time now,
 and the approach that most of the major algorithms have taken in this 
is the center-based pull from all voting sites
in conjunction with a count-tracker, to continually monitor the 
information about the incoming voter stream.&nbsp; This article presents an 
alternative solution to this problem, using site-based voter information
 push to the center, to reduce the communication complexity,
using a unique sampling technique.&nbsp; This technique is utilized to come 
up with a winner or an approximate winner with very high probability for
 Approval-based and Scoring-based rules.</div><div><br></div><div>The site-push based algorithm introduced here has been validated 
with correctness results, and has also been analyzed for different 
scenarios to prove the improvement in the number of communication units 
initiated, in comparison to the center based pull
algorithm considered for a checkpoint-based protocol by Filtser and 
Talmon [17].&nbsp; The effect of this algorithm is 
to reduce the communication complexity by a factor of 
$(1+\frac{\log{k}}{\log{\frac{n}{k}}})$ in comparison to the center-pull
algorithm (where $k$ is the number of voting sites, and $n$ the number 
of voters), which can be significant as $k &lt;&lt; n$.&nbsp; Also, to 
realize more realistic scenarios, simulation results are presented to 
show how the algorithm fares under a randomized voter assignment
scenario, with variations of the value of total voters, total sites and 
$\epsilon$.</div><p><br></p></td>
                </tr>
            
                <tr>
                    <td>65</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-65">Repeated win-lose coordination games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Other<br>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems<br>[Agent Theories and Models] Other</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_65" class="editable_bid" data-pk="65" data-value="30"
                    data-url="/rev_3/paper/bid/set/65/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-65"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;">We study repeated win-lose coordination games and analyse when they are 'solvable' without preplay communication on the given game amongst the players. We identify classes of coordination games in which coordination cannot be guaranteed in a single round by rational reasoning only, but can eventually be achieved in several rounds by following various coordination principles. In particular, we study coordination under some natural assumptions, including, inter alia, priority hierarchies amongst players, different patience thresholds and invariance of strategies under structural symmetries of games.</p></td>
                </tr>
            
                <tr>
                    <td>649</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-649">How to Stop Violence among Homeless: Extensions to Voter Model and Intervention Strategies</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Social networks<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_649" class="editable_bid" data-pk="649" data-value="30"
                    data-url="/rev_3/paper/bid/set/649/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-649"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Violence is a phenomenon that severely impacts homeless youth who are at an increased risk of experiencing it as a result of many contributing factors such as traumatic childhood experiences, involvement in delinquent activities and exposure to perpetrators due to street-tenure. Reducing violence in this population is necessary to ensure that the individuals can safely and successfully exit homelessness and lead a long productive life. Interventions to reduce violence in this population are difficult to&nbsp; implement due to the its complex nature. However, a peer-based intervention approach would likely be a worthy approach as previous research has shown that individuals who interact with more violent individuals are more likely to be violent, suggesting a contagious nature of violence. We propose Uncertain Voter Model to represent the complex process of diffusion of violence over a social network, that captures uncertainties in links and time over which the diffusion of violence takes place. Assuming this model, we define Violence Minimization problem where the task is to select a predefined number of individuals for intervention so that the expected number of violent individuals in the network is minimized over a given time-frame. We also extend the problem to a probabilistic setting, where the success probability of converting an individual into non-violent is a function of the number of ``units'' of intervention performed on her. We provide algorithms for finding the optimal intervention strategies for both scenarios. We demonstrate that our algorithms perform significantly better than interventions based on popular centrality measures in terms of reducing violence.<br></p></td>
                </tr>
            
                <tr>
                    <td>503</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-503">Coordination of Electric Vehicle Aggregators: A Coalitional Approach</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Cooperative games: computation</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_503" class="editable_bid" data-pk="503" data-value="30"
                    data-url="/rev_3/paper/bid/set/503/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-503"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style="margin-bottom: 0px;"><span style="white-space: pre-wrap;">Given the rapid rise of electric vehicles (EVs) worldwide, and the ambitious targets set for the near future, the smart charging of an EV fleet must be seen as a priority. Specifically, we study a scenario where EV charging is managed through self-interested EV aggregators (e.g. car parks or electricity suppliers) who compete in the day-ahead market in order to purchase the electricity needed to meet their clients' requirements. In order to reduce electricity costs and lower the impact on electricity markets, we study the possibility of inter-aggregator cooperation. Specifically, we model the system as a coalitional game and prove that the resulting game is superadditive and balanced, hence having a non-empty core. However, due to the game not being convex, the Shapley value is not guaranteed to lie in the core. As an alternative, we propose employing the payment mechanism provided by the least-core, which we show to be in the core in our setting. Furthermore, a realistic empirical evaluation is presented, using real market and driver data from the Iberian Peninsula. The simulations show that large payment reductions can be achieved when using the coordination mechanism. Moreover, we show that the individual payments of the least-core are very close to the Shapley value, suggesting that the payment mechanism is both fair and stable.</span><br></p><p style="margin-bottom: 0px;"><!--EndFragment--></p><p style="margin-bottom: 0px;"><!--EndFragment--></p><p style="margin-bottom: 0px;"><!--EndFragment--></p><p style="margin-bottom: 0px;"><!--EndFragment--></p><p style="margin-bottom: 0px;"><!--EndFragment--></p><p style="margin-bottom: 0px;"><!--EndFragment--></p><p style="margin-bottom: 0px;"><!--EndFragment--></p></td>
                </tr>
            
                <tr>
                    <td>634</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-634">Fairness in multiagent resource allocation with dynamic and partial observations</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_634" class="editable_bid" data-pk="634" data-value="30"
                    data-url="/rev_3/paper/bid/set/634/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-634"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="font-family: Helvetica; font-size: 12px; text-size-adjust: auto;">We investigate fairness issues in distributed resource allocation of indivisible goods. While the notion of envy-freeness has been widely studied to assess the fairness of a multi-agent resource allocation, it is usually computed in a centralized way and assumes perfect knowledge of the whole allocation. In this paper, we consider distributed allocation protocols where each agent has limited visibility of the other agents. Starting &nbsp;from a situation where each agent has (the same) number of items, and completely ignores how the rest of the resources are allocated, pairwise encounters occur as the result of the agents' decisions.</span><br style="font-family: Helvetica; font-size: 12px; text-size-adjust: auto;"><span style="font-family: Helvetica; font-size: 12px; text-size-adjust: auto;">As they do so, agents both observe the bundle currently held by the other agent, and try to agree on rational deals (swaps). Hence, agents have a partial and uncertain view of the entire allocation, that they maintain throughout the process, and which allows them to have different estimates of their envy.</span><br style="font-family: Helvetica; font-size: 12px; text-size-adjust: auto;"><span style="font-family: Helvetica; font-size: 12px; text-size-adjust: auto;">We provide a fully distributed protocol allowing to guarantee termination despite the limited knowledge of agents, and study some of its properties. We furthermore investigate experimentally the performance of this system, testing in particular several heuristics governing agents' decision-making both at the agent's selection and bilateral negotiation stage.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>374</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-374">Enhanced Delta-tolling:  Traffic Optimization via Policy Gradient Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Economic Paradigms] Game Theory for practical applications<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_374" class="editable_bid" data-pk="374" data-value="30"
                    data-url="/rev_3/paper/bid/set/374/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-374"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The prospect of widespread deployment of autonomous vehicles invites the reimagining of the multiagent systems protocols that govern traffic flow in our cities.&nbsp; One such possibility is the introduction of micro-tolling for fine-grained traffic flow optimization.&nbsp; In the micro-tolling paradigm, different toll values are assigned to different links within a congestable traffic network. Self-interested agents then select minimal cost routes, where cost is a function of the travel time and tolls paid. A centralized system manager sets toll values with the objective of inducing a user equilibrium that maximizes the total utility over all agents. A recently proposed algorithm for computing such tolls, denoted Delta-tolling, was shown to yield up to 32% reduction in total travel time in simulated traffic scenario compared to when there are no tolls. Delta-tolling includes two global parameters: 'beta' which is a proportionality parameter, and 'R' which influences the rate of change of toll values across all links. This paper introduces a generalization of Delta-tolling which allows different 'beta' and 'R' values on each link in the network.&nbsp; While this Enhanced Delta-tolling algorithm requires setting significantly more parameter, we show that they can be tuned effectively via policy gradient reinforcement learning. Experimental results from several traffic scenarios indicate that Enhanced Delta-tolling reduces total travel time by up to 49% compared to the original Delta-tolling algorithm, and by up to 111% compared to no tolling.<br></p></td>
                </tr>
            
                <tr>
                    <td>514</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-514">Towards the Mirror World: Mixed Reality Knowledge Representation for Context-Aware Agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Humans and Agents] Agent-based analysis of human interactions</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_514" class="editable_bid" data-pk="514" data-value="30"
                    data-url="/rev_3/paper/bid/set/514/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-514"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In order to act intelligently within real world scenarios, which are shared by agents and humans and are subject to constant change, an agent requires a great amount of contextual knowledge. To achieve this, we propose a <i>Mirror World</i> metaphor which combines smart and virtual environments. The <i>Mirror World</i> serves as a real-time mixed reality knowledge representation and visualization for single and multiagent systems, providing tools to infer knowledge at runtime. Both physical and virtual sensors provide data which is processed by a semantics-based rule system. A coupled 3D game engine constitutes the capability for spatial and physical reasoning. Combined, these techniques provide a continuum of knowledge, ranging from low-level sensory data to high-level semantic facts. In this contribution, we present the concept behind the <i>Mirror World</i> and its implementation. Our system aims at being 1) flexible enough to adapt to dynamic changes, 2) easily expandable for developers to adjust to new domains, and 3) transparent and comprehensible for users. In line with our aims, we examine our system in a three staged evaluation: from the perspectives of the system, the developer, and the user.<br><br></p></td>
                </tr>
            
                <tr>
                    <td>63</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-63">Fairly Dividing a Cake after Some Parts Were Burnt in the Oven</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_63" class="editable_bid" data-pk="63" data-value="30"
                    data-url="/rev_3/paper/bid/set/63/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-63"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>There is a heterogeneous resource that contains both good parts and bad parts, for example, a cake with some parts burnt, a land-estate with some parts heavily taxed, or a chore with some parts fun to do. The resource has to be divided fairly among n agents, each of whom has a personal value-density function on the resource. The value-density functions can accept any real value --- positive, negative or zero. Can standard cake-cutting procedures, developed for positive valuations, be adapted to this setting? This paper focuses on the question of envy-free cake-cutting with connected pieces. It is proved that such a division exists for 3 agents. <br><br></p></td>
                </tr>
            
                <tr>
                    <td>96</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-96">An Argumentation-based Conversational Recommender System for Recommending Learning Objects</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Argumentation-based dialogue and protocols<br>[Humans and Agents] Human-robot/agent interaction<br>[Humans and Agents] Other</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_96" class="editable_bid" data-pk="96" data-value="30"
                    data-url="/rev_3/paper/bid/set/96/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-96"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style="margin-bottom: 0px; font-stretch: normal; font-size: 12px; line-height: normal; font-family: &quot;Helvetica Neue&quot;;">With the current proliferation of online learning resources, many students have much more information available than they can consume in an efficient way.&nbsp;</p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 12px; line-height: normal; font-family: &quot;Helvetica Neue&quot;;">Consequently, students do not always find adaptive learning material for their needs and preferences. In this paper, we present an argumentation-based Conversational Educational Recommender System (C-ERS), which helps students to find the more suitable learning resources considering their learning objectives and profile.&nbsp;</p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 12px; line-height: normal; font-family: &quot;Helvetica Neue&quot;;">The recommendation process is based on an argumentation-based technique, which selects those learning objects (LOs) for which it is able to generate a greater number of arguments justifying their suitability. Our system includes a simple and intuitive communication interface with the user that provides an explanation to any recommendation.&nbsp;</p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 12px; line-height: normal; font-family: &quot;Helvetica Neue&quot;;">This allows the user to interact with the system and accept or reject the recommendations, providing reasons for such behavior. In this way, the user is able to inspect the system's operation and understand the recommendations, while the system is able to elicit the actual preferences of the user. The system has been tested online with a real group of undergraduate students in the Universidad Nacional de Colombia, showing promising results.</p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>287</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-287">Probably Almost Stable Strategy Profiles in Simulation-Based Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logic and Game Theory<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_287" class="editable_bid" data-pk="287" data-value="30"
                    data-url="/rev_3/paper/bid/set/287/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-287"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Empirical studies of strategic settings commonly model player interactions under supposed game-theoretic equilibrium behavior, as a way of predicting what outcomes would result among rational agents. But in sufficiently complex settings, analysts cannot solve for exact equilibria, and may resort to solving a restricted game where agents are limited to a tractable subset of strategies. This provides a solution, but one with unclear strategic stability in the original game. We propose a search and evaluation method that can guarantee a well-defined strategic stability property in the profile that it yields, even if only a small subset of possible strategies in a game have been analyzed. The method achieves this result by combining statistical confidence interval estimation, a multiple test correction, and empirical game-theoretic analysis. We demonstrate efficacy in two example settings: the first-price sealed-bid auction, and a cybersecurity game.</p></td>
                </tr>
            
                <tr>
                    <td>231</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-231">Model Checking Multi-Agent Systems against LDLK Specifications on Finite Traces</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Verification and Validation of Agent-based Systems] Verification techniques for multiagent systems, including model checking</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_231" class="editable_bid" data-pk="231" data-value="30"
                    data-url="/rev_3/paper/bid/set/231/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-231"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We introduce the logic LDL f K, a variant of the epistemic logic LDLK, interpreted on finite traces of multi-agent systems. We explore the verification problem of multi-agent systems against LDL f K specifications and give algorithms for the reduction of LDL f K model checking to LDLK verification on a different model and different specification. We analyse the resulting complexity and show it to be PSPACE-complete. We report on a full implementation of the algorithm and assess its performance on a number of examples.<br></p></td>
                </tr>
            
                <tr>
                    <td>540</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-540">Generating Sensor Events using Agent-based Simulation of Smart Home</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_540" class="editable_bid" data-pk="540" data-value="30"
                    data-url="/rev_3/paper/bid/set/540/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-540"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Smart Homes are currently one of the hottest topic on the market of sensor systems, IoT, augmented living, embedded AI. Yet, for really providing high-level intelligent solutions, algorithms are needed to detect what the human inhabitant's current activity is, what she intends to do, even how many persons are in the home. Based on that intelligent control and planning can be developed to support human activity in many ways. One of the major reasons why the development of such tools is not proceeding as much as&nbsp; expected and Smart Home applications remain on the level of simple systems with more or less direct feedback loops, is the lack of publicly available data to test and train such algorithms.<br>In this contribution we present concepts and solutions for generating high-quality data using a flexible agent-based simulation tool. Hereby, we integrate the simulation of a sensorized apartment with human behaviour modelling. Out of the many options for capturing human activities, we selected an intelligent, constraint-based planning approach for producing a sequence of daily activities of a human inhabitant. The overall set-up is shown to produce data that exhibits the same relevant properties like a comparable real-world scenario and thus can be used replacing expensive data collection campaigns.<br></p></td>
                </tr>
            
                <tr>
                    <td>561</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-561">An Operational Semantics for a Fragment of PRS</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Engineering Multiagent Systems] Programming languages and frameworks for agents and multi-agent systems</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_561" class="editable_bid" data-pk="561" data-value="30"
                    data-url="/rev_3/paper/bid/set/561/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-561"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The Procedural Reasoning System (PRS) was arguably the first implementation
of the Belief–Desire–Intention (BDI) approach to programming
autonomous agents. PRS remains extremely influential,
directly or indirectly inspiring the development of many subsequent
BDI-based agent programming languages. Many of these “successor
languages” implement only a subset of the features supported by
PRS. However, perhaps surprisingly given its centrality in the BDI
paradigm, PRS lacks a formal operational semantics, which makes
it difficult to determine the expressive power of PRS relative to other
BDI-based agent programming languages. In this paper, we take a
first step towards closing this gap, by giving a formal semantics for a
significant fragment of PRS. We prove key properties of the semantics
relating to PRS-specific programming constructs, and show that
even the fragment of PRS we consider is strictly more expressive
than the plan constructs found in typical BDI languages.<br></p></td>
                </tr>
            
                <tr>
                    <td>687</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-687">Crossmodal Attentive Skill Learner</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.660</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_687" class="editable_bid" data-pk="687" data-value="30"
                    data-url="/rev_3/paper/bid/set/687/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-687"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper introduces the Crossmodal Attentive Skill Learner (CASL), integrated with the recently-introduced Asynchronous Advantage Option-Critic (A2OC) architecture to enable hierarchical reinforcement learning across multiple sensory inputs. We provide concrete examples where the approach not only improves performance in a single task, but accelerates transfer to new tasks. We demonstrate the attention mechanism anticipates and identifies useful latent features, while filtering irrelevant sensor modalities during execution. We modify the Arcade Learning Environment to support audio queries, and conduct evaluations of crossmodal learning in the Atari games H.E.R.O. and Amidar. Finally, building on the recent work of Babaeizadeh et al. (2016), we open-source a fast hybrid CPU-GPU implementation of CASL.<br></p></td>
                </tr>
            
                <tr>
                    <td>381</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-381">End-to-End Influence Maximization in the Field</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_381" class="editable_bid" data-pk="381" data-value="30"
                    data-url="/rev_3/paper/bid/set/381/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-381"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This work is aims to overcome the challenges in deploying influence maximization to support community driven interventions. Influence maximization is a crucial technique used in preventative health interventions, such as HIV prevention amongst homeless youth. Drop-in centers for homeless youth train a subset of youth as peer leaders who will disseminate information about HIV through their social networks. The challenge is to find a small set of peer leaders who will have the greatest possible influence. While many algorithms have been proposed for influence maximization, none can be feasibly deployed by a service provider: existing algorithms require costly surveys of the entire social network of the youth to provide input data, and high performance computing resources to run the algorithm itself. Both requirements are crucial bottlenecks to widespread use of influence maximization in real world interventions.</p><p>To address the above challenges, this innovative applications paper introduces the CHANGE agent for influence maximization. CHANGE handles the end-to-end process of influence maximization, from data collection to peer leader selection. Crucially, CHANGE only surveys a fraction of the youth to gather network data and minimizes computational cost while providing comparable performance to previously proposed algorithms. We carried out a pilot study of CHANGE in collaboration with a drop-in center serving homeless youth in a major U.S. city. CHANGE surveyed only 18\% of the youth to construct its social network. However, the peer leaders it selected reached just as many youth as previously field-tested algorithms which surveyed the entire network. This is the first real-world study of a network sampling algorithm for influence maximization. Simulation results on real-world networks also support our claims.</p></td>
                </tr>
            
                <tr>
                    <td>211</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-211">Cognitive Agent Models for Major Depression and its Treatment by Adaptive Temporal-Causal Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent Theories and Models] Cognitive models<br>[Agent Theories and Models] Models of emotions</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_211" class="editable_bid" data-pk="211" data-value="30"
                    data-url="/rev_3/paper/bid/set/211/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-211"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="Abstract"><span lang="EN-US">This paper presents neurologically inspired cognitive
agent models for the field of Major Depressive Disorder. These cognitive agent
models are based on an (adaptive) temporal-causal network modelling approach
incorporating a dynamic perspective on mental states and causal relations. First
a basic cognitive agent model shows differences of mental states and their
connections between healthy subjects and those suffering Major Depression
Disorder. Next an adaptive temporal-causal network modelling approach is used
to address how a Deep Brain Stimulation treatment used for this disorder can
have its effect by a Hebbian learning effect. The models have turned out to
produce simulation patterns as are expected from the literature. Moreover
verification by mathematical analysis has shown correctness with respect to the
formal mathematical specifications.<o:p></o:p></span></p></td>
                </tr>
            
                <tr>
                    <td>418</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-418">A Structural Approach to Activity Selection</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_418" class="editable_bid" data-pk="418" data-value="30"
                    data-url="/rev_3/paper/bid/set/418/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-418"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The general task of finding an assignment of agents to activities under certain stability and rationality constraints has led to the introduction of two prominent problems in the area of computational social choice: Group Activity Selection (GASP) and Stable Invitations (SIP). In the former, we are given a set of agents with preference lists and the task is to assign these to certain distinct activities; in the latter there is only a single activity to assign to, but agents have friends and enemies which provide additional restrictions on valid assignments. Here we introduce and study the Comprehensive Activity Selection Problem, which naturally generalizes both of these problems: it is equivalent to SIP extended to more than 1 activity, and also equivalent to GASP with the addition of information about friends and enemies of agents.<br><br>We study CAS through the lens of the parameterized complexity paradigm, which has already been employed for SIP and GASP. In particular, previous work has focused nearly exclusively on parameterizing by the solution size (i.e., the number of assigned agents), and a number of mostly negative results have been obtained already for these less general problems. Instead of solution size, here we focus on parameters which capture the complexity of agent-to-agent interactions. Our results include a comprehensive complexity map for CAS under various restrictions on the number of activities in combination with restrictions on the complexity of agent interactions (measured by well-established graph parameters such as treewidth). We conclude with a fixed-parameter algorithm which exploits the sparsity of agent interactions to circumvent negative results obtained in previous work on SIP.<br><br><br></p></td>
                </tr>
            
                <tr>
                    <td>647</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-647">Representing and deriving explicit agent expectations</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent Theories and Models] Cognitive models<br>[Knowledge Representation and Reasoning] Other</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_647" class="editable_bid" data-pk="647" data-value="30"
                    data-url="/rev_3/paper/bid/set/647/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-647"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Expectations can be viewed as hopeful waiting rather than mere predictions or forecasts about future states and events. When an agent has an expectation, it has a set of beliefs about the future along with a preference for one state of affairs over another. If agents are to reason about their expectations and those of others, then there is a benefit to making those expectations explicit, so that they may be monitored for fulfilment or expiry, and communicated to other agents so that mutual expectations can be formed. Monitoring requires being able to express expectations in a particular way, in terms of the observable events in a system. In this paper, we present an agent architecture for creating and updating explicit expectations. We propose an events-based model for agent expectations and introduce the concepts of abstract expectations, those not tied to a specific situation, and active expectations, which are triggered by specific events.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>436</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-436">Learning to Schedule Deadline- and Agent-Sensitive Tasks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Other<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_436" class="editable_bid" data-pk="436" data-value="30"
                    data-url="/rev_3/paper/bid/set/436/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-436"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block">The centralized allocation of deadline sensitive tasks to agents is a difficult optimization problem. The problem becomes even more difficult when tasks arrive dynamically and each task has different requirements and valuation. This problem is essential to&nbsp; collaboration of dynamic agent teams. We present an online machine-learning-based algorithm which learns to rank the possible task allocations with the objective of maximizing the obtained value from completed tasks.</td>
                </tr>
            
                <tr>
                    <td>34</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-34">An Empirical Game-Theoretic Analysis of the One-Day Ad Exchange Game</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_34" class="editable_bid" data-pk="34" data-value="30"
                    data-url="/rev_3/paper/bid/set/34/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-34"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style="text-align: justify; "><font face="Open Sans, Arial, sans-serif">We introduce the one-day advertisement exchange (one-day AdX) game,&nbsp;</font><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">where agents play the role of ad networks competing in an&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">ad exchange for advertisement display opportunities needed to fulfill contracts&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">(i.e., advertising campaigns) from advertisers (e.g., retailers).&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">We perform an extensive empirical game-theoretical analysis&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">when many agents play two types of strategies in this game:&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">one in which an agent computes an approximate&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">Walrasian equilibrium of the combinatorial market induced by&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">the game, and bids accordingly;&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">and a natural heuristic we call the Waterfall in which&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">an agent simultaneously computes an allocation and bids by simulating the many&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">second-price auctions that unfold in the game.</span></p><p style="text-align: justify; "><font face="Open Sans, Arial, sans-serif">Our analysis is restricted to the case in which agents play only pure&nbsp;</font><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">strategies, a natural consideration in settings such as ours where agents&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">implement heuristic strategies and commit to them for some period of time.&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">Since a Nash equilibrium in pure strategies need not exist, we adopt&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">sink equilibria of the best-response graph associated with the game as our solution&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">concept, and present a simple sampling heuristic to efficiently compute&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">these equilibria. We demonstrate in a wide range of experimental&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">settings that our sampling procedure produces stable equilibria for this game.</span></p><p style="text-align: justify; "><font face="Open Sans, Arial, sans-serif">Then, having solved the game, we turn to the&nbsp;</font><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">empirical mechanism design question of how to set a reserve price to&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">maximize the market maker's (i.e., the exchange's) revenue, in light&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">of the fact that agents can change their behavior (and consequently, the&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">equilibria) in response to a change in the reserve price. We demonstrate&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">in extensive experiments that our methods are capable of identifying not&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">only sink equilibria for a given reserve,&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">but also a revenue-maximizing reserve price at the same time,&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">thereby finding a total equilibrium, i.e., an equilibrium between the players and&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">the market maker.</span></p></td>
                </tr>
            
                <tr>
                    <td>404</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-404">Efficient Mechanisms for Peer Grading and Dueling Bandits</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_404" class="editable_bid" data-pk="404" data-value="30"
                    data-url="/rev_3/paper/bid/set/404/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-404"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Many scenarios in our daily life require us to infer some ranking over items or people based on limited information. In this paper, we consider two such scenarios, one for ranking student papers in massive online open courses and one for identifying the best player (or team) in sports tournaments. For the peer grading problem, we design a mechanism with a new way of matching graders to papers. This allows us to aggregate partial rankings from graders into a global one, with an accuracy rate matching the best in previous works, but with a much simpler analysis. For the winner selection problem in sports tournaments, we cast it as the well-known dueling bandit problem and identify a new measure to minimize: the number of parallel rounds, as one normally would not like a large tournament to last too long. We provide mechanisms which can determine the optimal or an almost optimal player in a small number of parallel rounds and at the same time using a small number of competitions.<br></p></td>
                </tr>
            
                <tr>
                    <td>719</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-719">Bi-Directional Information Exchange in Decentralized Schedule-Driven Traffic Control</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Self-organization<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_719" class="editable_bid" data-pk="719" data-value="30"
                    data-url="/rev_3/paper/bid/set/719/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-719"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px;">Recent work in decentralized, schedule-driven traffic control has demonstrated the ability to improve the efficiency of traffic flow in complex urban road network. In this approach, a scheduling agent is associated with each intersection. Each agent senses the traffic approaching its intersection and in real-time constructs a schedule that minimizes the cumulative wait time of vehicles approaching the intersection over the current look-ahead horizon. In order to achieve network level coordination in a scalable manner, scheduling agents communicate only with their direct neighbors. Each time an agent generates a new intersection schedule it communicates its expected outflows to its downstream neighbors as a prediction of future demand and these outflows are appended to the downstream agent’s locally perceived demand. In this paper, we extend this basic coordination protocol to additionally incorporate the complementary flow of information reflective of an intersection’s current congestion level to its upstream neighbors. We present an asynchronous decentralized algorithm for updating intersection schedules and congestion level estimates based on these bi-directional information flows. By relating this algorithm to the self-optimized decision making of basic protocol, we are able to approach network-wide optimality and reduce the inefficiency due to strictly self-interested intersection control decisions.</span></td>
                </tr>
            
                <tr>
                    <td>661</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-661">Investigating the Impact of Rationality in an Agent-Based Model of the Electricity Market</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Economic Paradigms] Other</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_661" class="editable_bid" data-pk="661" data-value="30"
                    data-url="/rev_3/paper/bid/set/661/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-661"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We extend an existing agent-based model of the Italian electricity market. In that model, the agents determine their strategies thanks to a genetic algorithm. One of the particularities of the model is that it assumes all the power plants of a generating company, which are situated in the same zone and which use the same technology, to use the same strategy. We show that relaxing such hypothesis does not worsen the quality of the results. We show that the new "relaxed" model is a correct generalization of the existing model we extend.<br>We compare it to a baseline model where the agent’s economical rationality is implemented through a Monte Carlo method. Finally, we show that replacing the genetic algorithm with particle swarm optimization increases the accuracy of the model.<br></p></td>
                </tr>
            
                <tr>
                    <td>509</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-509">Group Activity Selection parameterized by the Number of Agent Types</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_509" class="editable_bid" data-pk="509" data-value="30"
                    data-url="/rev_3/paper/bid/set/509/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-509"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we study the parameterized complexity of GASP and its variant gGASP w.r.t. the number of different agent types as a parameter. We show that GASP can be solved in polynomial time if the number of agent types is constant and complement this result with a strong parameterized hardness result, showing that GASP is unlikely to be fixed-parameter tractable even when combining this parameter with the number of activities. In the case of gGASP we provide an even stronger hardness result showing that gGASP is unlikely to be fixed-parameter tractable parameterized by the number of agent types, the number of activities, and the vertex cover number of the network. This nicely complements (and resolves an open question) the result of Gupta et al. [SAGT 17] showing that gGASP is fixed-parameter tractable parameterized by the number of activities if the network has constant treewidth.<br><br><br></p></td>
                </tr>
            
                <tr>
                    <td>240</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-240">SILC: Smoother Imitation with Lipschitz Costs</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Adversarial machine learning</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_240" class="editable_bid" data-pk="240" data-value="30"
                    data-url="/rev_3/paper/bid/set/240/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-240"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>One of the difficulties in building a reinforcement learning agent is specifying an appropriate reward function to capture the requirements of a task. One approach for overcoming this difficulty is Imitation Learning, where the agent learns to solve a task by imitating an expert's behaviour. Generative Adversarial Imitation Learning (GAIL) presents a specific approach to the task of imitating an expert by jointly modelling the environment's reinforcement signal and the imitating agent's policy. GAIL provides state-of-the-art results in imitating complex behaviours in large, high dimensional environments. However, the algorithm often suffers from instability during the training and high variance in the returns and the trajectories. In this work, we propose SILC, a GAIL-like framework for learning smoother imitation and achieving consistently meaningful learning gradients. By smoother imitation, we mean that the learned policies and hence, the trajectories are smooth. SILC constrains the cost functions to be Lipschitz continuous, which in turn, results in learning a policy which minimizes the Wasserstein distance between the agent's and the expert's policies. Smooth intermediate costs induce smoothness in the policy space with respect to the input, a claim that we prove theoretically and empirically. The learned policy also achieves better performance than the existing methods in terms of closeness to the expert trajectories and the value of the true returns. We propose metrics to evaluate for the better imitation of the expert and the smoothness of the learned policies. We empirically evaluate the algorithm on simulated continuous control tasks from MuJoCo.<br></p></td>
                </tr>
            
                <tr>
                    <td>102</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-102">Limited Knowledge Prediction of Financial Timeseries</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_102" class="editable_bid" data-pk="102" data-value="30"
                    data-url="/rev_3/paper/bid/set/102/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-102"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We perform an empirical investigation about how simulated annealing and agent based simulation, as implemented in the L-FABS system, can model financial time series under two main experimental setups: without knowing the previous day value and with access to it. Goal of the reported case study is to show how a machine learning system can exploit significant information about a time series and how the exploitation will reduce the approximation error rate.<br>The reported experiments are performend on the Nasdaq Composite Index and on the SPDR Silver Trust timeseries.<br></p></td>
                </tr>
            
                <tr>
                    <td>334</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-334">Local Wealth Redistribution Promotes Cooperation in Multiagent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent Societies and Societal Issues] Social networks<br>[Agent-based Simulation] Social simulation<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_334" class="editable_bid" data-pk="334" data-value="30"
                    data-url="/rev_3/paper/bid/set/334/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-334"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Designing mechanisms that promote cooperation in Multiagent Systems has been a long-lasting goal in artificial intelligence. The task is especially challenging when agents are selfish, lack common goals and face social dilemmas, i.e., situations in which individual interest conflicts with social welfare. Past works explored mechanisms that explain cooperation in biological and social systems, providing important clues for the aim of designing cooperative artificial societies. In particular, several works show that cooperation is able to emerge when specific network structures underlie agents' interactions. Notwithstanding, social dilemmas in which defection is highly tempting still lack mechanisms that allow cooperation to be effectively sustained. Here we propose a new redistribution mechanism that can be applied in structured populations of agents. Importantly, we show that, when implemented locally (i.e., agents share a fraction of their wealth surplus with their nearest neighbors), redistribution excels in promoting cooperation under regimes where, before, only defection prevailed.</p></td>
                </tr>
            
                <tr>
                    <td>171</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-171">Recognising Assumption Violations in Autonomous Systems Verification</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Verification and Validation of Agent-based Systems] Verification techniques for multiagent systems, including model checking<br>[Verification and Validation of Agent-based Systems] Fault tolerance and resilience of multi-agent systems</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_171" class="editable_bid" data-pk="171" data-value="30"
                    data-url="/rev_3/paper/bid/set/171/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-171"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>When applying formal verification to a system that interacts with<br>the real world we must use a model of the environment. This model<br>represents an abstraction of the actual environment, but is necessarily incomplete and hence presents an issue for system verification.<br>If the actual environment matches the model, then the verification<br>is correct; however, if the environment falls outside the abstraction<br>captured by the model, then we cannot guarantee that the system<br>is well-behaved. A solution to this problem consists in exploiting<br>the model of the environment for statically verifying the system’s<br>behaviour and, if the verification succeeds, using it also for validating the model against the real environment via runtime verification.<br>The paper discusses this approach and demonstrates its feasibility<br>by presenting its implementation on top of a framework integrating<br>the Agent Java PathFinder model checker. Trace expressions are<br>used to model the environment for both static formal verification<br>and runtime verification.<br></p></td>
                </tr>
            
                <tr>
                    <td>138</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-138">A Near-Optimal Node-to-Agent Mapping Heuristic for GDL-based DCOP Algorithms in Multi-Agent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Other<br>[Agent Cooperation] Distributed problem solving</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_138" class="editable_bid" data-pk="138" data-value="30"
                    data-url="/rev_3/paper/bid/set/138/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-138"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block">Distributed Constraint Optimization Problems (DCOPs) can be used
to model a number of multi-agent coordination problems. The conventional DCOP model assumes that the subproblem that each agent
is responsible for (i.e. the mapping of nodes in the constraint graph
to agents) is part of the model description. While this assumption is
often reasonable, there are many applications where there is some
ﬂexibility in making this assignment. In this paper, we focus on
this gap and make the following contributions: (1) We formulate
this problem as an optimization problem, where the goal is to fnd
an assignment that minimizes the completion time of the DCOP
algorithm (e.g. Action-GDL or Max-Sum) that operates on this mapping. (2) We propose a novel heuristic, called MNA, that can be
executed in a centralized or decentralized manner. (3) Our empirical evaluation illustrates a substantial reduction in completion time,
ranging from 16% to 40%, without affecting the solution quality of
the algorithms, compared to the current state-of-the-art. In addition,
we observe empirically that the completion time obtained from our
approach is near-optimal; it never exceeds more than 10% of what
can be achieved from the optimal node-to-agent mapping.</td>
                </tr>
            
                <tr>
                    <td>230</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-230">Hedonic games with multiple solution concepts</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Agent Cooperation] Coalition formation (non-strategic)</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_230" class="editable_bid" data-pk="230" data-value="30"
                    data-url="/rev_3/paper/bid/set/230/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-230"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In multi-agent systems, agents must decide with whom to cooperate, knowing that all of them prefer some agents over some others. This problem is called hedonic game where agents seek to form stable coalitions. To this end, a solution concept characterizes the stability of outcomes with respect to the agents' preferences, and expresses an a priori about the behaviour of all agents. For instance, Nash stability models agents which join the coalitions they prefer without any considerations about the other agents' preferences. However, in the some games, we might have both individualistic agents with Nash stable behaviour and more respectful agents which deviates if, and only if, it is accepted by the other agents. Thus, in this article, we propose a new model of hedonic games where agents are heterogeneous in their way to form stable coalitions. We define a specific solution concept for this game and provide some properties and complexity results. Then, we extend this model to agents which express preferences both on coalitions and on sets of solution concepts. We define a last solution concept, leximax stability, to characterize stable solution in such games.<br></p></td>
                </tr>
            
                <tr>
                    <td>380</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-380">Learning Agents in Financial Markets: Consensus Dynamics on Volatility</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Engineering Multiagent Systems] Methodologies for agent-based systems<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_380" class="editable_bid" data-pk="380" data-value="30"
                    data-url="/rev_3/paper/bid/set/380/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-380"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Black-Scholes (BS) is the standard mathematical model for European option pricing in financial markets. Option prices are calculated using an analytical formula whose main inputs are strike (at which price to exercise) and&nbsp; volatility. The BS framework assumes that volatility remains constant across all strikes, however, in practice it varies. How do traders come to learn these parameters?</p><p>We introduce natural models of learning agents, in which they update their beliefs about the true implied volatility based on the opinions of other traders. We prove exponentially fast convergence of these opinion dynamics using techniques from control theory and leader-follower models, thus providing a resolution between theory and market practices. We allow for two different models, one with feedback and one with an unknown leader.<br></p></td>
                </tr>
            
                <tr>
                    <td>696</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-696">Felm\&quot;{e} : A New Theory of Emotions for Emotionally Intelligent Robots</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Agent Theories and Models] Cognitive models<br>[Agent Theories and Models] Models of emotions</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_696" class="editable_bid" data-pk="696" data-value="30"
                    data-url="/rev_3/paper/bid/set/696/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-696"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Numerous computational models of emotion have been proposed ab antiquo. &nbsp;While proficient in their intended but limited field of use, we have found these models to be insufficient for modeling robots that are genuinely emotionally intelligent. &nbsp;Hence we introduce a new model of emotion, Felm\"{e}, a linguistically-grounded Ortony-Collins-Clore (OCC) Theory-based formalization of emotions.\footnote{The OCC Theory (of Emotions) is set out in \cite{occ1989}.} Felm\"{e} is the affective extension to the multi-sorted quantified modal logic \DCEC and attempts to build a proof-theoretic system for an extended OCC theory. &nbsp;In addition, we take the first steps toward designing a relevant and novel AI system: one that navigates the linguistic aspects of a test of Emotional Intelligence (EI). &nbsp;The test in question is an established and much-used EI test: the Mayer Salovey Caruso Emotional Intelligence Test (MSCEIT). &nbsp;This paper explores the various sections of this test, and outlines algorithms for each section based on Felm\"{e} that, to varying degrees of accuracy, are able to determine correct answers in each section.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>447</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-447">Towards Designing Optimal Reward Functions in Multi-Agent Reinforcement Learning Problems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Multiagent learning</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_447" class="editable_bid" data-pk="447" data-value="30"
                    data-url="/rev_3/paper/bid/set/447/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-447"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Defining a reward function that, when optimized, results in a rapid acquisition of an optimal policy, is one of the most challenging problems involved when deploying reinforcement learning algorithms. The existing works on the optimal reward problem (ORP) propose mechanisms to design reward functions but their application is limited to specific sub-classes of single or multi-agent reinforcement learning problems.&nbsp;</p><p>Moreover, these methods identify which rewards should be given in which situation, but not which aspects of the state or environment should be used when defining the reward function. Those methods also do not directly model how quickly an optimal policy can be learned by optimizing a given candidate reward function.</p><p>In this paper, we define the <i>extended</i> optimal reward problem (EORP) which:</p><p>i) can identify both features and reward signals that compose the reward function;</p><p>ii) is general enough to deal with single and multi-agent reinforcement learning problems;</p><p>iii) is scalable to problems with large number of agents learning simultaneously;&nbsp;</p><p>iv) incorporates a learning effort metric in the evaluation of reward functions allowing the discovery of reward functions that result in faster learning.</p><p>Experimental results on gridworld-like and traffic assignment scenarios are used to evaluate the efficiency of our approach in designing effective reward functions.</p></td>
                </tr>
            
                <tr>
                    <td>107</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-107">Value-Decomposition Networks For Cooperative Multi-Agent Learning Based on Team Reward</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Teamwork, team formation, teamwork analysis<br>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_107" class="editable_bid" data-pk="107" data-value="30"
                    data-url="/rev_3/paper/bid/set/107/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-107"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We study the problem of cooperative multi-agent reinforcement learning with a single joint reward signal. This class of learning problems is difficult because of the often large combined action and observation spaces. In the fully centralized and decentralized approaches, we find the problem of spurious rewards and a phenomenon we call the ``lazy agent'' problem, which arises due to partial observability.&nbsp; We&nbsp; address these problems by training individual agents with a novel value decomposition network architecture, which learns to decompose the team value function into&nbsp; agent-wise value functions. We perform an experimental evaluation across a range of partially-observable multi-agent domains and show that learning such value-decompositions leads to superior results, in particular when combined with weight sharing, role information and communication channels. In fact, value-decomposition by itself and all evaluated combinations of techniques including value-decomposition, outperform individual learners and centralization.<br></p></td>
                </tr>
            
                <tr>
                    <td>538</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-538">Modelling the Social Practices of an Emergency Room to Ensure Staff and Patient Wellbeing</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Architectures for social reasoning<br>[Agent Theories and Models] Cognitive models<br>[Knowledge Representation and Reasoning] Ontologies for agents<br>[Humans and Agents] Agent-based analysis of human interactions</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_538" class="editable_bid" data-pk="538" data-value="30"
                    data-url="/rev_3/paper/bid/set/538/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-538"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Understanding the impact of activities is important for emergency rooms (ER) to ensure patient wellbeing and staff satisfaction. Decision support tools, such as agent-based simulations and formal reasoners, could contribute to this understanding by identifying possible problems. An ER though is a complex social multi-agent system where staff members should understand the needs of patients, what their colleagues expect of them and how the treatment usually goes about. Social practices aim to capture this social dimension by focussing on the shared routines in a system, such as diagnosing or treating the patient. This paper uses the Web Ontology Language (OWL) to formalize social practices and then applies it to the ER domain. This results in an ontology that can be used as a basis for simulations and formal reasoning. The latter is demonstrated by verifying a number of properties for our use case. These results serve not only as a first step to better decision-support tools for ER, but also serves as an example for formalizing the social dimension of other multi-agent systems.</p></td>
                </tr>
            
                <tr>
                    <td>88</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-88">Synthesizing Efficient Solutions for Patrolling Problems in the Internet Environment</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Verification and Validation of Agent-based Systems] Synthesis of agent-based systems</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_88" class="editable_bid" data-pk="88" data-value="30"
                    data-url="/rev_3/paper/bid/set/88/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-88"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We propose an algorithm for constructing efficient patrolling strategies in the Internet environment, where the protected targets are nodes connected to the network and the patrollers are software agents capable of detecting/preventing undesirable activities on the nodes. The algorithm is based on a novel compositional principle designed for a special class of strategies, and it can quickly construct (sub)optimal solutions even if the number of targets reaches hundreds of millions.<br></p></td>
                </tr>
            
                <tr>
                    <td>43</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-43">A Multi-Agent System Framework for Miniaturized Satellite Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Engineering Multiagent Systems] Programming languages and frameworks for agents and multi-agent systems</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_43" class="editable_bid" data-pk="43" data-value="30"
                    data-url="/rev_3/paper/bid/set/43/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-43"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Developing newer satellite missions faces increased onboard software complexity. Next generations of small satellites need to enable the infrastructure for implementation of concurrent and deterministic onboard algorithms for mission coordination and control. Multi-agent-based architectures are a new developing approach adopted in the software engineering field due to its flexibility, scalability, and adaptability to dynamic operating environments. This paper describes the design and implementation of a deterministic multi-agent system framework to develop applications for highly constrained embedded computers used in small satellite missions. As a result of the implementation of this framework the user coding effort for describing complex onboard software applications is reduced up to 50\% with minimum impact on CPU load and program memory allocation. This paper also shows a set of benchmarks that demonstrate not only the feasibility of MAS-based software for small satellite missions but its value to achieve aggressive development schedules.<br></p></td>
                </tr>
            
                <tr>
                    <td>518</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-518">Trade-off and Winners Selection for Pareto Optimal QoS Compositions in Competitive Negotiations</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Agents and Mainstream Computing] Service-oriented architectures</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_518" class="editable_bid" data-pk="518" data-value="30"
                    data-url="/rev_3/paper/bid/set/518/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-518"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>		 	 	 		</p><div class="page" title="Page 1">			<div class="layoutArea">				<div class="column">					<p>		 	 	 		</p><div class="page" title="Page 1">			<div class="layoutArea">				<div class="column">					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">QoS-based service composition allows for the development of complex business applications composed of services that need to be selected, among the ones available, according to end-to-end QoS constraints set, when the application is required. In fact, for each component service, more candidates are available that may differ for their QoS referring to non-functional characteristics of services, such as cost, execution time, reliability. Automated negotiation is proposed as an enabling mechanism to select component services in a dynamic market of services, where provided QoS values may vary according to different market strategies depending on the considered market sector. Nevertheless, when dealing with multiple QoS attributes, multiple service providers, and no shared information, that are typical characteristics of a market of services, it is difficult to guarantee formal properties of the negotiation outcomes. In the present work, we propose a trade-off strategy that exploits both the competition due to the number of services providing the same functionality but with different QoS, and the cooperation needed among the providers of component services in order to make it possible to meet the required end-to-end QoS constraints. The proposed strategy allows selecting the component services by determining the winners of the negotiation that reached a Pareto-optimal agreement consisting in the composition of their local QoS values.&nbsp;</span></p>				</div>			</div>		</div>				</div>			</div>		</div></td>
                </tr>
            
                <tr>
                    <td>204</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-204">Surprise in Elections</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Societies and Societal Issues] Social networks<br>[Humans and Agents] Multi-user/multi-virtual-agent interaction</td>
                    
                        <td>0.650</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_204" class="editable_bid" data-pk="204" data-value="30"
                    data-url="/rev_3/paper/bid/set/204/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-204"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Elections involving a very large voter population often lead to outcomes that surprise many. This is particularly important for the elections in which results affect the economy of a sizable population. A better prediction of the true outcome helps reduce the surprise (or shock) and keeps the voters prepared. </p><p>This paper starts from the basic observation that individuals in the underlying population build estimates of the distribution of preferences of the whole population based on their local neighborhoods. The outcome of the election leads to a surprise/shock if these local estimates contradict the outcome of the election for some fixed voting rule. To get a quantitative understanding, we propose a simple mathematical model of the setting where the individuals in the population and their connections (through geographical proximity, social networks etc.) are described by a random graph with connection probabilities that are biased based on the preferences of the individuals. Each individual also has some estimate of the bias in their connections.</p><p>We show that the election outcome leads to a surprise if the discrepancy between the estimated bias and the true bias in the local connections exceeds a certain threshold, and confirm the phenomenon that surprising outcomes are associated only with {\em closely contested elections}. We compare standard voting rules based on their performance on surprise and show that they have different behavior for different parts of the population. It also hints at an impossibility that a single voting rule will be less surprising for {\em all} parts of a population. Finally, we experiment with the UK-EU referendum (a.k.a.\ Brexit) dataset that attest some of our theoretical predictions.<br></p></td>
                </tr>
            
                <tr>
                    <td>562</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-562">Pedagogical Value-Aligned Crowdsourcing: Inspiring the Wisdom of Crowds via Interactive Teaching</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Humans and Agents] Human-robot/agent interaction<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_562" class="editable_bid" data-pk="562" data-value="30"
                    data-url="/rev_3/paper/bid/set/562/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-562"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Crowdsourcing offers an economical means to leverage human wisdom for large-scale data annotation. However, the crowdsourced labeled data often suffer from low quality and significant inconsistencies, since the low-cost crowd workers are commonly lacking in corresponding domain knowledge and might make cursory choices. Most research in this area emphasizes the post-processing of the obtained noisy labels, which cannot radically ameliorate the quality of crowdsourcing service. In this paper, we focus on improving the worker's reliability during the label collecting process. We propose a novel game-theoretical framework of crowdsourcing, which formulates the interaction between the annotation system and the crowd workers as an incentivized pedagogical process between the teacher and the students. In this framework, the system is able to infer the worker's belief or prior from their current answers, reward them by performance-contingent bonus, and instruct them accordingly via near-optimal examples. We develop an effective algorithm for the system to select examples, even when the worker's belief is unidentifiable. Also, our mathematical guarantees show that our framework not only ensures a fair payoff to crowd workers regardless of their initial priors but also facilitates value-alignment between the annotation system (requester) and the crowd workers. Our experiments further demonstrate the effectiveness and robustness of our approach among different worker populations and worker behavior in improving the crowd worker's reliability.</p></td>
                </tr>
            
                <tr>
                    <td>506</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-506">Adaptive Adjacency Kanerva Coding for Memory-Constrained Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_506" class="editable_bid" data-pk="506" data-value="30"
                    data-url="/rev_3/paper/bid/set/506/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-506"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9pt; font-family: NimbusRomNo9L;">When encountering continuous, or very large do-
mains, using a compact representation of the state space is prefer-
able for practical reinforcement learning (RL). This approach
can reduce the size of the state space and enable generalization
by relating similar or neighboring states. However, many state
abstraction techniques cannot achieve satisfactory approximation
quality in the presence of limited memory resources, while expert
state space shaping can be costly and usually does not scale
well. We have investigated the principle of Sparse Distributed
Memories (SDMs) and applied it as a function approximator to
learn good policies for RL.
</span></p>
					<p><span style="font-size: 9pt; font-family: NimbusRomNo9L;">This paper describes a new approach, adaptive adjacency
in SDMs, that is capable of representing very large continuous
state spaces with a very small collection of prototype states.
This algorithm enhances an SDMs architecture to allow on-
line, dynamically-adjusting generalization to assigned memory
resources to provide high-quality approximation. The memory
size and memory allocation no longer need to be manually
assigned before and during RL. Based on our results, this
approach performs well both in terms of approximation quality
and memory usage.
</span></p>
					<p><span style="font-size: 9pt; font-family: NimbusRomNo9L;">The superior performance of this approach over existing
SDMs and CMACs is demonstrated through a comprehensive
simulation study in two classic domains, Mountain Car with 2
dimensions and Hunter-Prey with </span><span style="font-size: 9.000000pt; font-family: 'CMR9'">5 </span><span style="font-size: 9pt; font-family: NimbusRomNo9L;">dimensions. Given equivalent
memory resources, our approach learns better policies over
existing SDMs and CMACs, revealing </span><span style="font-size: 9.000000pt; font-family: 'CMR9'">14</span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">.</span><span style="font-size: 9.000000pt; font-family: 'CMR9'">7% </span><span style="font-size: 9pt; font-family: NimbusRomNo9L;">to </span><span style="font-size: 9.000000pt; font-family: 'CMR9'">39</span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">.</span><span style="font-size: 9.000000pt; font-family: 'CMR9'">5% </span><span style="font-size: 9pt; font-family: NimbusRomNo9L;">and
</span><span style="font-size: 9.000000pt; font-family: 'CMR9'">32</span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">.</span><span style="font-size: 9.000000pt; font-family: 'CMR9'">8% </span><span style="font-size: 9pt; font-family: NimbusRomNo9L;">to </span><span style="font-size: 9.000000pt; font-family: 'CMR9'">73</span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">.</span><span style="font-size: 9.000000pt; font-family: 'CMR9'">2% </span><span style="font-size: 9pt; font-family: NimbusRomNo9L;">improvements on the learned average returns,
respectively, when applied to both domains’ tasks, while it can
also achieve similar or even better performance when using only
</span><span style="font-size: 9.000000pt; font-family: 'CMR9'">20% </span><span style="font-size: 9pt; font-family: NimbusRomNo9L;">of the memory used by CMACs in our experiments. We
conclude that the adaptive adjacency approach can be used to
efficiently approximate value functions with limited memories,
and that the approach scales well across tested domains with
continuous, large-scale state spaces.&nbsp;</span></p>
				</div>
			</div>
		</div>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>313</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-313">Foresee: Attentive Future Projections of Chaotic Road Environments with Online Training</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_313" class="editable_bid" data-pk="313" data-value="30"
                    data-url="/rev_3/paper/bid/set/313/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-313"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we focus on anticipation of road environment which is highly dynamic and uncertain by projecting future from the raw camera images. Interaction among traffic participants make this anticipation very challenging as the motion of one affect another. On the other hand, humans are very effective in anticipating the environment. For example, irrespective of the number of traffic participants they are efficacious to drive on the chaotic roads. Proliferation in deep learning have shown the efficacy of neural networks in learning this human behavior. In that direction, we investigate recurrent neural networks to understand the chaotic road environment which is shared by pedestrians, vehicles (cars, trucks, bicycles etc.), and sometime animals as well. We propose Foresee, a unidirectional gated recurrent units (GRUs) with attention to foresee future locations of the objects in terms of the images itself.</p><p>We train foresee in an unsupervised way. We have collected several videos on Delhi roads consisting of various traffic participants, background and infrastructure differences (like 3D pedestrian crossing) at various times on various days. We also explore online training for \emph{Foresee} to project future for up to $0.5$ seconds. We compared our proposal with two state of the art methods and finally, we show that the our trained generalizes to a public dataset for future projections.</p></td>
                </tr>
            
                <tr>
                    <td>72</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-72">Maximizing Spread in Emerging Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Multi-user/multi-virtual-agent interaction<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_72" class="editable_bid" data-pk="72" data-value="30"
                    data-url="/rev_3/paper/bid/set/72/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-72"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>When investigating how phenomena spread in a network, we may wish to infer under what conditions the spread is maximized. Influence maximization enables us, for instance, to pick targets for advertising campaigns in a social network. The goal is to select seed nodes so as to maximize the overall number of influenced nodes. Previous work has treated the network as a static graph, whereas, in reality, networks of interest may still be going through a phase of rapid expansion, especially when a market is growing. In this work, we propose an algorithm for epidemic-motivated and game-motivated influence in networks of growing size, with favorable theoretical properties as well as significantly improved empirical results on a number of datasets.<br></p></td>
                </tr>
            
                <tr>
                    <td>118</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-118">Best of Both Worlds: Mitigating Imbalance of Crowd Worker Strategic Choices Without Budget</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Socio-technical systems<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_118" class="editable_bid" data-pk="118" data-value="30"
                    data-url="/rev_3/paper/bid/set/118/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-118"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Crowdsourcing has become a popular paradigm for requesters to hire ubiquitous crowd workers. The worker's selfish instinct of choosing the most profitable task can cause the imbalance of task completion: some tasks achieve a number of redundant worker choices, while others may achieve no worker choice. Although budget-based incentives can mitigate the imbalance of crowd workers' strategic choices, the extra budget makes them less attractive. To mitigate task completion imbalance without budget, a price mediation mechanism is proposed. This mechanism works by allowing the crowdsourcing platforms to adjust task price, thereby eliciting workers to balance their choices. The price adjustment is carefully designed to satisfy 1) task completion integrity, and 2) social welfare maximization. We prove that this optimization problem is NP-hard to solve. By designing bound function and pruning policies, we propose an optimal branch-and-bound algorithm for small-scale instances. To further improve the scalability for large-scale instances, we relax the optimal algorithm, and get an approximation performance. Experimental results on a real dataset show that compared with benchmarks, our approaches are effective on maximizing social welfare on realistic-sized applications.<br></p></td>
                </tr>
            
                <tr>
                    <td>526</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-526">Towards the use of Contextual Information in Lending Automated Negotiation Processes</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Agent Theories and Models] Logics for agents and multi-agent systems</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_526" class="editable_bid" data-pk="526" data-value="30"
                    data-url="/rev_3/paper/bid/set/526/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-526"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="p1">






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
  <o:PixelsPerInch>96</o:PixelsPerInch>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>PT-BR</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073786111 1 0 415 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
p.p1, li.p1, div.p1
	{mso-style-name:p1;
	mso-style-unhide:no;
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:7.0pt;
	font-family:"Helvetica",sans-serif;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
@page WordSection1
	{size:612.0pt 792.0pt;
	margin:70.85pt 3.0cm 70.85pt 3.0cm;
	mso-header-margin:36.0pt;
	mso-footer-margin:36.0pt;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Tabela normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin:0cm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-fareast-language:EN-US;}
</style>
<![endif]-->



<!--StartFragment-->



<!--EndFragment--></p><p class="p1" style="text-align:justify"><span lang="EN-US" style="font-size:14.0pt;
mso-bidi-font-size:7.0pt;mso-ansi-language:EN-US">In this work it is discussed
the incorporation of context information in Lending Automated Negotiation
processes, so that agents can be able to make amends on strategies purely based
on the negotiation object attributes. In this sense, it is presented, as the
main contribution, an efficient negotiation model that takes the borrower position
into account in order to mitigate risks while maximizing gains for the
financial institution. A solution model is introduced by adapting and extending
the so called Haleema optimized negotiation model to E-Commerce transactions.
Simulations involving the implementation of both the Haleema and the proposed
model show a more conservative behavior to the latter, but with the same profit
margin. For the financial institution, results may indicate that the model is a
feasible approach to improve automatic services in Lending processes by
regulating decisions accordingly to the context.<o:p></o:p></span></p><style type="text/css">
p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 9.0px Helvetica}
</style></td>
                </tr>
            
                <tr>
                    <td>472</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-472">Question Generation for Conversational Agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Ontologies for agents<br>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Learning and Adaptation] Deep learning<br>[Verification and Validation of Agent-based Systems] Verification techniques for multiagent systems, including model checking</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_472" class="editable_bid" data-pk="472" data-value="30"
                    data-url="/rev_3/paper/bid/set/472/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-472"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper we evaluate current state-of-the-art Question Generation systems in the task of generating questions to populate the knowledge base of a domain-oriented conversational agent. Three Question Generation systems are considered. The first is a highly cited tool representing linguistically-based approaches. The second illustrates the family of recent Question Generation systems based in deep neural networks. We contribute with a third system in which patterns are created based on a small set of seeds, constituted by sentence/question pairs; in this system, questions are generated based in a pattern matching at the semantic role level. Contrary to the usual evaluations, in our study we consider three evaluation dimensions that we consider more appropriate to automatically evaluate generated questions for a domain-oriented conversational agent -- correction, usefulness, and coverage of the produced questions. In this context, we evaluate the different systems individually, but also as a whole, with a reference corpus hand-crafted by humans, which we make public. Results show that these Question Generation systems should be seen as complementary, as coverage, although poor, duplicates when using them combined. In addition, we show that these systems can also contribute with interesting questions that were not considered in the reference manually created.<br></p></td>
                </tr>
            
                <tr>
                    <td>431</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-431">Convention Formation during Conflict Resolution Process in Networked Agent Societies</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Normative systems<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_431" class="editable_bid" data-pk="431" data-value="30"
                    data-url="/rev_3/paper/bid/set/431/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-431"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Social conventions have been used as an efficient mechanism to facilitate coordination among agents in networked agent societies. A convention is a situation where each agent adopts the same strategy on the choice of actions. When agents are performing tasks, such as manufacturing products and driving on the roads, the agents should not execute conflicting actions to avoid inefficiency or even danger. To try to make agents execute conflict-free actions in these tasks, current approaches focus on establishing conventions before agents start to perform tasks. These approaches may provide a sub-convention situation, where conflicting strategies among agents exist when agents start to perform tasks. However, there is no solution to the problem of how to resolve conflicts and form conventions at the same time when agents are performing tasks. To tackle this problem, in this paper, we propose an approach which forms conventions during a conflict resolution process. In this process, each agent interacts repeatedly with its neighbours. In each interaction, if conflicting strategies exist, the agents need to resolve the conflict. We proof that, when each agent applies the same multi-agent learning algorithm to resolve conflicts, a convention is guaranteed to be formed during the conflict resolution process. We also conduct empirical experiments to evaluate the proposed approach with respect to different kinds of social networks, number of agents, number of actions, influences of non-adaptive agents, and so on. Experimental results reveal significant insights into convention emergence in networked agent societies using the proposed approach.<br></p></td>
                </tr>
            
                <tr>
                    <td>622</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-622">Real-time Machine Learning Prediction of an Agent-Based Model for Urban Decision-making</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Interactive simulation<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Engineering Multiagent Systems] Methodologies for agent-based systems<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_622" class="editable_bid" data-pk="622" data-value="30"
                    data-url="/rev_3/paper/bid/set/622/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-622"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span id="docs-internal-guid-4f2e3f1a-a7c4-ac19-0634-be8a5cbbb7d6"><span style="font-size: 11pt; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">Cities are becoming bigger, more complex, and changing even more rapidly. Currently, community engagement of urban decision-making is ineffective, uninformed, and normally happens in late stages. To facilitate more collaborative and evidence-based urban decision-making process for both experts and non-experts, real-time feedback is essential. However, current tools for urban planning are not capable of quickly performing complex simulation. To address these challenges, machine learning techniques were applied to achieve real-time prediction of an agent-based model (ABM) of city traffic. An ABM capable of determining accumulated traffic volume and waiting time by location was developed on the GAMA Platform. 10,000 generated city configurations were simulated. These simulation results were then used to train a convolutional neural network (CNN) to predict the traffic performance of an unseen city configuration. Prediction with the CNN is more than 5000 times faster than the original ABM. Its R squared value relative to the ABM was 0.86. This machine learning approach was applied as a versatile, quick, accurate, and computationally efficient method for real-time feedback and optimization for urban decision-making in the CityMatrix project. Users had a better understanding of the embodied trade-offs of the city, and achieved their goals for the city faster.</span></span><br></p></td>
                </tr>
            
                <tr>
                    <td>629</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-629">A simple and efficient algorithm to compute epsilon-equilibria of discrete Colonel Blotto games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_629" class="editable_bid" data-pk="629" data-value="30"
                    data-url="/rev_3/paper/bid/set/629/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-629"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The Colonel Blotto game is a famous game commonly used to model resource allocation problems in many domains ranging from security to advertising. Two players distribute a fixed budget of resources on multiple battlefields to maximize the aggregate value of battlefields they win, each battlefield being won by the player who allocates more resources to it. Since its introduction in 1921, the continuous version of the game---where players can choose any fractional allocation---has been extensively studied, albeit only with partial results to date. Only very recently, the discrete version---where allocations can only be integers---started to gain traction and algorithms were proposed to compute the equilibrium in polynomial time; but these remain computationally impractical for large (or even moderate) numbers of battlefields. In several important applications, meaningful models naturally have a large number of battlefields; the question of efficiently finding an equilibrium for such cases remains open.&nbsp;</p><p>In this paper, we propose an algorithm to compute very efficiently an <i>approximate </i>equilibrium for the discrete Colonel Blotto game with many battlefields. Specifically, we propose a strategy (the <i>discrete independently uniform</i> strategy) and show that it is an epsilon-equilibrium. We provide a theoretical bound on the approximation error, epsilon, as a function of the number of battlefields and players budgets. We also propose an efficient dynamic programming algorithm to compute the best response of a player against an arbitrary set of marginals of the opponent. Using this algorithm, we can then compute for each game instance the actual value of epsilon. We perform numerical experiments that show that the proposed <i>discrete independently uniform</i> strategy provides a good approximation to the equilibrium even for a relatively moderate number of battlefields.<br></p></td>
                </tr>
            
                <tr>
                    <td>290</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-290">New cloning approach to solve Distributed Constraint Optimization Problems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Agent Cooperation] Collective intelligence<br>[Learning and Adaptation] Multiagent learning</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_290" class="editable_bid" data-pk="290" data-value="30"
                    data-url="/rev_3/paper/bid/set/290/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-290"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><b><span lang="EN-US" style="font-size:9.0pt;font-family:
&quot;Times New Roman&quot;,serif;mso-fareast-font-family:&quot;Times New Roman&quot;;mso-ansi-language:
EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">Geographical and
natural distributed problems such as distributed scheduling problems and
distributed allocation resources problems can be described as a Distributed
Optimization under Constraints Problems Maximum Relaxation. DOC-MaxRelax is a
version of the general framework DOC-BRelax dealing with Distributed Constraint
Optimization Problems where the goal is to find a set of variables assignments
that maximize the number of satisfied constraints among agents. However, when
the number of variable per agent is more and more important, then the time
resolution will be exponential and computational resources will be overloaded.
As solution to these problems, we introduce a new cloning approach. In this paper,
we provide an analysis of the circumstances under which agents should consider
cloning, and present experimental results on how cloning improves the
performance of our Multi-Agent System.</span></b><br></p></td>
                </tr>
            
                <tr>
                    <td>491</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-491">ComPAS: Community Preserving Sampling for Streaming Graphs</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Other<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_491" class="editable_bid" data-pk="491" data-value="30"
                    data-url="/rev_3/paper/bid/set/491/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-491"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In the era of big data, graph sampling is indispensable in many&nbsp;<span style="line-height: 1.42857;">settings. Existing sampling methods are mostly designed for static&nbsp;</span><span style="line-height: 1.42857;">graphs, and aim to preserve basic structural properties of the original&nbsp;</span><span style="line-height: 1.42857;">graph (such as degree distribution, clustering coefficient etc.) in the&nbsp;</span><span style="line-height: 1.42857;">sample. We argue that for any sampling method it is impossible to&nbsp;</span><span style="line-height: 1.42857;">produce an universal representative sample which can preserve all&nbsp;</span><span style="line-height: 1.42857;">the properties of the original graph; rather sampling should be ap</span><span style="line-height: 1.42857;">plication specific (such as preserving hubs - needed for information&nbsp;</span><span style="line-height: 1.42857;">diffusion). Here we consider community detection as an application&nbsp;</span><span style="line-height: 1.42857;">scenario. We propose ComPAS, a novel sampling strategy that un</span><span style="line-height: 1.42857;">like previous methods, is not only designed for streaming graphs&nbsp;</span><span style="line-height: 1.42857;">(which is a more realistic representation of a real-world scenario) but&nbsp;</span><span style="line-height: 1.42857;">also preserves the community structure of the original graph in the&nbsp;</span><span style="line-height: 1.42857;">sample. Empirical results on both synthetic and different real-world&nbsp;</span><span style="line-height: 1.42857;">graphs show that ComPAS is the best to preserve the underlying&nbsp;</span><span style="line-height: 1.42857;">community structure with average performance reaching 73.2% of&nbsp;</span><span style="line-height: 1.42857;">the most informed algorithm for static graphs.</span></p></td>
                </tr>
            
                <tr>
                    <td>624</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-624">Analyzing the Effect of Information Stagnancy on the Distributed Stochastic Algorithm</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_624" class="editable_bid" data-pk="624" data-value="30"
                    data-url="/rev_3/paper/bid/set/624/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-624"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style="margin-bottom: 0in; line-height: 100%" align="justify">


	
	
	
	<style type="text/css">p { margin-bottom: 0.1in; direction: ltr; line-height: 120%; text-align: left; }</style>


<font color="#000000"><font face="Times New Roman, serif"><font style="font-size: 12pt" size="3">Despite
the fact that many real world problems change over time, many
Distributed Constraint Optimization Problem (</font></font></font><font color="#000000"><font face="Times New Roman, serif"><font style="font-size: 12pt" size="3"><u>DCOP</u></font></font></font><font color="#000000"><font face="Times New Roman, serif"><font style="font-size: 12pt" size="3">)
algorithms assume that the problem is constant or changing at a
negligible rate. In addition, these algorithms also assume that
changes to the environment are instantaneously observable.  However,
in highly dynamic environments with communication delays, both of
these assumptions can be violated resulting in problem solving with
out-of-date information.  In this study, we explore the relationship
between environmental dynamics, information stagnancy, and solution
quality in Dynamic DCOP problems.  By using recent advances in the
analysis of dynamic, distributed problems, we show that information
stagnancy can be characterized and used to accurately predict the
behavior of a protocol.  To evaluate our finding, we use the
Distributed Stochastic Algorithm (</font></font></font><font color="#000000"><font face="Times New Roman, serif"><font style="font-size: 12pt" size="3"><u>DSA</u></font></font></font><font color="#000000"><font face="Times New Roman, serif"><font style="font-size: 12pt" size="3">)
as a basis. Through extensive empirical testing, we show that the
prediction function is accurate.</font></font></font></p><p>

<br></p></td>
                </tr>
            
                <tr>
                    <td>582</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-582">Eligibility Traces for Options</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_582" class="editable_bid" data-pk="582" data-value="30"
                    data-url="/rev_3/paper/bid/set/582/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-582"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Temporally extended actions not only represent knowledge in the hierarchical setup in reinforcement learning, they also improve exploration while reducing the complexity of choosing actions. The option framework provides a concrete way to implement and reason about temporal abstraction. This work attempts to test the utility of eligibility traces with options and find good ways of doing multi-step intra-option updates. Three algorithms, based on off-policy methods - importance sampling, tree backup and retrace, are proposed for using eligibility traces with options.<br></p></td>
                </tr>
            
                <tr>
                    <td>522</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-522">Stability in Barter Exchange Markets</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Coalition formation (non-strategic)<br>[Agents and Mainstream Computing] Service-oriented architectures</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_522" class="editable_bid" data-pk="522" data-value="30"
                    data-url="/rev_3/paper/bid/set/522/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-522"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The notion of stability is the foundation of several classic problems in economics and computer science that arise in a wide-variety of real-world situations, including Stable Marriage, Stable Roommate, Hospital Resident and Group Activity Selection. We study this notion in the context of barter exchange markets. The input of our problem of interest consists of a set of people offering goods/services, with each person subjectively assigning values to a subset of goods/services offered by other people. The goal is to find a <i>stable transaction</i>, a set of cycles that is <i>stable</i> in the following sense: there does not exist a cycle such that every person participating in that cycle prefers to his current “status”. For example, consider a market where families are seeking vacation rentals and offering their own homes for the same. Each family wishes to acquire a vacation home in exchange of its own home without any monetary exchange. We study such a market by analyzing a stable transaction of houses involving cycles of fixed length. The underlying rationale is that an entire trade/exchange fails if any of the participating agents cancels the agreement; as a result, shorter (trading) cycles are desirable.</p><p>We show that given a transaction, it can be verified whether or not it is stable in polynomial time, and that the problem of finding a stable transaction is NP-hard even if each person desires only a small number of other goods/services. Having established these results, we study the problem of finding a stable transaction in the framework of parameterized algorithms.</p></td>
                </tr>
            
                <tr>
                    <td>269</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-269">Stable Outcomes in Modified Fractional Hedonic Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Noncooperative games: computation<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_269" class="editable_bid" data-pk="269" data-value="30"
                    data-url="/rev_3/paper/bid/set/269/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-269"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In <i>coalition formation games</i> self-organized coalitions are created as a result of the strategic interactions of independent agents. For each couple of agents (i,j), weight w<sub>i,j</sub> = w<sub>j,i</sub> reflects how much agents i and j benefit from belonging to the same coalition. We consider the modified fractional hedonic game, that is a coalition formation game in which agents’ utilities are such that the total benefit of agent i belonging to a coalition (given by the sum of w<sub>i,j</sub> over all other agents j belonging to the same coalition) is averaged over all the other members of that coalition, i.e., excluding herself. Modified fractional hedonic games constitute a class of succinctly representable hedonic games.<br></p><p>We are interested in the scenario in which agents, individually or jointly, choose to form a new coalition or to join an existing one, until a stable outcome is reached. To this aim, we consider common stability notions, leading to strong Nash stable outcomes, Nash stable outcomes or core stable outcomes: we study their existence, complexity and performance, both in the case of general weights and in the case of 0-1 weights. In particular, we completely characterize the existence of the considered stable outcomes and show many tight or asymptotically tight results on the performance of these natural stable outcomes for modified fractional hedonic games, also highlighting the differences with respect to the model of fractional hedonic games, in which the total benefit of an agent in a coalition is averaged over all members of that coalition, i.e., including herself.</p></td>
                </tr>
            
                <tr>
                    <td>537</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-537">Learning Game-theoretic Models from Aggregate Behavioral Data with Applications to Vaccination Rates in Public Health</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Organisations and institutions<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: computation</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_537" class="editable_bid" data-pk="537" data-value="30"
                    data-url="/rev_3/paper/bid/set/537/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-537"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: small;">A survey is a common method to elicit behavioral data. The collected data provides a noisy representation of the actions of a sampled population. Direct access to individual responses is rare, for many obvious reasons. Instead, most of us would only have access to aggregated information about the percentage of individuals who reportedly took certain actions. Public-health data on populations' vaccination rates collected by government officials is such example and will be the focus of this paper. Naturally, behavioral data capture implicit interdependencies governing the decision-making process of the sampled population. In this work, we undertake the challenging task of uncovering such independencies of the data and use computational game theory (CGT) to model data as the result of distributed decision-making at the reported granularity level (e.g., nations, states, districts, and towns). Indeed, CGT has increasingly gained popularity as both a formal and practical framework in which to study the potential effect of policy making of agents in a variety of settings, like the vaccination setting we study here. To achieve our task, in this paper, we posit the view of aggregated behavioral data as jointly&nbsp;</span><g class="gr_ gr_19 gr-alert gr_gramm gr_inline_cards gr_run_anim Punctuation only-del replaceWithoutSep" id="19" data-gr-id="19" style="display: inline; color: rgb(34, 34, 34); font-size: small; border-bottom: 2px solid transparent; background-repeat: no-repeat; background-position: -1px calc(100% + 3px); background-image: url(&quot;data:image/svg+xml;charset=utf8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='100%' height='100%'%3E%3Cline opacity='0.75' x1='4' y1='100%' x2='100%' y2='100%' transform='translate(-1.5, -2.5)' stroke-width='3' stroke-linecap='round' stroke='%23fc5454'/%3E%3C/svg%3E&quot;); background-size: calc(100% + 1px) 100%; animation: gr__appear_critical 0.4s ease forwards; font-family: arial, sans-serif;">randomized,</g><span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: small;">&nbsp;or mixed, strategies of multiple agents. We propose a novel general machine-learning approach to infer game-theoretic models from a potentially noisy dataset of mixed strategies. Our goal is to learn instantiations of game-theoretic models from the data that would best explain and compactly represent the global behavior of the population within a given hypothesis class of games. Ultimately, we want to employ the learned models for policy analysis on the underlying system as a whole, which cannot be achieved using other existing approaches. We illustrate our framework in a health-policy setting using publicly available data on vaccination rates in the continental USA.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>280</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-280">Monte Carlo based Negotiation Strategy</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Economic Paradigms] Noncooperative games: computation</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_280" class="editable_bid" data-pk="280" data-value="30"
                    data-url="/rev_3/paper/bid/set/280/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-280"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Automated negotiation is a rising topic in Artificial Intelligence. Recent advances in this domain have shown that opponent modeling as much as bidding strategy are crucial issues to improve agent performances. Several solutions have thus been proposed to handle them. This paper explores a Monte Carlo-base approach for automated negotiation. Monte Carlo has become a topic of great interest since its successes in AI for games, and particularly for Go. Indeed AlphaGo, which has won all its competitions so far, is based on this family of methods. In spite of this rising interest, &nbsp;Monte Carlo methods have not yet been explored in the domain of automated negotiation. In this paper, we formalize negotiation as a game and we introduce MoCaNA, an automated negotiation strategy based on Monte Carlo Tree Search. The latter is very adaptive and makes it possible to negotiate without any knowledge on the bound of the negotiation, which is not the case for traditional strategies. This adaptation may be important in several contexts such as e-commerce, where negotiation may not be bounded at all. Our approach also uses a model of the opoponent strategy, and a model of its utility.</p><p><br></p><p>We compare our Monte Carlo-base agent to the agents of ANAC 2014. Our agent is able to outperform some finalists of the ANAC 2014 on one of the domain they have been conceived for.</p></td>
                </tr>
            
                <tr>
                    <td>433</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-433">Probabilistic Coalition Structure Generation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Coalition formation (non-strategic)<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_433" class="editable_bid" data-pk="433" data-value="30"
                    data-url="/rev_3/paper/bid/set/433/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-433"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Computing an optimal coalition structure is an important problem in many multi-agent applications. In this paper this problem is investigated in the situation when some of the agents considered at start may be&nbsp; finally defective and a new coalition structure based on the agents who are present cannot be formed. When the uncertainty about the presence of the agents is given as a probability distribution, an optimal coalition structure is one with a maximal expected utility. We introduce a model for probabilistic coalition structure generation (PCSG) which generalizes the standard model for coalition structure generation (CSG). We present some of its properties, and focus on two policies which make precise how the utility of a coalition structure may evolve when some agents are missing. Two encoding schemes (one per policy) associating a PCSG instance with a MILP instance are also provided, and some empirical results are furnished.<br></p></td>
                </tr>
            
                <tr>
                    <td>143</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-143">Optimally Protecting Elections with Uncertainty about Voter Preferences</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Game Theory for practical applications<br>[Agent Theories and Models] Logic and Game Theory</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_143" class="editable_bid" data-pk="143" data-value="30"
                    data-url="/rev_3/paper/bid/set/143/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-143"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Election control has always been an important issue of democratic institutions concerned. Considering that a voting rule is indeed susceptible to control, it is natural to seek ways to protect elections. Much of prior work has focused on complete voter preferences and approached the problem from the perspective of the computational complexity of election control. However, it is impractical for anybody to have complete voter preferences in real-world scenarios. In addition, when given a voting rule, such as plurality which is widely used in our lives, is easy to control, how to design protection strategies to prevent the occurrence of election control is ignored. In this paper, we model the problem, where the attacker can deploy a single attack such as a denial-of-service attack to convert the voting result through deleting some voter groups, and the defender allocates the limited protection resources to prevent attacks on specific voter groups, as a Stackelberg game. Then we first use the minimax regret decision criterion for uncertainty about voter preferences in the game.We also propose heuristic algorithms to speed up computing minimax regret for the Stackelberg game. Finally, we conduct detailed experiments on both synthetic and real data, which show that our algorithms lead to much better solution quality than other algorithms in the literature and can scale to realistic instances.</p></td>
                </tr>
            
                <tr>
                    <td>330</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-330">A Study of AI Population Dynamics with Million-agent Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Monitoring agent societies<br>[Agent Societies and Societal Issues] Self-organization<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_330" class="editable_bid" data-pk="330" data-value="30"
                    data-url="/rev_3/paper/bid/set/330/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-330"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We conduct an empirical study on discovering the ordered collective dynamics obtained by a population of artificial intelligence (AI) agents. Our intention is to put AI agents into a simulated natural context, and then understand their induced dynamics at the population level. In particular, we aim to verify if the principles developed in the real world could also be used in understanding an artificially-created intelligent population. To achieve this, we simulate a large-scale predator-prey world, where the laws of the world are designed by only the findings or logical equivalence that have been discovered in nature. We endow the agents with the intelligence based on deep reinforcement learning (DRL), and scale the population size up to millions. A large-scale DRL training platform with redesigned experience buffer is introduced. Our results show that the population dynamics of AI agents, driven only by each agent's individual self-interest, reveals an ordered pattern that is similar to the Lotka-Volterra model studied in population biology. We further discover the emergent behaviors of collective adaptations in studying how the agents' grouping behaviors will change &nbsp;with the environmental resources. Both of the two findings could be explained by the self-organization theory in nature.<br></p></td>
                </tr>
            
                <tr>
                    <td>543</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-543">Industry 4.0: Repurposing Manufacturing Lines On-the-fly with Multi-agent Systems for the Web of Things</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Ontologies for agents<br>[Engineering Multiagent Systems] Other<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agents and Mainstream Computing] P2P, web services, grid computing, IoT, HPC</td>
                    
                        <td>0.640</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_543" class="editable_bid" data-pk="543" data-value="30"
                    data-url="/rev_3/paper/bid/set/543/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-543"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Multi-agent systems (MAS) have long been envisioned as a key enabling technology in manufacturing, but this promise is yet to be realized: the lack of proper models, architectures, tooling, and the high level of expertise required for designing and programming agent-based manufacturing systems hindered their large-scale acceptance. The emerging Web of Things now being standardized at W3C and IETF provides new research opportunities that can help MAS enter the mainstream and achieve their long-promised impact. In this paper, we integrate these new developments with MAS and automated planning in order to design scalable and flexible agent-based manufacturing systems that can be re-purposed on-the-fly: our agents synthesize production plans using semantic descriptions of Web-based artifacts and coordinate with one another via semantic organizations. The deployed systems use the Web as an application architecture (and not just a transport layer), which facilitates the seamless integration of geographically distributed production cells. Engineers can program and re-purpose the systems using an intuitive interface that runs in any standard Web browser and on any device. To demonstrate our approach, we implemented a prototypical production cell that integrates two industry-grade robots and an augmented reality interface for human workers. Together, these contributions demonstrate a means to achieve an intriguing vision for the forthcoming fourth industrial revolution: a global collective intelligence for manufacturing.</p></td>
                </tr>
            
                <tr>
                    <td>679</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-679">Monocular Vision Based Approach for Autonomous Taxi</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_679" class="editable_bid" data-pk="679" data-value="30"
                    data-url="/rev_3/paper/bid/set/679/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-679"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Intelligent public transport is an integral component of smart cities. In this paper, a simpler approach has been demonstrated for autonomous taxi navigation. A single front camera with 1920x1080 pixel resolution at 60 frames per second has been used for real-time object detection and path planning. Two hours of driving data has been used for training the proposed deep neural network. The duly trained network was then tested with 30 minutes of driving data, recorded and used separately. Two control parameters were derived viz. speed of the vehicle and the steering angle. An eight layered convolutional network with two gated recurrent and four dense layers was trained and tested on Nvidia Tesla K 40 GPU based system with Core i-7 processor. The mean squared error (MSE) for the target parameters viz. speed and steering angle were 1.79 and 2.69 percent, respectively, with 38 milli seconds of real-time response delay. An additional information on real-time perception module via semi-dense depth map interpolation usingerceptual loss function is provided for future integration with SLAM methods.</p></td>
                </tr>
            
                <tr>
                    <td>142</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-142">Game Theory for Adaptive Defensive Cyber Deception</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Learning and Adaptation] Reward structures for learning<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_142" class="editable_bid" data-pk="142" data-value="30"
                    data-url="/rev_3/paper/bid/set/142/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-142"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Based on prior work by others we seek to combine recent advances in game theory of both cyber defense and deception. In particular we have begun work on applying online learning and game theory to the task of advancing deception for cyber defense. Cyber deception games are generally modeled as non-cooperative, multi-turn, signaling games where the quality and authenticity of the signal is being manipulated. &nbsp;We will harness artificial intelligence techniques to allow our cyber deception to evolve over time, changing as attacks change, thus maintaining an enhanced defensive posture.<br></p></td>
                </tr>
            
                <tr>
                    <td>61</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-61">Swarm vs Swarm Adaptive Search and Tracking</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Collective intelligence<br>[Agent Cooperation] Multi-robot systems<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_61" class="editable_bid" data-pk="61" data-value="30"
                    data-url="/rev_3/paper/bid/set/61/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-61"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style="margin-bottom: 0.14in; line-height: 115%">


	
	
	
	<style type="text/css">p { margin-bottom: 0.1in; direction: ltr; line-height: 120%; text-align: left; widows: 2; orphans: 2; }</style>


As the number of
commercial drones continue to increase there will be a need for
autonomous mechanisms that enable us to police these drones. This
paper introduces a novel approach for detecting and tracking “B”
teamed swarms of quadrotor unmanned aerial vehicles using a
corresponding “A” teamed swarm. The key goal is to produce
scalable, robust and flexible search &amp; tracking mechanisms, which
enable us to overcome confusing evasive tactics expressed by swarm
“B”. During the search process swarm “A” first scatter to
cover a region of interest, and then progress by searching for “B”
teamed swarm nodes. If one or more “B” nodes are detected, a
number of “A” nodes switch to tracking mode to pursue detected
nodes, while the remaining nodes continue the search process.
<font color="#000000"><span lang="en-US">Multi-objective optimization
(MOO) is used for the simulation. </span></font>The results show
multi-objective evolutionary algorithm by decomposition (<span lang="en-US">MOEA/D)
as the best algorithm for the most of “B” nodes detection,
non-dominated sorting genetic algorithm version 2 (NSGA2) for the
fastest first convergence, and multiple particle swarm optimization
(MPSO) for the least processing time.</span></p><p>

<br></p></td>
                </tr>
            
                <tr>
                    <td>723</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-723">Online Multi-Robot Coverage: Evaluating Assumptions and Metrics</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Multi-robot systems<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_723" class="editable_bid" data-pk="723" data-value="30"
                    data-url="/rev_3/paper/bid/set/723/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-723"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>When considering the use of multi-robot systems for exploration or coverage, it is important to carefully assess the assumptions made when designing the algorithms, and ensure that consistent metrics are used when comparing different systems. We provide an analysis of the common assumptions made and metrics used in multi-robot coverage and exploration algorithms. We then take three algorithms--the Rolling Dispersion Algorithm (RDA), the Multi-Robot Depth-First-Search (MR-DFS) algorithm, and the "BoB" algorithm--chosen for their different strengths and assumptions, and compare, using a set of common metrics, their performance in different environments in simulation. We also present two extensions to RDA--RDA-MS (multi-start) and RDA-EC (extended communication)--because it was the most constrained algorithm. These extensions preserve the original set of assumptions, but are able to perform as well as the less constrained algorithms, which makes them applicable to constrained settings, such as search and rescue. We show the performance of the extensions both in simulation and in experiments with physical robots.<br></p></td>
                </tr>
            
                <tr>
                    <td>452</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-452">Towards Cooperation in Sequential Prisoner’s Dilemmas: a Deep Multiagent Reinforcement-Learning Approach</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_452" class="editable_bid" data-pk="452" data-value="30"
                    data-url="/rev_3/paper/bid/set/452/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-452"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Matrix games like the Prisoner's Dilemma have guided research on social dilemmas for decades. However, they only distinguish two atomic actions: cooperate and defect. In real-world prisoner's dilemmas, these choices are temporally extended and different strategies may correspond to a sequence of actions. We introduce a Sequential Prisoner's Dilemma (SPD) game to better capture the aforementioned characteristics. In this work, we propose a deep multiagent reinforcement-learning framework that investigates the evolution of mutual cooperation in SPD games. Our framework consists of two phases. The first phase is offline: it synthesizes policies with different cooperation degrees and then trains a cooperation degree detection network. The second phase is online: an agent adaptively selects its policy based on the detected degree of opponent cooperation. The effectiveness of our approach is empirically demonstrated in two representative SPD 2-D games: the Apple-Pear game and the Fruit Gathering game. Experimental results show that our strategy can avoid being exploited by exploitative opponents and achieve cooperation against cooperative opponents.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>218</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-218">Playing the Wrong Game: Bounding Negative Externalities in Diverse Populations of Agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Behavioral game theory<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_218" class="editable_bid" data-pk="218" data-value="30"
                    data-url="/rev_3/paper/bid/set/218/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-218"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="white-space:pre">	</span>The robustness of multiagent systems can be affected by mistakes or behavioral biases (e.g., risk-aversion, altruism, toll-sensitivity), with some agents playing the ``wrong game.'' This can change the set of equilibria, and may in turn harm or improve the social welfare of agents in the system. We are interested in bounding what we call the {\em biased price of anarchy} (BPoA) in populations with diverse agent behaviors, which is the ratio between welfare in the ``wrong'' equilibrium and optimal welfare.&nbsp;&nbsp;</p><p><span style="white-space:pre">	</span>We study nonatomic routing games, and derive an externality bound that depends on a key topological parameter of the underlying network.&nbsp;</p><p><span style="white-space:pre">	</span>We then prove two general BPoA bounds for games with diverse populations: one that relies on the network structure and the \emph{average bias} of all agents in the population, and one that is independent of the structure but depends on the \emph{maximal bias}. Both types of bounds can be combined with known results to derive concrete BPoA bounds for a variety of specific behaviors (e.g., varied levels of risk-aversion).&nbsp;</p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>265</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-265">Prosocial learning agents solve generalized Stag Hunts better than selfish ones</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_265" class="editable_bid" data-pk="265" data-value="30"
                    data-url="/rev_3/paper/bid/set/265/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-265"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Deep reinforcement learning has become an important paradigm for constructing agents that can enter complex multi-agent situations and improve their policies through experience. One commonly used technique is reactive training - applying standard RL methods while treating other agents as a part of the learner's environment. It is known that in general-sum games reactive training can lead groups of agents to converge to inefficient outcomes. We focus on one such class of environments: Stag Hunt games. Here agents either choose a risky cooperative policy (which leads to high payoffs if both choose it but low payoffs to an agent who attempts it alone) or a safe one (which leads to a safe payoff no matter what). We ask how we can change the learning rule of a single agent to improve its outcomes in Stag Hunts that include other reactive learners. We extend existing work on reward-shaping in multi-agent reinforcement learning and show that that making a single agent prosocial, that is, making them care about the rewards of their partners can increase the probability that groups converge to good outcomes. Thus, even if we control a single agent in a group making that agent prosocial can increase our agent's long-run payoff. We show experimentally that this result carries over to a variety of more complex environments with Stag Hunt-like dynamics including ones where agents must learn from raw input pixels.</p></td>
                </tr>
            
                <tr>
                    <td>619</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-619">To Charge or not to Charge: Selfish Storage and Its Effect on Electricity Markets</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Economic Paradigms] Auctions and mechanism design</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_619" class="editable_bid" data-pk="619" data-value="30"
                    data-url="/rev_3/paper/bid/set/619/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-619"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><pre style="margin-bottom: 0px;"><span style=" color:#000000;">The volatility of prices in modern electricity markets, caused by fluctuations in generation and fast-changing demand, can be significantly reduced by the introduction of arbitrage-oriented storage suppliers. The behavior of selfish agents that provide storage is greatly influenced by both strategic considerations and by the physical constraints of storage systems, limiting their beneficial effect on the market. In this work we use agent-based modeling to examine the effect of both these factors on the agent's behavior and the subsequent market outcome. For a market in which a single monopolistic storage provider exists, we analyze the welfare loss caused by profit-maximizing behavior of the agent, showing that in case of linear demand and supply curves, the price of anarchy is 3/4, and the monopolist extracts 2/3 of the total welfare that it adds. For smaller-scale storage, we use Markov Decision Processes (</span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">MDPs</span><span style=" color:#000000;">) to realistically model the physical behavior of a storage system. We then utilize this model to provide an agent-based framework to derive the bidding strategies of storage agents, and use it to analyze the effect of multiple agents on the market, empirically showing the effect of physical specifications of storage on the market equilibrium and storage saturation. </span></pre></td>
                </tr>
            
                <tr>
                    <td>305</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-305">Identifying Reusable Macros for Efficient Exploration via Policy Compression</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_305" class="editable_bid" data-pk="305" data-value="30"
                    data-url="/rev_3/paper/bid/set/305/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-305"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Reinforcement Learning agents often need to solve not a single <i>task</i>, but several tasks pertaining to a same <i>domain</i>; in particular, each task corresponds to an MDP drawn from a family of related MDPs (a domain). An agent learning in this setting should be able exploit policies it has learned in the past, for a given set of sample tasks, in order to more rapidly acquire policies for novel tasks. Consider, for instance, a navigation problem where an agent may have to learn to navigate different (but related) mazes. Even though these correspond to distinct tasks (since the goal and starting locations of the agent may change, as well as the maze configuration itself), their solutions do share common properties---e.g. in order to reach distant areas of the maze, an agent should not move in circles. After an agent has learned to solve a few sample tasks, it may be possible to leverage the acquired experience to facilitate solving novel tasks from the same domain.</p><p><br></p><p>Our work is motivated by the observation that trajectory samples from optimal policies for tasks belonging to a common domain, often reveal underlying useful patterns for solving novel tasks. We propose an optimization algorithm that characterizes the problem of learning reusable temporally extended actions (macros). We introduce a computationally tractable surrogate objective that is equivalent to finding macros that allow for maximal compression of a given set of sampled trajectories. We develop a compression-based approach for obtaining such macros and propose an exploration strategy that takes advantage of them. We show that meaningful behavioral patterns can be identified from sample policies over discrete and continuous action spaces, and present evidence that the proposed exploration strategy improves learning time on novel tasks.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>259</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-259">Uniform Mixed Equilibria in Affine Congestion Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_259" class="editable_bid" data-pk="259" data-value="30"
                    data-url="/rev_3/paper/bid/set/259/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-259"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><pre id="code" class="brush: ; plain-text" style="margin-bottom: 0px; padding: 10px; white-space: pre-wrap; color: rgb(0, 0, 0); font-size: 12px;">Motivated by possible applications in fault-tolerant systems, we introduce the notion of uniform mixed equilibria for resource selection games. Given an integer $\rho\geq 1$, a $\rho$-uniform mixed strategy is a mixed strategy in which a player plays exactly $\rho$ pairwise disjoint pure strategies with uniform probabilities, so that a $\rho$-uniform mixed equilibrium is a tuple of $\rho$-uniform mixed strategies, one for each player, in which no player can lower her cost by deviating to another $\rho$-uniform mixed strategy. We evaluate this solution concept within the well-studied class of congestion games with affine latency functions. For games with weighted players, we show existence of $\rho$-uniform mixed equilibria and provide a tight characterization of their price of anarchy. For games with unweighted players, instead, we extend the existential guarantee to any class of latency functions and, restricted to games with affine latencies, we derive a tight characterization of both the prices of anarchy and stability.</pre></td>
                </tr>
            
                <tr>
                    <td>81</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-81">On a Flexible Representation for Defeasible Reasoning Variants</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Deductive, rule-based and logic-based argumentation<br>[Knowledge Representation and Reasoning] Ontologies for agents</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_81" class="editable_bid" data-pk="81" data-value="30"
                    data-url="/rev_3/paper/bid/set/81/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-81"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We propose Statement Graphs (SG), a new logical formalism for defeasible reasoning based on argumentation. Using a flexible labeling function, SGs can capture the variants of defeasible reasoning (ambiguity blocking or propagating, with or without team defeat, and circular reasoning). We evaluate our approach with respect to human reasoning and propose a working first order defeasible reasoning tool that, compared to the state of the art, has richer expressivity at no added computational cost.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>266</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-266">Strategic Monitor Placement against Malicious Flows</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: computation</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_266" class="editable_bid" data-pk="266" data-value="30"
                    data-url="/rev_3/paper/bid/set/266/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-266"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal">Security Games have been widely adopted to model scenarios
in which one player, the Defender, has to decide how to deploy her resources to
minimize the loss that can be caused by an attack performed by another player,
the Attacker, aiming at maximizing such loss. In the present paper, we
focus on scenarios in which the Defender has lexicographic-like preferences on the targets, being primarily interested in defending the
integrity of a subset of the targets and, only secondarily, to reduce the amount
of the other damaged targets. Our central motivation for studying this problem
comes from the need to reduce the impact of malicious flows in networks. Such
networks can be either physical, like cities, or virtual, e.g., social
networks. In this work, we introduce a new class of security games to model
these scenarios, characterizing it and proving the NP-hardness of computing a
leader-follower equilibrium, which is the most appropriate solution concept for
this setting. To compute such an equilibrium, we provide an exact
exponential-time algorithm, capable of exploiting the topological properties of
the network. Finally, we show empirically that the number of instances in which
the algorithm requires exponential time turns out being very small, stating the
actual applicability to real-world scenarios of the algorithm we designed.<o:p></o:p></p></td>
                </tr>
            
                <tr>
                    <td>225</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-225">Context-based and Explainable Decision Making with Argumentation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Deductive, rule-based and logic-based argumentation<br>[Communication and Argumentation] Other<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_225" class="editable_bid" data-pk="225" data-value="30"
                    data-url="/rev_3/paper/bid/set/225/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-225"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Argumentation-based approaches to decision making have gained
considerable research interest, due to their ability to select and
justify decisions. In order to make better decisions, context is a key
piece of information that needs to be considered. However, most existing
argumentation-based models and frameworks have not modelled
or reasoned with context explicitly. In this paper, we present a
new argumentation-based approach for making context-based and
explainable decisions. We propose a graphical representation for
modelling decision problems involving varying contexts, Decision
Graph with Context (DGC), and a reasoning mechanism for making
context-based decisions which relies on the Assumption-based
Argumentation formalism. Based on these constructs, we introduce
two types of explanations, argument explanation and context explanation, identifying the reasons for the decisions made from an
argument-view and a context-view respectively.</p></td>
                </tr>
            
                <tr>
                    <td>182</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-182">An Axiomatic View of the Parimutuel Consensus Wagering Mechanism</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Other</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_182" class="editable_bid" data-pk="182" data-value="30"
                    data-url="/rev_3/paper/bid/set/182/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-182"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider an axiomatic view of the \emph{Parimutuel Consensus Mechanism} defined by Eisenberg and Gale (1959). The parimutuel consensus mechanism can be interpreted as a parimutuel market for wagering with a proxy that bets optimally on behalf of the agents, depending on the bets of the other agents.&nbsp; We show that the parimutuel consensus mechanism satisfies the desirable properties of Pareto optimality, individual rationality, budget balance and sybilproofness. While the parimutuel consensus mechanism does violate the key property of incentive compatibility, it is incentive compatible in the limit as the number of agents becomes large. Via simulations on real contest data, we show that violations of incentive compatibility are both rare and only minimally beneficial for the participants. This suggests that the parimutuel consensus mechanism is a reasonable mechanism for eliciting information in practice.<br></p></td>
                </tr>
            
                <tr>
                    <td>728</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-728">Approximation for Competitive Equilibria with Indivisible Goods and Generic Budgets</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Agent Theories and Models] Logic and Game Theory</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_728" class="editable_bid" data-pk="728" data-value="30"
                    data-url="/rev_3/paper/bid/set/728/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-728"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We study the existence of Competitive Equilibria in Fisher market model but with generic budgets. We assume that the preferences of players are additive and the same for all players. Such equilibria do not exist for the simplest possible example of two players with equal budgets and a single item, thus, we study cases with unequal budgets. First, we prove existence of an approximation for Competitive Equilibria, then we represent a simple algorithm satisfying the same bound.<br></p></td>
                </tr>
            
                <tr>
                    <td>576</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-576">An Adaptive E-Learning System Based on Agents and Artifacts Metamodel</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Methodologies for agent-based systems<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_576" class="editable_bid" data-pk="576" data-value="30"
                    data-url="/rev_3/paper/bid/set/576/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-576"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we propose an adaptive e-learning system that supports personalization based on Agents and Artifacts (A{\&amp;}A) Metamodel. A{\&amp;}A Metamodel focuses on environment modeling in multi agent system (MAS) design and models entities in agents’ environments with artifacts as first class entities like the agents. From the perspective of MAS based E-Learning systems, learner models and learning resources are part of the environment of the agents and agents interact with them constantly. Thus, we propose an e-learning system that focuses on environment abstraction and models access to different learner models and learning resources with artifacts to support personalization. In MAS based e-learning systems with the same functionality, specific agents are responsible for modeling learner information and retrieving learning resources. However, in the proposed approach, by exploiting the A{\&amp;}A Metamodel, this operations are performed by artifacts to provide a more flexible and scalable solution. The proposed adaptive e-learning environment model is developed as a prototype with CArtAgO framework and a MAS based E-Learning system is also developed with Jason agent platform as a case study exploiting the proposed environment model. As part of the development of the proposed system, learning resources for Logic Design course are stored as learning objects in two learning object repositories and learners are modeled by using an ontology according to their learning styles. However, the proposed model can be extended to support various learning object repositories and different learning styles models. Finally, we present a discussion of current limitations and future directions for our approach.<br><br><br></p></td>
                </tr>
            
                <tr>
                    <td>748</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-748">Reinforcement Learning based on Limited Goal Selection for Multi-Agent Cooperation without Communication</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Teamwork, team formation, teamwork analysis<br>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Multiagent learning</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_748" class="editable_bid" data-pk="748" data-value="30"
                    data-url="/rev_3/paper/bid/set/748/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-748"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal"><span lang="EN-US">This paper focuses on reinforcement learning for multi-agent cooperation without communication among them and proposed the reinforcement learning which locally solves conflicts among agents to promote the local multi-agent cooperation without communication. Concretely, the proposed method extends Q-learning to employ internal reward for such a local cooperation instead of ordinary (external) reward. To guarantee the effectiveness of the proposed methods, we derived the mechanisms that can solve the following questions: (1) how the values of the cooperative behaviors types (i.e., the varieties of the cooperative behaviors of the agents) should be updated under the condition of no communication; and (2) how the optimal goal should be selected for cooperation among the agents (i.e., how to limit the cooperation). The intensive simulations on the maze problem for the agent-cooperation task have been revealed that our proposed method successfully enable the agents to acquire their cooperative behaviors even in no communication, while the conventional method (Q-learning) always fails to acquire such behaviors.<o:p></o:p></span></p></td>
                </tr>
            
                <tr>
                    <td>349</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-349">A Memory-based Multiagent Framework for Adaptive Decision Making</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Agent Cooperation] Collective intelligence<br>[Learning and Adaptation] Evolutionary algorithms<br>[Learning and Adaptation] Multiagent learning</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_349" class="editable_bid" data-pk="349" data-value="30"
                    data-url="/rev_3/paper/bid/set/349/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-349"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Rapid adaptation to dynamically change one's policy based on a singular observation is a complex problem. This is especially difficult in multiagent systems where the global behavior is emergent from inter-agent interactions. In this paper, we introduce a memory-based learning framework called Distributed Gated Recurrent Unit with Memory Block (DGRU-MB) that enables rapid and adaptive decision making. Our framework builds on the Gated Recurrent Unit with Memory Block (GRU-MB) architecture, exploiting its modularity to define a flexible framework that can process multiple streams of sequential information; by using an external memory to identify and store dynamic features. The DGRU-MB framework combines multiagent learning with memory-based learning's ability to stitch together information across time. This enables DGRU-MB to rapidly assimilate useful features from a group of agents acting in parallel, consolidate it into a rapidly reconfigurable external memory and use it for adaptive decision making. We compare the performance of the DGRU-MB network on a simulated cybersecurity task with a traditional feedforward neural ensemble, and a centralized feedforward framework. Results demonstrate that DGRU-MB significantly outperforms the other methods and exhibits adaptive decision making to effectively solve this task.&nbsp;&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>192</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-192">Applying Social Choice Theory to Multi-Objective Optimization</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Learning and Adaptation] Evolutionary algorithms<br>[Agent Cooperation] Biologically-inspired approaches and methods<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_192" class="editable_bid" data-pk="192" data-value="30"
                    data-url="/rev_3/paper/bid/set/192/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-192"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Multi-objective optimization problems, for both discrete and continuous domains,&nbsp; often don't have a unique optimal solution. Furthermore, there are usually many possible available algorithms from which to chose for these problems, and one typically does not know in advance which one will be the most effective for a particular instance.&nbsp; Hyper-heuristics are&nbsp; often used as a means to solve this problem. In particular, the underlying idea of hyper-heuristics is to run several algorithms&nbsp; or heuristics and dynamically decide, based on different criteria, which problem or part of the problem should be solved by which algorithm or heuristic. In this paper, we explore the use of social choice theory in creating hyper-heuristics. Using hyper-heuristics created by using Borda, Copeland, and Kemeny-Young voting rules, we solve both continuous (WFG benchmark) and discrete (moTSP) multi-objective optimization problems, and the discuss the results obtained by each of these methods.</p></td>
                </tr>
            
                <tr>
                    <td>732</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-732">Bidding Strategies for Periodic Double Auctions Using Monte Carlo Tree Search</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Learning and Adaptation] Multiagent learning<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_732" class="editable_bid" data-pk="732" data-value="30"
                    data-url="/rev_3/paper/bid/set/732/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-732"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 15px;">The Power Trading Agent Competition (TAC) game models a realistic smart grid energy trading scenario. It simulates multiple markets, including a day-ahead wholesale trading market based on a Periodic Double Auction (PDA) structure. &nbsp;Bidding strategies for PDAs are complicated by the need to make predictions and plan for bidding in future actions for the same good, which may affect the bidding strategy in the current auction. &nbsp;We present a general bidding strategy for PDAs based on forecasting clearing prices and using Monte Carlos Tree Search (MCTS) to plan a bidding strategy across multiple time periods. &nbsp;We developed a controlled simulator that isolates a version of the Power TAC wholesale market to evaluate bidding strategies in a realistic energy market PDA. We&nbsp;show that our MCTS bidding strategy cost-effective in buying energy comparing to other baselines and state-of-the-art strategies. The experiments also show that the performance of our strategy improves with a higher number of MCTS simulations, a more accurate price predictor, and action spaces with advanced action selection.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>691</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-691">Maximum Likelihood approach for model-free Inverse Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_691" class="editable_bid" data-pk="691" data-value="30"
                    data-url="/rev_3/paper/bid/set/691/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-691"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal" style="margin-bottom:0in;margin-bottom:.0001pt;text-align:
justify;line-height:normal;mso-layout-grid-align:none;text-autospace:none"><span style="font-size: 12pt;">The problem of learning unknown reward function using a limited
number of demonstrations recorded from an expert’s behavior has been investigated
by researchers using different inverse reinforcement learning (IRL) approaches.
Most of the existing IRL algorithms either assume the availability of a transition
function or provide a complex inefficient approach to learn it. In this paper,
we present a model-free approach to IRL (learning without the knowledge of a transition
function), which casts IRL in the maximum likelihood framework. We use a
modification of Q-learning that replaces maximization with averaging to allow
computing the gradient of the Q-function. Our algorithm learns the reward
function of the expert represented as a linear combination of known features. We
use gradient ascent to update the feature weights to maximize the likelihood of
expert’s trajectories. We demonstrate on two problem domains that our approach improves
the likelihood compared to a previous method and converges in less number of
iterations.<o:p></o:p></span></p></td>
                </tr>
            
                <tr>
                    <td>428</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-428">Manipulating Rating Systems on Unknown Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Game Theory for practical applications<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_428" class="editable_bid" data-pk="428" data-value="30"
                    data-url="/rev_3/paper/bid/set/428/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-428"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We study the effects of manipulation strategies on a network-based rating system, where the attacker, as often the case in real-world situations, does not have complete knowledge about the system's users and their connections.</p><p><br>Starting from a `personalised' rating model, in which individuals form their opinion looking at their influential peers, we analyse how a malicious service provider can take advantage of the underlying (social) network structure, even when the individuals' private evaluations and their connections are unknown, thereby lifting a number of constraining assumptions in the literature. </p><p>Specifically, we equip the attacker with the possibility of iterative manipulation and we identify how they can gain knowledge of the network and improve upon their final expected gain.</p><p><br>We look at several scenarios of increased generality, in particular whether or not existing users' types can be recognised, e.g. users that have already expressed an evaluation of the system, even if their precise evaluation cannot. </p><p><br>We present procedures yielding an optimal manipulation strategy, focussing on worst-case results, and then present computer simulations on a number of real-world inspired social networks.<br></p></td>
                </tr>
            
                <tr>
                    <td>459</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-459">Integrating Social Network Models with BDI-based simulations: An evacuation case study</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_459" class="editable_bid" data-pk="459" data-value="30"
                    data-url="/rev_3/paper/bid/set/459/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-459"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper presents an integration of Social Network modelling into an Agent Based Simulation framework that incorporates a cognitive and a physical model. We argue that social networks are an appropriate tool for modelling large scale macro-processes of diffusion of various kinds of content. These processes influence and interact with the cognitive processes of agents which in turn affect the agent behaviour in the (simulated) physical world. We consider it appropriate to integrate existing specialised subsystems into an overall architecture to achieve an integrated model. We present our implemented architecture for this, along with a case study which compares the results of a benchmark evacuation simulation, with simulations that integrate influence from a social network. We explore evacuation rates and travel time duration for comparison with the benchmark under 3 different configurations, with two different network structures. We observe that the social network, including its specific configuration does have a substantial effect on evacuation outcomes. We believe that the framework presented here provides a basis for modelling, exploring and understanding these interactions.</p></td>
                </tr>
            
                <tr>
                    <td>551</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-551">Learning with Opponent-Learning Awareness</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_551" class="editable_bid" data-pk="551" data-value="30"
                    data-url="/rev_3/paper/bid/set/551/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-551"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Multi-agent settings are quickly gathering importance in machine learning. Beyond a plethora of recent work on deep multi-agent reinforcement learning, hierarchical reinforcement learning, generative adversarial networks and decentralized optimization can all be seen as instances of this setting. However, the presence of multiple learning agents in these settings renders the training problem non-stationary and often leads to unstable training or undesired final results. We present Learning with Opponent-Learning Awareness (LOLA), a method that reasons about the anticipated learning of the other agents. The LOLA learning rule includes an additional term that accounts for the impact of the agent's policy on the anticipated parameter update of the other agents. We show that the LOLA update rule can be efficiently calculated using an extension of the likelihood ratio policy gradient update, making the method suitable for model-free reinforcement learning. This method thus scales to large parameter and input spaces and nonlinear function approximators. Preliminary results show that the encounter of two LOLA agents leads to the emergence of tit-for-tat and therefore cooperation in the infinitely iterated prisoners' dilemma, while independent learning does not. In this domain, LOLA also receives higher payouts compared to a naive learner, and is robust against exploitation by higher order gradient-based methods. Applied to infinitely repeated matching pennies, LOLA agents converge to the Nash equilibrium. In a round robin tournament we show that LOLA agents can successfully shape the learning of a range of multi-agent learning algorithms from literature, resulting in the highest average returns on the IPD. We also apply LOLA to a grid world task with an embedded social dilemma using deep recurrent policies. Again, by considering the learning of the other agent, LOLA agents learn to cooperate out of selfish interests.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>682</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-682">Allocating Structured Tasks to Multiple Robots in Flooding Disaster Scenarios</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Agent Cooperation] Multi-robot systems</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_682" class="editable_bid" data-pk="682" data-value="30"
                    data-url="/rev_3/paper/bid/set/682/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-682"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal"><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>PT-BR</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="true"
  DefSemiHidden="true" DefQFormat="false" DefPriority="99"
  LatentStyleCount="267">
  <w:LsdException Locked="false" Priority="0" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="59" SemiHidden="false"
   UnhideWhenUsed="false" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" QFormat="true" Name="TOC Heading"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin-top:0cm;
	mso-para-margin-right:0cm;
	mso-para-margin-bottom:10.0pt;
	mso-para-margin-left:0cm;
	line-height:115%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-fareast-language:EN-US;}
</style>
<![endif]-->Disasters such as flooding are dangerous for people in the affected areas and also for the rescue teams. Using multiple autonomous robots to support rescuers can minimise the risks. However, there are challenges in developing appropriate coordination strategies for multi-robots in such a way that robots perform their operations efficiently. Real-world scenarios, such rescue operations in flooding disasters, usually require the use of heterogeneous entities working on tasks with different structures, constraints, and degrees of complexity. In addition, dynamic changes in the environment and failures in robots during the mission may lead also to the need to reallocate previously allocated tasks. In this paper, we propose a dynamic, distributed, task allocation mechanism that considers different types of tasks for heterogeneous robots, where robots can play various different roles and carry out a limited number of tasks according to the roles they can play in order to support rescue teams. Furthermore, our task allocation mechanism can deal with dynamic task allocation. We have run several experiments in order to evaluate the proposed mechanism. The results demonstrate that the proposed mechanism performs reasonably fast and provides near-optimal allocations.</p></td>
                </tr>
            
                <tr>
                    <td>395</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-395">Solving the Synergistic Team Formation Problem</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Coalition formation (non-strategic)<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_395" class="editable_bid" data-pk="395" data-value="30"
                    data-url="/rev_3/paper/bid/set/395/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-395"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The term co-operative learning is used to refer to learning procedures based on the organization of students into heterogeneous teams in which individual and team work are organized with the aim of achieving both completed academic tasks and co-learning. Key factors influencing team performance are competences, personality and gender of team members. Hence, we present a computational model to compose proficient and congenial teams based on individuals' personalities and gender, and their competences to perform tasks of different nature. Our model, called the synergistic team formation problem (STFP), extends Wilde's post-Jungian method for team composition, which solely employs individuals’ personalities and gender. In addition to presenting the synergistic team formation problem, we develop algorithms for solving the problem. The first one of these algorithms is based on an ILP formulation and its solution by a commercial ILP solver. While for small instances this approach is rather successful, this is not case for larger problem instances. Hence, we also develop a heuristic for the STFP that is meaningful for organizations and classrooms. Our computational results show that the heuristic approach underpins a powerful algorithm for the synergistic team composition problem.<br></p></td>
                </tr>
            
                <tr>
                    <td>548</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-548">Burn-In Demonstrations for Multi-Modal Imitation Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_548" class="editable_bid" data-pk="548" data-value="30"
                    data-url="/rev_3/paper/bid/set/548/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-548"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Recent work on imitation learning has generated policies that reproduce expert behavior from multi-modal data. However, past approaches have focused only on recreating a small number of distinct, expert maneuvers, or have relied on supervised learning techniques that produce unstable policies. This work extends InfoGAIL, an algorithm for multi-modal imitation learning, to reproduce behavior over an extended period of time. Our approach involves reformulating the typical imitation learning setting to include ``burn-in demonstrations'' upon which policies are conditioned at test time. We demonstrate that our approach outperforms standard InfoGAIL in maximizing the mutual information between predicted and unseen style labels in road scene simulations, and we show that our method leads to policies that imitate expert autonomous driving systems over long time horizons.<br></p></td>
                </tr>
            
                <tr>
                    <td>596</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-596">A decomposition-based approach of global norms for hierarchical normative systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Agent Societies and Societal Issues] Normative systems<br>[Agent Theories and Models] Logics for norms and normative systems</td>
                    
                        <td>0.630</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_596" class="editable_bid" data-pk="596" data-value="30"
                    data-url="/rev_3/paper/bid/set/596/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-596"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The norms concept (obligations, permissions and prohibitions) adapts well to the definition of Holonic Multiagent System (HMAS). HMAS forms a promising approach to software engineering for the modeling and development of hierarchical complex systems (Intelligent transportation systems, Smart city management systems, etc.). During the construction of these systems, different requirements can be considered: non-functional requirements&nbsp; and behavioral requirements. Norms are used as a mechanism to specify the requirements of these systems. However, most normative models for multi-agent systems do not take into account algorithms for norms coherence verification and theirs underlying complexities.&nbsp;</p><p>This paper proposes a Global Norms Decomposition (GND) approach for hierarchical normative systems. This approach allows the specification and verification of the requirements of hierarchical and critical intelligent systems. The requirements of these systems are specified by norms. Indeed, the GND approach allows (i) the specification of global norms in the abstract level of the studied system, (ii) the norms coherence checking for this level, and (iii) the successive refinement of these norms using a set of refinement rules that preserve properties of the system already proven in the highest level, in order to arrive finally at a concrete normative context which constitutes the behaviour model of the system. The GND approach allows the simplification of specification of norms, for an incrimental specification using a refinement process, and the reduction of complexity of checking the coherence of norms, building verification using refinement rules. Our approach is also illustrated by a case study describing the smart city management system.</p></td>
                </tr>
            
                <tr>
                    <td>123</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-123">Decentralised Inventory Routing in Dynamic, Adversarial and Partially Observable Environments</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_123" class="editable_bid" data-pk="123" data-value="30"
                    data-url="/rev_3/paper/bid/set/123/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-123"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider a dynamic inventory routing problem with multiple resource types, supply nodes, and autonomous vehicle agents (road, sea, and air) making decisions on where to collect and deliver resource in a decentralised manner. Sink nodes consume dynamically varying demands (whose timing and size are not known <i>a priori</i>). Network arcs, and vehicles, experience failures at times, and for durations, that are not known <i>a priori</i>. These dynamic events are caused by an intelligent adversary, seeking to disrupt the network. Our objective is to design policies for vehicle agents (indicating which resources to collect, and where to deliver those resources, over time) that minimise the likelihood of <i>stockout </i>events arising (where insufficient resource is present at a sink to meet demand). We present a series of policies to be applied by each vehicle agent in a decentralised fashion. We evaluate the performance of these policies across several scenarios with varying network topologies, and examine the impact of <i>partial observability</i>, where vehicles collect and spread state knowledge as they traverse the network.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>274</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-274">Compositional Correctness in Multiagent Interactions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Communication languages and protocols<br>[Verification and Validation of Agent-based Systems] Verification techniques for multiagent systems, including model checking</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_274" class="editable_bid" data-pk="274" data-value="30"
                    data-url="/rev_3/paper/bid/set/274/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-274"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>&nbsp; An interaction protocol specifies the constraints on communication</p><p>&nbsp; between agents in a multiagent system.&nbsp; Ideally, we would like to be</p><p>&nbsp; able to treat protocols as modules and compose them in a declarative</p><p>&nbsp; manner to systematically build more complex protocols.&nbsp; Supporting</p><p>&nbsp; composition correctly requires taking into account the causal</p><p>&nbsp; dependencies between protocols.&nbsp; One particular problem that may</p><p>&nbsp; arise from inadequate consideration of causal dependencies is that</p><p>&nbsp; the enactment of a composite protocol may violate \emph{atomicity};</p><p>&nbsp; that is, some components may be initiated but prevented from</p><p>&nbsp; completing.&nbsp; We use this \emph{all or nothing} principle as the</p><p>&nbsp; basis for formalizing atomicity as a novel correctness property for</p><p>&nbsp; protocols.</p><p><br></p><p>&nbsp; Our contributions are the following.&nbsp; One, we motivate and formalize</p><p>&nbsp; atomicity and highlight its distinctiveness from related correctness</p><p>&nbsp; notions.&nbsp; Two, we give a decision procedure for verifying atomicity</p><p>&nbsp; and report results from an implementation.&nbsp; For concreteness of</p><p>&nbsp; exposition and technical development, we adopt BSPL as an exemplar</p><p>&nbsp; of information-based approaches.</p></td>
                </tr>
            
                <tr>
                    <td>173</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-173">Boundedly Rational Voters in Large(r) Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Societies and Societal Issues] Social networks<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_173" class="editable_bid" data-pk="173" data-value="30"
                    data-url="/rev_3/paper/bid/set/173/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-173"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In Iterative Voting, voters first cast their ballots but may change their minds upon observing the ballots of others.&nbsp; Previous models have extended Iterative Voting to the incomplete information domain of social networks, where voters only observe the ballots of their friends.&nbsp; However, these models are based on computationally-intensive calculations of expected utilities.&nbsp; We propose a framework of bounded rationality for voters situated in social networks.&nbsp; Using this framework, we propose and test a number of heuristics that reduce the computation required for optimal strategic reasoning by several orders of magnitude compared to previous work, while retaining similar qualitative behaviors.&nbsp; These heuristics enable us to conduct simulations on how the size of the voting population affects strategic behavior.&nbsp; To illustrate the effectiveness of our approach, we apply our heuristics to explore the Micromega rule –-- an observation in political science that large political parties favor small assemblies.&nbsp; We find that the size of electoral districts is a contributing factor to the Micromega rule in some networks. Fringe candidates retain more support in smaller districts, while larger parties dominate in larger districts.</p></td>
                </tr>
            
                <tr>
                    <td>484</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-484">Microservices as an Architectural Style for Multi-agent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Engineering Multiagent Systems] Methodologies for agent-based systems<br>[Agents and Mainstream Computing] Service-oriented architectures</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_484" class="editable_bid" data-pk="484" data-value="30"
                    data-url="/rev_3/paper/bid/set/484/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-484"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper presents an empirical approach to implement multi-agent systems adopting microservices as an architectural style. First, we discuss the conceptual similarities between microservices and agents through a cross analysis of microservice tenets and the general characterization of agents. The analysis reveals that indeed just like agents, microservices can be thought of as autonomous software entities, driven by goals and</p><p>evolving within an environment and communicating with one another. Next, using a real-world application we follow established guidelines for developing applications using a microservice architecture. We document the key steps along the way. Finally, we show how the theoretical model within each agent in the system is being realized by the corresponding service(s).</p></td>
                </tr>
            
                <tr>
                    <td>493</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-493">Bayesian Best-Arm Identification for Selecting Influenza Mitigation Strategies</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agent-based Simulation] Simulation of complex systems<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_493" class="editable_bid" data-pk="493" data-value="30"
                    data-url="/rev_3/paper/bid/set/493/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-493"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Pandemic influenza has the epidemic potential to kill millions of people. While various preventive measures exist (i.a., vaccination and school closures), deciding on strategies that lead to their most effective and efficient use, remains challenging. To this end, individual-based epidemiological models are essential to assist decision makers in determining the best strategy to curve epidemic spread. However, individual-based models are computationally intensive and therefore it is pivotal to identify the optimal strategy using a minimal amount of model evaluations. Additionally, as epidemiological modeling experiments need to be planned, a computational budget needs to be specified a priori. Consequently, we present a new sampling method to optimize the evaluation of preventive strategies using fixed budget best-arm identification algorithms. We use epidemiological modeling theory to derive knowledge about the reward distribution which we exploit using Bayesian best-arm identification algorithms (i.e., Top-two Thompson sampling and BayesGap). We evaluate these algorithms in a realistic experimental setting and demonstrate that it is possible to identify the optimal strategy using only a limited number of model evaluations, i.e., 2-to-3 times faster compared to the uniform sampling method, the predominant technique used for epidemiological decision making in the literature. Finally, we contribute and evaluate a statistic for Top-two Thompson sampling to inform the decision makers about the confidence of an arm recommendation.<br></p></td>
                </tr>
            
                <tr>
                    <td>446</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-446">Combining Prediction of Human Decisions with ISMCTS in Imperfect Information Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Humans and Agents] Agents competing against humans<br>[Humans and Agents] Other</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_446" class="editable_bid" data-pk="446" data-value="30"
                    data-url="/rev_3/paper/bid/set/446/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-446"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Monte Carlo Tree Search (MCTS) has been extended to many imperfect information games.</p><p>However, due to the added complexity that uncertainty introduces, these adaptations have not reached the same level of practical success as their perfect information counterparts. In this paper we consider the development of agents that perform well against humans in imperfect information games with partially observable actions. We introduce the Semi-Determinized-MCTS (SDMCTS), a variant of the Information Set MCTS algorithm (ISMCTS). More specifically, SDMCTS generates a predictive model of the unobservable portion of the opponent's actions from historical behavioral data. Next, SDMCTS performs simulations on an instance of the game where the unobservable portion of the opponent's actions are determined. Thereby, it facilitates the use of the predictive model in order to decrease uncertainty. We present an implementation of the SDMCTS applied to the Cheat Game, a well-known card game, with partially observable (and often deceptive) actions.</p><p>Results from experiments with 120 subjects playing a head-to-head Cheat Game against our SDMCTS agents suggest that SDMCTS performs well against humans, and its performance improves as the predictive model's accuracy increases.&nbsp;</p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>713</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-713">Utility Decomposition with Deep Corrections for Scalable Planning under Uncertainty</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_713" class="editable_bid" data-pk="713" data-value="30"
                    data-url="/rev_3/paper/bid/set/713/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-713"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Decomposition methods have been proposed in the past to approximate solutions to large sequential decision making problems. In contexts where an agent interacts with multiple entities, utility decomposition can be used where each individual entity is considered independently. The individual utility functions are then combined in real time to solve the global problem. Although these techniques can perform well empirically, they sacrifice optimality. This paper proposes an approach inspired from multi-fidelity optimization to learn a correction term with a neural network representation. Learning this correction can significantly improve performance. We demonstrate this approach on a pedestrian avoidance problem for autonomous driving. By leveraging strategies to avoid a single pedestrian, the decomposition method can scale to avoid multiple pedestrians. We verify empirically that the proposed correction method leads to a significant improvement over the decomposition method alone and outperforms a policy trained on the full scale problem without utility decomposition.<br></p></td>
                </tr>
            
                <tr>
                    <td>574</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-574">Enhancing Social Experience via Context Sharing</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Normative systems<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_574" class="editable_bid" data-pk="574" data-value="30"
                    data-url="/rev_3/paper/bid/set/574/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-574"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>A socially intelligent personal agent understands and helps its user respect norms governing the user's interactions in a society. However, it is often appropriate for a user---and the user's agent---to deviate from a norm under certain context. We develop a framework wherein a personal agent deviating from a norm reveals the context to other agents in the society. We make two claims about the impact of such context revealing. First, revealing deviation context and reasoning about context revealed by others helps personal agents accurately learn applicable norms. Second, by acting according to such shared context-dependent norms, a personal agent can provide its user a more satisfying social experience than an agent who does not reason about context revealed by others. We demonstrate these claims via social simulations involving agent societies of varying sizes and diverse characteristics reflecting pragmatic, considerate, and selfish agents.</p></td>
                </tr>
            
                <tr>
                    <td>559</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-559">Training Dialogue Systems With Human Advices</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_559" class="editable_bid" data-pk="559" data-value="30"
                    data-url="/rev_3/paper/bid/set/559/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-559"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>One major drawback of Reinforcement Learning (RL) Spoken Dialogue Systems is that they inherit from the general exploration requirements of RL which makes them hard to deploy from an industry perspective. On the other hand, industrial systems rely on human expertise and hand written rules so as to avoid irrelevant behavior to happen and maintain acceptable experience from the user point of view.&nbsp;&nbsp;</p><p>In this paper, we attempt to bridge the gap between those two worlds by providing an easy way to incorporate all kinds of human expertise in the training phase of a Reinforcement Learning Dialogue System. Our approach, based on the TAMER framework, enables safe and efficient policy learning by combining the traditional Reinforcement Learning reward signal with an additional reward, encoding expert advices.</p><p>Experimental results show that our method leads to substantial improvements over more traditional Reinforcement Learning methods.</p></td>
                </tr>
            
                <tr>
                    <td>451</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-451">On Designing Optimal Data Purchasing Strategies for Online Ad Auctions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_451" class="editable_bid" data-pk="451" data-value="30"
                    data-url="/rev_3/paper/bid/set/451/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-451"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In online advertising, advertisers can purchase consumer relevant data from data marketplaces with a certain expenditure, and exploit the purchased data to guide the bidding process in ad auctions. One of the pressing problem faced by advertisers is to design the optimal data purchasing strategy (how much data to purchase to be competitive in bidding process) in online ad auctions. In this paper, we model the data purchasing strategy design as a convex optimization problem, jointly considering the expenditure paid during data purchasing and the benefits obtained from ad auctions. Using the techniques from Baysian game theory and convex analysis, we derive the optimal purchasing strategies for advertisers in different market scenarios. We also theoretically prove that the resulting strategy profile is the unique one that achieves Nash Equilibrium. Our analysis shows that the proposed data purchasing strategy can handle diverse ad auctions and valuation learning models. Our numerical results further confirm intuitions that the advertisers would typically purchase less data to avoid the risks of wasted purchasing under fiercer competition, and purchase more to extract huger profits when the website gains more popularity.<br></p></td>
                </tr>
            
                <tr>
                    <td>643</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-643">Nash equilibrium computation in resource allocation games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Cooperative games: computation<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_643" class="editable_bid" data-pk="643" data-value="30"
                    data-url="/rev_3/paper/bid/set/643/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-643"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We study Nash equilibrium (NE) computation in <i>resource allocation games</i>, where each player has a set of resources with exponentially many possibilities for allocation (exponentially many strategies), but with succinct payoff representation. Blotto is one such celebrated game between two players for devising war strategies. A recent series of works provided the first polynomial time algorithm for Blotto zero-sum games [Ahmadinejad et al. 2016]. Our first set of results extends this algorithm to multi-player Blotto game on a network (polymatrix game), where every node plays a two-player Blotto game with each of its neighbors in the network but has to choose a common strategy to play against all of them. The algorithm applies even when the game on each edge is not zero-sum, but the total payoff is zero. This captures situations where teams of players are competing against each other.&nbsp;</p><p>Given that general Blotto games are PPAD-hard, next we consider <i>coordination Blotto game</i>, where players are trying to "coordinate" resource allocation. We focus on the pure NE, since a coordination game is guaranteed to have one. We obtain a polynomial-time algorithm to find a best payoff NE for the case of two-players, and then extend it to polymatrix game with constantly many players. On the other hand, with arbitrarily many players, we show that finding a best payoff NE is NP-complete even in case of star graphs. Additionally, for the general polymatrix case, we show that finding an arbitrary NE is in PLS; PLS-hardness follows from [Cai, Daskalakis 2011].&nbsp;</p><p>Lastly, we consider a security-type <i>patrolling game</i> on a graph, where the first player (attacker) is trying to select paths to connect a set of sources to a set of destinations, while the second player (defender) is trying to block these paths by putting patrols on edges but is restricted by the number of patrols available. We show that even computing a best-response of the first player is NP-hard. Despite this we design efficient algorithms to compute a NE for two cases: <i>(i)</i> single path multiple edges, and <i>(ii)</i> multiple paths and single edge. The algorithms crucially uses a simple characterization of NE strategies through min-cuts.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>371</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-371">Activating the &quot;Breakfast Club&quot;: Modeling Influence Spread in Natural-World Social Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Teamwork, team formation, teamwork analysis<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_371" class="editable_bid" data-pk="371" data-value="30"
                    data-url="/rev_3/paper/bid/set/371/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-371"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>&nbsp; While reigning models of diffusion have privileged the structure of a given social network as the key to informational exchange, real human interactions do not appear to take place on a single graph of connections. Using data collected from a pilot study of the spread of HIV awareness in social networks of homeless youth, we show that health information did not diffuse in the field according to the processes outlined by dominant models. Since physical network diffusion scenarios often diverge from their more well-studied counterparts on digital networks, we propose an alternative Activation Jump Model (AJM) that describes information diffusion on physical networks from a multi-agent team perspective. Our model exhibits two main differentiating features from leading cascade and threshold models of influence spread: 1) The structural composition of a seed set team impacts each individual node's influencing behavior, and 2) an influencing node may spread information to non-neighbors. We show that the AJM significantly outperforms existing models in its fit to the observed node-level influence data on the youth networks. We then prove theoretical results, showing that the AJM exhibits many well-behaved properties shared by dominant models. Our results suggest that the AJM presents a flexible and more accurate model of network diffusion that may better inform influence maximization in the field.</p></td>
                </tr>
            
                <tr>
                    <td>382</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-382">A Game-theoretic Approach for Channel Security Against Active Time-Varying attacks Based on Artificial Noise.</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Other</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_382" class="editable_bid" data-pk="382" data-value="30"
                    data-url="/rev_3/paper/bid/set/382/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-382"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><div>To penetrate sensitive communication systems, attackers can attack the channel using an Active Time-Varying(ATV) way, which will lead to a great information losses. The conventional way is to encrypt the original signal making it difficult for attackers to get information. However, this technology is restricted by the limited wireless terminal equipment. In this paper, we choose to insert artificial noises into the channel, which aims at disturbing the attackers and reducing the losses of system once attacks occur. But this technology would produce some side effects and there is a tradeoff between inserting artificial noise and minimizing information losses.</div><div><br></div><div>In this paper, we address this issue and propose a game-theoretic framework to minimize the total losses. We model the problem as a Stackelberg security game and propose a novel binary search based algorithm to efficiently compute the Strong Stackelberg Equilibrium which is the optimal defense strategy. This algorithm reduces a M-dimensional problem to M 1-dimensional problems so that the complexity is reduced. The simulation results show that our proposed algorithm significantly outperforms other non-strategic strategies in terms of decreasing the total losses against ATV attacks.</div></td>
                </tr>
            
                <tr>
                    <td>236</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-236">Modeling dysfunctional and functional emotions in BDI agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Agent Theories and Models] Models of emotions</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_236" class="editable_bid" data-pk="236" data-value="30"
                    data-url="/rev_3/paper/bid/set/236/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-236"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:
Calibri;mso-fareast-theme-font:minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA">Emotional modeling in intelligent agents has had
an increasing development in recent years, so different types of emotions and several
aspects related to these have been modeled, seeking to achieve a realistic
human-like behavior. An interesting not yet modeled aspect related to emotions
is their dysfunctional/functional character which is essential as it is related
to the individual adaptation capability. In the present paper, we propose an
EBDI framework to model the dysfunctional/functional character of emotions and
its related conduct. The framework is based on a therapeutic model named ABC
that allows determining the irrational/rational nature of the
cognitive-affective process and its consequences. We have expanded the BDI belief
concept to classify the nature (irrational/rational) of the cognitive process,
that lead to emotional and behavioral consequences allowing the modeling of
negative and positive (dysfunctional/functional) emotions and the conduct
(maladaptive/adaptive) related to them. Moreover, the proposal opens the possibility
to model interesting disturbing humans’ states, very hard of modeling on
intelligent agents, and to reproduce real human behavior. Its potential through
an example scenario.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>533</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-533">On the Role of Mobility, Adaptivity, and Interaction Topologies in Social Dilemmas</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Behavioral game theory<br>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Agent Societies and Societal Issues] Social networks<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_533" class="editable_bid" data-pk="533" data-value="30"
                    data-url="/rev_3/paper/bid/set/533/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-533"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Numerous studies have developed and analysed strategies for maximising utility in social dilemmas from both an individual agent's perspective and more generally from the viewpoint of a society. In this paper we bring this body of work together by investigating the success of a wide range of strategies in environments with varying characteristics, comparing their success. In particular we study within agent-based simulations, different interaction topologies, agents with and without mobility, and strategies with and without adaptation in the form of reinforcement learning, in both competitive and cooperative settings represented by the Prisoner's Dilemma and the Stag Hunt, respectively. The results of our experiments show that allowing agents mobility decreases the level of cooperation in the society of agents, due to singular interactions with individual opponents that limit the possibility for direct reciprocity. Unstructured environments similarly support a greater number of singular interactions and thus higher levels of defection in the Prisoner's Dilemma. In the Stag Hunt, strategies that prioritise risk taking show a greater level of success regardless of environment topology. As such, our range of experiments yield new insights into the role that mobility, adaptivity and interaction topologies all play in the study of co-operation&nbsp; in agent societies.<br></p></td>
                </tr>
            
                <tr>
                    <td>597</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-597">Poll-Confident Voters in Iterative Voting</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_597" class="editable_bid" data-pk="597" data-value="30"
                    data-url="/rev_3/paper/bid/set/597/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-597"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This article deals with strategic voting under incomplete information. The only indication available to a voter consists in the results of a public opinion poll and the vote intentions of her relatives, given by a social network, which is modeled as a graph over the agents. We assume a specific type of behaviour for the voters: they are confident in the poll and they update the results given by the poll with the information they get from their relatives. We consider an iterative voting model based on this behaviour type and study the associated “poll-confident” dynamics. Two configurations are investigated: an election with a single initial poll and one where several polls are performed and communicated all along the period. For both configurations, we analyse the convergence of the poll-confident dynamics regarding the structure of the social network. Moreover, we ask the natural question of manipulation from the polling institute.<br></p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>648</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-648">Deceiving Cyber Adversaries: A Game Theoretic Approach</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: computation</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_648" class="editable_bid" data-pk="648" data-value="30"
                    data-url="/rev_3/paper/bid/set/648/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-648"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>An important way cyber adversaries find vulnerabilities in modern networks is through reconnaissance, in which they attempt to identify configuration specifics of network hosts. To increase uncertainty of adversarial reconnaissance, the network administrator (henceforth, defender) can introduce deception into responses to network scans, such as obscuring certain system characteristics.</p><p>We introduce a novel game theoretic model of deceptive interactions of this kind between a defender and a cyber attacker, which we call the Cyber Deception Game. We consider both a powerful (rational) attacker, who is knows the defender's exact deception strategy, and a naive attacker who is not. We show that the problem is NP-hard for both types of attackers. For the case with a powerful attacker, we provide a mixed-integer linear program solution, sped up with a novel cut generation method, as well as a fast and effective greedy algorithm. Similarly, we provide complexity results and propose exact and heuristic approaches when the attacker is naive. Our extensive experimental analysis demonstrates the effectiveness of our approaches.</p></td>
                </tr>
            
                <tr>
                    <td>569</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-569">Temporal Multiple-Plan Recognition and Failure Prediction for Ambient Assisted Living</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_569" class="editable_bid" data-pk="569" data-value="30"
                    data-url="/rev_3/paper/bid/set/569/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-569"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The process of inferring agent's plans/goals from their observed actions is known as plan recognition, which analyses how low-level observations about agents and environment can be associated with a high-level plan description. This work addresses the problems of recognising multiple plans in realistic environments, learning activity duration, and detecting anomalies in plan execution. We deal with problems related to disambiguation of multiple hypotheses and detecting anomalies in plan execution by exploiting both the inherent hierarchical organisation of activities and their expected time and duration, developing an efficient algorithm to filter hypotheses by applying temporal and path length constraints. We present a number of experimental results showing that, besides addressing limitations of traditional plan recognition algorithms, our filtering approach can significantly improve the precision of the underlying plan recognition algorithm. The experiments include synthetically generated plan libraries as well as plan libraries and observations obtained from real-world datasets relevant to the context of ambient assisted living.<br></p></td>
                </tr>
            
                <tr>
                    <td>546</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-546">Symbolic Dynamic Programming for Risk-sensitive Markov Decision Process with limited budget</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems<br>[Agent Theories and Models] Other</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_546" class="editable_bid" data-pk="546" data-value="30"
                    data-url="/rev_3/paper/bid/set/546/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-546"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Risk-Sensitive Markov Decision Processes (RS-MDPs) set the optimization criterion as maximizing the probability of the cumulative cost not to be greater than an user-defined budget $\theta_u$,&nbsp; guaranteeing that worst executions of an MDP occur with the least possible probability. Solutions for these problems have a scalability issue when handling large cost intervals, since they require the enumeration of the costs and reasoning over the space of augmented states, i.e. a set of pairs $(state,budget)$. In this work, we propose the first&nbsp; symbolic dynamic programming algorithm for risk-sensitive MDPs that explores conditional independence of the transition structure over the augmented state space. We first define a factored RS-MDP and propose a new, sound and complete, Symbolic Value Iteration algorithm, called RS-SPUDD. The proposal algorithm also prunes invalid states and performs early termination.</p></td>
                </tr>
            
                <tr>
                    <td>406</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-406">Full Epistemic-entrenchment Characterization of Parikh’s Axiom</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.620</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_406" class="editable_bid" data-pk="406" data-value="30"
                    data-url="/rev_3/paper/bid/set/406/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-406"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="font-family: verdana, arial, helvetica; font-size: small;">In this article, we provide the full epistemic-entrenchment characterization of Parikh's relevance-sensitive axiom for belief revision — known as axiom (P). In short, axiom (P) states that, if a belief set K can be divided into two disjoint compartments (referring to different subject matters), and the new information φ relates only to the first compartment, then the revision of K by φ should not affect the second compartment. Accordingly, we define the subclass of epistemic entrenchments, that induce AGM revision functions, satisfying the strong version of axiom (P). Since the notions of relevance and local change are inherent in almost all intellectual activity, the results reported herein are significant for many domains of Artificial Intelligence.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>606</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-606">Argumentation-based reasoning in BDI agents using the Toulmin model</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Argumentation-based dialogue and protocols<br>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_606" class="editable_bid" data-pk="606" data-value="30"
                    data-url="/rev_3/paper/bid/set/606/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-606"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The theory of argumentation encompasses several fields of knowledge, gaining significant space in the community of multi-agent systems, since it can enable the agent to reason about its decisions, through perceptions about the environment or through dialogue with other agents. Toulmin has developed an argumentation model in the field of philosophy, which indicates six components to assemble the structure of an argument: data, warranty, claim, backing, qualifier and refutation. This work proposes an architecture for BDI agents for argumentation-based reasoning based on the Toulmin model. We have developed some examples in the AgentSpeak (L) language in order to validate the proposed architecture.<br></p></td>
                </tr>
            
                <tr>
                    <td>241</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-241">Outlook on Multi-agent Technology for Industrial Applications</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Engineering Multiagent Systems] Programming languages and frameworks for agents and multi-agent systems<br>[Engineering Multiagent Systems] Modelling and specification languages</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_241" class="editable_bid" data-pk="241" data-value="30"
                    data-url="/rev_3/paper/bid/set/241/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-241"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span lang="EN-US" style="font-size: 11pt; line-height: 115%; font-family: 'Times New Roman', serif;">For over a quarter of a century multi-agent systems
have been considered as one of the most promising technologies for
conceptualization and software implementation of complex distributed systems.
However, in practice, the situation is very different: the industry rarely uses
this technology, despite the appearing new classes of applications for which it
is the perfect match. The paper analyzes recent anticipations and real
achievements in the practical application of multi-agent systems at the
industrial level. It also identifies problems that, currently impede extensive
industrial implementation of multi-agent systems and technologies, as well as
ways to overcome them. Additionally the paper analyzes classes of applications,
for which multi-agent technologies have undeniable advantages. Finally,
prospects for development of these technologies are evaluated up to the level
of industrial application.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>126</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-126">Efficient Auctions with Identity-Dependent Mixed Externalities</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Agent Theories and Models] Logic and Game Theory</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_126" class="editable_bid" data-pk="126" data-value="30"
                    data-url="/rev_3/paper/bid/set/126/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-126"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-family: verdana, arial, helvetica; font-size: small;">We investigate a class of single-item multi-supply auctions with bidders who have identity-based mixed externalities. In such an auction, each bidder has a set of competitors and a set of friends (either set can be empty). Her private valuation from winning an item decreases with the number of her winning competitors while increases with the number of her winning friends.
</span><br style="font-family: verdana, arial, helvetica;"><span style="font-family: verdana, arial, helvetica; font-size: small;">Externalities are prevalent in many applications when the auctioned goods play a role in future interactions among the auction’s participants, such as patent licensing and sponsored search auctions. The development of auctions with externalities, however, is stymied by the computational difficulty of the underlying welfare maximization allocation problem; even without the consideration of truthfulness, the problem of social welfare maximization with only negative externalities is NP-hard and even hard to approximate within a constant factor (unless P=NP).
</span><br style="font-family: verdana, arial, helvetica;"><span style="font-family: verdana, arial, helvetica; font-size: small;">In this work, we design polynomial time and truthful mechanisms under different restrictions on the underlying competitor/friend graph structure. Our results can be summarized as follows.
</span><br style="font-family: verdana, arial, helvetica;"><span style="font-family: verdana, arial, helvetica; font-size: small;">1. When each bidder has only one competitor or one friend, we propose a truthful and welfare maximizing mechanism.
</span><br style="font-family: verdana, arial, helvetica;"><span style="font-family: verdana, arial, helvetica; font-size: small;">2. We design a truthful and 1+ε-approximationmechanism when the underlying graph is planar.
</span><br style="font-family: verdana, arial, helvetica;"><span style="font-family: verdana, arial, helvetica; font-size: small;">3. We give two truthful mechanisms when bidders have arbitrary mixed relations, with welfare approximation ratio n/ log n and ⌈(d + 1)/3⌉, respectively, where d is the maximum degree of the “undirected” graph.
</span><br style="font-family: verdana, arial, helvetica;"><span style="font-family: verdana, arial, helvetica; font-size: small;">Finally, we conduct experiments in a company-relation scenario and analyze the trade-off between social welfare and revenue obtained by our mechanism, item supply, and the degree of externality.</span><br></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>254</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-254">Facing Multiple Attacks in Adversarial Patrolling Games with Alarmed Targets</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: computation</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_254" class="editable_bid" data-pk="254" data-value="30"
                    data-url="/rev_3/paper/bid/set/254/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-254"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal">We study, to the best of our knowledge, the first security
game in which an Attacker can observe the movements of a patroller controlled
by a Defender on an arbitrary graph and, exploiting multiple resources, can
perform sequential attacks in a single (non-repeated) game against perfectly
alarmed targets. Our game model is in extensive form—allowing each player to
play multiple times—with perfect information and zero-sum utilities, and the
game tree is exponentially large both in the size of graph and in the number of
resources available to the Attacker. Nevertheless, we show that, fixed the
number of resources of the Attacker, the equilibrium path can be computed in
polynomial time in the size of the graph, while it is NP-hard otherwise.
Furthermore, we study the robustness of the Defender’s strategy when she makes
a wrong guess about the number of Attacker’s resources (that usually is
unknown), showing that even the error of just a single resource can lead to an
arbitrary loss. Finally, we investigate the performance of online algorithms when
no information about the Attacker’s resources is available.<o:p></o:p></p></td>
                </tr>
            
                <tr>
                    <td>191</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-191">Finite Sample Analysis of LSTD($\lambda$) with Random Projections</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Methodologies for agent-based systems<br>[Learning and Adaptation] Reward structures for learning</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_191" class="editable_bid" data-pk="191" data-value="30"
                    data-url="/rev_3/paper/bid/set/191/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-191"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Policy evaluation (i.e., estimate the value function of a fixed policy which is the expected long-term accumulated reward an agent would receive) with linear function approximation is an important problem in reinforcement learning. When facing high-dimensional feature spaces, such a problem becomes extremely hard considering the computation efficiency and quality of approximations. We propose a new algorithm, LSTD($\lambda$)-RP, which leverages random projection techniques and takes eligibility traces into consideration to tackle the above two challenges. We carry out theoretical analysis of LSTD($\lambda$)-RP from two aspects: (1) deriving sufficient conditions to guarantee the uniqueness of sample-based LSTD($\lambda$)-RP solution with high probability; (2) providing meaningful upper bounds of the estimation error, approximation error and total generalization error.</p></td>
                </tr>
            
                <tr>
                    <td>363</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-363">Arbitrage-free Pricing in User-based Markets</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Other</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_363" class="editable_bid" data-pk="363" data-value="30"
                    data-url="/rev_3/paper/bid/set/363/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-363"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'CMR9'">Users have various attributes, and in user-based markets there are buyers who wish to
buy a target set of users with specific sets of attributes. The problem we address is that, given a set
of demand from the buyers, how to allocate users to buyers, and how to price the transactions. This
problem arises in online advertising, and is particularly relevant in advertising in social platforms like
Facebook, LinkedIn and others where users are represented with many attributes, and advertisers are
buyers with specific targets. This problem also arises more generally in selling data about online users,
in a variety of data markets.
</span></p>
					<p><span style="font-size: 9.000000pt; font-family: 'CMR9'">We introduce </span><span style="font-size: 9.000000pt; font-family: 'CMTI9'">arbitrage-free </span><span style="font-size: 9.000000pt; font-family: 'CMR9'">pricing, that is, pricing that prevents buyers from acquiring a lower unit
price for their true target by strategically choosing substitute targets and combining them suitably.
We show that </span><span style="font-size: 9.000000pt; font-family: 'CMTI9'">uniform </span><span style="font-size: 9.000000pt; font-family: 'CMR9'">pricing – pricing where all the targets have identical price – can be computed in
polynomial time, and while this is arbitrage-free, it is also a logarithmic approximation to the maximum
revenue arbitrage-free pricing solution. We also design a different arbitrage-free non-uniform pricing
– pricing where different targets have different prices – solution which has the same guarantee as the
arbitrage-free uniform pricing but is empirically more effective as we show through experiments. We
also study more general versions of this problem and present hardness and approximation results.&nbsp;</span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>583</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-583">One-Shot Learning using Mixture of Variational Autoencoders: a Generalization Learning approach</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Collective intelligence<br>[Agent Cooperation] Biologically-inspired approaches and methods<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_583" class="editable_bid" data-pk="583" data-value="30"
                    data-url="/rev_3/paper/bid/set/583/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-583"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Deep learning, even if it is very successful nowadays, traditionally needs very large amounts of labeled data to perform excellent on the classification task. In an attempt to solve this problem, the one-shot learning paradigm, which makes use of just one labeled sample per class and prior knowledge, becomes increasingly important. In this paper, we propose a new one-shot learning method, dubbed MoVAE (Mixture of Variational AutoEncoders), to perform classification. Complementary to prior studies, MoVAE represents a shift of paradigm in comparison with the usual one-shot learning methods, as it does not use any prior knowledge. Instead, it starts from zero knowledge and one labeled sample per class. Afterward, by using unlabeled data and the generalization learning concept (in a way, more as humans do), it is capable to gradually improve by itself its performance. Even more, if there are no&nbsp; unlabeled data available MoVAE can still perform well in one-shot learning classification. We demonstrate empirically the efficiency of our proposed approach on three datasets, i.e. the handwritten digits (MNIST), fashion products (Fashion-MNIST), and handwritten characters (Omniglot), showing that MoVAE outperforms state-of-the-art one-shot learning algorithms.<br></p></td>
                </tr>
            
                <tr>
                    <td>552</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-552">A Conceptual Framework for the Design of Human-Agent Collectives Architectures Based on Consent Patterns</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems<br>[Humans and Agents] Multi-user/multi-virtual-agent interaction<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_552" class="editable_bid" data-pk="552" data-value="30"
                    data-url="/rev_3/paper/bid/set/552/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-552"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Human-Agent Collectives (HAC) are systems in which humans and agents coalitions work together to take advantage of their collective intelligence in order to optimize the performance of tasks within scenarios that involve potentially high degrees of dynamism and uncertainty. This paper presents a contribution to design methodology to be used to implement systems that involve humans and agents. In particular, building upon patterns of consent for HACs, we &nbsp;formalize the main patterns of interaction and consent that exist in such HACs. We demonstrate the use of such patterns the case of an emergency response scenario where humans and agents are called upon to gather data and act on events in the real world.<br></p></td>
                </tr>
            
                <tr>
                    <td>252</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-252">Socially Motivated Partial Cooperation in Multi-agent Local Search</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Other<br>[Agent Cooperation] Distributed problem solving</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_252" class="editable_bid" data-pk="252" data-value="30"
                    data-url="/rev_3/paper/bid/set/252/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-252"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Partial Cooperation is a paradigm and a corresponding model that was proposed to represent Multi-agent systems in which agents, like regular people in many realistic situations, are willing to cooperate to achieve a global goal, as long as some minimal threshold on their personal utility is satisfied. For example, a professor willing to take upon herself an additional teaching assignment for the benefit of the department and her students, as long as she has enough time left for her research. Distributed local search algorithms were proposed in order to solve asymmetric distributed constraint optimization problems (ADCOPs) in which agents are partially cooperative.</p><p><br></p><p>We contribute to the research on partial cooperative multi-agent local search by: 1) extending the partial cooperative model to allow it to represent dynamic cooperation intentions, affected by changes in agents wealth. Such changes in agents' intentions correspond to studies on human cooperation intentions in social studies literature. 2) proposing a novel local search algorithm in which agents receive indications of others' preferences on their actions (assignment selection) and thus, can perform actions that are socially beneficial. Our empirical study reveals the advantage of the proposed algorithm in multiple benchmarks. Specifically, on realistic meeting scheduling problems it overcomes limitations of standard local search algorithms.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>127</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-127">An Efficient Auction with Variable Reserve Prices for Ridesourcing</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications<br>[Agent Theories and Models] Logic and Game Theory</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_127" class="editable_bid" data-pk="127" data-value="30"
                    data-url="/rev_3/paper/bid/set/127/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-127"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="font-family: verdana, arial, helvetica; font-size: small;">Ridesourcing refers to the service that matches passengers who need a car to personal drivers. In this work, we study an auction model for ridesourcing that sells multiple items to unit-demand single-parameter agents with variable reserve price constraints. In this model, there is an externally imposed reserve price set for every item, and the price is both item- and bidder-dependent. Such auctions can also find applications in a number of other traditional and online markets, such as ad auction or online laboring market. Our main result is a truthful, individually rational, and computationally efficient mechanism that respects the reserve price constraints and always achieves at least half of the optimal social benefit (i.e., the sum of the valuations of the winning agents). Furthermore, we show such efficiency approximation is tight by proving that even without any computational constraints, no truthful and individually rational mechanism can achieve better than 2-approximation for social benefit maximization. Finally, we evaluate the performance of our mechanism based on real taxi-trace data. The empirical results show that our mechanism outperforms other benchmark mechanisms in terms of both social benefit and revenue.&nbsp;</span><br></p></td>
                </tr>
            
                <tr>
                    <td>456</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-456">Efficient Coalition Structure Generation via Approximately Equivalent Induced Subgraph Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Economic Paradigms] Game Theory for practical applications<br>[Agent Cooperation] Coalition formation (non-strategic)</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_456" class="editable_bid" data-pk="456" data-value="30"
                    data-url="/rev_3/paper/bid/set/456/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-456"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We show that any characteristic function game (CFG) G can be always turned into an approximately equivalent game represented using the induced subgraph game (ISG) representation. Such a transformation incurs obvious benefits in terms of tractability of computing solution concepts for G. Our transformation approach, namely AE-ISG, is based on the solution of a norm approximation problem. We then propose a novel coalition structure generation (CSG) approach for ISGs that is based on graph clustering, which outperforms existing CSG approaches for ISGs by using state of the art optimisation solvers. Finally, we provide theoretical guarantees on the value of the optimal CSG solution of G wrt the optimal CSG solution of the approximately equivalent ISG. As a consequence, our approach allows one to compute approximate CSG solutions with quality guarantees for any CFG. Results on a realistic application domain (i.e., ridesharing) show that our approach outperforms the state of the art algorithm both in terms of quality of the solutions and theoretical quality guarantees.<br></p></td>
                </tr>
            
                <tr>
                    <td>439</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-439">Imbalance Management of an Autonomous Power Trading Agent to Exploit Balancing Market Incentives in a Smart Grid Ecosystem</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_439" class="editable_bid" data-pk="439" data-value="30"
                    data-url="/rev_3/paper/bid/set/439/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-439"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:minor-latin;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">Electricity
retailers have to take severe financial risks since they are responsible for
the power imbalance management. In case of an imbalance they are penalized by
system operators in the extent of their
harm to the grid. Therefore, imbalance management is one of the core objectives
of retailers. It helps to substantially reduce the overall costs and increases
the competitive power. This paper presents novel agent-based solutions for two
important aspects of imbalance management, namely for the forecast of
heterogeneous customer demand and for a smart strategical bidding in the
wholesale market that exploits the incentives in the balancing market. The
underlying algorithms were first deployed and tested in our broker agent</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;
font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">&nbsp;that competed in the 2017 edition of the Power Trading Agent Competition (Power
TAC). This paper will first present the economic
motivation behind the algorithms. Then the algorithms are formalized and
explained in detail. Finally, we analyze the tournament data using several key
performance indicators. The post tournament analysis revealed that our broker</span><span class="FirstName"><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:
Calibri;mso-fareast-theme-font:minor-latin;border:none;mso-ansi-language:EN-US;
mso-fareast-language:EN-US;mso-bidi-language:AR-SA"><span style="border:none"><span style="border:none"><span style="border:none"><span style="border:none">&nbsp;</span></span></span></span></span></span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;
font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">successfully
generated revenues from its imbalance, having the highest
imbalance/distribution rate with the lowest penalty payments and procurement
costs among all broker agents.</span><br></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>281</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-281">Asynchronous Co-Learning in Urban Traffic Systems: a microscopic approach</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_281" class="editable_bid" data-pk="281" data-value="30"
                    data-url="/rev_3/paper/bid/set/281/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-281"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>A better use of the urban traffic infrastructure is key in the effort of mitigating the effects of traffic congestion. Popular approaches range from classical control and optimization to multiagent reinforcement learning (MARL). This paper follows the latter track. Challenges here are manifold. First, most of the literature assumes that either traffic lights learn (while drivers do not change their behaviors) or vice-versa. Second, no matter what kind of class of learning agents is considered, their actions are&nbsp; highly coupled (thus making the learning task harder). Third, when both classes of agents co-learn, these learning tasks are of different nature (from the point of view of MARL). Finally, a microscopic modeling and simulation of the this problem is not trivial as the pace of each agent is different. Therefore, this paper not only proposes a co-learning approach in which agents act in a shared environment, but also argues that this task needs to be formulated asynchronously. Besides, driver agents are able to update the value of the available actions by receiving information from other drivers. Results show that the co-learning approach outperforms other policies in terms of average travel time of all vehicles. Moreover, when co-learning is used, more vehicles can start and finish their trips as a consequence of a better distribution of the trips within the network.<br></p></td>
                </tr>
            
                <tr>
                    <td>242</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-242">Trifle: Information-oriented Normative Reasoning with Structured Argumentation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Organisations and institutions<br>[Agent Societies and Societal Issues] Normative systems<br>[Agent Theories and Models] Logics for norms and normative systems</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_242" class="editable_bid" data-pk="242" data-value="30"
                    data-url="/rev_3/paper/bid/set/242/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-242"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Norms are used to regulate agents in a multi-agent system (MAS)</p><p>without compromising their autonomy, by specifying correct</p><p>behaviour, and rewards and punishments for non-compliance.</p><p>Often, such social facts are informational entities (i.e., belonging</p><p>to relational tables), comprising attributes and foreign-key relations,</p><p>and informational operations may be required to make inferences</p><p>(e.g., joining tables representing GP registration and immunisation</p><p>to infer whether a norm requiring both is violated). Orthogonally,</p><p>non-monotonicity and uncertainty is important, since some inferences</p><p>are provisionally true and subject to being proven false as new</p><p>or further information is considered. Trifle captures these concerns</p><p>with normative reasoning for information-oriented norms and</p><p>constitutive rules, founded on non-monotonic structured argumentation</p><p>to capture uncertainty. Trifle meets four rationality postulates,</p><p>including consistency in the face of contradictory information.</p><p>In short, Trifle bridges the gap between information-oriented and</p><p>structured argumentation approaches for normative reasoning.</p></td>
                </tr>
            
                <tr>
                    <td>375</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-375">Active Crowd Labeling: Improving Task Assignment with Online Variational Inference</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Collective intelligence<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_375" class="editable_bid" data-pk="375" data-value="30"
                    data-url="/rev_3/paper/bid/set/375/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-375"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Crowd labeling improves label accuracy by assigning a same task to multiple workers. Since workers usually vary in quality, improper task assignment may significantly increase the number of labels needed for high accuracy. In this paper, we formulate a framework to improve task assignment with online variational inference. One distinct advantage is that it can flexibly incorporate different worker models. Another is its novel prediction-based task assignment strategy to select the assignment with the maximum accuracy increment. To improve accuracy growth rate, we keep the prediction optimistic but modulate the scope of task assignment according to the uncertainty measurement of online inference. To improve efficiency, we develop an approximation algorithm for variational inference. The extensive experiments on four popular worker models and four MTurk datasets show that our framework not only achieves the highest label accuracy but also the best computation efficiency.<br></p></td>
                </tr>
            
                <tr>
                    <td>328</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-328">Overlapping Coalition Formation via Probabilistic Topic Modeling</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Coalition formation (non-strategic)<br>[Learning and Adaptation] Multiagent learning<br>[Economic Paradigms] Cooperative games: computation</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_328" class="editable_bid" data-pk="328" data-value="30"
                    data-url="/rev_3/paper/bid/set/328/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-328"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Research in cooperative games often assumes that agents know the coalitional values with certainty, and that they can belong to one coalition only. By contrast, this work assumes that the value of a coalition is based on an underlying collaboration structure emerging due to existing but unknown relations among the agents; and that agents can form overlapping coalitions. Specifically, we first propose Relational Rules, a novel representation scheme for cooperative games with overlapping coalitions, which encodes the aforementioned relations, and which extends the well-known MC-nets representation to this setting. We then present a novel decision-making method for decentralized overlapping coalition formation, which exploits probabilistic topic modeling—and, in particular, online Latent Dirichlet Allocation. By interpreting formed coalitions as documents, agents can effectively learn topics that correspond to profitable collaboration structures.</p></td>
                </tr>
            
                <tr>
                    <td>703</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-703">Zero Shot Transfer Learning for Robot Soccer</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Teamwork, team formation, teamwork analysis<br>[Learning and Adaptation] Multiagent learning<br>[Agent Cooperation] Multi-robot systems<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_703" class="editable_bid" data-pk="703" data-value="30"
                    data-url="/rev_3/paper/bid/set/703/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-703"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we present techniques for doing zero-shot transfer of<br>RoboCup robot soccer policies as the number of teammates, opponents,<br>and field size change. In real robot soccer matches, the number of<br>robots on the field can vary throughout a match due to breakages and<br>rule violations. Additionally, the field sizes played may vary<br>yearly. We show how to use deep reinforcement learning (DeepRL) for<br>the robot soccer domain, by using generated images as the state<br>space. The DeepRL is able to learn for different numbers of robots<br>on the field without affecting the input layers to the network. We<br>also show a method of using fully convolutional networks such that<br>the action space of the network can adapt to different field<br>sizes. Thus, allowing a single policy to be trained on one field<br>size and then run on a different field size, without retraining.<br>Finally, we present a method for different agents on the field to<br>share their decision making features, so that as teammates are added<br>and removed, no additional training is required. We demonstrate all<br>of these techniques on domains based on the sub-game of Keep-away,<br>where the goal is for the team to retain control of the ball for as<br>long as possible. Using these techniques we are able to learn a<br>Keep-away policy where the number of teammates, opponents, and field<br>size can vary with zero retraining and limited loss in performance.<br></p></td>
                </tr>
            
                <tr>
                    <td>615</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-615">Q-Learning Acceleration via State-space Partitioning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Adversarial machine learning</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_615" class="editable_bid" data-pk="615" data-value="30"
                    data-url="/rev_3/paper/bid/set/615/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-615"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><font size="4" style="color: rgb(34, 34, 34); font-family: arial, sans-serif;">Recent work in Reinforcement Learning (RL) has focused on learning acceleration in order to overcome the method's slow convergence rate in large state spaces or with sparse rewards. In situations where multiple independent, cooperative agents are solving the same task, it has been shown that single-agent RL can be accelerated in a cooperative multi-agent scenario via information sharing. Efficient RL acceleration via information sharing among agents depends on how well the agents' information complements each other's. For example, a single agent's RL in a grid world is ideally accelerated when incorporating exploration information from other disjoint areas within the same environment.&nbsp;</font><span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: large;">In this work, we propose a single-agent RL acceleration approach by state space partitioning. We also define a "partition reward" as an external reward to demarcate partitions for agents to learn and decrease their overlap. The approach has two advantages: 1) agents' actions are not diminished and remain relatively independent from one another; 2) it can be used to accelerate learning in both structured state domains (where partitions can be pre-determined) and arbitrarily-structured state domains (where partitions may be developed dynamically by agent teams as they explore the environment). Finally, we validate the proposal's efficacy by comparing it to previous related work in a simplified soccer domain.&nbsp;</span><br></p></td>
                </tr>
            
                <tr>
                    <td>64</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-64">Towards an Enthymeme-Based Communication Framework</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Speech act theory<br>[Communication and Argumentation] Deductive, rule-based and logic-based argumentation<br>[Communication and Argumentation] Argumentation-based dialogue and protocols</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_64" class="editable_bid" data-pk="64" data-value="30"
                    data-url="/rev_3/paper/bid/set/64/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-64"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Communication is one of the most important aspects of multi-agent systems. Among the different communication techniques applied to multi-agent systems, argumentation-based approaches have received special interest from the community, because allowing agents to exchange arguments provides a rich form of communication. In contrast to the benefits that argumentation-based techniques provide to multi-agent communication, extra weight on the communication infrastructure results from the additional information exchanged by agents, which could restrict the practical use of such techniques. In this work, we propose an argumentation framework whereby agents are able to exchange fewer and shorter messages when engaging in dialogues by omitting information that is common knowledge (e.g., information about a shared multi-agent organisation). In particular, we focus on using<i> enthymemes</i>, shared argumentation schemes (i.e., reasoning patterns from which arguments are instantiated) and common organisational knowledge to build an enthymeme-based communication framework. We show that the approach makes argumentation-based communication more efficient in the sense that agents can exchange fewer messages with shorter content, yet without any loss in the intended arguments.</p></td>
                </tr>
            
                <tr>
                    <td>633</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-633">The Eigenoption-Critic Framework</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_633" class="editable_bid" data-pk="633" data-value="30"
                    data-url="/rev_3/paper/bid/set/633/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-633"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Eigenoptions (EOs) have been recently introduced as a promising idea for generating a diverse set of options through the graph Laplacian, having been shown to allow efficient exploration. Despite its first initial promising results, a couple of issues in current algorithms limit its application, namely: 1) EO methods require two separate steps (eigenoption discovery and reward maximization) to learn a control policy, which can incur a significant amount of storage and computation; 2) EOs are only defined for problems with discrete state-spaces and; 3) it is not easy to take the environment’s reward function into consideration when discovering EOs. In this paper we introduce an algorithm termed eigenoption-critic (EOC) that addresses these issues. It is based on the Option-critic (OC) architecture, a general hierarchical reinforcement learning algorithm that allows learning the intra-option policies simultaneously with the policy over options. We also propose a generalization of EOC to problems with continuous state-spaces through the Nystr\"{o}m approximation. EOC can also be seen as extending OC to nonstationary settings, where the discovered options are not tailored for a single task.<br></p></td>
                </tr>
            
                <tr>
                    <td>758</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-758">Abstractly Interpreting Argumentation Frameworks for Sharpening Extensions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Other<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Verification and Validation of Agent-based Systems] Verification techniques for multiagent systems, including model checking</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_758" class="editable_bid" data-pk="758" data-value="30"
                    data-url="/rev_3/paper/bid/set/758/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-758"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style="margin-bottom: 0px; font-stretch: normal; font-size: 9px; line-height: normal; font-family: Helvetica;">Cycles of attacking arguments pose non-trivial issues in Dung style argumentation theory, apparent behavioural difference between odd and even length cycles being a notable one. While a few methods were proposed for treating them, to - in particular - enable selection of acceptable arguments in an odd-length cycle when Dung semantics could select none, so far the issues have been observed from a purely argument-graph-theoretic perspective. Per contra, we consider argument graphs together with a certain lattice like semantic structure over arguments e.g. ontology. As we show, the semantic-argumentgraphic hybrid theory allows us to apply abstract interpretation, a widely known methodology in static program analysis, to formal argumentation. With this, even where no arguments in a cycle could be selected sensibly, we could say more about arguments acceptability of an argument framework that contains it. In a certain sense, we can ‘verify’ Dung extensions with respect to a semantic structure in this hybrid theory, to consolidate our confidence in their suitedness. By defining the theory, and by making comparisons to existing approaches, we ultimately discover that whether Dung semantics, or an alternative semantics such as cf2, is adequate or problematic depends not just on an argument graph but also on the semantic relation among the arguments in the graph.</p></td>
                </tr>
            
                <tr>
                    <td>462</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-462">A Game-Theoretic Algorithm for Link Prediction</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Cooperative games: computation<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_462" class="editable_bid" data-pk="462" data-value="30"
                    data-url="/rev_3/paper/bid/set/462/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-462"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Predicting edges in networks is a key problem in social network analysis and involves reasoning about the relationships between nodes based on the structural properties of a network. In particular, link prediction can be used to analyse how a network will develop or - given incomplete information about relationships - to discover "missing" links. Our approach to this problem is rooted in cooperative game theory, where we propose a new, quasi-local approach (i.e., one which considers nodes within some radius k) that combines generalised group closeness centrality and semivalue interaction indices. We develop fast algorithms for computing our measure and evaluate it on a number of real-world networks, where it outperforms a selection of other state-of-the-art methods from the literature. Importantly, choosing the optimal radius k for quasi-local methods is difficult, and there is no assurance that the choice is optimal. Additionally, when compared to other quasi-local methods, ours achieves very good results even when given a suboptimal radius k as a parameter.<br></p></td>
                </tr>
            
                <tr>
                    <td>660</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-660">Provenance Driven Trust Assessment</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Trust and reputation<br>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Agents and Mainstream Computing] Service-oriented architectures</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_660" class="editable_bid" data-pk="660" data-value="30"
                    data-url="/rev_3/paper/bid/set/660/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-660"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Trust and reputation are typically assessed based on past interactions between individual agents. However, an individual encounter may be part of a complex overarching process involving many individual interactions. In supply chain management, for example, numerous agents may be involved in sourcing raw materials, delivering them to manufacturing centres, and dispatching the final product to consumers. Similarly, providers in service oriented computing offer various services that can be orchestrated into complex compositions. In such scenarios, the composition structure affects interactions and their utilities, as well as the individual agents and services involved. Existing reputation assessment methods typically focus on assessing individual agents and their capabilities, rather than compositions. Such complex interactions can be described using workflows, which define a series of tasks to be performed by agents. It is beneficial to estimate how a workflow will perform prior to execution, because it may be costly to execute or because a poorly designed workflow may have severe negative consequences. In this paper, we document past workflow executions as provenance records, which are directed acyclic graphs that describe the relationships between entities, activities, and agents in interactions. A workflow with several possible executions, therefore, is defined as a set of provenance records. We propose to record the executions of workflows and apply frequent subgraph mining and machine learning to learn a mapping from the provenance records to performance, which in turn is used to assess the trust in a workflow.</p></td>
                </tr>
            
                <tr>
                    <td>52</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-52">Unbiased Weighted Policy Learner</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logic and Game Theory<br>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Learning and Adaptation] Multiagent learning</td>
                    
                        <td>0.610</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_52" class="editable_bid" data-pk="52" data-value="30"
                    data-url="/rev_3/paper/bid/set/52/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-52"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Several multi-agent reward-based learning (MARL) algorithms have been proposed to optimize agents’ decisions. Despite many having unrealistic assumptions, the Weighted Policy Learner (WPL) algorithm has been shown to converge to Nash Equilibria (NE) in several challenging environments with minimum knowledge.</p><p>However, WPL is biased against pure NE, also known as deterministic strategies, and only converges in the limit, since the policy update rate approaches zero. Despite the authors claiming that this theoretical limitation is of no concern in practical scenarios, a noticeable delay in learning is observed in tasks where actions are dominated by other actions. We show how a trivial range clipping of the update function can remove this delay and still maintain the algorithm’s convergence properties.</p><p>We demonstrate this behavior with two separate variants of the algorithm, in several common game-theoretic environments (with stochastic equilibrium policies) and in some maze related games (where some actions dominate others in most states). We draw conclusions over the adequacy of our proposals and their advantages over the original algorithm.</p></td>
                </tr>
            
                <tr>
                    <td>220</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-220">An Oligopoly Two-Stage-Game Model for Investigating the Search Engine Market</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_220" class="editable_bid" data-pk="220" data-value="30"
                    data-url="/rev_3/paper/bid/set/220/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-220"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="15"><span style="font-family: 宋体; font-size: 12pt;">This paper shows that characteristics of competitive oligopoly exist in the search engine market by analyzing the market. An oligopoly two-stage-game(TSG) model </span><span style="font-family: 宋体; font-size: 12pt;">based on the Stackelberg and Cournot models</span><span style="font-family: 宋体; font-size: 12pt;">&nbsp;is proposed to maximize search engines</span><span style="font-family: Calibri; font-size: 12pt;">’</span><span style="font-family: 宋体; font-size: 12pt;">&nbsp;profit.Combining game theory and economic analysis, the strategies of optimal pricing and advertising quantity for search engines have been investigated at different costs.The model considers followers entering and price demand elasticity factors to infer the equilibrium of price and advertising quantity. We analyze the impact of price demand elasticity on the price and advertising quantity in the oligopoly two-stage-game model.Furthermore, the relationship between the demanded advertising quantity and the remaining adverting quantity in the second stage market is showed. Finally, the simulation results show that Nash equilibrium exists in the second stage market .</span><span style="font-family: 宋体; font-size: 12pt;"><o:p></o:p></span></p></td>
                </tr>
            
                <tr>
                    <td>176</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-176">Stackelberg Security Games with Multiple Uncoordinated Defenders</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_176" class="editable_bid" data-pk="176" data-value="30"
                    data-url="/rev_3/paper/bid/set/176/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-176"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Stackelberg security games have received much attention in recent years. While most existing work focuses on single-defender games, there are many real-world scenarios that involve multiple defenders (e.g., multi-national anti-crime actions in international waters and patrols of different security agencies in the same areas). It is therefore important to investigate security games with multiple defenders. In this paper, we focus on uncoordinated defenders who jointly protect a set of targets, but may have different valuations for these targets; each defender schedules her own resources and selfishly optimizes her own utility. We generalize the standard (single-defender) model of Stackelberg security games to this setting and formulate an equilibrium concept that captures the nature of strategic interaction among the players. We argue that an exact equilibrium may fail to exist, and, in fact, deciding whether it exists is NP-hard. However, under mild assumptions, every multi-defender security game admits an $\epsilon$-equilibrium for every $\epsilon&gt;0$, and the respective limit points can be efficiently approximated.<br></p></td>
                </tr>
            
                <tr>
                    <td>705</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-705">An Architecture for Supporting the Development of Ambient Intelligence Systems Managed by Cognitive Augmented Agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Engineering Multiagent Systems] Programming languages and frameworks for agents and multi-agent systems<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_705" class="editable_bid" data-pk="705" data-value="30"
                    data-url="/rev_3/paper/bid/set/705/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-705"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The development of ubiquitous systems for Ambient Intelligence (AmI) is a complex task since data communication, node synchronization, handover support, and inference mechanism for decision making based on context information and collaboration among system's devices is hard to deploy. The use of middleware plays an important role in collecting and managing context information for the development of ubiquitous systems covering devices in an Internet of Things (IoT) network. In this scenario, the management of such devices can be performed by employing intelligent and augmented agents capable of cognitive reasoning. In some cases, these agents can have limited resources or processing power and should be desirable to delegate some inference rules for a third part (e.g. middleware). Besides, it is also interesting that agents of a Multi-Agent System (MAS) embedded and responsible for a single device can communicate and interact sharing information with agents situated in a different MAS of another device using the IoT network. So, the objective of this paper is to propose an architecture for developing ubiquitous systems for AmI that uses embedded agents for interfacing with sensors and actuators and are able of communication and interacting with devices in IoT using a scalable middleware. For this purpose, ContextNet was used as middleware for the proposed architecture, the Jason framework was extended to allow communication between agents from different MAS, and an augmented agent extension for transferring inferring rules for the ContextNet middleware core solution was also proposed. As proof-of-concept solution, a real laboratory was assembled with several devices (using MAS or not) in an IoT for controlling some basic functions of the room. The proposed architecture shows to be a real option for the development of such kind of AmI systems.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>390</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-390">A Unifying Framework for Manipulation Problems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_390" class="editable_bid" data-pk="390" data-value="30"
                    data-url="/rev_3/paper/bid/set/390/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-390"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Manipulation models for electoral systems are a coreresearch theme in socialchoice theory;they&nbsp;include bribery (unweighted, weighted, swap, shift, ...), control (by adding or deleting voters or candidates), lobbying in referenda and others.<br>We develop a unifying framework for manipulation models with few types of people, one of the most commonly studied scenarios. A critical insight of our framework is to separate the descriptive complexity of the voting rule R from the number of types of people. This allows us to finally settle the computational complexity of R-Swap Bribery, one of the most fundamental manipulation problems. In particular, we prove that R-Swap Bribery is fixed-parameter tractable when R is Dodgson’s rule and Young’s rule, when parameterized by the number of candidates. This way, we resolve a long-standing open question from 2007 which was explicitly asked by Faliszewski et al. [JAIR 40, 2011].<br>Our algorithms reveal that the true hardness of bribery problems often stems from the complexity of the voting rules. On one hand, we give a fixed-parameter algorithm parameterized by number of types of people for complex voting rules. Thus, we reveal that R-Swap Bribery with Dodgson’s rule is much harder than with<br>Condorcet’s rule, which can be expressed by a conjunction of linear inequalities, while Dodson’s rule requires quantifier alternation and a bounded number of disjunctions of linear systems. On the other hand, we give an algorithm for quantifier-free voting rules which is parameterized only by the number of conjunctions of the<br>voting rule and runs in time polynomial in the number of types of people. This way, our framework explains why Shift Bribery is polynomial-time solvable for the plurality voting rule, making explicit that the rule is simple in that it can be expressed with a single linear inequality, and that the number of voter types is polynomial.<br></p></td>
                </tr>
            
                <tr>
                    <td>409</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-409">Dynamically Forming a Group of Human Forecasters and Machine Forecaster for Forecasting Economic Indicators</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Collective intelligence<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_409" class="editable_bid" data-pk="409" data-value="30"
                    data-url="/rev_3/paper/bid/set/409/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-409"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>How can human forecasts and a machine forecast be combined in inflation forecast tasks? A machine-learning-based forecaster makes a forecast based on a statistical model constructed from past time-series data, while humans take varied information such as economic policies into account. Combination methods for different forecasts have been studied such as ensemble and consensus methods. These methods, however, always use the same manner of combination regardless of the situation (input), which makes it difficult to use the advantages of different types of forecasters. To overcome this drawback, we propose an ensemble method for estimating the expected error of a machine forecast and dynamically determining the optimal number of humans included in the ensemble. We evaluated the proposed method by using the six datasets on U.S. inflation and confirmed that it attained the highest forecast accuracy for three datasets and the same accuracy as the highest one of traditional methods for two datasets.<br><br><br></p></td>
                </tr>
            
                <tr>
                    <td>463</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-463">Envy-Free Allocations Respecting Social Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_463" class="editable_bid" data-pk="463" data-value="30"
                    data-url="/rev_3/paper/bid/set/463/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-463"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Finding an envy-free allocation of indivisible resources to agents is a central task in many multiagent systems. Often, non-trivial envy-free allocations do not exist, and finding them can be a computationally hard task. Classic envy-freeness requires that every agent likes the resources allocated to it at least as much as the resources allocated to any other agent. In many situations this assumption can be relaxed since agents often do not even know each other. We enrich the envy-freeness concept by taking into account (directed) social networks of the agents. Thus, we compare every agent’s resources with those of its (out)neighbors. This leads to a “more local” concept of envy-freeness. We also consider a strong variant where every agent must like its own allocations more than those of all its (out)neighbors.<br><br>We analyze the classic and the parameterized complexity of finding allocations that are envy-free with respect to one of the variants of our new concept, and that either are complete, are Pareto-efficient, or optimize the utilitarian social welfare. To this end, we study different restrictions of the agents’ preferences and of the social network structure. We identify cases that become easier (from Σ^2_p-hard or NP-hard to P) and cases that become harder (from P to NP-hard) when comparing classic envy-freeness with our graph-based envy-freeness. Furthermore, we spot cases where graph envy-freeness is easier to decide than strong graph envy-freeness, and vice versa.<br></p></td>
                </tr>
            
                <tr>
                    <td>786</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-786">Social mechanisms for collective ontology engineering</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Knowledge Representation and Reasoning] Ontologies for agents</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_786" class="editable_bid" data-pk="786" data-value="30"
                    data-url="/rev_3/paper/bid/set/786/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-786"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><font face="Helvetica"><span style="font-size: 12px;">Building ontologies&nbsp;</span></font><span style="font-size: 12px; font-family: Helvetica;">collaboratively presents the advantage of allowing practitioners to&nbsp; share their expertise in the modelling of a domain. However, collaborative ontology engineering, seen as a form of knowledge integration, is prone to inconsistencies. We propose two techniques to deal with this situation. First, we study how to repair an inconsistent&nbsp;</span><span style="font-size: 12px; font-family: Helvetica;">collective ontology that results from the views of heterogeneous experts, once they have been aggregated by means of voting. Second, we prevent the creation of any inconsistencies by letting the experts engage in a turn-based rational negotiation about the axioms to be added&nbsp;</span><span style="font-size: 12px; font-family: Helvetica;">to the collective ontology. We instantiate the two approaches using real-world ontologies and we compare them by measuring the level of satisfaction of the experts w.r.t. the collective ontology obtained by the two procedures and employing two alternative measures for `agent happiness'.</span></p></td>
                </tr>
            
                <tr>
                    <td>557</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-557">Of Mice and Mazes: Simulating Mice Behavior with Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent Cooperation] Biologically-inspired approaches and methods<br>[Agent Theories and Models] Other</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_557" class="editable_bid" data-pk="557" data-value="30"
                    data-url="/rev_3/paper/bid/set/557/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-557"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Reinforcement learning (RL) algorithms are strongly motivated by biological systems.&nbsp; In this paper, we compare the output of RL agents against the observed behavior of real mice learning to navigate mazes as a way of exploring the extent to which instantiations of standard&nbsp; RL algorithms can approximate mouse learning.&nbsp; Using two similarity metrics, we found that certain parameterizations of Q-learning and SARSA were able to approximate the mice's behavior better than random- and optimal-behaving baselines. Furthermore, we identify trends in learning algorithms, reward functions, and parameterizations that cause RL agents to better approximate mouse learning. A main contribution of the paper is a novel methodology for comparing the learning processes of biological and RL agents.<br></p></td>
                </tr>
            
                <tr>
                    <td>490</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-490">Learning-Aware Human-Centered Collaborative Task Assignment in Open Environments</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Humans and Agents] Agent-based analysis of human interactions<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_490" class="editable_bid" data-pk="490" data-value="30"
                    data-url="/rev_3/paper/bid/set/490/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-490"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:RelyOnVML/>
  <o:AllowPNG/>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>JA</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
   <w:UseFELayout/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="381">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1107305727 0 0 415 0;}
@font-face
	{font-family:SimSun;
	panose-1:2 1 6 0 3 1 1 1 1 1;
	mso-font-charset:134;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:3 680460288 22 0 262145 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	text-align:justify;
	text-justify:inter-ideograph;
	mso-pagination:widow-orphan;
	font-size:9.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:SimSun;}
h1
	{mso-style-priority:9;
	mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-link:"Heading 1 Char";
	mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	text-justify:inter-ideograph;
	mso-pagination:widow-orphan lines-together;
	page-break-after:avoid;
	mso-outline-level:1;
	font-size:16.0pt;
	font-family:Calibri;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:major-latin;
	mso-fareast-font-family:"ＭＳ ゴシック";
	mso-fareast-theme-font:major-fareast;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:major-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:major-bidi;
	color:#365F91;
	mso-themecolor:accent1;
	mso-themeshade:191;
	mso-font-kerning:0pt;
	font-weight:normal;}
p.Abstract, li.Abstract, div.Abstract
	{mso-style-name:Abstract;
	mso-style-unhide:no;
	mso-style-parent:"Heading 1";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	text-align:justify;
	text-justify:inter-ideograph;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	font-size:9.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:SimSun;
	mso-font-kerning:14.0pt;}
span.Heading1Char
	{mso-style-name:"Heading 1 Char";
	mso-style-priority:9;
	mso-style-unhide:no;
	mso-style-locked:yes;
	mso-style-link:"Heading 1";
	mso-ansi-font-size:16.0pt;
	mso-bidi-font-size:16.0pt;
	font-family:Calibri;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:major-latin;
	mso-fareast-font-family:"ＭＳ ゴシック";
	mso-fareast-theme-font:major-fareast;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:major-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:major-bidi;
	color:#365F91;
	mso-themecolor:accent1;
	mso-themeshade:191;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-size:10.0pt;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-fareast-font-family:SimSun;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman";}
</style>
<![endif]-->



<!--StartFragment-->



<!--EndFragment--></p><p class="Abstract">Intelligent agents provide useful interfaces between complex
systems and human users.<span style="mso-spacerun:yes">&nbsp; </span>For example,
agents can interact with people to discover their preferences, skills, and
expertise, then find tasks that are appropriate for the users’ abilities.<span style="mso-spacerun:yes">&nbsp; </span>Notably, human users benefit from
participating in tasks not only through rewards received (e.g., payments for
completing tasks) but also by learning through experience, which improves each
user’s expertise and skills required for future tasks. Human learning is
especially essential in open environments where both (1) people join and leave
the environment over time, potentially causing available expertise to disappear
and affect collaboration success, and (2) tasks available for assignment
change, potentially requiring new skills or greater expertise over time.<span style="mso-spacerun:yes">&nbsp;&nbsp; </span>Here, human learning enables users to adapt
with the open environment and positions users for greater future task
accomplishment.<span style="mso-spacerun:yes">&nbsp; </span>We contribute an
agent-based solution that models human learning to account for its benefit
during task selection, which is leveraged in a sequential decision making
process where personal assistant agents select and acquire tasks for their
users in order to maximize users’ cumulative task rewards in open
environments.<span style="mso-spacerun:yes">&nbsp; </span>Experimental results
demonstrate the benefits of reasoning about human learning: improved expertise
leading to increased cumulative rewards.<o:p></o:p></p></td>
                </tr>
            
                <tr>
                    <td>332</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-332">A Dynamic Framework for Decentralized Norm Emergence in Open Multiagent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Normative systems<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_332" class="editable_bid" data-pk="332" data-value="30"
                    data-url="/rev_3/paper/bid/set/332/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-332"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">Norms (social norms) are powerful tools to determine the standards
of agents’ behavior in multiagent systems as the agents interact
in pursuit of their respective goals. Norms are important as they
promote both autonomy (agents do not need to comply with a norm)
and heterogeneity (agents’ internal reasoning about norms are
speci c to each agent). Researchers have studied norm emergence
through the social learning technique in which agents interact (play
games) repeatedly in a closed system with  xed payo s de ned for
the behaviors.
</span></p>
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">We propose Cha, a framework for open multiagent systems, in
which member agents may enter and leave dynamically, and each
agent reasons individually about norms. Also, unlike previous stud-
ies, our normative framework can change dynamically based on
the continual changes of the environment. We evaluated Cha in a
simulated tra c-regulation case study. Our results showed that us-
ing the Cha framework, norms that promote con ict resolution and
fairness can emerge, and norms adapt to a changing environment
in a decentralized manner.&nbsp;</span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>480</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-480">Fair resource allocation over time</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Economic Paradigms] Other</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_480" class="editable_bid" data-pk="480" data-value="30"
                    data-url="/rev_3/paper/bid/set/480/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-480"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider the over-time version of the Max-Min Fair Allocation problem. In the usual (static) problem, given a set of resources and a set of agents, we have to allocate the resources to agents in such a way that the utility of the least happiest agent is maximized. In the over-time version there is a time horizon t=1,2,..., T, with at each time t a set of agents and a set of available resources that may change over the time defining instance I_t; we seek a sequence of allocations (S_1, S_2, ... , S_T) that&nbsp; (1) are near-optimal at each time t, and (2) are as stable as possible: we want to minimize transition costs induced by modification between allocations at time t and time (t+1). </p><p>We focus on the impact of the knowledge of the future on the quality and the stability of the returned solutions by distinguishing three settings: the off-line setting where the whole set of instances through the time horizon is known in advance, the online setting where no future instance is known, and the k-lookahead setting where at time t, the instances at times t+1,..., t+k are known.<br>We first consider the case without restrictions where the set of resources and the set of agents are the same for all instances and where every resource can be allocated to any agent.<br>For the off-line setting, we show that the over-time version of the problem is much harder than the static one, since it becomes NP-hard even for families of instances for which the static problem is trivial. Then, we provide a r/(r+1)-approximation algorithm for the off-line setting using as&nbsp; subroutine an r-approximation algorithm for the static version. We also give a r/(r+1)-competitive algorithm for the online setting using also as subroutine an r-approximation algorithm for the static version. </p><p>Furthermore, for the case with restrictions, we show that in the off-line setting it is possible to get a polynomial-time algorithm with the same approximation ratio as in the case without restrictions, while for the online setting, we prove that it is not possible to find an online algorithm with bounded competitive ratio. For the 1-lookahead setting however, we give a r/(4r+2)-approximation algorithm using as subroutine an r-approximation algorithm for the static version.<br></p></td>
                </tr>
            
                <tr>
                    <td>741</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-741">Modeling User Communications in Social Media</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent Societies and Societal Issues] Social networks<br>[Humans and Agents] Agent-based analysis of human interactions</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_741" class="editable_bid" data-pk="741" data-value="30"
                    data-url="/rev_3/paper/bid/set/741/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-741"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>With the sudden and significant growth of participation in social media, there has been a shift in need for intelligent agents to accommodate its users. One of the most salient aspects of social media is its conversational aspect, where users can interact to share and evolve their opinions and beliefs. The ``conversational context'' of social media posts has a large influence on their topics, and is usually even more influential than the characteristics of the community or other features. The nature of how topics may evolve in a conversation, or the ``topic flow'' of a conversation, is strongly dependent on the personality of users that participate in the conversation. Our work introduces a novel, unsupervised statistical model of topic flow on social networks, expanding from existing work on topic models. The Author-Aware Topic Flow Model (AATFM) learns distinct conversational behaviors with user and conversational information, which can discover human-interpretable topics and transition characteristics on corpora in an efficient manner. The AATFM is found to outperform other state-of-the-art topic models and topic flow models in prediction tasks on conversations.</p></td>
                </tr>
            
                <tr>
                    <td>735</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-735">Actively Learning from Demonstration with Diverse Query Types</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_735" class="editable_bid" data-pk="735" data-value="30"
                    data-url="/rev_3/paper/bid/set/735/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-735"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><font face="Arial"><span style="font-size: 14.6667px; white-space: pre-wrap;">Task learning agents should be able to actively engage their human partners in order to generalize concepts relevant to the task being learned.  Towards that end, active learning literature has explored the selection of optimal candidate queries by a learning agent, with respect to a given utility function, but prior work has primarily focused on making one specific type of query towards generalization along that dimension of the task.  For example, repeatedly querying the oracle for class labels of unlabelled objects in the scene about which the learner is uncertain.  This work seeks to explore the scenario where a social learning agent has access to more than one type of active learning query it can make requests about, and the query types are not necessarily evaluated using the same utility functions.  In this case, it is important for the learner to have a way of selecting between the different query types, in order to decide which type of query is best to make at each turn in the learning interaction.  This work builds upon prior work in robot active learning which introduced a framework of three types of active learning queries explored in the literature: demonstration queries, label queries, and feature queries.  Given the three query types, we explore four rule-based strategies for enabling a learner to combine different types of queries in a learning episode.  We conducted experiments on two different tasks comparing 4 experimental strategies for combining the three AL query types against baselines of more traditional supervised learning, active learning, and random selection.  Our findings show it is more important the learner be enabled to elicit diverse types of information and be given an appropriate prioritization the question types than it is to focus on any one specific strategy for asking questions of the human teacher.</span></font><br></p></td>
                </tr>
            
                <tr>
                    <td>693</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-693">Joint Attention for Context-Aware Camera Agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Humans and Agents] Agent-based analysis of human interactions<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_693" class="editable_bid" data-pk="693" data-value="30"
                    data-url="/rev_3/paper/bid/set/693/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-693"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Joint attention refers to the idea of finding the focal points in an environment that are most salient to its occupants. In this work, we introduce the joint attention metric to an editing task for situated context-aware camera agents in corporate meetings. In a meeting room equipped with cameras from different viewpoints, the focal point of meeting participants is calculated using the extracted pose data and gaze direction. The automated editing algorithm then compiles the information from each agent to determine the joint attention of all the participants in the meeting, and select at each time point the camera viewpoint that best conveys joint attention. The editing also take into account basic filmmaking practices such as pacing and frame composition. The meeting videos are chosen from the AMI meeting corpus to represent 3 types of interactions: design and brainstorming, status update, and project planning. These videos provide a range of dynamics of the meetings in terms of conversational interaction, movement in the room, and focus shifts between objects and participants. The output of the agents is an editing plan for the meeting in Edit Description Language (EDL) format. We evaluate the output with a similarity metric against a baseline audio-based edit and an expert human-edited version.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>468</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-468">Reputation as a barrier to entry – an agent based simulation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Trust and reputation<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_468" class="editable_bid" data-pk="468" data-value="30"
                    data-url="/rev_3/paper/bid/set/468/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-468"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Reputation systems are being widely used in online markets as a tool which prevents moral hazard and helps in dealing with the prevalent problem of asymmetric information. This research explores one of the challenges that comes with their implementation, a high barrier to entry for market newcomers. We implement an agent based simulation of a reputation system and by running a series of experiments try to analyze effects of sellers' reputation and experience aggregation on market structure. The simulation reveals that if experience is used as one of the criteria in deciding who to trade with, barriers to entry can appear for new sellers. Furthermore, there is a possibility that less quality traders with high experience drive out more quality ones with less experience. Results should be considered when building reputation systems.<br></p></td>
                </tr>
            
                <tr>
                    <td>398</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-398">Agent-Based Simulation of Offender Mobility: Integrating Activity Nodes from Location-Based Social Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent Societies and Societal Issues] Social networks<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_398" class="editable_bid" data-pk="398" data-value="30"
                    data-url="/rev_3/paper/bid/set/398/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-398"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="Abstract"><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:RelyOnVML></o:RelyOnVML>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>IT</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
   <w:UseFELayout></w:UseFELayout>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="371">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" Priority="0" SemiHidden="true"
   UnhideWhenUsed="true" Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="0" SemiHidden="true"
   UnhideWhenUsed="true" Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if !supportAnnotations]--><!--[endif]--><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Calibri",sans-serif;
	mso-ansi-language:IT;
	mso-fareast-language:IT;}
</style>
<![endif]--> 



<!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="371">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" Priority="0" SemiHidden="true"
   UnhideWhenUsed="true" Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="0" SemiHidden="true"
   UnhideWhenUsed="true" Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>IT</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
   <w:UseFELayout></w:UseFELayout>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:RelyOnVML></o:RelyOnVML>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]-->



<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Calibri",sans-serif;
	mso-ansi-language:IT;
	mso-fareast-language:IT;}
</style>
<![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" LatentStyleCount="371">
  <w:LsdException Locked="false" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="line number"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="page number"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="No List"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>IT</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
   <w:UseFELayout></w:UseFELayout>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:RelyOnVML></o:RelyOnVML>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Calibri",sans-serif;
	mso-ansi-language:IT;
	mso-fareast-language:IT;}
</style>
<![endif]--></p><p class="Abstract"><span style="mso-ligatures:standard" lang="EN-US">In recent
years, simulation techniques have been applied to investigate the
spatio-temporal dynamics of crime. Researchers have instantiated mobile offenders
in agent-based simulations for theory testing, experimenting with prevention
strategies, and crime prediction purposes, despite facing challenges due to the
complex dynamics of crime and the lack of detailed information about offender
mobility. This paper presents an agent-based model to explore offender
mobility, focusing on the interplay between the agent’s awareness space and
activity nodes. To instantiate a realistic urban environment, we use open and location-based
social networks data to design the road network, and as proxy for human
activity we use activity nodes, respectively. 18 mobility strategies have been
tested, combining search distance strategies (e.g. Lévy flight, inspired by
insights in human dynamics literature) and target selection strategies
(enriched with Foursquare data). We analyze and compare the different mobility
strategies, and show the impact of using activity nodes extracted from social
networks to simulate offender mobility. This agent-based model provides a basis
for comparing offender mobility in crime simulations by inferring offender
mobility in urban areas from real world data.</span><span style="font-size:14.0pt;line-height:110%;mso-ligatures:standard" lang="EN-US"></span></p><p class="Abstract"><span style="mso-ligatures:standard" lang="EN-US"><br></span><span style="font-size:14.0pt;
line-height:110%;mso-ligatures:standard" lang="EN-US"></span></p><p class="Abstract"><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Calibri",sans-serif;
	mso-ansi-language:IT;
	mso-fareast-language:IT;}
</style>
<![endif]--></p><p class="Abstract"><span style="color:red;mso-ligatures:standard" lang="EN-US"><br></span><span style="color:red;mso-ligatures:
standard;mso-ansi-language:EN-GB;mso-fareast-language:JA" lang="EN-GB"></span></p><p>

</p></td>
                </tr>
            
                <tr>
                    <td>309</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-309">Integrating Multi-Agent Systems with Mixed Reality: the Augmented World Approach</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Programming languages and frameworks for agents and multi-agent systems<br>[Humans and Agents] Human-robot/agent interaction<br>[Humans and Agents] Multi-user/multi-virtual-agent interaction</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_309" class="editable_bid" data-pk="309" data-value="30"
                    data-url="/rev_3/paper/bid/set/309/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-309"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><div><div>In agent literature, a partially unexplored area is related to the integration of ever-wider opportunities offered by technologies such as Mixed Reality (MR) and Augmented Reality (AR). In this paper we present a framework called Augmented Worlds (AW), which provides a model and a technological support to develop a broad spectrum of agent-based AR/MR systems. Distinguishing key features of the approach include: bi-directional augmentation, support for existing cognitive agent technologies, support for developing open multi-user environments. In the paper, we describe first the conceptual model on which the framework is based, and then a concrete architecture and prototype implementation. Two case studies about real-world applications - an augmented museum and an augmented harbour - engineered with the framework are finally discussed.</div></div><div><br></div></td>
                </tr>
            
                <tr>
                    <td>642</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-642">Algorithms to Manage Load Shedding Events in Developing Countries</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Socio-technical systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_642" class="editable_bid" data-pk="642" data-value="30"
                    data-url="/rev_3/paper/bid/set/642/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-642"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Due to the limited generation capacity of power stations, many developing countries frequently resort to disconnecting large parts of the power grid from supply, a process termed load shedding. This leaves homes in these parts without electricity, causing them discomfort and inconvenience. Because fairness is not a priority when shedding load, some homes bear the brunt of these effects. In this paper, we present a number of heuristic approaches that aim to make load shedding fair to homes. Because these heuristics depend on the prediction of household electricity consumption, we begin by developing a predictive model of consumer energy consumption. We show that our model produces results that are 30$\%$ more accurate than those of a standard approach. Then, we present algorithms that shed load at the household level. Finally, we evaluate these algorithms against standard fairness metrics and thus establish new benchmarks for fair load shedding schemes.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>300</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-300">Non-parametric Fitted Relational Value Iteration: Unifying Relational and Propositional Discrete Domains</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_300" class="editable_bid" data-pk="300" data-value="30"
                    data-url="/rev_3/paper/bid/set/300/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-300"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider the problem of Approximate Dynamic Programming in relational domains. Inspired by the success of fitted value iteration methods in propositional settings, we develop the first relational fitted value iteration method by representing the value function as a linear combination of relational regression trees. We show how the two steps of Bellman operator application and projection steps can be performed using a gradient-boosting technique. Our proposed framework can be seen as a unified framework that can be effectively applied to both relational and propositional discrete domains.<br></p></td>
                </tr>
            
                <tr>
                    <td>294</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-294">Intolerance does not necessarily lead to segregation: a computer-aided analysis of the Schelling Segregation Model</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_294" class="editable_bid" data-pk="294" data-value="30"
                    data-url="/rev_3/paper/bid/set/294/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-294"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The Schelling Segregation Model is a spacial proximity model where individuals have preferences over their neighbours and can change their location according to a specific pecking order. We provide instances in which such order has an impact on the properties of the final outcome, in particular its segregation level, measured as a function of the number of clusters formed in the end.</p><p>Motivated by this finding, we introduce a tool for the systematic analysis of the starting scenarios, which handles the complexity of the problem with a randomised exploration module. We show a number of surprising findings which shed light on the relation between individuals' tolerance, neighbourhood size, and final level of segregation. In particular, challenging Schelling's claim that small preferences for local uniformity inevitably lead to higher levels of global segregation, we have been able to find instances of starting scenarios that, even when using the pecking order proposed by Schelling, display a reduced -- and at times, zero -- level of final segregation.</p></td>
                </tr>
            
                <tr>
                    <td>467</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-467">Rent Division Among Groups</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Other</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_467" class="editable_bid" data-pk="467" data-value="30"
                    data-url="/rev_3/paper/bid/set/467/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-467"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we extend the Rent Sharing problem for the case that every room must be allocated to a group of agents. In the classic Rent Sharing problem, there are $n$ agents and a house with $n$ rooms, and the goal is to allocate one room to each agent and assign a rent to each room, such that no agent envies any other option. Our setting deviates from the classic Rent Sharing problem in a sense that the rent determined for every room must be divided among the members of the resident group. <br></p><p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;">We define three notions to evaluate fairness, namely, weak envy-freeness, aggregate envy-freeness and strong envy-freeness. We also define three different policies to divide the cost among group members, namely, equal, proportional, and free cost-sharing policies. </p><p>
<br></p><p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;">We present several positive and negative results for different combinations of the fairness criteria and rent-division policies. Specifically, when the groups are pre-determined, we propose a strong envy-free solution that allocates the rooms to the agents, regarding free cost-sharing policy. In addition, for the case that the groups are not pre-determined, we propose a strong envy-free allocation algorithm with equal cost-sharing policy. In addition, we investigate on the problem of finding the maximum total rent that is possible to guarantee strong envy-freeness. We leverage our results to obtain an algorithm that determines the maximum total rent along with the proper allocation and rent-division method.</p><p><br></p></td>
                </tr>
            
                <tr>
                    <td>89</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-89">Robustness to Model Uncertainty for Agent-Based Influencing of a Flock</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent Cooperation] Other<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_89" class="editable_bid" data-pk="89" data-value="30"
                    data-url="/rev_3/paper/bid/set/89/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-89"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Many biological species exhibit flocking behavior whereby each animal bases its actions on the locations of nearby animals, leading to unchoreographed yet cohesive emergent flock behavior.&nbsp; Recent research has considered how controlled autonomous agents that are recognized by flock members as "one of their own" can exert a desired influence on the overall flock behavior.&nbsp; This past research has assumed that the underlying local behavior model of the flock is known.&nbsp; However in practice, these underlying behaviors are not known with certainty.&nbsp; This paper contributes the first detailed empirical study considering how well methods from the existing research on controllable agent behavior generalize to alternate flocking models when the true underlying flock model is unknown.<br></p></td>
                </tr>
            
                <tr>
                    <td>136</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-136">A Generic Domain Pruning Technique for GDL-based DCOP algorithms in Cooperative Multi-Agent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Other<br>[Agent Cooperation] Distributed problem solving</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_136" class="editable_bid" data-pk="136" data-value="30"
                    data-url="/rev_3/paper/bid/set/136/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-136"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span class="fontstyle0">Generalized Distributive Law (GDL) based message passing algorithms, such as Max-Sum and Bounded Max-Sum, are often used to solve distributed constraint optimization problems in cooperative multi-agent systems (MAS). However, scalability becomes a challenge when these algorithms have to deal with constraint functions with high arity or variables with a large domain size. In either case, the ensuing exponential growth of search space can make such algorithms computationally infeasible in practice. To address this issue, we develop a generic domain pruning technique that enables these algorithms to be effectively applied to larger and more complex problems. We theoretically prove that the pruned search space obtained by our approach does not affect the outcome of the algorithms. Moreover, our empirical evaluation illustrates a significant reduction of the search space, ranging from </span><span class="fontstyle2">33% </span><span class="fontstyle0">to </span><span class="fontstyle2">81%</span><span class="fontstyle0">, without affecting the solution quality of the algorithms, compared to the state-of-the-art.</span>&nbsp;&nbsp;<br style="line-height: normal; text-align: -webkit-auto; text-size-adjust: auto;"></p></td>
                </tr>
            
                <tr>
                    <td>202</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-202">Mitigating Strategic Attack Diffusion in Security Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logic and Game Theory<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.600</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_202" class="editable_bid" data-pk="202" data-value="30"
                    data-url="/rev_3/paper/bid/set/202/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-202"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>One of the key problems studied by game theorists is the confrontation between a defender of a network of targets and an aggressor who attacks the network. In some cases, the attack spreads and therefore it can be modeled as a stochastic contagion. In this work we consider a setting in which the process of spreading is entirely strategic, sequential and under the control of the attacker. We define this problem as a Stackelberg game between two players, the defender and the attacker. We prove that finding an optimal strategy of the attacker is an NP-complete problem when the attack is strategic. To aid the defense efforts, we analyze possible strategies of protecting the network from different strategies of sequential attack.</p></td>
                </tr>
            
                <tr>
                    <td>626</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-626">A Combinatorial Market for Distributed Data</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_626" class="editable_bid" data-pk="626" data-value="30"
                    data-url="/rev_3/paper/bid/set/626/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-626"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Data is becoming more and more valuable, and there already exists an efficient technology for querying and combining data from distributed databases. However, this technology is very much underutilized. This happens mostly because of a lack of financial incentives for data providers to publish their data in a suitable format. The primary reason for this is that advertisement, the main source of income of data providers in the traditional Web, does not work in the domain of distributed databases where data is processed by machines rather than by humans. Enabling users to seamlessly combine data from different sources would allow them to automatically integrate and process distributed data, resulting in more efficient search processes. In this paper, we address this issue by designing a market for selling distributed data. We present a formal model for this problem, a market design solution, and we perform an economic analysis of the resulting market in equilibrium. Our results show that such a data market leads to high utility for buyers while data providers are guaranteed to recoup their costs for producing their databases.<br></p></td>
                </tr>
            
                <tr>
                    <td>613</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-613">Competition between Charging Stations: Queues, Capacities, Prices and Optimal Subsidies</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: computation<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_613" class="editable_bid" data-pk="613" data-value="30"
                    data-url="/rev_3/paper/bid/set/613/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-613"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Electric vehicles (EVs) have a limited range and charging stations are required to ensure wide-spread adoption. However, limitations in charging capacity can result in significant queueing times. Charging stations are expensive to build and require careful planning of location, capacity as well as prices. We propose a game-theoretic model in which competing charging station investors strive to maximise individual net profit, while EV drivers strive to minimise travel costs and queueing at the stations. Existing literature largely considers monopolistic optimisation and either assumes fixed prices or disregards queues. In contrast, here we account for stochastic EV queuing times, driver behaviour, charging station investor behaviour, station capacities and prices, building and operational costs and extraneous competition. Our model is evaluated using a duopoly example and is used to examine subsidies as incentives to EV adoption. We calculate the rebate in utility for drivers and stations due to the subsidy, and determine optimal subsidy levels for system-wide and driver utility gain per pound spent on subsidy. Results show that subsidising the purchase of charging units for stations can have a significant beneficial effect for both EV drivers and station investors, with increasing benefit for drivers for increasing levels of subsidy, and increasing subsidy efficiency for increasing numbers of EV drivers. In contrast, subsidies on the energy price for stations can have a minor beneficial effect when subsidies are small and drivers are few, but can also incentivise stations to reduce capacities and increase prices. Last, subsidising only one station can result in most of the subsidy being absorbed by that station, with an adverse effect for the other station and little or no utility gain for the drivers.<br></p></td>
                </tr>
            
                <tr>
                    <td>614</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-614">Adversarial Regression for Stealthy Attacks in Cyber-Physical Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Adversarial machine learning<br>[Verification and Validation of Agent-based Systems] Fault tolerance and resilience of multi-agent systems</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_614" class="editable_bid" data-pk="614" data-value="30"
                    data-url="/rev_3/paper/bid/set/614/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-614"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Attacks manipulating the sensor measurements of a cyber-physical system (CPS) can be tuned by the attacker to cause a spectrum of damages. Attackers can attempt to remain undetected and hide their sensor manipulations by following the expected behavior of the system, while manipulating just enough sensor information that achieves their malicious goals. In this paper, we study the problem of adversarial regression in CPS. We consider a safety-critical CPS that is monitored by regression-based anomaly detectors. An adversary attempts to drive the system to an unsafe state by perturbing the values of a subset of sensors while remaining undetected. We solve the adversarial regression problem, considering linear regression- and neural network regression-based detectors. Then, we present a resilient detector that mitigates the impact of stealthy attacks through resilient configuration of detection thresholds. We numerically evaluate the adversarial regression problem, and demonstrate the effectiveness of the resilient detector using a case study of a process control system.<br></p></td>
                </tr>
            
                <tr>
                    <td>443</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-443">Efficient Convention Emergence through Decoupled Reinforcement Social Learning with Teacher-Student Mechanism</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Learning and Adaptation] Multiagent learning<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_443" class="editable_bid" data-pk="443" data-value="30"
                    data-url="/rev_3/paper/bid/set/443/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-443"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we design reinforcement learning based (RL-based) strategies to promote convention emergence in multiagent systems (MASs) with large convention space. We apply our approaches to a language coordination problem in which agents need to coordinate on a dominant lexicon for efficient communication. By modeling each lexicon which maps each concept to a single word as a Markov strategy representation, the original single-state convention learning problem can be transformed into a muti-state multiagent coordination problem. The dynamics of lexicon evolutions during an interaction episode can be modeled as a Markov game, which allows agents to improve the action values of each concept separately and incrementally. Specifically we propose two learning strategies, multiple-Q and multiple-R, and also propose incorporating teacher-student mechanism on top of the learning strategies to accelerate lexicon convergence speed. Extensive experiments verify that our approaches outperform the state-of-the-art approaches in terms of convergence efficiency and convention quality.<br></p></td>
                </tr>
            
                <tr>
                    <td>223</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-223">An Imperfect Algorithm for Coalition Structure Generation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Coalition formation (non-strategic)<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_223" class="editable_bid" data-pk="223" data-value="30"
                    data-url="/rev_3/paper/bid/set/223/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-223"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style="margin-bottom: 0px;">Optimal coalition structure generation (CSG) is a significant research problem in multi-agent systems that remains difficult to solve. The problem has many important applications such as in transportation, eCommerce, distributed sensor networks and others. The CSG problem is NP-complete and finding the optimal result for n agents needs to check O (n<sup>^</sup>n) possible partitions. The ODP-IP algorithm achieves the current lowest worst-case time complexity - O (3^n).</p><p>

</p><p style="margin-bottom: 0px;">In the light of its high computational time complexity, we devise an Imperfect Dynamic Programming (ImDP) algorithm for CSG problem with runtime O (n2^n) given n agents.<i> Imperfect algorithm</i> means, there are some contrived inputs for which the algorithm fails to give the optimal result. We benchmark our algorithm against the hybrid dynamic programming ODP-IP.</p></td>
                </tr>
            
                <tr>
                    <td>427</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-427">BelMan: Bayesian Bandits on the Belief--Reward Manifold</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Learning and Adaptation] Adversarial machine learning</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_427" class="editable_bid" data-pk="427" data-value="30"
                    data-url="/rev_3/paper/bid/set/427/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-427"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We propose a generic, Bayesian, information geometric algorithm to the exploration--exploitation trade-off in multi-armed bandit problems. Our algorithm, BelMan, uniformly supports pure exploration, exploration--exploitation, and two-phase bandit problems. The knowledge on bandit arms and their reward distributions is summarised by the barycentre of the joint distributions of beliefs and rewards of the arms, the <i>pseudobelief--reward</i>, within the belief--reward manifold. BelMan alternates <i>information projection</i> and <i>reverse information projection</i>, i.e., projection of the pseudobelief--reward onto belief--reward distributions to choose the arm to play, and projection of the resulting belief--reward distributions onto the pseudobelief--reward. BelMan introduces a mechanism that infuses an exploitative bias by means of a <i>focal distribution</i>, i.e., a reward distribution that gradually concentrates on higher rewards. Comparative performance evaluation with state-of-the-art algorithms shows that BelMan is not only competitive but also outperforms other approaches in specific setups, for instance involving many arms and continuous rewards.<br></p></td>
                </tr>
            
                <tr>
                    <td>756</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-756">Defender Stackelberg Game with Inverse Geodesic Length as Utility Metric</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_756" class="editable_bid" data-pk="756" data-value="30"
                    data-url="/rev_3/paper/bid/set/756/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-756"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; text-size-adjust: auto;">The inverse geodesic length (IGL) is a well-known and widely used measure of network performance. It equals the sum of the inverse distances of all pairs of vertices in the network. A Stackelberg game is a strategic game in which one player commits to a strategy while taking into account that other players will respond accordingly. We propose a natural defender-attacker Stackelberg game on a network in which the defender wants to maximize the IGL level of the network and commits to protecting parts of the network while having knowledge of the strength of an attacker that wants to weaken the network. We present several algorithmic and complexity results concerning the problem of finding the optimal commitment for the defender. Some of our computational hardness results also answer open problems posed in prior work on IGL.&nbsp;</span><br></p></td>
                </tr>
            
                <tr>
                    <td>438</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-438">Resolving Incompatibilities among Procedural Goals under Uncertainty</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Deductive, rule-based and logic-based argumentation<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_438" class="editable_bid" data-pk="438" data-value="30"
                    data-url="/rev_3/paper/bid/set/438/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-438"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>By considering rational agents, we focus on the problem of selecting goals out of a set of incompatible ones.&nbsp; We consider the three forms of incompatibility introduced by Castelfranchi and Paglieri, namely the terminal incompatibility, the instrumental or resources incompatibility and the superfluity. We represent the plans associated with the goals by means of structured arguments whose premises are pervaded with uncertainty. Thus, we measure the strength of such arguments in order to determine the set of compatible goals. We propose two novel ways for calculating the strength of the arguments, depending on the kind of incompatibility that exists between goals. The logical strength value is represented by a three-dimensional vector determined from a probabilistic interval associated with each argument. These three dimensions represent the precision of the interval, the location of the interval and the combination of precision and location. This type of representation and treatment of the strength of a structured argument can be considered as a novelty in the study of structured arguments with uncertainty. The second way for calculating the strength of the argument is based on the cost of the plans (regarding the necessary resources) and the preference of the goals associated with the plans. Finally, the strategy for the selection of plans and goals is based on Dung's abstract argumentation theory.</p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>761</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-761">Strategic Evasion of Centrality Measures</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Monitoring agent societies<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_761" class="editable_bid" data-pk="761" data-value="30"
                    data-url="/rev_3/paper/bid/set/761/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-761"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px;">Centrality measures – techniques that rank nodes in networks - belong to the fundamental tools of social network analysis. Similarly to other tools, they</span><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">&nbsp;were built around the assumption that individuals or groups in a network do not act strategically to evade&nbsp;</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">analysis</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">. Even&nbsp;</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">the centrality anal</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">ysis of</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">&nbsp;covert networks typically assume that the network under investigation is not strategic</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">ally</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">&nbsp;manipula</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">ted</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">.&nbsp;</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">To circumvent this problem, a few recent studies attempted to understand how a member of a social network could try to mislead centrality measures. These models, however, were based on the assumption that the network analyser is oblivious to any evasion attempts. In this paper, we extend those models and present the first analysis of a strategic game between an analyser whose aim is to detect the leaders of the network, and the leaders whose aim is to evade such analysis.</font><br></p></td>
                </tr>
            
                <tr>
                    <td>235</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-235">Making Room for Refugees: Agent-Based Simulation of West Asian Urban Dynamics</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Policy, regulation and legislation<br>[Agent-based Simulation] Emergent behaviour<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_235" class="editable_bid" data-pk="235" data-value="30"
                    data-url="/rev_3/paper/bid/set/235/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-235"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block">Rapid international migration of significant populations is generating profound implications for countries in West Asia, Europe, and other regions. Our motivation is to develop an agent-based model (ABM) to capture the existence of such migrant and refugee flows, and to explore their effects on urban dynamics. We leverage an extant agent-based model founded on the rent-gap theory, as a lens to study the effect of sizeable refugee migration upon a capital city in West Asia. In order to calibrate and validate the simulation model we construct indices for housing prices and other factors. Results from the model show the impact of migration shock on the housing market, and identify the relative efficacy of housing intervention policies. Our work progresses towards a tool for policy makers asking what-if questions about the urban environment in the context of migration.</td>
                </tr>
            
                <tr>
                    <td>697</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-697">A Gibbs Sampling Approach to Argument-Based Inference of Attack Graphs</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Other<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_697" class="editable_bid" data-pk="697" data-value="30"
                    data-url="/rev_3/paper/bid/set/697/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-697"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Inferential analysis of discourse with computational argumentation is a new and potential approach to argumentation mining. This is interesting because one of the important tasks of argumentation mining is identification of an attack relation between arguments, and it is too optimistic to think that lexical analysis with natural language processing can provide a complete solution to the problem. In this paper, a Bayesian generative model characterizing Dung's abstract argumentation is extended so that it performs efficient approximate inference of attack interaction among arguments. A Gibbs sampling algorithm is implemented on the extended model to empirically show its reasonable estimation accuracy, sensitivity and time complexity. This model is applied to estimate customer review conflicts from rating scores of the individual reviews in Amazon.com. We demonstrate that reasonable consistency is observed between model's estimation and customers' conflict-judgement. This work will serve as an algorithmic foundation of the practical use of computational argumentation in argumentation mining.<br></p></td>
                </tr>
            
                <tr>
                    <td>106</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-106">Fair Knapsack</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Economic Paradigms] Social choice theory</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_106" class="editable_bid" data-pk="106" data-value="30"
                    data-url="/rev_3/paper/bid/set/106/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-106"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We study the following multiagent variant of the knapsack problem. We are given a set of items, a set of voters, and a value of the budget; each item is endowed with a cost and each voter assigns to each item a certain value. The goal is to select a subset of items with the total cost not exceeding the budget, in a way that is consistent with the voters' preferences. Since the preferences of the voters over the items can vary significantly, we need a way of aggregating these preferences, in order to select the socially most preferred valid knapsack. We study three approaches to aggregating voters preferences, which are motivated by the literature on multiwinner elections and fair allocation. This way we introduce the concepts of individually best, diverse, and fair knapsack. We study computational complexity (including parameterized complexity, and complexity under restricted domains) of computing the aforementioned variants of multiagent knapsacks.<br></p></td>
                </tr>
            
                <tr>
                    <td>299</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-299">Positional Social Decision Schemes: Fair and Efficient Randomized Voting</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_299" class="editable_bid" data-pk="299" data-value="30"
                    data-url="/rev_3/paper/bid/set/299/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-299"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We introduce a new family of randomized voting rules, which is a probabilistic<br>counterpart of positional scoring rules. A rule in this family is defined by a<br>scoring vector associating a positive value with each rank in a vote, and an<br>aggregation function. We focus on two types of aggregation functions: those<br>corresponding to egalitarianism (min, and leximin) and the Nash product. We address the computation of the<br>rules and their normative properties. We argue that some these rules are<br>particularly useful for time-sharing in an efficient and fair manner.<br><br><br></p></td>
                </tr>
            
                <tr>
                    <td>702</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-702">Adaptive Bandit with Context-Dependent Embeddings</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Agent Cooperation] Biologically-inspired approaches and methods</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_702" class="editable_bid" data-pk="702" data-value="30"
                    data-url="/rev_3/paper/bid/set/702/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-702"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We propose a technique for improving the performance of contextual bandit in non-stationary environments via adaptive, dynamic representation learning. Our approach combines off-line pre-training on unlabeled history of contexts (which, when available, can be exploited by our approach but not by the standard contextual bandit) with on-line choice and change of embedding functions facilitating representation learning. Our experiments on a variety of datasets consistently demonstrate advantages of our approaches over the standard contextual bandit approach. <br><br></p></td>
                </tr>
            
                <tr>
                    <td>340</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-340">Learning the Reward Function for a Misspecified Model</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_340" class="editable_bid" data-pk="340" data-value="30"
                    data-url="/rev_3/paper/bid/set/340/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-340"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In model-based reinforcement learning it is typical to treat the problems of learning the dynamics model and learning the reward function separately. However, when the dynamics model is flawed, it may generate erroneous states that would never occur in the true environment. A reward function trained only to map environment states to rewards (as is typical practice) would have little guidance in such states. This paper presents a novel error bound that accounts for the reward model's behavior in states sampled from the model. This bound is used to extend the existing Hallucinated DAgger-MC algorithm, which offers theoretical performance guarantees in deterministic MDPs that do not assume a perfect model can be learned. Empirically, this approach to learning a reward function can yield dramatic improvements in control performance when the dynamics model is flawed.</p></td>
                </tr>
            
                <tr>
                    <td>417</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-417">Parameter Design for Continuous Tasks based on Type Identification of Crowd Workers</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_417" class="editable_bid" data-pk="417" data-value="30"
                    data-url="/rev_3/paper/bid/set/417/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-417"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper proposes a method of task design based on type identification of crowd workers. Here, the task design means finding the values of task parameters that are suitable for individual workers. Multi-armed bandit techniques are promising, but if we consider continuous tasks, exploring various task settings for a single worker interferes with that worker, which deteriorates the quality of contributions. To solve this problem, we introduce the type identification test, i.e., we divide the entire period for a worker into a type identification phase and an execution phase and alternately handle the calculation at the individual worker level and at the aggregated workers level. Our method can find an appropriate task setting without exploring various settings for a worker, i.e., excessively interfering with the worker. Also, we provide a method of calculating the optimal type identification test to maximize the expected quality of contributions in the execution phase. Finally, we show the proposed method outperforms conventional multi-armed bandit algorithms such as Softmax and UCB1 with data we collected on the Amazon Mechanical Turk and with a simulation.<br><br><br></p></td>
                </tr>
            
                <tr>
                    <td>197</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-197">Multi-Agent Reinforcement Learning for Multi-Object Tracking</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_197" class="editable_bid" data-pk="197" data-value="30"
                    data-url="/rev_3/paper/bid/set/197/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-197"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We present a novel, multi-agent reinforcement learning formulation of multi-object tracking that treats creating, propagating, and terminating object tracks as actions in a sequential decision-making problem. In our formulation, each agent tracks a single object at a time by updating a Bayesian filter according to a discrete number of actions. At each timestep, the reward received is dependent on the joint actions taken by all agents and the ground truth object tracks. We optimize for different tracking metrics directly while propagating covariance information about each object's state. We use trust region policy optimization (TRPO) to train a shared policy across all agents, parameterized by a multi-layer neural network. Our experiments show an improvement in tracking accuracy over similar state-of-the-art, rule-based approaches on a popular multi-object tracking dataset.<br></p></td>
                </tr>
            
                <tr>
                    <td>753</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-753">Solving Dynamic Multi Objective Distributed Constraint Optimization Problems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Agent Theories and Models] Other</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_753" class="editable_bid" data-pk="753" data-value="30"
                    data-url="/rev_3/paper/bid/set/753/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-753"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper we propose an algorithm for solving dynamic multi objective distributed constraint optimization problems (D-MODCOP) with Pareto solution. D-MODCOP is method for modeling problems in which the problems are modeled as a sequence of multi objective constraint optimization problems that must be solved decentralized. The dynamic nature of the problem is modeled with unpredictable random variables in the objective functions. Our algorithm searches the space of the problem point by point to find the Pareto frontier set in a decentralized manner in each time step. The D-MODCOP solver, solves a dynamic multi objective optimization(MODCOP) in each time step, computes a solution and uses the solution as the starting points for the next time step. In our experimental evaluation we show the convergence of our algorithm and its superiority in the number of message reduction over time steps in comparison with solving a new problem in each time step from scratch.</p></td>
                </tr>
            
                <tr>
                    <td>525</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-525">Efficient Influence Maximization Under Network Uncertainty</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Social networks<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_525" class="editable_bid" data-pk="525" data-value="30"
                    data-url="/rev_3/paper/bid/set/525/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-525"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider the influence maximization (IM) problem in a partially visible social network. In this problem, the aim is to design a decision-making framework for an autonomous agent to select a limited set of influential seed nodes in order to spread a belief or message as widely as possible across the network. Unlike most existing work, we consider the realistic case where the agent has to deal with uncertainty about parts of the network structure. Specifically, we assume that a partial section of the network is visible to the agent, while the rest is one of a finite set of known structures, each with a given realization probability. We show that solving the IM problem in this setting is NP-hard, and we provide analytical guarantees for the performance of a novel computationally-efficient seed-selection approximation algorithm for the agent. In empirical experiments on real-world social networks, we demonstrate the efficiency of our agent and show that it outperforms state-of-the-art approaches that do not model the uncertainty, reaching 14.9% more nodes in case of high uncertainty. Finally, we show that computationally more efficient heuristics, which considers uncertainty, do not perform well in this case.<br></p></td>
                </tr>
            
                <tr>
                    <td>169</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-169">Complexity of Scheduling Charging in the Smart Grid</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Other<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_169" class="editable_bid" data-pk="169" data-value="30"
                    data-url="/rev_3/paper/bid/set/169/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-169"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>In the smart grid, the intent is to use flexibility in demand, both to balance demand and supply as well as to resolve potential congestion. A first prominent example of such flexible demand is the charging of electric vehicles, which do not necessarily need to be charged as soon as they are plugged in. The problem of optimally scheduling the charging demand of electric vehicles within the constraints of the electricity infrastructure is called the charge scheduling problem. The models of the charging speed, horizon, and charging demand determine the computational complexity of the charge scheduling problem. For about 20 variants the problem is either in P or weakly NP-hard and dynamic programs exist to compute optimal solutions. About 10 other variants of the problem are strongly NP-hard, presenting a potentially significant obstacle to their use in practical situations of scale. An experimental study establishes up to what parameter values the dynamic programs can determine optimal solutions in a couple of minutes.</p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>415</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-415">Moral values in norm decision making</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Policy, regulation and legislation<br>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Agent Societies and Societal Issues] Normative systems<br>[Agent Societies and Societal Issues] Other</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_415" class="editable_bid" data-pk="415" data-value="30"
                    data-url="/rev_3/paper/bid/set/415/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-415"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Most often, both agents and human societies use norms to coordinate their on-going activities. Nevertheless, choosing the 'right' set of norms to regulate these societies constitutes an open problem. Firstly, intrinsic norm relationships may lead to inconsistencies in the chosen set of norms. Secondly, and more importantly, there is an increasing demand of including ethical considerations in the decision making process. This paper focuses on choosing the 'right' norms by considering moral values together with society's partial preferences over these values and the extent to which candidate norms promote them. The resulting decision making problem can then be encoded as a linear program, and hence solved by state-of-the art solvers. Furthermore, we empirically test several optimisation scenarios so to determine the system's performance and the characteristics of the problem that affect its hardness.<br><br></p></td>
                </tr>
            
                <tr>
                    <td>310</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-310">Trial without Error: Towards Safe Reinforcement Learning via Human Intervention</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.590</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_310" class="editable_bid" data-pk="310" data-value="30"
                    data-url="/rev_3/paper/bid/set/310/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-310"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="font-family: &quot;Lucida Grande&quot;, helvetica, arial, verdana, sans-serif; font-size: 14.4px;">AI systems are increasingly applied to complex tasks that involve interaction with humans. During training, such systems are potentially dangerous, as they haven't yet learned to avoid actions that could cause serious harm. How can an AI system explore and learn without making a single mistake that harms humans or otherwise causes serious damage? For model-free reinforcement learning, having a human "in the loop" and ready to intervene is currently the only way to prevent all catastrophes. We formalize human intervention for RL and show how to reduce the human labor required by training a supervised learner to imitate the human's intervention decisions. We evaluate this scheme on Atari games, with a Deep RL agent being overseen by a human for four hours. When the class of catastrophes is simple, we are able to prevent all catastrophes without affecting the agent's learning (whereas an RL baseline fails due to catastrophic forgetting). However, this scheme is less successful when catastrophes are more complex: it reduces but does not eliminate catastrophes and the supervised learner fails on adversarial examples found by the agent. Extrapolating to more challenging environments, we show that our implementation would not scale (due to the infeasible amount of human labor required). We outline extensions of the scheme that are necessary if we are to train model-free agents without a single catastrophe.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>368</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-368">Argumentation with Goals for Clinical Decision Support in Multimorbidity</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Argumentation-based dialogue and protocols<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_368" class="editable_bid" data-pk="368" data-value="30"
                    data-url="/rev_3/paper/bid/set/368/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-368"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Decision-making in multimorbidity carries a complexity related with the multiple variables involved in the process. These variables reflect the concomitant health conditions that should be considered when defining a proper therapy. However, current Clinical Decision Support Systems (CDSSs) are not equipped to deal with such a setting. They do not go beyond the straightforward application of the rules that build their knowledge base and simple interpretation of Computer-Interpretable Guidelines (CIGs). The present work proposes a computational argumentation system equipped with goal seeking to combine independently generated CIG recommendations and enhance CDSSs to support physicians in these decisions.<br></p></td>
                </tr>
            
                <tr>
                    <td>641</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-641">Group Decision Making with Uncertain Subjective Preferences</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Economic Paradigms] Social choice theory<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_641" class="editable_bid" data-pk="641" data-value="30"
                    data-url="/rev_3/paper/bid/set/641/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-641"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><pre style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;"><!--StartFragment--><span style=" color:#000000;">Social choice theory, in particular voting, has been embraced by the AI community as it provides a principled framework for the aggregation of individuals' preferences in support of group decision-making and recommendation.  Much of this work, however, either assumes that individuals' subjective preferences (and thus, their votes) are correctly specified by the individuals themselves, or alternatively that the votes of individuals are  noisy estimates of some underlying ground truth over rankings of alternatives. We argue that neither model appropriately addresses some of the issues which arise in the context of group-recommendation domains where individuals have subjective preferences but for some reason (e.g., the high cognitive burden, </span><span style="color: rgb(0, 0, 0);">concerns about privacy, etc.) may instead vote using a noisy estimate of their subjective preferences. </span><span style="color: rgb(0, 0, 0);">In this paper we propose a general probabilistic framework for modeling noisy subjective preferences, and study the accuracy and reliability of four well-studied voting rules  (Plurality, </span><span style="color: rgb(0, 0, 0);">Borda</span><span style="color: rgb(0, 0, 0);">, </span><span style="color: rgb(0, 0, 0);">Kemeny</span><span style="color: rgb(0, 0, 0);"> and Copeland) in this context. We also propose and evaluate inference methods for recovering true subjective preferences given noisy ones. Our experiments confirm the efficacy of our proposed method in dealing with noisy preferences.</span></pre></td>
                </tr>
            
                <tr>
                    <td>362</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-362">Large Scale Multi-Issue Multi-Lateral Negotiation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Communication languages and protocols<br>[Economic Paradigms] Auctions and mechanism design<br>[Agent Cooperation] Collective intelligence<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_362" class="editable_bid" data-pk="362" data-value="30"
                    data-url="/rev_3/paper/bid/set/362/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-362"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we consider the problem of large scale multiissue negotiation. We assume that agents have different preferences over the negotiated issues and may be indifferent regarding some of the issues. They nevertheless have to make a collective choice that addresses all issues at stake. In practice,&nbsp; we consider an example of a joint purchase of energy where the concerned households have to define a collective energy contract. Given the complexity of the negotiation problem, we propose a multi-step negotiation process that involves iteratively partitioning the agents into subgroups according to their similarity over the issues they want to negotiate and negotiation outcomes. We don’t require the agents to reveal their preferences for the mechanism to work but we elicit these preferences through the negotiation steps. Furthermore, we design a negotiation protocol to support the creation of efficient outcomes. Our experimental results show that our negotiation algorithm allows the agents to reach agreements in limited numbers of rounds.<br></p></td>
                </tr>
            
                <tr>
                    <td>134</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-134">Classification with Costly Features using Deep Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Deep learning<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_134" class="editable_bid" data-pk="134" data-value="30"
                    data-url="/rev_3/paper/bid/set/134/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-134"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We study a classification problem where each feature can be acquired for a cost and the goal is to optimize the trade-off between classification precision and the total feature cost. We frame the problem as a sequential decision-making problem, where we classify one sample in each episode. At each step, an agent can use values of acquired features to decide whether to purchase another one or whether to classify the sample. We use vanilla Double Deep Q-learning, a standard reinforcement learning technique, to find a classification policy. We show that this generic approach outperforms Adapt-Gbrt, currently the best-performing algorithm developed specifically for classification with costly features.</p></td>
                </tr>
            
                <tr>
                    <td>329</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-329">AgentSpeak(ER): An Extension of AgentSpeak(L) improving Encapsulation and Reasoning about Goals</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Engineering Multiagent Systems] Programming languages and frameworks for agents and multi-agent systems</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_329" class="editable_bid" data-pk="329" data-value="30"
                    data-url="/rev_3/paper/bid/set/329/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-329"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we introduce AgentSpeak(ER), an extension of the AgentSpeak(L) language tailored to support encapsulation. The AgentSpeak(ER) extention allows for significantly improving the style of BDI agent programming along relevant aspects, including program modularity and readability, failure handling, and reactive as well as goal-based reasoning. The paper introduces the novel language, formalises the changes in the usual semantics of AgentSpeak, illustrate the features of the language through examples, and shows results of experiments evaluating the proposed language.<br></p></td>
                </tr>
            
                <tr>
                    <td>486</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-486">Guiding Reinforcement Learning Exploration Using Natural Language</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Humans and Agents] Human-robot/agent interaction<br>[Humans and Agents] Other</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_486" class="editable_bid" data-pk="486" data-value="30"
                    data-url="/rev_3/paper/bid/set/486/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-486"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this work we present a technique to use natural language to help reinforcement learning generalize to unseen environments. This technique uses neural machine translation, specifically the use of encoder-decoder networks, to learn associations between natural language behavior descriptions and state-action information. We then use this learned model to guide agent exploration using a modified version of policy shaping to make it more effective at learning in unseen environments. We evaluate this technique using the popular arcade game, Frogger, under ideal and non-ideal conditions. This evaluation shows that our modified policy shaping algorithm improves over a Q-learning agent as well as a baseline version of policy shaping</p></td>
                </tr>
            
                <tr>
                    <td>49</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-49">Agent-Based Modeling of Emergency Evacuations Considering Human Panic Behavior</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent-based Simulation] Simulation of complex systems<br>[Humans and Agents] Agent-based analysis of human interactions</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_49" class="editable_bid" data-pk="49" data-value="30"
                    data-url="/rev_3/paper/bid/set/49/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-49"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>During mass evacuations, many psychological and physical factors are<br>responsible for stampedes and other life threatening<br>situations. Quantitative and qualitative analyses of these factors are<br>of high importance while devising optimal strategies for evacuations.<br>In this work we present an agent-based model that considers<br>psychological and physical factors that cause panic in such<br>situations.&nbsp; We have also simulated some simple evacuation scenarios<br>and presented a method to identify possible bottlenecks and<br>shortcomings in the environments during emergency evacuations.&nbsp; Our<br>method also helps in evaluation and analysis of different evacuation<br>strategies.&nbsp; To enable this analysis we have used a rule-based roadmap<br>approach, where critical nodes in the environment are identified by<br>the evacuation planner and each node has a special rule according to<br>the strategy of the planner.&nbsp; We evaluate different strategies on<br>parameters such as evacuation time and physical discomfort caused to<br>the agents.<br><br><br><p><br></p></p></td>
                </tr>
            
                <tr>
                    <td>425</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-425">Social Convention Emergence in Systems where Agents have Conflict of Interest</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Normative systems<br>[Agent Societies and Societal Issues] Self-organization</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_425" class="editable_bid" data-pk="425" data-value="30"
                    data-url="/rev_3/paper/bid/set/425/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-425"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Recently, social conventions, a type of social norms, have attracted much attention in the multi-agent system literature. We here focus on the case that each agent specially prefers one convention and is indifferent to all the others. Therefore, agents have conflict in to which particular convention they should conform, although conformity is in their common interest. We formalize such kind of scenarios as <i>coordination games with conflict of interest</i>. In these games, an agent prefers choosing the same action as its opponent's, i.e., coordination, over discoordination. However, agents have different degrees of preference on by which action to achieve coordination. In our experimental study, we investigate if and how a social convention can emerge in systems where agents play coordination games with conflict of interest with their neighbours repeatedly. Moreover, we identify two key factors, the ratios of agents which prefer different conventions and the degree of such preference, and investigate their influences on the speed, dynamics and individual payoffs of convention emergence phenomena.</p></td>
                </tr>
            
                <tr>
                    <td>348</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-348">When less is more: Reducing agent noise with probabilistically learning agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_348" class="editable_bid" data-pk="348" data-value="30"
                    data-url="/rev_3/paper/bid/set/348/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-348"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Distributed agents concurrently learning to coordinate in a multiagent system can suffer from considerable amounts of agent noise. This is the noise that arises from the non-stationarity of the learning environment for each individual agent since other agents in the system are also constantly updating their policies, thereby continually shifting the goal posts for successful coordination. In this work, we propose a method to reduce agent noise by allowing individual agents to probabilistically determine whether or not to undergo policy updates based on their estimated impact on the team learning performance. We show that using this method to adapt the number of actively learning agents over time provides improvements to the convergence speed of the team as a whole without affecting the final converged learning performance.<br></p></td>
                </tr>
            
                <tr>
                    <td>203</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-203">Trust Network-based Spam Worker Identification in Crowdsourcing Environments</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Trust and reputation<br>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_203" class="editable_bid" data-pk="203" data-value="30"
                    data-url="/rev_3/paper/bid/set/203/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-203"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Reputation-based defense models and trust network-based defense models have been widely investigated to defend against spammers in general online applications. In recent years, particularly targeting spam workers in crowdsourcing environments, several novel reputation-based models have also been proposed. However, the existing models overlook the fact that a spam worker can masquerade as an “honest” workers<br>by colluding with accomplices. In particular, a spam worker can obtain guises, such as a “good” reputation and trust links to honest requesters, via collusions. More importantly, the low or even free transaction fee and the availability of high-degree anonymity in crowdsourcing environments could allow spam workers to easily collude with accomplices to obtain guises.<br></p><p><br>In order to solve the challenging spam worker identification problem, in this paper, we propose a new model that is the first one to investigate trust network based features for identifying spam workers in crowdsourcing environments. In particular, we firstly propose a Crowdsourcing Trust Network (CTN). Based on it, we propose a novel worker trust representation called Worker Trust Matrix (WTM). A worker’s WTM is essentially a global trust feature set that consists of trust indicators measuring the extents to which the worker is trusted by different requesters in different sub-CTNs. Moreover, we prove that a WTM possesses the un-manipulable property and the usable property that are critical for effectively identifying a worker’s identity. Furthermore, we devise a learning-based algorithm to predict a worker’s identity with its WTM as input. Finally, we demonstrate the superior effectiveness of our proposed spam worker identification model in extensive experiments.<br></p></td>
                </tr>
            
                <tr>
                    <td>94</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-94">Modelling contingent modernisation of irrigation systems in farmer communities</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Policy, regulation and legislation<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_94" class="editable_bid" data-pk="94" data-value="30"
                    data-url="/rev_3/paper/bid/set/94/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-94"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Of all the uses of water, agriculture is the one that
requires the greatest proportion of water resources worldwide and, consequently,
it is a salient subject for policy-making and modernisation of irrigation
systems is a key instrument to improve water use efficiency. Because of
economies of scale, farmer communities that share irrigation infrastructure are
natural candidates for innovations. In this paper we present an agent-based
model of the modernisation process of a farmer community. The phenomenon is
approached as a contingent innovation adoption: a first stage of collective
agreement followed by an individual adoption decision. The model is based on
historical data from two Spanish "irrigator communities" during the
period 1975-2010. Results suggest that individual profits and farm extension
(as proxy of social influence) are suitable assumptions when modelling the modernisation
of communities in regions where agriculture is strongly market-oriented and
water is scarce. These results point towards the interest of more sophisticated
socio-cognitive modelling within a more realistic socio-hydrologic context.<br></p><p class="MsoPlainText"><o:p></o:p></p></td>
                </tr>
            
                <tr>
                    <td>479</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-479">Local Envy-Freeness with Indivisible Goods</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_479" class="editable_bid" data-pk="479" data-value="30"
                    data-url="/rev_3/paper/bid/set/479/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-479"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We study the fair division problem consisting in &nbsp;allocating one item per agent so as to avoid (or minimize) envy, in a setting where only agents connected in a given social network may experience envy. In a variant of the problem, agents themselves can be located on the network by the central authority. These problems turn out to be difficult even on very simple graph structures, but we identify several tractable cases. We further provide practical algorithms and experimental insights. &nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>567</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-567">Dynamic fans economy: sequential all-pay auctions with proportional allocations</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_567" class="editable_bid" data-pk="567" data-value="30"
                    data-url="/rev_3/paper/bid/set/567/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-567"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we study an extensive-form game, coined sequential
all-pay auctions with proportional allocations (SAPAPA), in which
bidders submit their bids in a given order and each gets allocated a
fraction of the item that equals the proportion of his bid over the
sum of all bids while paying his own bid. This game models realistic
scenarios where fans dynamically donate to a host in the so-called
fans economy model, recently proposed by Tang et al. [14]. This
game can also be thought of as an extensive form Tullock contest,
which has not been well understood in the literature. In contrast,
the simultaneous form of this game, aka. all-pay auctions with
proportional allocations (APAPA), has been well studied and shown
to have good revenue and welfare properties.
We conduct a game-theoretical analysis of the SAPAPA game.
We obtain the closed-form solution of the unique subgame perfect
equilibrium (SPE) in the two-player complete information setting
and prove there could be infinite many SPEs for some general nplayer
cases. In addition, we show that, for the general n-player
cases, when the bidders are ordered in ascending order of their
values, there exists a unique SPE and its revenue is at least half
of that of the second highest value. For the case of incomplete
information, we also prove the uniqueness of perfect Bayesian
equilibrium (PBE) for the two-player case and give a monotonicity
characterization of the PBE strategies.<br></p></td>
                </tr>
            
                <tr>
                    <td>774</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-774">Toward a Misrepresentation Game with Ambiguous Preferences</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_774" class="editable_bid" data-pk="774" data-value="30"
                    data-url="/rev_3/paper/bid/set/774/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-774"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
  <o:PixelsPerInch>96</o:PixelsPerInch>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:DrawingGridVerticalSpacing>10 pt</w:DrawingGridVerticalSpacing>
  <w:DisplayHorizontalDrawingGridEvery>0</w:DisplayHorizontalDrawingGridEvery>
  <w:DisplayVerticalDrawingGridEvery>2</w:DisplayVerticalDrawingGridEvery>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>JA</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:SpaceForUL/>
   <w:BalanceSingleByteDoubleByteWidth/>
   <w:DoNotLeaveBackslashAlone/>
   <w:ULTrailSpace/>
   <w:DoNotExpandShiftReturn/>
   <w:AdjustLineHeightInTable/>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
   <w:UseFELayout/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"/>
 </w:LatentStyles>
</xml><![endif]-->

<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:標準の表;
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0mm 5.4pt 0mm 5.4pt;
	mso-para-margin:0mm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Yu Mincho";
	mso-ascii-font-family:"Yu Mincho";
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:"Yu Mincho";
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:"Yu Mincho";
	mso-hansi-theme-font:minor-latin;
	mso-font-kerning:1.0pt;}
</style>
<![endif]-->



<!--StartFragment-->



<!--EndFragment--></p><p class="MsoNormal"><span lang="EN-US">In this paper, we show an analysis on a Misrepresentation
Game with ambiguous preferences. A Misrepresentation Game is a game that sometimes
an agent obtains higher utility than truth-telling on a preference-elicitation
based fair division negotiation by misrepresenting their preferences while it
is still difficult to be noticed by the counterpart. We investigate whether we
can generate mechanisms for fair negotiations which avoids incentives to make
misrepresentations by using a way of automated design of mechanisms.<o:p></o:p></span></p></td>
                </tr>
            
                <tr>
                    <td>497</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-497">A framework for a dynamic inter-connection of collaborating agents with multi-layered application abstraction based on a software-bus system</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Engineering Multiagent Systems] Programming languages and frameworks for agents and multi-agent systems</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_497" class="editable_bid" data-pk="497" data-value="30"
                    data-url="/rev_3/paper/bid/set/497/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-497"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>With the currently ongoing and necessary process to define standards for multi-agent systems, their potential for adaptation to specific underlying system requirements becomes increasingly challenging. Especially in applications, where MAS are coupled to hardware which has strict requirements to the logic-level controlling it, such as a specific response time, or quality-of-service. As a result, it is proposed to separate the high-level decision making process based on standardized MAS and the low-level control into two layers. In this paper, based on a publisher/subscriber software-bus system, we propose a framework which allows dynamic allocation and linking of agents to underlying low-level hardware control. The concept of the framework and its architecture is introduced as well as a proof-of-concept for dynamic agent linking.<br></p></td>
                </tr>
            
                <tr>
                    <td>394</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-394">Deep Recurrent Auto-encoder for Network Representation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Social networks<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_394" class="editable_bid" data-pk="394" data-value="30"
                    data-url="/rev_3/paper/bid/set/394/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-394"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In the research of network, a key problem is how to represent the network reasonably. Most existing network representation methods do not fully consider local and global information of the network. In this paper, we In network representation, a key problem is how to learn the network structure information. To solve this problem, a traditional way is making use of matrix factorization. However, almost all of these methods adopt shallow models and cannot capture the complex network structure. In recent years, neural networks based methods have been applied to this task. Though these methods make a certain progress than MF-based methods, most of them still have not fully considered the network structure including global and local information.&nbsp;</p><p>In this paper, to solve the network representation problem, we first present the concept of a small structure unit and then propose a deep recurrent auto-encoder model. For each small structure unit, we construct several global-local node sequences. Then the proposed model can learn the local and global information of the network by these node sequences. Specifically, we learn the global information of each node by a multi-layer nonlinear neural network, and preserve the local information by a recurrent neural network. Besides, to solve the sparse problem, we design a penalty mechanism to enhance existing link information in network. Finally, we evaluate our model on three real datasets and conduct extensive experiments on visualization, parameter sensitivity and efficiency. The result demonstrates that the proposed model can preserve network structure well for network representation.</p></td>
                </tr>
            
                <tr>
                    <td>195</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-195">Action Categorization for Computationally Improved Task Learning and Planning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_195" class="editable_bid" data-pk="195" data-value="30"
                    data-url="/rev_3/paper/bid/set/195/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-195"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper explores the problem of task learning and planning, contributing the <i>Action-Category Representation (ACR)</i> to improve computational performance of both Planning and Reinforcement Learning (RL). ACR is an algorithm-agnostic, abstract data representation that maps objects to action categories (groups of actions), inspired by the psychological concept of <i>action codes</i>. We validate our approach in StarCraft and Lightworld domains; our results demonstrate several benefits of ACR relating to improved computational performance of planning and RL, by reducing the action space for the agent.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>590</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-590">Multiagent RL for Real-World Interdependent Congestion Problems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Learning and Adaptation] Multiagent learning</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_590" class="editable_bid" data-pk="590" data-value="30"
                    data-url="/rev_3/paper/bid/set/590/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-590"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><div class="" style="font-family: Garamond; font-size: 15px; text-size-adjust: auto; margin: 0px;">In this article, we explore the computation of joint policies for autonomous agents to resolve multiple interdependent congestions.<span class="Apple-converted-space">&nbsp;</span></div><div class="" style="font-family: Garamond; font-size: 15px; text-size-adjust: auto; margin: 0px;">Agents have limited information about others' payoffs and preferences, and need to coordinate to achieve their tasks while adhering to operational constraints.&nbsp;</div><div class="" style="font-family: Garamond; font-size: 15px; text-size-adjust: auto; margin: 0px;">We formalize the generic problem as a multi-agent MDP, and instantiate it to a real-world problem: deciding required flight delays to resolve demand and capacity balance (DCB) problems in air traffic management (ATM).<span class="Apple-converted-space">&nbsp;</span></div><div class="" style="font-family: Garamond; font-size: 15px; text-size-adjust: auto; margin: 0px;">To this end, we present collaborative reinforcement learning methods that allow agents to interact and form own strategies in coordination with others.&nbsp;</div><div class="" style="font-family: Garamond; font-size: 15px; text-size-adjust: auto; margin: 0px;">We provide results on real-world ATM datasets, which confirm the effectiveness of our approach.</div></td>
                </tr>
            
                <tr>
                    <td>159</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-159">Winners-Restricted Utility- and Revenue-Maximizing Equilibria for Size-Interchangeable Bidders</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Other</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_159" class="editable_bid" data-pk="159" data-value="30"
                    data-url="/rev_3/paper/bid/set/159/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-159"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>A Walrasian equilibrium (WE) is a fundamental market outcome where all bidders are utility-maximizers (UM), and the market clears (MC), meaning that the price of unallocated goods is zero. However, a WE need not exist in combinatorial markets and, even if it exists, its revenue might be arbitrarily low. An Envy-Free Pricing (EFP) is one way to address the existence issue by dropping the MC condition. Although an EFP always exists, computing a revenue-maximizing EFP outcome remains computationally intractable even for simple combinatorial markets. In this paper, we propose a further relaxation of EFP, which we call Winners-Restricted Pricing (WiReP), which requires that only winners are UM. We show that a WiReP can be computed in polynomial time for some types of combinatorial markets, and develop methods to compute revenue-maximizing WiRePs for a fixed allocation. We embed these methods in a heuristic to search for revenue-maximizing outcomes over all feasible allocations, and show in extensive experiments that WiRePs&nbsp;are in fact close to WE while consistently achieving higher revenue and welfare than other algorithms in the literature.</p></td>
                </tr>
            
                <tr>
                    <td>565</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-565">Market making via reinforcement learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Economic Paradigms] Other</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_565" class="editable_bid" data-pk="565" data-value="30"
                    data-url="/rev_3/paper/bid/set/565/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-565"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><div>Market making is a fundamental trading problem in which an agent provides liquidity by continually offering to buy and sell a security. The problem is challenging due to inventory risk, the risk of accumulating an unfavourable position and ultimately losing money. In this paper, we develop a high-fidelity simulation of limit order book markets, and use it to design a market making agent using temporal-difference reinforcement learning. We use a linear combination of tile codings as a value function approximator, and design a custom reward function that controls inventory risk. We demonstrate the effectiveness of our approach by showing that our agent outperforms both simple benchmark strategies and a recent online learning approach from the literature.</div><div><br></div></td>
                </tr>
            
                <tr>
                    <td>688</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-688">Inverse Reinforcement Learning with Nonparametric Behavior Clustering</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.580</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_688" class="editable_bid" data-pk="688" data-value="30"
                    data-url="/rev_3/paper/bid/set/688/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-688"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Inverse Reinforcement Learning (IRL) is the task of learning
a single reward function given a Markov Decision Process
(MDP) without defining the reward function, and a set
of demonstrations generated by humans/experts. However, in
practice, it may be unreasonable to assume that human behaviors
can be explained by one reward function since they
may be inherently inconsistent. Also, demonstrations may be
collected from various users and aggregated to infer and predict
users’ behaviors. In this paper, we introduce the Nonparametric
Behavior Clustering IRL algorithm to simultaneously
cluster demonstrations and learn multiple reward functions
from demonstrations that may be generated from more
than one behaviors. Our method is iterative: It alternates between
clustering demonstrations into different behavior clusters
and inverse learning the reward functions until convergence.
It is built upon the Expectation-Maximization formulation
and non-parametric clustering in the IRL setting. Further,
to improve the computation efficiency, we remove the
need of completely solving multiple IRL problems for multiple
clusters during the iteration steps and introduce a resampling
technique to avoid generating too many unlikely clusters.
We demonstrate the convergence and efficiency of the
proposed method through learning multiple driver behaviors
from demonstrations generated from a grid-world environment
and continuous trajectories collected from autonomous
robot cars using the Gazebo robot simulator.<br></p></td>
                </tr>
            
                <tr>
                    <td>461</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-461">Traffic Optimization Using an Online Social Network</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Socio-technical systems<br>[Agent Societies and Societal Issues] Self-organization<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.570</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_461" class="editable_bid" data-pk="461" data-value="30"
                    data-url="/rev_3/paper/bid/set/461/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-461"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Traffic congestion is ubiquitous in cities across the globe and has great economic and environmental costs associated with it. Although real-time traffic updates are now available, the tendency of drivers to make uncoordinated routing decisions exacerbates the congestion problem. Existing solutions, both in private and public domains, do not provide efficient mechanisms for creating a socially optimal traffic distribution to overcome the congestion problem. In this paper, we present an online social network-based solution that enables drivers to coordinate about their route choices to overcome the congestion problem. We develop a route selection-based algorithm that favors a socially optimal distribution of traffic and reduces the average travel time of drivers. We study the effect of our approach on multiple networks, both synthetic and real. Extensive simulation results show that our approach is able to establish socially optimal traffic distribution in various networks as compared to existing road pricing-based techniques.<br></p></td>
                </tr>
            
                <tr>
                    <td>158</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-158">Fast Terminating Procedures for Equitable Stable Marriages</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Monitoring agent societies<br>[Economic Paradigms] Social choice theory<br>[Engineering Multiagent Systems] Methodologies for agent-based systems<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.570</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_158" class="editable_bid" data-pk="158" data-value="30"
                    data-url="/rev_3/paper/bid/set/158/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-158"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The stable marriage problem calls for finding a perfect bipartite matching among agents in a two-sided market (e.g., women and men, or job applicants and employers). Each agent ranks members of the opposite side by strictly decreasing preference. The solution must be {\em stable}, meaning that no pair of agents prefer each other to their assigned matches. Gale and Shapley proposed an algorithm that yields a stable solution for any instance of the problem in polynomial time. However, out of all possible stable matchings, the Gale-Shapley algorithm yields the best possible (optimal) preference to each agent on the one side, and the worst possible (pessimal) to each on the other side. Accordingly, the {\em equitable stable marriage} (ESM) problem calls for minimizing the distance between average assigned preferences on the two sides as a measure of equality. Unfortunately, this problem is strongly NP-hard. Proposed heuristics run for an unpredictable and unbounded number of iterations with non-guaranteed termination. Thus, a cardinal question has remained open since 1962: is there an efficient procedure that achieves equitable stable matchings and is guaranteed to terminate?<br></p><p>This paper resolves this open question. We show that knowledge of a stable matching can guide a procedure towards a stable matching, from a &nbsp;random starting position, and study the monotonicity properties of procedures leading to stability. Armed with these results, we design a suite of agent strategies and associated procedures that provably terminate to stable and equitable matchings in low-polynomial time. A thorough experimental study with diverse preference distributions shows that our procedures stand out in terms of equality and other quality measures.</p></td>
                </tr>
            
                <tr>
                    <td>639</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-639">An Agent-Based Traffic Signal Timing System for Alleviating Urban Traffic Congestion</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Other</td>
                    
                        <td>0.570</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_639" class="editable_bid" data-pk="639" data-value="30"
                    data-url="/rev_3/paper/bid/set/639/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-639"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal"><span style="background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;">In this paper we present a multi-agent
Traffic Signal Timing system (TST) for congestion reduction. The agent traffic
system is based on a real-world TST and intended to be deployed with minimal
changes to the infrastructure. As such, it considers attaching agents to
intersection controllers and using existing communication technologies. Our
fully decentralized agent TST has been validated on a simulated model of a city
comprising 128 intersections. The experimental results show that it outperforms
the conventional pre-timed and fully-actuated operation modes.</span><o:p></o:p></p></td>
                </tr>
            
                <tr>
                    <td>593</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-593">Towards Online Goal Recognition Combining Goal Mirroring and Landmarks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.570</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_593" class="editable_bid" data-pk="593" data-value="30"
                    data-url="/rev_3/paper/bid/set/593/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-593"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Online goal recognition is the problem of recognizing the goal of an agent based on an incomplete sequence of incrementally revealed observations as early along in the recognition process as possible.&nbsp;</p><p>Recognizing goals with minimal domain knowledge as an agent executes its plan requires efficient algorithms to sift through a large space of hypotheses.&nbsp;</p><p>We develop an online approach to goal recognition which operates in both continuous and discrete domains using a combination of Goal Mirroring and a generalized notion of landmarks adapted from the planning literature.&nbsp;</p><p>Extensive experiments demonstrate the approach is more efficient and substantially more accurate than the state-of-the-art.</p></td>
                </tr>
            
                <tr>
                    <td>681</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-681">Detecting miscomunication in dialogue with conversational agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Other<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.570</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_681" class="editable_bid" data-pk="681" data-value="30"
                    data-url="/rev_3/paper/bid/set/681/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-681"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>During the process of mastering language for the purpose of communication, humans are able to successfully learn how to overcome issues in dialogue. We believe a similar process could be used in dialogue agents when dealing with miscommunication issues. We propose the creation of two models: a preventive one, which detects problematic dialogue turns before answering the user; and a reactive one, which marks previous interactions as problematic. These models can be used to prevent miscommunication during dialogue and to assist in the analysis of human-agent dialogue logs, in order to detect problems and potential improvements on the agent's strategies and Knowledge Base.<br><br>To evaluate our approach, we collected 
and annotated a corpus of interactions in European Portuguese (that will
 be freely available) with AGENT-X, a conversational agent that answers 
questions posed by PLACE-X visitors, and tested our approach achieving an F-Measure of 0.84 
with 0.93 True Negative rate, showing that is possible to use the 
training data to reduce the amount of dialogue turns an agent's developer 
has to review.</p></td>
                </tr>
            
                <tr>
                    <td>508</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-508">Establishing Relationships between Security and Efficiency: a Case Study in Airport Terminals</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.570</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_508" class="editable_bid" data-pk="508" data-value="30"
                    data-url="/rev_3/paper/bid/set/508/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-508"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Both security and efficiency are important performance areas of air transport systems. Several methods have been proposed in literature to assess security risks and estimate efficiency, but only few of these methods identify relationships between security risks and efficiency indicators. However, intuitively there is a relationship between security and efficiency. For example, removing the security checkpoint from the airport leads to lower waiting times for passengers, but reduces security. To identify and quantify such relationships, an agent-based methodology is proposed in this work. This methodology combines an agent-based security risk assessment approach with agent-based efficiency estimation. The methodology is applied to a case study that identifies relationships between security regarding an Improvised Explosive Device (IED) attack and different efficiency indicators in the aviation domain. Results show relationships between risks regarding an IED attack and efficiency indicators like queuing time for passengers and number of missed flights. The proposed methodology was showed to be useful to find and quantify relationships between security and efficiency and therefore forms a promising way to investigate different trade-offs in detail.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>424</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-424">Adaptive Incentive Selection for Crowdsourcing Contests</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Humans and Agents] Agent-based analysis of human interactions<br>[Humans and Agents] Agents for improving human cooperative activities<br>[Humans and Agents] Other</td>
                    
                        <td>0.570</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_424" class="editable_bid" data-pk="424" data-value="30"
                    data-url="/rev_3/paper/bid/set/424/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-424"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The success of crowdsourcing projects relies critically on motivating the crowd to contribute. One particularly effective method for incentivising participants to perform tasks is to run contests. However, there are numerous ways to implement such contests in specific projects (that vary in how performance is evaluated, how to reward, and the sizes of the prizes). Additionally, with a given financial budget and a time limit, choosing incentives that maximise the total outcome (e.g., the total number of completed tasks) is not trivial, as their effectiveness in a specific project is usually unknown in advance. Therefore, in this paper, we introduce algorithms to select such incentives effectively using budgeted multi-armed bandits. To do that, we first introduce the \kw{incentive selection problem}, then formalise it as a 2d-budgeted multi-armed bandit, where each arm corresponds to an incentive (i.e., a contest with a specific structure). We then propose the HAIS and Epsilon First algorithms to solve the incentive selection problem. The two algorithms are shown to be effective on both synthetic data and authentic data with a real microtask crowdsourcing project. Epsilon First performs well, but requires a situation-specific parameter to be tuned appropriately (which may be difficult in settings with little prior experience). In contrast to this, HAIS performs better in most cases without depending significantly on the parameter tuning.<br></p></td>
                </tr>
            
                <tr>
                    <td>317</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-317">PANO: Privacy Auctioning for Online Social Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Economic Paradigms] Auctions and mechanism design<br>[Humans and Agents] Agents for improving human cooperative activities</td>
                    
                        <td>0.570</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_317" class="editable_bid" data-pk="317" data-value="30"
                    data-url="/rev_3/paper/bid/set/317/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-317"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Online Social Networks (OSNs) enable their users to share content with their connections.&nbsp; Shared contents over OSNs raise privacy concerns, since they tend to contain personal information of users. More importantly, a single content, e.g, a photo of a group of people, can potentially contain private information of multiple users, which become available without their consent.&nbsp; Ensuring that all relevant users' privacy requirements are met is important but difficult since the requirements can easily be conflicting.&nbsp; Hence, mechanisms to resolve privacy disputes are needed.&nbsp; Accordingly, this paper proposes an agent-based collaborative privacy management model, where agents represent users and manage their privacy requirements.&nbsp; When an image is about to be shared, the relevant agents enter an auction and bid on behalf of their users about how private the considered image is. The bids are processed with a modified version of Clarke-Tax mechanism that achieves fair handling of privacy settings and taxes the agents whose privacy settings are chosen.&nbsp; We evaluate our approach over multi-agent simulations and show that it produces privacy policies efficiently and more accurately than existing approaches.</p></td>
                </tr>
            
                <tr>
                    <td>367</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-367">Practical Scalability for Stackelberg Security Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: computation</td>
                    
                        <td>0.570</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_367" class="editable_bid" data-pk="367" data-value="30"
                    data-url="/rev_3/paper/bid/set/367/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-367"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Stackelberg Security Games (SSGs) have been adopted widely for modeling adversarial interactions. With increasing size of the applications of SSGs, scalability of equilibrium computation is an important research problem. While prior research has made progress with regards to scalability, many real world problems cannot be solved satisfactorily yet as per current requirements; these include the deployed federal air marshals (FAMS) application and the threat screening (TSG) problem at airports. Further, scalability in these problem domains is inherently limited by NP hardness shown in prior literature. We initiate a principled study of approximations in zero-sum SSGs. Our contribution includes the following: (1) a unified model of SSGs called adversarial randomized allocation (ARA) games that allows studying most SSGs in one model, (2) hardness of approximation results for zero-sum ARA, as well as for the sub-problem of allocating federal air marshal (FAMS) and threat screening problem (TSG) at airports, (3) an approximation framework for zero-sum ARA with instantiations for FAMS and TSG using intelligent heuristics along with provable approximation guarantees and (4) experiments demonstrating the significant scalability of up to 1000x improvement in runtime with an acceptable 5% solution quality loss.<br></p></td>
                </tr>
            
                <tr>
                    <td>393</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-393">The Core of Hedonic Games under Enemies Aversion: Algorithms, Probabilities and Experiments</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Economic Paradigms] Cooperative games: computation</td>
                    
                        <td>0.570</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_393" class="editable_bid" data-pk="393" data-value="30"
                    data-url="/rev_3/paper/bid/set/393/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-393"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We investigate hedonic games under enemies aversion when each agent considers other agents to be friends, enemies, or neutrals. The core's existence, its computation and other characteristics are fundamental issues in coalition formation games. The core can be empty and deciding core non-emptiness is intractable (i.e., $\Sigma_2^P$-complete). In this paper, we first obtain a new counter-example showing that the core can be empty even when the agent relations are symmetric. Secondly, we face the challenge of computing core-stable coalition structures, despite this problem's high intractability. It turns out that by column generation, our MILP formulation scales surprisingly well with respect to the number of agents. Thirdly, we prove formally that the core's expected size is at least an exponential of the number of agents. Finally, our experiments show that the core is very unlikely to be empty, despite the counter-examples, and we observe that on average the core's size is indeed exponential with respect to the number of agents.<br></p></td>
                </tr>
            
                <tr>
                    <td>455</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-455">Deep Multiagent Q-Learning for Autonomous Agents in Future Smart Grid</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.570</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_455" class="editable_bid" data-pk="455" data-value="30"
                    data-url="/rev_3/paper/bid/set/455/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-455"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Modern smart grid is an information-based electricity transmission and distribution system deployed with digital technologies to automatically manage electricity delivery and achieve sustainability, reliability, security, and efficiency of the electric grid. Broker mechanism is widely applied to serve for interested parties in smart grid. However, smart grid constitutes a complex, dynamic and real-time environment and raises great challenge for brokers, such as balancing demand and supply from customers and competing with other efficient brokers to gain profits. In this paper, we develop a pricing strategy for broker agents in local electricity retail market based on recurrent deep multiagent reinforcement learning. We introduce real data to simulate the retail market and evaluate the proposed broker pricing strategy. The experiments demonstrate the superior performance of deep reinforcement learning technique and highlight the effectiveness of the proposed pricing strategy with contribution value calculation in the context of complex environment.<br></p></td>
                </tr>
            
                <tr>
                    <td>513</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-513">Multi-player Flow Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: computation<br>[Engineering Multiagent Systems] Methodologies for agent-based systems<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.570</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_513" class="editable_bid" data-pk="513" data-value="30"
                    data-url="/rev_3/paper/bid/set/513/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-513"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
<style type="text/css">
p, li { white-space: pre-wrap; }
</style>
</p><pre style="margin-bottom: 0px;"><!--StartFragment--><span style=" color:#000000;">In the traditional maximum-flow problem, the goal is to transfer maximum flow in a network by directing, in each vertex in the network, incoming flow into outgoing edges. The problem corresponds to settings in which a central authority has control on all </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">vertices</span><span style=" color:#000000;"> of the network. Today's computing environment, however, involves systems with no central authority. In particular, in many applications of flow networks, the </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">vertices</span><span style=" color:#000000;"> correspond to decision-points controlled by different and selfish entities. For example, in communication networks, routers may belong to different companies, with different destination objectives. This suggests that the maximum-flow problem should be revisited, and redefined as a game.</span></pre><p>
</p><pre style="margin-bottom: 0px;"><br></pre><p>
</p><pre style="margin-bottom: 0px;"><span style=" color:#000000;">We introduce and study {</span><span style=" color:#800000;">\em</span><span style=" color:#000000;"> </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">multi</span><span style=" color:#000000;">-player flow games</span><span style=" color:#800000;">\/</span><span style=" color:#000000;">} (</span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">MFGs</span><span style=" color:#000000;">, for short). Essentially, the </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">vertices</span><span style=" color:#000000;"> of an MFG are partitioned among the players, and a player that owns a vertex directs the flow that reaches it. Each player has a different target vertex, and the objective of each player is to maximize the flow that reaches her target vertex. We study the stability of </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">MFGs</span><span style=" color:#000000;"> and show that, unfortunately, an MFG need not have a Nash Equilibrium. Moreover, the Price of Anarchy and even the Price of Stability of </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">MFGs</span><span style=" color:#000000;"> are unbounded. That is, the reduction in the flow due to selfish behavior is unbounded. We also study the problem of deciding whether a given MFG has a Nash Equilibrium and show that it is </span><span style=" color:#008000;">$\Sigma_2^P$</span><span style=" color:#000000;">-complete, as well as the problem of finding optimal strategies for the players, which we show to be NP-complete. We continue with some good news and consider a variant of </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">MFGs</span><span style=" color:#000000;"> in which flow may be swallowed. For example, when routers in a communication network may drop messages.​ We show that, surprisingly, while this model seems to </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">incentivize</span><span style=" color:#000000;"> selfish behavior, a Nash Equilibrium that achieves the maximum flow always exists, and can be found in polynomial time. Finally, we consider </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">MFGs</span><span style=" color:#000000;"> in which the strategies of the players may use non-integral flows, which we show to be stronger.</span><!--EndFragment--></pre></td>
                </tr>
            
                <tr>
                    <td>389</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-389">Matching domain to top level ontologies for enhancing agent interoperability</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Ontologies for agents<br>[Knowledge Representation and Reasoning] Other</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_389" class="editable_bid" data-pk="389" data-value="30"
                    data-url="/rev_3/paper/bid/set/389/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-389"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Ontologies play a fundamental role in Multi-Agent systems, formalizing the knowledge from the agent's perception of the world. Ontology matching is a primary problem that has to be solved in order to allow agents with different backgrounds to adjust themselves before starting any form of cooperation or communication. In this task, top-level ontologies provide a well-founded common understanding that can be shared across knowledge domains and that acts as semantic bridges helping the matching task. However, most domain ontologies are not equipped with alignments to top-level ontologies and automatically finding such alignments is an open problem in the field. In this paper, we propose a background knowledge-based ontology matching approach for automatically matching domain and top-level ontologies. We run our experiments on two agent domain ontologies (SSN and CORA) and two well-known top-level ontologies (DOLCE and SUMO). Our approach outperforms state-of-the-art matching systems in this task.</p></td>
                </tr>
            
                <tr>
                    <td>98</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-98">Hypersequential Argumentation Frameworks: An Instantiation in the Modal Logic S5</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Deductive, rule-based and logic-based argumentation<br>[Communication and Argumentation] Other<br>[Knowledge Representation and Reasoning] Other</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_98" class="editable_bid" data-pk="98" data-value="30"
                    data-url="/rev_3/paper/bid/set/98/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-98"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper we introduce hypersequent-based frameworks for the modeling of defeasible reasoning by means of logic-based argumentation. These frameworks are an extension of sequent-based argumentation frameworks, in which arguments are represented not only by sequents, but by more general expressions, called hypersequents. This generalization allows to incorporate, as the deductive-base of our formalism, some well-studied logics like the modal logic S5, the relevance logic RM, and Gödel-Dummett logic LC, to which no cut-free sequent calculi are known. In this paper we take S5 as the core logic and show that the hypersequent-based argumentation frameworks that are obtained in this case yield a robust defeasible variant of S5 with several desirable properties.<br></p></td>
                </tr>
            
                <tr>
                    <td>177</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-177">Rapid Randomized Restarts for Multi-Agent Path Finding Solvers</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Agent Cooperation] Multi-robot systems</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_177" class="editable_bid" data-pk="177" data-value="30"
                    data-url="/rev_3/paper/bid/set/177/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-177"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Multi-Agent Path Finding (MAPF) is an NP-hard problem well studied in artificial intelligence and robotics. It has many real-world applications for which existing MAPF solvers use various heuristics. However, these solvers are deterministic and perform poorly on ``hard'' instances which are typically characterized by many agents interfering with each other in a small region of space. In this paper, we enhance MAPF solvers with randomization and observe that they exhibit heavy-tailed distributions of runtimes on hard instances. This leads us to develop simple rapid randomized restart (RRR) strategies with the intuition that, given a hard instance, multiple short runs will have a better chance of solving it than one long run. We validate this intuition through experiments, showing that our RRR strategies indeed boost the performance of state-of-the-art MAPF solvers such as iECBS, M* and CBS-CL.<br></p></td>
                </tr>
            
                <tr>
                    <td>502</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-502">Distributed bottom-up bus regulation mechanism in urban traffic</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_502" class="editable_bid" data-pk="502" data-value="30"
                    data-url="/rev_3/paper/bid/set/502/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-502"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>For several decades, urban congestion has caused various nuisances for the inhabitants of the cities. There are several responses to this problem, including traffic regulation and the development of public transport, which helps mitigate the negative effects. The problem with public transport is that it is sometimes not reliable in terms of arriving time, especially for buses since they depend on the traffic condition. Developments in technology over the last few decades have improved the level of vehicle equipment, making it possible to offer new answers to the problems related to this issue.</p><p>Vehicles are now able to communicate and coordinate, and recent approaches are taking advantage of these advances to solve research problems that may be related to different requirements such as safety, comfort, energy efficiency or the one we are interested in more particularly in the context of this paper, namely the punctuality of buses. We propose in this paper a distributed coordination mechanism allowing intersections to anticipate to provide a clear path for the bus, allowing it to reach the bus stops in time.<br></p></td>
                </tr>
            
                <tr>
                    <td>194</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-194">Modeling Normative Multi-Agent Systems from a Kelsenian Perspective</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Normative systems<br>[Engineering Multiagent Systems] Modelling and specification languages<br>[Agent Theories and Models] Logics for norms and normative systems</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_194" class="editable_bid" data-pk="194" data-value="30"
                    data-url="/rev_3/paper/bid/set/194/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-194"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Standard Deontic Logic (SDL) has been used as the underlying logic to model and reason over Multi-Agent Systems governed by norms (NorMAS). It is known that SDL is not able to represent contrary-to-duty (CTD) scenarios in a consistent way. That is the case, for example, of the so-called Chisholm paradox, which models a situation in which a conditional obligation that specifies what must be done when a primary obligation is violated holds. In SDL, the set of sentences that represent the Chisholm paradox derives inconsistent sentences. Due to the <i>autonomy </i>of the software agents of a NorMAS, norms may be violated and the underlying logic used to model the NorMAS should be able to represent <i>violation scenarios</i>. The contribution of this paper is threefold: (i) we present how Kelsenian thinking, from his jurisprudence in the context of legal ontologies, and Intuitionist Hybrid Logic can be adopted in the modeling of NorMAS, (ii) discuss how this approach overcomes limitations of the SDL and (iii) present a discussion about normative conflict identification according to Hill's functional taxonomy, that generalizes from standard identification by impossibility-of-joint-compliance test.<br></p></td>
                </tr>
            
                <tr>
                    <td>316</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-316">Peer Prediction with Heterogeneous Tasks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_316" class="editable_bid" data-pk="316" data-value="30"
                    data-url="/rev_3/paper/bid/set/316/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-316"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Peer prediction promotes contributions of useful information
by users in settings in which there is no way to verify the quality
of responses. This paper introduces the problem of peer
prediction with heterogeneous tasks, where each task is associated
with a different distribution on responses. The motivation
comes from eliciting user-generated content about places
in a city, where tasks vary because places and questions about
places vary. We extend the correlated agreement (CA) mechanism
((Shnayder et al. 2016a)) to this setting, aligning incentives
for investing effort without creating opportunities for coordinated
manipulations. We demonstrate in simulation much
better incentive properties than other mechanisms, using data
from user reports on a crowdsourcing platform.<br></p></td>
                </tr>
            
                <tr>
                    <td>357</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-357">A Robust Method for Inferring User Intention in a Dynamic Environment using Gaze</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Verification and Validation of Agent-based Systems] Fault tolerance and resilience of multi-agent systems<br>[Humans and Agents] Human-robot/agent interaction<br>[Humans and Agents] Agent-based analysis of human interactions</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_357" class="editable_bid" data-pk="357" data-value="30"
                    data-url="/rev_3/paper/bid/set/357/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-357"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The ability of an autonomous system to understand something about a human's intent is important to the success of many systems that involve both humans and autonomous agents. In this work, we consider the specific setting of a human passenger riding in an autonomous vehicle, where the passenger intends to go to or learn about a specific point of interest along the vehicle's route. In this setting, we seek to provide the vehicle with the ability to infer this point of interest using real-time gaze information. This is a difficult problem in that the inference must be designed in the context of the moving vehicle, i.e., in a dynamic environment with dynamic interest points. We propose here a solution to this problem via a novel methodology called Dynamic Interest Point Detection (DIPD) for inferring the point of interest corresponding to the human's intent using gaze tracking data and a dynamic Markov Random Field (MRF) model. The energy function we develop allows the algorithm to successfully filter out noise from the eye tracker, such as eye blinks, high-speed tracking misalignment, and other sources of error. We demonstrate the success of our DIPD technique experimentally, and show improvement over both nearest-neighbor and filtered-nearest-neighbor approaches.<br></p></td>
                </tr>
            
                <tr>
                    <td>44</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-44">Protecting Election from Bribery: New Approach and Computational Complexity Characterization</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Engineering Multiagent Systems] Methodologies for agent-based systems</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_44" class="editable_bid" data-pk="44" data-value="30"
                    data-url="/rev_3/paper/bid/set/44/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-44"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Protecting election from bribery is an important problem that has received considerable attention, including many algorithmic and complexity results. In this paper, we initiate the study of a new approach to protecting election from bribery. The basic idea underlying the new approach is to "award some voters" for their honesty (i.e., an awarded voter cannot be bribed by the attacker). This approach naturally leads to the following bi-level decision problem: Is it possible for the defender with a given award budget to protect a proper subset of the voters such that no attacker with a fixed budget for bribing can manipulate the election? We give the first systematic characterization on the computational complexity of this "protection problem". Compared with many other studies in the field of voting systems, the computation complexity of our protection problem is, in general, very high. For example, the problem is $\Sigma_2^p$-complete even for very restricted special cases, in contrast to the NP-completeness of most problems studied before. Nevertheless, we characterize the parameter settings in which the protection problem is in P, NP or $\Sigma_2^p$, which can be used to guide the design and analysis of real-world elections.</p></td>
                </tr>
            
                <tr>
                    <td>573</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-573">CrowdEval: A Cost-Efficient Strategy to Evaluate Crowdsourced Workers’ Reliability</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Trust and reputation<br>[Agent Cooperation] Coalition formation (non-strategic)<br>[Agent Cooperation] Collective intelligence<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_573" class="editable_bid" data-pk="573" data-value="30"
                    data-url="/rev_3/paper/bid/set/573/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-573"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Crowdsourcing platforms depend on the quality of work provided by a distributed workforce. Yet, it is challenging to dependably measure the reliability of these workers, particularly in the face of strategic or malicious behavior. In this paper, we present a dynamic and efficient solution to keep tracking workers’ reliability. In particular, we use both gold standard evaluation and peer consistency evaluation to measure each worker performance, and adjust the proportion of the two types of evaluation according to the estimated distribution of workers’ behavior (e.g., being reliable or malicious). Through experiments over real Amazon Mechanical Turk traces, we find that our approach has a significant gain in terms of accuracy and cost compared to state-of-the-art algorithms.</p></td>
                </tr>
            
                <tr>
                    <td>163</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-163">Personalized Peer Truth Serum for Crowdsourcing Multi-Attribute Personal Data</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Humans and Agents] Other</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_163" class="editable_bid" data-pk="163" data-value="30"
                    data-url="/rev_3/paper/bid/set/163/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-163"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>Recently, peer consistency based schemes have been proposed that incentivize crowd for investing effort and answering honestly. Such game theoretic schemes require that a group of peer agents evaluate a common object (such as an image) and report the labels independently. The reward is calculated based on statistical match in the reports provided by different agents.</p><p>In this paper, we formulate the problem of eliciting multi-attribute personal data from a crowd. Personal attributes of individuals are important in personalization algorithms and in other studies but are difficult to obtain. With attributes being personal in nature, there are no obvious peers in this case. We show how to extend an incentive scheme, the Peer Truth Serum, to settings where participants report combinations of individual data, by exploiting coherence of the different data items with what is reported by others. This new scheme applies, for example, to collecting personal health records or other multi-attribute measurements about personal properties such as smart homes. We provide a theoretical analysis of the incentive properties of the new scheme and show the performance of the scheme on several public datasets involving personal data, which further confirms the theoretical analysis.</p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>42</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-42">A Ranking Semantics based on Subgraphs Analysis</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_42" class="editable_bid" data-pk="42" data-value="30"
                    data-url="/rev_3/paper/bid/set/42/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-42"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style="margin-bottom: 0px;">In this paper we first propose a measure of the sensitivity of an argument in an abstract argumentation framework. The index is an indicator of how sensitive is the label assigned to the argument by an argumentation semantics. This numerical indicator is derived from the topology of the graph via a subgraphs analysis, coupled with the postulates of the chosen semantics. </p><p style="margin-bottom: 0px;">Using the total rank on arguments induced by such indicator, we propose two ranking-based semantics. We compare the behaviour of our ranking-semantics with recent proposals and a widespread set of properties identified in literature.</p><p style="margin-bottom: 0px;">A key feature of the semantics is that the attack relation between arguments keeps the same meaning as found in Dung' abstract semantics.</p><p>


</p><p style="margin-bottom: 0px;">By still relying on Dung' semantics we can soundly deal with any graph configuration, produce justified results, minimize the addition of ad-hoc postulates and provide a clear interpretation of the ranking of arguments.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>50</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-50">Multilevel Holonification Model : Application to Road Traffic Simulation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Simulation techniques, tools and platforms<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_50" class="editable_bid" data-pk="50" data-value="30"
                    data-url="/rev_3/paper/bid/set/50/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-50"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Organizational models and holonic multi-agent systems are growing as a powerful tool for modeling and developing large-scale complex system.&nbsp; The main issue in deploying holonic multiagent systems is the&nbsp; building of the holonic model called holarchy. This paper presents a novel density approach to cluster and hierarchize population in order to build the holarchy. The proposal extends DBSCAN algorithm. Moreover,&nbsp; multilevel indicators based on standard deviation&nbsp; are proposed in order to evaluate the consistency of the holonification process. The proposed model is&nbsp; tested in a road traffic modeling.<br></p></td>
                </tr>
            
                <tr>
                    <td>625</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-625">Database Aggregation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_625" class="editable_bid" data-pk="625" data-value="30"
                    data-url="/rev_3/paper/bid/set/625/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-625"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Knowledge can be represented compactly in a multitude ways, from a set 
of propositional formulas, to a Kripke model, to a database. In this 
paper we study the aggregation of information coming from multiple 
sources, each source submitting a database modelled as a first-order 
relational structure. In the presence of an integrity constraint, we 
identify classes of aggregators that respect it in the aggregated 
database, provided all individual databases satisfy it. We also 
characterise languages for first-order queries on which the answer to 
queries on the aggregated database coincides with the aggregation of the
 answers to the query obtained on each individual database. This 
contribution is meant to be a first step on the application of 
techniques from rational choice theory to knowledge representation in databases.<br></p></td>
                </tr>
            
                <tr>
                    <td>450</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-450">Combine Abstract Algorithm and Midgame solving to Bulid Stronger Poker AI</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Other<br>[Learning and Adaptation] Adversarial machine learning<br>[Humans and Agents] Agents competing against humans</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_450" class="editable_bid" data-pk="450" data-value="30"
                    data-url="/rev_3/paper/bid/set/450/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-450"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block">Poker has been an ongoing challenge in artificial intelligence
for long time. The traditional approach for solving no-limit
poker is that first use abstract algorithm to produce an smaller
abstract game for the original game and then use
Counterfactual regret minimization to compute an Nash equilibrium
of the abstract game, finally map abstracted game
Nash equilibrium to the original game. But using action abstraction
causes the off-tree poblem that is part of reasons
why computer program Claudico lost to a team of top poker
players. Very recent work uses the midgame solving to
relieve this problem. Before the Midgame, we use the abstract
algorithm and CFR to produce precomputed strategies.
The midgame solver is produce the strategies in real time.
Midgame solve each round independently but needs hand
ranges of players including opponents as input. The previous
work assumes each hand of opponents has the same probability
or use the strategy of itself to compute the hand ranges
of opponents which is unreasonable. So in this paper, we
present an data-based model to predit the opponents’ range
while solving the Midgame, and we also use the modified
Effective hand strength to evaluate more exact payoff for
the Midgame than before. Finally, we make a change to the
Midgame solving that we always solve a midgame to product
a strategy for a new state every time it is our turn to take
actions while playing different from the previous work. Utilizing
our approaches we produce an stronger agent for no-limit
Texas Hold’em and win 3th in 2017 Annual Computer Poker
Competition .</td>
                </tr>
            
                <tr>
                    <td>535</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-535">An FPTAS for Computing Nash Equilibrium in Resource Graph Games, with Applications to Security Games, Congestion Games, and Bilinear Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_535" class="editable_bid" data-pk="535" data-value="30"
                    data-url="/rev_3/paper/bid/set/535/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-535"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><div style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: small;">We consider the computational complexity of computing a mixed-strategy Nash equilibrium (MSNE)&nbsp; in resource graph games (<g class="gr_ gr_12 gr-alert gr_spell gr_inline_cards gr_run_anim ContextualSpelling ins-del multiReplace" id="12" data-gr-id="12" style="display: inline; color: inherit !important; font-size: inherit !important; border-bottom: 2px solid transparent; background-repeat: no-repeat; background-position: -1px calc(100% + 3px); background-image: url(&quot;data:image/svg+xml;charset=utf8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='100%' height='100%'%3E%3Cline opacity='0.75' x1='4' y1='100%' x2='100%' y2='100%' transform='translate(-1.5, -2.5)' stroke-width='3' stroke-linecap='round' stroke='%23fc5454'/%3E%3C/svg%3E&quot;); background-size: calc(100% + 1px) 100%; animation: gr__appear_critical 0.4s ease forwards;">RGGs</g>), a compact representation for games with an exponential number of strategies. In an RGG, there are m resources and a directed graph of the resources, and each player's pure strategy set consists of subsets of resources. Each player's pure strategy is represented by a binary vector, and the pure strategy set is represented compactly using a rational polytope defined by a set of linear inequality constraints. Given the pure strategies of the players, each player's utility depends on the directed resource graph&nbsp;and the numbers of times the neighboring resources are used.&nbsp;</div><div style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: small;"><br></div><div style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: small;">In this paper, we provide the first FPTAS for computing an MSNE in any symmetric multilinear RGG&nbsp;</div><div style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: small;">where its constraint moralized resource graph (a graph formed between the moralized resource graph&nbsp;and the constraints defining the strategy polytope) has bounded treewidth. Our FPTAS can be generalized to a constant number of player types. As a consequence, our FPTAS provides the first and improved approximation results for domain-specific games such as general multiple-attack single-attacker and single-defender security&nbsp;games and congestion games, respectively. Finally, leveraging the RGG representation and our FPTAS result, we obtain an FPTAS to compute an MSNE for a large class of bilinear games.</div></td>
                </tr>
            
                <tr>
                    <td>319</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-319">Automatic Generation of Multi-Agent Programs from Ontology Models</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Ontologies for agents<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Engineering Multiagent Systems] Methodologies for agent-based systems</td>
                    
                        <td>0.560</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_319" class="editable_bid" data-pk="319" data-value="30"
                    data-url="/rev_3/paper/bid/set/319/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-319"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper presents our proposal for the development of multi-agent systems designed as ontology models supporting code generation. The foundation of such work takes into consideration ontologies for agent-oriented software engineering aligned with the JaCaMo framework. These techniques are implemented in a tool that supports multi-agent systems core code generation for JaCaMo. The underlying ontology also allows for reasoning about the multi-agent systems models under development. Such comprehensive approach therefore spans through the modelling, programming, and verification of agent-oriented software.<br></p></td>
                </tr>
            
                <tr>
                    <td>771</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-771">Cost-Free Advertising for Selling Multiple Items in Social Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_771" class="editable_bid" data-pk="771" data-value="30"
                    data-url="/rev_3/paper/bid/set/771/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-771"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
</p><pre style="margin-bottom: 0px;"><pre style="margin-bottom: 0px;"><span style=" color:#000000;">We consider a market where a seller sells multiple units of a commodity in a social network. Each node/buyer in the social network can only directly communicate with her neighbours, i.e. the seller can only directly sell the commodity to her neighbours without any advertising. In this paper, we design a cost-free advertising mechanism that </span><span style=" text-decoration: underline; color:#000000;">incentivizes</span><span style=" color:#000000;"> all buyers, who are aware of the sale, to invite all their neighbours to join the sale, even though there is no guarantee that their effort will be paid. While traditional prepaid sale promotions such as sponsored search auction cannot guarantee a positive return for the advertisers, our mechanism guarantees that the seller's revenue is greatly improved compared with </span><span style=" text-decoration: underline; color:#000000;">VCG</span><span style=" color:#000000;"> without advertising, and the seller does not need to pay if the advertising is not beneficial to the seller. </span><!--EndFragment--></pre><!--EndFragment--></pre></td>
                </tr>
            
                <tr>
                    <td>399</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-399">Mitigating the Curse of Correlation in Security Games by Entropy Maximization</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_399" class="editable_bid" data-pk="399" data-value="30"
                    data-url="/rev_3/paper/bid/set/399/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-399"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">In Stackelberg security games, a defender seeks to randomly allocate limited security resources to protect critical targets from an
attack. In this paper, we study a fundamental, yet underexplored,
phenomenon in security games, which we term the </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineTI'">Curse of Correlation </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">(CoC). Specifically, we observe that there are </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineTI'">inevitable
</span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">correlations among the protection status of different targets. Such
correlation is a crucial concern, especially in </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineTI'">spatio-temporal </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">domains like conservation area patrolling, where attackers can surveil
patrollers at certain areas and then infer their patrolling routes
using such correlations. To mitigate this issue, we propose to design entropy-maximizing defending strategies for spatio-temporal
security games, which frequently suffer from CoC. We prove that
the problem is #P-hard in general. However, it admits efficient algorithms in well-motivated special settings. Our experiments show
significant advantages of max-entropy algorithms over previous
algorithms. A scalable implementation of our algorithm is currently
under pre-deployment testing for integration into FAMS software
to improve the scheduling of US federal air marshals.&nbsp;</span></p>
				</div>
			</div>
		</div>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>247</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-247">A Prioritized Routing Agent for Flow of Traffic</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_247" class="editable_bid" data-pk="247" data-value="30"
                    data-url="/rev_3/paper/bid/set/247/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-247"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Traffic management during emergency evacuation presents an important set of challenges as compared to regular traffic management. We focus here on one particular challenge, namely prioritized routing. Prioritized routing may happen even during normal times, but it becomes even more important during emergencies, as emergency vehicles, police vehicles and large vehicles (such as buses) that carry a lot of people need to have a higher priority in terms of evacuation. It is also reasonable to assume that traffic police may need to perform a centralized control of traffic, since they typically have a global view of the emergency and have accurate real-time updates. The Ford-Fulkerson and other known algorithms which perform an efficient centralized planning of routes for evacuation in different conditions, do not handle this issue of prioritized routing. Hence, we focus on this problem and make the following contributions in this paper: (a) First, we develop an agent called Prioritized Routing Agent for Flow of Traffic (PRAFT) that can encode the notion of priority for vehicles as well as priority of routes for helping the traffic police perform a prioritized routing, while computing the maximum flow solution. Uniform Cost Search (UCS) is used as a key step in this procedure. (b) Through a series of experiments performed using the well-known traffic simulator SUMO, we establish that our solution maps higher priority vehicles to better quality routes and is monotonic in the sense that decreasing priority order of vehicles maps to a decreasing route quality.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>477</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-477">Compact Preference Representation via Fuzzy Constraints in Stable Matching Problems: theoretical and experimental studies</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_477" class="editable_bid" data-pk="477" data-value="30"
                    data-url="/rev_3/paper/bid/set/477/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-477"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>The stable matching problem has many practical applications in two-sided markets, like those that assign doctors to hospitals or students to schools. Usually it is assumed that all agents in each side explicitly express a preference ordering over all those in the other side. This can be unfeasible and impractical when the set of agents is very big. However, usually this set has a combinatorial structure, since each agent is often described by some features. To tackle these scenarios, we define a framework for stable matching problems where agents are allowed to express their preferences over those of the other group in a compact way, via soft constraints over the features describing these agents. We focus on a special kind of soft constraints, namely fuzzy constraints. We provide a solving engine for this new kind of stable matching problems that does not increase the time complexity of the classical GS algorithm, while maintaining stability of the matching returned. We then evaluate the approach experimentally.<br></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>379</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-379">Multi-armed bandit algorithms for  crowdsourcing systems with  online estimation of  workers&#39; ability</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Engineering Multiagent Systems] Methodologies for agent-based systems<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_379" class="editable_bid" data-pk="379" data-value="30"
                    data-url="/rev_3/paper/bid/set/379/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-379"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Crowdsourcing systems have become a valuable solution for various organizations to outsource work on a temporary basis. &nbsp;Quality assurance in these systems remains a key issue due to the distributed setup of the crowdsourcing platforms and the absence of a priori information about the workers. Our work proposes a notion of Limited-information Crowdsourcing Systems (LCS), where the task master can assign the work &nbsp; based on some &nbsp;knowledge of the workers' ability acquired &nbsp; &nbsp;over time. The key challenges in this new setup are determining an efficient workers' selection policy and estimating the abilities of the workers. For the former challenge, we reduce the problem to an arm-limited, budget limited, multi-armed bandit (MAB) set-up and use the simplified bounded KUBE (B-KUBE) algorithm &nbsp;of \cite{tran2014efficient} &nbsp;as a solution. This algorithm has previously &nbsp;only been experimentally evaluated, and we provide provable performance guarantees, showing that it is order optimal. This work closes the gap in the literature of budget limited arm limited MAB by proving that expected regret of B-KUBE is $O(\log(B))$ where $B$ is the total budget of the task master. The latter challenge is solved by &nbsp;formalizing the notion of workers' ability mathematically, and proposing a strategy for the estimation of the workers' &nbsp;ability. Later, we experimentally evaluate B-KUBE in conjunction with this &nbsp;strategy, showing that it outperforms other state-of- the-art MAB algorithms when applied in the same setting.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>187</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-187">Characterization of group behavior in crowd simulations using complex event processing</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent-based Simulation] Interactive simulation<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent-based Simulation] Validation of simulation systems</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_187" class="editable_bid" data-pk="187" data-value="30"
                    data-url="/rev_3/paper/bid/set/187/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-187"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Frequently, researchers in social sciences look for experiments where interacting individuals are expected to show some kind of emergent behavior. The multi-agent based simulation approach is relevant for conceiving such experiments, but, currently, there is a lack of conceptual tools to manage and validate the outcome of the simulation. Most works refer to particular variables, such as the ratio of evacuated people per minute or how much time it takes to empty a building. However, these variable means little if the behavior of the individuals is too much artificial. Researchers have proposed different means, most of them based on visual inspection by human users, but it is not an efficient solution if hours of simulations have to be reviewed. To address this issue, the recent advances and tools for Complex Event Processing provides new insights that are worth being studied. This paper uses this approach to computationally identify patterns of expected behavior of agents in a multi-agent based simulation and provide quantitative assessment of the behavior beyond individual and isolated variables. The contribution focuses precisely in the challenges associated to identifying group behaviors and other individual non-desirable traits, such as characters walking in perfectly straight unnatural lines. This work could be taken further to determine which behavior is the most intelligent, given a particular simulation. This permits too for a more serious testing and evaluation of the simulations, where not only the final outcome is important, but how one reaches such outcome too.<br></p></td>
                </tr>
            
                <tr>
                    <td>30</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-30">Why Bad Coffee? Explaining BDI Agent Behaviour with Valuings</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_30" class="editable_bid" data-pk="30" data-value="30"
                    data-url="/rev_3/paper/bid/set/30/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-30"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>An important issue in deploying an autonomous system is how to enable human users and stakeholders to develop an appropriate level of trust in the system. It has been argued that a crucial mechanism to enable appropriate trust is the ability of a system to explain its behaviour. Obviously, such explanations need to be comprehensible to humans. We argue that it makes sense to build on the results of extensive research in social sciences that explores how humans explain their behaviour. Using similar concepts for explanation is argued to help with comprehensibility, since the concepts are familiar. Following work in the social sciences, we propose the use of a folk-psychological model that utilises beliefs, desires, and "valuings". We propose a formal framework for constructing explanations of the behaviour of an autonomous system, present an (implemented) algorithm for giving explanations, and present evaluation results.&nbsp;</p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>519</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-519">Multi-agent Negotiation and Coordination Mechanisms to Manage User Satisfaction for SaaS</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Agents and Mainstream Computing] P2P, web services, grid computing, IoT, HPC</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_519" class="editable_bid" data-pk="519" data-value="30"
                    data-url="/rev_3/paper/bid/set/519/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-519"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal"><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>FR</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>AR-SA</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="true"
  DefSemiHidden="true" DefQFormat="false" DefPriority="99"
  LatentStyleCount="267">
  <w:LsdException Locked="false" Priority="0" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="59" SemiHidden="false"
   UnhideWhenUsed="false" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" QFormat="true" Name="TOC Heading"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Tableau Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin-top:0cm;
	mso-para-margin-right:0cm;
	mso-para-margin-bottom:10.0pt;
	mso-para-margin-left:0cm;
	line-height:115%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-fareast-language:EN-US;}
</style>
<![endif]-->

<span style="mso-ansi-language:EN-US" lang="EN-US">With the
rapid growth of personal and interactive applications on the cloud, end-user
satisfaction is becoming a key factor to ensure the prosperity of any Software
as a Service (SaaS). Elasticity management has been defined as a process
whereby the SaaS provider seeks to minimize the cost it pays to the cloud
provider while providing a satisfactory service to its users. Multi-agent
systems have been proposed as a platform to integrate the end-user satisfaction
into elasticity management. However, existing works rely on a binary vision of
end-user satisfaction. Recently, this vision has received growing criticism
from the theoretical and empirical research on Quality of Experience (QoE)
where it has been shown that the user's subjective satisfaction is a degree. In
the context of a multi-agent negotiation framework, this article proposes a
mechanism enabling the SaaS provider to undertake satisfaction management: <span style="mso-spacerun:yes">&nbsp;</span>to meet fine-grained user satisfaction goals
while still minimizing the cost paid to the cloud provider. This problem is
formulated as an optimization problem, for which a linear model is proposed.
For reference, a generic linear program solver is used to find the optimal
solution. An alternative heuristic algorithm is also devised in order to
improve responsiveness when the system has to scale up with fast growing number
of users. Both are implemented and their results are compared and analyzed.</span></p><p>

<br></p></td>
                </tr>
            
                <tr>
                    <td>128</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-128">Gerrymandering Over Graphs</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_128" class="editable_bid" data-pk="128" data-value="30"
                    data-url="/rev_3/paper/bid/set/128/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-128"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In many real-life scenarios, voting problems consist of several phases: an overall set of voters is partitioned into subgroups, each subgroup chooses a preferred candidate, and the final winner is selected from among those candidates. The attempt to skew the outcome of such a voting system through strategic partitioning of the overall set of voters into subgroups is known as ``gerrymandering''. We investigate the problem of gerrymandering over a network structure; the voters are embedded in a social network, and the task is to divide the network into connected components such that a target candidate will win in a plurality of the components. We first show that the problem is NP-complete in the worst case. We then perform a series of simulations, using random graph models incorporating a homophily factor. In these simulations we show that a simple greedy algorithm can be quite successful in finding a partition in favor of a specific candidate.<br></p></td>
                </tr>
            
                <tr>
                    <td>248</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-248">Efficient Reciprocal Collision Avoidance between Heterogeneous Agents Using CTMAT</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Interactive simulation<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent Cooperation] Multi-user/multi-virtual-agent interaction<br>[Agent Cooperation] Multi-robot systems</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_248" class="editable_bid" data-pk="248" data-value="30"
                    data-url="/rev_3/paper/bid/set/248/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-248"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We present a novel algorithm for reciprocal collision avoidance between heterogeneous agents of different shapes and sizes. We present a novel CTMAT representation based on medial axis transform to compute a tight fitting bounding shape for each agent. Each CTMAT is represented using tuples, which are composed of circular arcs and line segments. Based on the reciprocal velocity obstacle formulation, we reduce the problem to solving a low-dimensional linear programming between each pair of tuples belonging to adjacent agents. We precompute the Minkowski Sums of tuples to accelerate the runtime performance. Finally, we provide an efficient method to update the orientation of each agent in a local manner. We have implemented the algorithm and highlight its performance on benchmarks corresponding to road traffic scenarios and different vehicles. The overall runtime performance is comparable to prior multi-agent collision avoidance algorithms that use circular or elliptical agents. Our approach is less conservative and results in fewer false collisions.<br></p></td>
                </tr>
            
                <tr>
                    <td>471</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-471">Revenue Maximization for Electric Vehicle Charging Service Providers using Sequential Dynamic Pricing</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Other<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Economic Paradigms] Other</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_471" class="editable_bid" data-pk="471" data-value="30"
                    data-url="/rev_3/paper/bid/set/471/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-471"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block">With the rising penetration of electric vehicles (EVs), the provision of EV charging is becoming a standard commercial service. With this shift, EV charging service providers are looking for ways to make their business more profitable. Dynamic pricing is a proven technique to increase revenue in markets with time-variant, heterogeneous demand. In this paper, we propose a Markov Decision Process (MDP)-based approach to revenue-maximizing dynamic pricing for charging service providers. We implement the approach using an ensemble of policy iteration MDP solvers and evaluate it using a simulation based on real-world data. We show that our proposed method achieves significantly higher revenue than methods utilizing flat-based pricing. In addition to achieving higher revenue for charging service providers, the method also increases the efficiency of allocation measured in terms of the total utilization of the charging station.</td>
                </tr>
            
                <tr>
                    <td>664</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-664">Super Altruistic Hedonic Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Economic Paradigms] Cooperative games: computation</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_664" class="editable_bid" data-pk="664" data-value="30"
                    data-url="/rev_3/paper/bid/set/664/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-664"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Hedonic games are coalition formation games in which agents’ utility depends only on their own coalition. However, the introduction of Altruistic Hedonic Games expanded the focus by considering the utility of agents’ friends within the coalition. We introduce Super Altruistic Hedonic Games, in which an agent’s utility may depend on the utility of all other agents in the coalition, weighted according to distance in the friendship graph. We establish the framework for this new model and investigate the complexity of multiple notions of stability.</p></td>
                </tr>
            
                <tr>
                    <td>54</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-54">On the Role of Abstract Argumentation in Belief Modelling</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_54" class="editable_bid" data-pk="54" data-value="30"
                    data-url="/rev_3/paper/bid/set/54/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-54"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The paper proposes a belief model based on abstract argumentation semantics and its probabilistic extensions. The model has been defined taking Smets’ TBM as the main reference, with further references to the original DS theory and the Bayesian update. The model represents possible worlds and evidence as defeasible propositions connected by a relation of attack. Degrees of believes are quantifying by evaluating abstract grounded semantics. When a decision-making is needed, a probability distribution over possible worlds is generated by computing the preferred semantics and applying the indifferent reason principle, in analogy with the pignisitc transformation of the TBM. We compare the behaviour of the model with TBM, DS and the Bayesian update in well-known critical situations, such as total ignorance, the so-called “Mr. Jones case”, Zadeh’s critical examples on combining highly conflicting belief. By relying on argumentation semantics, the model allows for a definition of complex relations among evidence, it is easily expandable with new evidence and it provides an undec label to deal with conflicting evidence in a more coherent and principled&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>58</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-58">Corrupted Contextual Bandits</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Adversarial machine learning</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_58" class="editable_bid" data-pk="58" data-value="30"
                    data-url="/rev_3/paper/bid/set/58/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-58"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider a novel variant of the contextual bandit problem (i.e., the multi-armed bandit with side-information, or context, available to a decision-maker) where the context used at each decision may be Corrupted (”Corrupted Context”). This new problem is motivated by certain on-line settings including clinical trial and ad recommendation applications. In order to address the Corrupted-context setting, we propose to combine the standard contextual bandit approach with a classical multi-armed bandit mechanism. Unlike standard contextual bandit methods, we are able to learn from all iteration, even those with corrupted context, by improving the expectation on the different arms. Promising empirical results are obtained on several real-life datasets.<br></p></td>
                </tr>
            
                <tr>
                    <td>458</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-458">On the Frequency of Decision Making in On-line Temporal Difference Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_458" class="editable_bid" data-pk="458" data-value="30"
                    data-url="/rev_3/paper/bid/set/458/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-458"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The growth of Artificial Intelligence has been boosted by progress in allied fields such as computer architecture&nbsp; and communication engineering. An interesting fallout of the resulting technological acceleration is a notable increase in the \textit{frequency} with which agents can make decisions. It seems intuitive that a higher frequency of decision making will improve an agent's performance. We investigate if this intuition remains correct even if the agent's behaviour is to be \textit{learned} from experience. We anchor our study in the Sarsa family of algorithms for on-line Temporal Difference (TD) learning. On a deliberately-designed grid-world domain, and also the well-known Acrobot test bed, we find evidence in favour of performing decision making at a \textit{lower} frequency than maximum. We attribute this result to the use of function approximation, which is inevitable in&nbsp; most practical tasks. Interestingly, ``slowing down'' the standard Sarsa($\lambda$) algorithm also enables us to learn a competitive \textit{defense} strategy in the more complex Half Field Offense task. To the best of our knowledge, this is the first successful application of an on-line TD learning method to this task. At the heart of our contribution is a single ``decision interval'' parameter ``$d$'' to Sarsa, which we find significantly more effective in high-frequency settings than ``$n$'' and ``$\lambda$'', the usual parameters to control bootstrapping. In our experiments, we also demonstrate that $d$ can be tuned effectively by using the EXP3 algorithm.</p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>62</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-62">Dealing with multiple intentions of cooperative ambient agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Belief-Desire-Intention theories and models<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_62" class="editable_bid" data-pk="62" data-value="30"
                    data-url="/rev_3/paper/bid/set/62/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-62"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal">This paper presents a cooperative approach to deal with multiple intentions for a specific type of intelligent agents that interact with Ambient Intelligent environments, denominated ambient agent (AA). Since the environment provides contextual information subject to dynamic changes, it is desirable for the reasoning process used by an AA to be as adaptive and efficient as possible. At the same time, the AA must still achieve its goals. In order to address the planning adaptability, a formal context-based planning mechanism called Contextual Planning System (CPS) can be used to provide contextual guidance to an AA. The CPS proposes an optimal plan based on the current context that satisfies multiple intentions of the agent while preserving their consistency. It is, however, designed for a single agent. Different scenarios may require a cooperative approach, where AAs can be able to cooperate among themselves while achieving their individual goals. In these scenarios, benevolence cannot be assumed, and cooperation will be dependent on each of the agent's own intentions. We propose a mechanism denominated Collective CPS (CCPS) that allows an AA to partially delegate its own plans to other agents, or to collaborate with other agents' plans during their execution, while still using the CPS for its individual planning. An implementation of a working scenario for a simple and realistic Ambient Intelligence (AmI) environment is also discussed.<br></p></td>
                </tr>
            
                <tr>
                    <td>284</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-284">Prioritized Sequent-Based Argumentation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Deductive, rule-based and logic-based argumentation<br>[Communication and Argumentation] Other<br>[Knowledge Representation and Reasoning] Other</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_284" class="editable_bid" data-pk="284" data-value="30"
                    data-url="/rev_3/paper/bid/set/284/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-284"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper we integrate priorities in sequent-based argumentation. The former is a useful and extensively investigated tool in the context of non-monotonic reasoning, and the latter is a modular and general way of handling logical argumentation. Their combination offers a platform for representing and reasoning with maximally consistent subsets of prioritized knowledge bases. Moreover, many frameworks of the resulting formalisms satisfy common rationality postulates and other desirable properties, like conflict preservation.<br></p></td>
                </tr>
            
                <tr>
                    <td>257</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-257">Agents Interoperability via Conformance Modulo Mapping</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Communication languages and protocols<br>[Verification and Validation of Agent-based Systems] Verification techniques for multiagent systems, including model checking</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_257" class="editable_bid" data-pk="257" data-value="30"
                    data-url="/rev_3/paper/bid/set/257/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-257"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>In this work we present an algorithm for establishing a flexible conformance relation between two local agent interaction protocols (LAIPs) based on mappings involving agents and messages, respectively.&nbsp;</p><p>Conformance is in fact computed "modulo mapping": two LAIPs tau &nbsp;and tau' may involve different agents and use different syntax for messages, but may still be found to be conformant provided that a given map from entities appearing in tau to corresponding entities in tau' is applied. Also, LAIPs are modelled as trace expressions whose high expressive power allows for the design of protocols that could not be specified using finite state automata or equivalent formalisms. This expressive power makes the problem of stating if tau conforms to tau' undecidable. We cope with this problem by over-approximating trace expressions that may lead to infinite computations, obtaining a sound but not complete implementation of the proposed conformance check.&nbsp;</p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>278</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-278">Learning Optimal Redistribution Mechanisms Through Neural Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_278" class="editable_bid" data-pk="278" data-value="30"
                    data-url="/rev_3/paper/bid/set/278/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-278"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider a social setting where $p$ public resources/objects are to be allocated among $n$ competing and strategic agents so as to maximize social welfare (the objects should be allocated to those who value them the most). This is called allocative efficiency (AE). We need the agents to report their valuations&nbsp; for obtaining these resources, truthfully. This is called dominant strategy incentive compatibility (DSIC). Typically, we use auction based mechanisms to achieve AE and DSIC. However, due to Green-Laffont Impossibility Theorem, we cannot ensure budget balance in the system while ensuring AE and DSIC. That is, the net transfer of money cannot be zero. This problem has been addressed by designing a redistribution mechanism so as to ensure minimum surplus of money as well as AE and DSIC. The objective could be to minimize surplus in expectation or in worst case and these objects could be homogeneous or heterogeneous. The designing of such mechanisms is non-trivial and especially designing redistribution mechanisms which perform well in expectation becomes analytically challenging for heterogeneous settings.&nbsp;</p><p><br></p><p>In this paper, we take a completely different, data-driven approach. We train a neural network to determine an optimal redistribution mechanism based on given settings with both the objectives,&nbsp; optimal in expectation and optimal in worst case. We also propose a loss function to train neural network to optimize worst case. We design&nbsp; neural networks with underlying rebate functions to be linear as well as nonlinear in terms of bids of the agents. Our networks achieve the theoretical guarantees for the cases where it has been solved. We observe that a neural network based redistribution mechanism for homogeneous settings which uses nonlinear rebate functions, outperforms linear rebate functions when the objective is optimal in expectation. Our approach also yields an optimal in expectation redistribution mechanism for heterogeneous settings.</p></td>
                </tr>
            
                <tr>
                    <td>114</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-114">On Testing Preferential Domains by Sampling</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Engineering Multiagent Systems] Methodologies for agent-based systems</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_114" class="editable_bid" data-pk="114" data-value="30"
                    data-url="/rev_3/paper/bid/set/114/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-114"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>A preferential domain is a collection of sets of linear orders (called preferences) over a set of alternatives. It forms a core area of research in social choice theory due to both its practical importance and theoretical elegance. Example of some extensively studied preferential domains includes single peaked, single crossing, Euclidean, etc. In this paper, we study sample complexity of testing whether a given preference profile is close to some specific domain or far from the domain. We consider various notion of closeness, for example, deletion of alternatives, deletion of preferences, and simultaneous deletion of alternatives as well as preferences. We further explore the effect of assuming the deleted preferences to be random (instead of arbitrary) on the sample complexity of the testing problem. In most cases, we show that the above testing problem can be solved with high probability for all domains by observing a small (independent of the number n of preferences) number of samples. In the remaining few cases, we prove either impossibility results or Omega(n) lower bound on the sample complexity.<br></p></td>
                </tr>
            
                <tr>
                    <td>355</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-355">Self-Organizing Maps for Storage and Transfer of Knowledge in Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Knowledge Representation and Reasoning] Ontologies for agents<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_355" class="editable_bid" data-pk="355" data-value="30"
                    data-url="/rev_3/paper/bid/set/355/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-355"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The idea of reusing or transferring information from previously learned tasks (source tasks) for the learning of new tasks (target tasks) has the potential to significantly improve the sample efficiency of a reinforcement learning agent. In this work, we describe an approach to reuse previously acquired knowledge by using it to guide the exploration of an agent while it learns new tasks. In order to do so, we use a measure of similarity that is defined directly in the space of the value function weight vectors. This similarity measure is also used as a basis for a&nbsp;variant of the growing self-organizing map algorithm, which is simultaneously used to enable the efficient storage of previously acquired task knowledge in an adaptive and scalable manner. We empirically validate our approach in a simulated navigation environment, and also demonstrate its utility through simple experiments using a mobile micro-robotics platform. Further, we discuss some of the possible improvements and extensions to this approach, as well as some potential applications where it could be particularly useful.</p></td>
                </tr>
            
                <tr>
                    <td>579</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-579">Inferring Commitment Semantics in Multi-Agent Interactions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Commitments<br>[Communication and Argumentation] Communication languages and protocols</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_579" class="editable_bid" data-pk="579" data-value="30"
                    data-url="/rev_3/paper/bid/set/579/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-579"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Commitments are a useful abstraction to specify the social semantics of multi-agent communication languages. To use them in open and heterogeneous systems, it is necessary to develop solutions to the problem of interoperability, an effort that has already provided methods to, for example, align commitments between interlocutors. In this paper we consider the problem of commitment semantics inference, which can be summarized as follows: how can an agent that arrives to a community with an established language discover its social semantics, only by observing interactions? We introduce a method based on simple learning techniques that tackles this problem. We show that the basic commitment semantics is not possible to infer, and discuss different ways of enriching it that make inference feasible. We show experimentally how our technique performs for each of these extensions. To the best of our knowledge, that is the first approach that tackles the problem of inferring commitment semantics.<br></p></td>
                </tr>
            
                <tr>
                    <td>640</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-640">Handling Disagreement in Ontologies-based Reasoning via Argumentation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Deductive, rule-based and logic-based argumentation<br>[Knowledge Representation and Reasoning] Ontologies for agents</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_640" class="editable_bid" data-pk="640" data-value="30"
                    data-url="/rev_3/paper/bid/set/640/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-640"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>

	
		
		
	
	
		<br></p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">Ontologies play an important role in agent inter-communication via
providing formal definitions of the vocabularies used by agents to
describe their knowledge about the world. However, in practice, it
is often hard to have a confliction free ontology shared by differ-
ent agents, where disagreement occurs. Moreover, the information
from each agent can be uncertain due to her modeling choice or the
lack of confidence for a piece of ontological information. In this
paper, we present a </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'; font-style: italic">general </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">approach that makes use of argumen-
tation theory to deal with imperfect ontologies. It has the merits
that all inconsistency, incoherence and uncertainty can be handled
in a unified framework. Our approach spreads uncertainty degrees
throughout argumentation trees, where each argument is associated
with a label reflecting its justification status. We present different
labelling methods by taking account the structure of agents. The
enriched argument structure leads us to several interesting inference relations from imperfect ontological information. We further
present the properties of these inference relations and their relation-ships with other well-known inference ones.
</span></p>
				</div>
			</div>
		</div><p>
	
<br></p></td>
                </tr>
            
                <tr>
                    <td>53</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-53">Competitive Equilibrium for almost All Incomes</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.550</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_53" class="editable_bid" data-pk="53" data-value="30"
                    data-url="/rev_3/paper/bid/set/53/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-53"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Competitive equilibrium from equal incomes (CEEI)&nbsp; is a well-known rule for fair allocation of resources among agents with different preferences. It has many advantages, among them is the fact that a CEEI allocation is both Pareto efficient and envy-free. However, when the resources are indivisible, a CEEI allocation might not exist even when there are two agents and a single item.<br><br>In contrast to this discouraging non-existence result, Babaioff and Nisan and Talgam-Cohen (2017) recently suggested a new and more encouraging approach to allocation of indivisible items: instead of insisting that the incomes be equal, they suggest to look at the entire space of possible incomes, and check whether there exists a competitive equilibrium for almost all income-vectors (CEFAI) --- all income-space except a subset of measure zero.<br><br>They show that a CEFAI exists when there at most 3 indivisible items, or when there are 4 indivisible items and two agents. They also show that when there are 5 items and two agents with arbitrary monotone preferences, there might not exist a CEFAI. They leave open the cases of 4 items with three or four agents.<br><br>This paper presents a new way to implement a CEFAI, as&nbsp; a subgame-perfect equilibrium of a sequential game.&nbsp;&nbsp; This new implementation allows us to both offer much simpler solutions to the known cases (at most 3 items, and 4 items with two agents), and to prove that a CEFAI exists even in the much more difficult case of 4 items and three agents.&nbsp; Moreover, we prove that a CEFAI might not exist with 4 items and four agents.&nbsp; Thus, this paper completes the characterization of CEFAI for monotone preferences.<br></p></td>
                </tr>
            
                <tr>
                    <td>97</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-97">Fair Allocation of Indivisible Goods Considering Contribution Diversity</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.540</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_97" class="editable_bid" data-pk="97" data-value="30"
                    data-url="/rev_3/paper/bid/set/97/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-97"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Fair allocation&nbsp; of a set of goods among several agents is a classic problem in economics and computer science. Although the problem has been extensively studied, the existing work usually assumes that each agent has the same contribution to the agent group and endows each agent with the equal entitlement. However, in real applications, different agents may have different contributions to the agent group, e.g., in a company, different project teams may have different profitability. Inspired by the max-min fairness, we can adopt generalized max-min fairness criterion, i.e., maximizing the minimum utility contribution ratio, to allocate the goods in the situation with contribution diversity. The utility contribution ratio of an agent is the ratio between the utility of the acquired goods of the agent and its contribution value. Nevertheless, the generalized max-min fairness may lead to serious wealth gap, especially when the variance of the contribution distribution is large. Serious wealth gap is harmful to the unity and cooperation of the agent group. Therefore, this paper considers how to make tradeoff between the generalized max-min fairness and wealth gap during the fair allocation of the goods. First, we propose an evaluation indicator of allocation strategy that is positively related to the minimum utility contribution ratio of the agents and that is inversely related to the wealth gap. Second, we present a branch-and-bound algorithm to compute the optimal allocation strategy that maximizes the evaluation indicator. Third, because finding the optimal allocation strategy is NP-hard, we propose a heuristic algorithm that can provide suboptimal allocation strategy in polynomial time and is a max{1.4, m-n+1} factor approximation algorithm for the case that all the agents have the same utility function, where m is the goods number and n is the agent number. The heuristic algorithm consists of three phases: i) we allocate some indivisible goods to the agents based on the generalized max-min fairness; ii) we adopt greedy idea to allocate the remaining goods to minimize the wealth gap; iii) we improve the allocation strategy based on hill climbing search. Experiments conducted on real data show that the heuristic algorithm produces near-optimal solutions.<br></p></td>
                </tr>
            
                <tr>
                    <td>250</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-250">Classification of Disruptive Trading Practices Through Support Vector Machines</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Economic Paradigms] Auctions and mechanism design</td>
                    
                        <td>0.540</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_250" class="editable_bid" data-pk="250" data-value="30"
                    data-url="/rev_3/paper/bid/set/250/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-250"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Disruptive Trading, defined by the U.S. Commodity Futures Trading Commission (CFTC) as "bidding or offering with the intent to cancel the bid or offer before execution", is an illegal trading strategy aimed to manipulate stock prices and gain profits, and is hard to detect and therefore to prosecute. This paper proposes the identification of these trading practices through Support Vector Machines (SVM) applied to reconstructed Limit Order Books. Our results show the SVM can predict the cancellation of large orders within a time-event horizon T, given properties of the existing order-flow within a particular time window. This is of great importance as the SVM reveals the events of relevance that should be considered to detect trading activities that could be associated with market manipulation. Consequently, financial regulatory bodies can apply procedures to real cases of manipulation as our model predicts the activity of the manipulators.<br></p></td>
                </tr>
            
                <tr>
                    <td>595</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-595">Deep Abstract Q-Networks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.540</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_595" class="editable_bid" data-pk="595" data-value="30"
                    data-url="/rev_3/paper/bid/set/595/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-595"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We examine the problem of learning and planning on high-dimensional domains with long horizons and sparse rewards. Recent approaches have shown great successes in many Atari 2600 domains. However, domains with long horizons and sparse rewards, such as Montezuma’s Revenge and Venture, remain challenging for existing methods. Methods using abstraction (Dietterich 2000; Sutton, Precup, and Singh 1999) have shown to be useful in tackling long-horizon problems. We combine recent techniques of deep reinforcement learning with existing model-based approaches using an expert-provided state abstraction. We construct toy domains that elucidate the problem of long horizons, sparse rewards and high-dimensional inputs, and show that our algorithm significantly outperforms previous methods on these domains. Our abstraction-based approach outperforms Deep Q-Networks (Mnih et al. 2015) on Montezuma’s Revenge and Venture, and exhibits backtracking behavior that is absent from previous methods.</p></td>
                </tr>
            
                <tr>
                    <td>224</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-224">A tensor-based approach for the trust evaluation in web-based service-oriented environments</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Trust and reputation<br>[Agents and Mainstream Computing] P2P, web services, grid computing, IoT, HPC<br>[Agents and Mainstream Computing] Service-oriented architectures</td>
                    
                        <td>0.540</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_224" class="editable_bid" data-pk="224" data-value="30"
                    data-url="/rev_3/paper/bid/set/224/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-224"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal"><a name="OLE_LINK2"></a><span lang="EN-US"></span>Multi-agent technologies have been widely applied in many web-based applications such as the cloud computing, service-oriented environments, etc. In real applications, web-based service-oriented environments are open and dynamic, where loosely coupled agents interact to consume and provide services. How to select the most suitable provider for the requested service in such open and dynamic environments is a challenging issue in both theory and practice. In this paper, an innovative approach is proposed to evaluate the trusts of providers based on their historical performance. The proposed approach borrows the reference report mechanism of the certified reputation model so as to efficiently collect historical performance of providers. Based on the collected reference reports, the tensor based mechanism of the proposed approach can model the historical performance of providers by involving comprehensive information of service provision in a tensor. Based on the tensor, the CP decomposition based mechanism of the proposed approach can accurately evaluate the trusts of providers by considering the difference between services, the bias of consumers, and the timelines of reference reports. From the experiments, it can be seen that the proposed approach has better performance than current approaches on trust evaluation in open and dynamic environments, especially when the reference reports (i.e, historical performance) of providers are sparse.<br><span lang="EN-US"></span></p><p class="MsoNormal">

<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:普通表格;
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin:0cm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:等线;
	mso-ascii-font-family:等线;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:等线;
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:等线;
	mso-hansi-theme-font:minor-latin;
	mso-font-kerning:1.0pt;}
</style>
<![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="371">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:DrawingGridVerticalSpacing>7.8 磅</w:DrawingGridVerticalSpacing>
  <w:DisplayHorizontalDrawingGridEvery>0</w:DisplayHorizontalDrawingGridEvery>
  <w:DisplayVerticalDrawingGridEvery>2</w:DisplayVerticalDrawingGridEvery>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>ZH-CN</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:SpaceForUL></w:SpaceForUL>
   <w:BalanceSingleByteDoubleByteWidth></w:BalanceSingleByteDoubleByteWidth>
   <w:DoNotLeaveBackslashAlone></w:DoNotLeaveBackslashAlone>
   <w:ULTrailSpace></w:ULTrailSpace>
   <w:DoNotExpandShiftReturn></w:DoNotExpandShiftReturn>
   <w:AdjustLineHeightInTable></w:AdjustLineHeightInTable>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
   <w:UseFELayout></w:UseFELayout>
  </w:Compatibility>
  <w:DoNotOptimizeForBrowser></w:DoNotOptimizeForBrowser>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><a name="OLE_LINK1"><span lang="EN-US"></span></a><span lang="EN-US"></span></p><p>

</p></td>
                </tr>
            
                <tr>
                    <td>352</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-352">Moving Agents in Formation in Congested Environments</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Teamwork, team formation, teamwork analysis<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.540</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_352" class="editable_bid" data-pk="352" data-value="30"
                    data-url="/rev_3/paper/bid/set/352/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-352"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we formalize and study the Moving Agents in Formation (MAiF) problem that combines the tasks of finding low-cost paths for multiple agents and keeping them in a desired formation as much as possible. Previous work focused on only one or the other of these tasks. We present a complete two-phase algorithm, called SWARM-MAPF, whose first phase is inspired by swarm-based approaches and whose second phase is inspired by multi-agent path-finding (MAPF) approaches. The first phase focuses on the selection of a leader and finds a path for it that is sufficiently away from the obstacles so that other agents can preserve the desired formation around it. The first phase also identifies the critical segments of the leader's path where other agents cannot preserve the formation and the refinement of which has to be thus delegated to the second phase. In the second phase, the combinatorial problem is similar to MAPF and is solved using algorithmic procedures that combine current MAPF techniques with our own novel contributions. We present experimental results to show several benefits of SWARM-MAPF in congested environments.<br></p></td>
                </tr>
            
                <tr>
                    <td>150</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-150">Equilibrium Behavior in Competing Dynamic Matching Markets</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Other</td>
                    
                        <td>0.540</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_150" class="editable_bid" data-pk="150" data-value="30"
                    data-url="/rev_3/paper/bid/set/150/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-150"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Rival markets like rideshare services, universities, and organ exchanges compete to attract participants, seeking to maximize their own utility at potential cost to overall social welfare.&nbsp; Similarly, individual participants in such multi-market systems also seek to maximize their individual utility. If entry is costly, they should strategically enter only a subset of the available markets. All of this decision making---markets competitively adapting their matching strategies and participants arriving, choosing which market(s) to enter, and departing from the system---occurs dynamically over time. This paper provides the first analysis of equilibrium behavior in dynamic competing matching market systems---first from the points of view of individual participants when market policies are fixed, and then from the points of view of markets when agents are stochastic. When compared to single markets running social-welfare-maximizing matching policies, losses in overall social welfare in competitive systems manifest due to both market fragmentation and the use of non-optimal matching policies. We quantify such losses and provide policy recommendations to help alleviate them in fielded systems.</p></td>
                </tr>
            
                <tr>
                    <td>185</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-185">COMBIMA: Truthful, Budget Maintaining, Dynamic Combinatorial Market</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.540</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_185" class="editable_bid" data-pk="185" data-value="30"
                    data-url="/rev_3/paper/bid/set/185/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-185"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style="margin-bottom: 0px;">Current interest in two-sided markets is motivated by examples of successful practical applications of market mechanisms in supply chain markets, online advertising exchanges, and pollution-rights markets. Many of these examples require markets where agents arrive dynamically and can trade multiple commodities. However, the known literature largely focuses on settings with single commodity unit demand.</p><p style="margin-bottom: 0px;">We present and evaluate a general solution that matches agents in a dynamic, two-sided combinatorial market. Multiple commodities, each with multiple units, are bought and sold in different bundles by agents that arrive over time.</p><p style="margin-bottom: 0px;"><br></p><p style="margin-bottom: 0px;">Our mechanism, COMBIMA, provides the first dynamic two-sided combinatorial market that allows truthful and individually-rational behavior for all agents, keeps the market budget balanced and approximates social welfare efficiency. We experimentally examine and compare the allocative efficiency of COMBIMA with respect to other known (dynamic and non-dynamic) two-sided markets under a variety of distributions of bids, market demand and market size. COMBIMA performs well by all benchmarks and improves on previous mechanisms.</p><p style="margin-bottom: 0px;"><!--EndFragment--></p></td>
                </tr>
            
                <tr>
                    <td>716</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-716">Coalitional Permutation Manipulations in the Gale-Shapley Algorithm</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.540</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_716" class="editable_bid" data-pk="716" data-value="30"
                    data-url="/rev_3/paper/bid/set/716/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-716"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="p1">In this paper, we consider permutation manipulations by any subset of women, which is motivated by the college admissions process in China. Our result also answer the open problem on what can be achieved by permutation manipulations. We present an efficient algorithm to find a strategy profile such that the induced matching is stable and Pareto-optimal while the strategy profile itself is inconspicuous. Surprisingly, we show that such a strategy profile actually forms a Nash equilibrium of the manipulation game.</p><p class="p1"><br></p><p class="p1">




<style type="text/css">
p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 19.0px; font: 13.0px 'Helvetica Neue'}
p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 19.0px; font: 13.0px 'Helvetica Neue'; min-height: 15.0px}
</style>




</p><p class="p1">In the end, we show that it is NP-complete to find a manipulation that is strictly better for all members of the coalition. This result demonstrates a sharp contrast between weakly better off outcomes and strictly better off outcomes.</p><style type="text/css">
p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 19.0px; font: 13.0px 'Helvetica Neue'}
p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 19.0px; font: 13.0px 'Helvetica Neue'; min-height: 15.0px}
</style></td>
                </tr>
            
                <tr>
                    <td>91</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-91">On the Design of Revenue-Enhancing Signal Structures in Common- and Interdependent-Value Second Price Auctions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Other</td>
                    
                        <td>0.540</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_91" class="editable_bid" data-pk="91" data-value="30"
                    data-url="/rev_3/paper/bid/set/91/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-91"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider the problem of designing the information environment for revenue maximization in a sealed-bid second price auction with two bidders. Much of the prior literature has focused on signal design in settings where bidders are symmetrically informed, or on the design of optimal mechanisms under fixed information structures. We study common- and interdependent-value settings where the mechanism is fixed (a second-price auction), but the auctioneer controls the signal structure for sellers. We show that in a standard common-value auction setting, there is no benefit to the auctioneer in terms of expected revenue from sharing information with the bidders, although there are effects on the distribution of revenues. In an interdependent-value model with mixed private- and common-value components, however, we show that asymmetric, information-revealing signals can increase revenue.<br></p></td>
                </tr>
            
                <tr>
                    <td>119</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-119">Human-Interactive Subgoal Supervision for Efficient Inverse Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Deep learning<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.540</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_119" class="editable_bid" data-pk="119" data-value="30"
                    data-url="/rev_3/paper/bid/set/119/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-119"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Humans are able to understand and perform complex tasks&nbsp;</p><p>by strategically structuring tasks into incremental steps</p><p>or sub-goals. For a robot attempting to learn to perform&nbsp;</p><p>a sequential task with critical subgoal states, these&nbsp;</p><p>subgoal states can provide a natural opportunity for&nbsp;</p><p>interaction with a human expert. This paper&nbsp;</p><p>analyzes the benefit of incorporating a notion of subgoals</p><p>into Inverse Reinforcement Learning (IRL) with&nbsp;</p><p>a Human-In-The-Loop (HITL) framework. The learning process&nbsp;</p><p>is interactive, with a human expert first providing input&nbsp;</p><p>in the form of full demonstrations along with subgoal states. These</p><p>subgoal states defines a set of sub-tasks for the learning&nbsp;</p><p>agent to complete in order to achieve the final goal. The learning agent&nbsp;</p><p>queries for partial demonstrations corresponding to each sub-task</p><p>as needed when the learning agent struggles with individual&nbsp;</p><p>sub-tasks. The proposed Human Interactive IRL (HI-IRL) framework</p><p>is evaluated on several discrete path-planning tasks. We&nbsp;</p><p>demonstrate that subgoal-based interactive&nbsp;</p><p>structuring of the learning task results in significantly more&nbsp;</p><p>efficient learning, requiring only a fraction of the demonstration&nbsp;</p><p>data needed for learning the underlying reward function with a&nbsp;</p><p>baseline IRL model.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>228</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-228">An Optimal Algorithm for the Bandits with Knowing Near-optimal Mean Reward</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.540</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_228" class="editable_bid" data-pk="228" data-value="30"
                    data-url="/rev_3/paper/bid/set/228/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-228"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper studies a variation of stochastic multi-armed bandit (MAB) problem where the learner knows a priori knowledge named Near-optimal Mean Reward (NoMR). This variation of bandit problem is seen in practical applications such as online web ad services, where a near-optimal average click rate of a user can be estimated from his/her demographic characteristics. A novel algorithm, NoMR-Bandit, is proposed to solve this bandit variation. It is proved that a proper NoMR can lead to an efficient exploration strategy and thereby the cumulative regret of NoMR-Bandit has a uniform upper bound of $O\left(\Delta\right)$, where $\Delta$ is the gap between the optimal and the second optimal mean reward. It is also proved that the cumulative regret of the bandit variation has a lower bound of $\Omega\left(1/\Delta\right)$, and hence NoMR-Bandit is optimal in terms of the order of regret bounds. For practical situations where a good NoMR is not directly available, NoMR-Bandit can be extended to obtain a NoMR from some arbitrarily poor estimation of the optimal mean reward. The extended algorithm, Cascade-Bandit, has a cumulative regret upper bound of $O\left(\Delta\log n\right)$, which is in the same order with state-of-the-art bandit solutions that are unaware of any priori knowledge. Extensive experiments show that the proposed NoMR-Bandit is also more efficient than all the other state-of-the-art bandit solutions, in the sense that NoMR-Bandit achieves 50\%-90\% less cumulative regret after sufficiently many iterations.</p></td>
                </tr>
            
                <tr>
                    <td>314</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-314">Modeling Consecutive Task Learning with Task Graph Agendas</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)</td>
                    
                        <td>0.530</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_314" class="editable_bid" data-pk="314" data-value="30"
                    data-url="/rev_3/paper/bid/set/314/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-314"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Recent advances in transfer, multi-task, and lifelong learning have demonstrated that agents can efficiently learn a challenging target task through a curriculum of simpler-to-harder tasks.<br>Yet relatively little work examines how learning can be self-directed, especially when there can be multiple underspecified targets, or when the environment combines their rewards, creating ambiguity.<br>We formalize this space of transfer among consecutive tasks as a task graph, where the inter-task similarity is measured based on high-level task descriptions.&nbsp; This framework permits us to define a learning agenda as a traversal on this task graph, generalizing the idea of curricula and unlocking a mechanism for describing (self-directed) learning as a path through the task graph.<br>We describe several task-graph traversal strategies that optimize knowledge acquisition, search for agent-specific optima in task space, and perform automatic curriculum generation. <br>Additionally, we identify the variance of the cumulative reward as a useful tool for disambiguating task descriptors, which may be incomparable otherwise. <br>Our empirical results suggest that agendas are beneficial in building on prior successes in transfer and curriculum learning, while providing a path forward for self-directed learning.<br></p></td>
                </tr>
            
                <tr>
                    <td>273</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-273">On the Impact of Buyers Preselection in Pricing Problems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Social choice theory</td>
                    
                        <td>0.530</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_273" class="editable_bid" data-pk="273" data-value="30"
                    data-url="/rev_3/paper/bid/set/273/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-273"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We investigate the problem of preselecting a subset of buyers participating in a market so as to optimize the performance of stable outcomes. We consider four scenarios arising from the combination of two stability notions, item and bundle envy-freeness, with the two classical objective functions, i.e., the social welfare and the seller’s revenue. When adopting the notion of item envy-freeness, we prove that, for both the two objective functions, the problem cannot be approximated within n<sup>1−ε</sup> for any ε &gt; 0, and provide tight or nearly tight approximation algorithms. We also prove that maximizing the seller’s revenue is NP-hard even for a single buyer, thus closing a longstanding open question. Under bundle envy-freeness, instead, we show how to transform in polynomial time any stable outcome for a market involving only a subset of buyers to a stable one for the whole market without worsening its performance, both for the social welfare and the seller’s revenue. This transformation implies that, although in this case buyers preselection cannot improve the performance, it can still be used as an algorithmic tool for computing good stable outcomes when preselection is not allowed. In fact, it can be first exploited to simplify the combinatorics of the problem, and then for mapping back the computed solution to one encompassing all the buyers. Finally, we consider multi-unit markets, where all items are of the same type and are assigned the same price. For this specific case, we show that buyers preselection can improve the performance of stable outcomes in all of the four considered scenarios, and design corresponding approximation algorithms.<br></p></td>
                </tr>
            
                <tr>
                    <td>628</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-628">Deep Reinforcement Learning of Behavior from Policy-Dependent Human Feedback</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Deep learning<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.530</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_628" class="editable_bid" data-pk="628" data-value="30"
                    data-url="/rev_3/paper/bid/set/628/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-628"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>To widen their accessibility and increase their utility, intelligent agents must be able to learn complex behaviors as specified by (non-expert) human users. Moreover, they will need to learn these behaviors within a reasonable amount of time while leveraging the low, sparse amount of feedback a human trainer is capable of providing, as efficiently as possible. Recent work has shown that human feedback can be characterized as a critique of an agent's current behavior rather than as an alternative reward signal to be maximized, culminating in the COnvergent Actor-Critic by Humans (COACH) algorithm for making direct policy updates based on human feedback. Our work builds on COACH, taking a further step in this direction, to a setting where the agent's policy is represented by a deep neural network. We employ a series of modifications on top of the original COACH algorithm that are critical for successfully learning behaviors from high-dimensional observations while also satisfying the constraint of minimal sample complexity. We demonstrate the effectiveness of our Deep COACH algorithm in the rich 3D world of Minecraft with an agent that learns to complete tasks by mapping from raw pixels to actions using only real-time human feedback and 10-15 minutes of interaction.<br></p></td>
                </tr>
            
                <tr>
                    <td>302</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-302">PELTE: Privacy Estimation of Images from Tags</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Values in MAS (privacy, safety, security, transparency, etc)<br>[Humans and Agents] Agent-based analysis of human interactions</td>
                    
                        <td>0.530</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_302" class="editable_bid" data-pk="302" data-value="30"
                    data-url="/rev_3/paper/bid/set/302/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-302"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Image sharing is a service offered by many online social networks.&nbsp; In order to preserve privacy of images, users need to think through and set the privacy settings for each image that they upload.&nbsp; This is difficult for two main reasons: First, research shows that many times users do not know their own privacy preferences, but only become aware of them over time.&nbsp; Second, even when users know their privacy preferences, specifying these policies is cumbersome and requires too much effort, interfering with the quick sharing behavior expected on an social network. Accordingly, this paper proposes an agent-based approach, PELTE, that predicts the privacy setting of images using their content tags.&nbsp; Each user agent makes use of the privacy settings that its user have set for previous images to predict the privacy setting for a new uploaded one automatically.&nbsp; When in doubt, the agent analyzes the sharing behavior of other trusted agents to make a recommendation to its user about what is private.&nbsp; Contrary to existing approaches that assume a centralized online social network where privacy is set by accessing all the available images, our approach is distributed and thus each agent can only view the privacy settings of the images that it has shared or those that have been shared with it.&nbsp; Our simulations on a real-life dataset shows that PELTE can accurately predict privacy settings even when a user has shared a few images with others, the images have only a few tags or the user's friends have varying privacy preferences.<br></p></td>
                </tr>
            
                <tr>
                    <td>46</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-46">Methods for Joining and Leaving a Flock</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent Cooperation] Collective intelligence<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis</td>
                    
                        <td>0.530</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_46" class="editable_bid" data-pk="46" data-value="30"
                    data-url="/rev_3/paper/bid/set/46/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-46"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>As autonomous agents become realizable in robotic forms that closely resemble biological agents, the possibility emerges to indirectly influence biological agents' behaviors through controlled interactions with autonomous agents.&nbsp; For example, birdstrikes - where one or more birds collide with a plane - are an expensive and dangerous problem at airports.&nbsp; Robot birds could potentially reduce birdstrikes by influencing flocks of natural birds to travel around an airport instead of over the airport.&nbsp; Prior research has considered how such robot birds should behave and where they should be placed within the flock. However, before robot birds can be used to influence flocks of real birds, we must consider how the robot birds could join and leave flocks of natural birds.&nbsp; Due to the influence the robot birds have once they become neighbors of birds in the flock, joining and leaving are not straightforward.&nbsp; In this paper, we introduce and evaluate several approaches for robot birds to use when joining and leaving flocks of natural birds.&nbsp; We introduce a variety of metrics to compare these approaches in the MASON simulator and present detailed experimental results.<br><br></p></td>
                </tr>
            
                <tr>
                    <td>260</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-260">Partial Verification as a Substitute for Money</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Social choice theory</td>
                    
                        <td>0.530</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_260" class="editable_bid" data-pk="260" data-value="30"
                    data-url="/rev_3/paper/bid/set/260/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-260"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Recent work has shown that we can use partial verification instead of money to implement truthful mechanisms. In this paper we develop tools to answer the following question. Given an allocation rule that can be made truthful with payments, what is the minimal verification needed to make it truthful without them? Our techniques leverage the geometric relationship between the type space and the set of possible allocations.<br></p></td>
                </tr>
            
                <tr>
                    <td>175</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-175">Explore, Exploit or Listen: Combining Human Feedback and Policy Model to Speed up Deep Reinforcement Learning in 3D Worlds</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Deep learning<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.520</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_175" class="editable_bid" data-pk="175" data-value="30"
                    data-url="/rev_3/paper/bid/set/175/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-175"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We describe a method to use discrete human feedback to enhance the performance of deep learning agents in virtual three-dimensional environments by extending deep-reinforcement learning to model the confidence and consistency of human feedback. This enables deep reinforcement learning algorithms to determine the most appropriate time to listen to the human feedback, exploit the current policy model, or explore the agent's environment. Managing the trade-off between these three strategies allows DRL agents to be robust to inconsistent or intermittent human feedback. Through experimentation using a synthetic oracle, we show that our technique improves the training speed and overall performance of deep reinforcement learning in navigating three-dimensional environments using Minecraft.We further show that our technique is robust to highly innacurate human feedback and can also operate when no human feedback is given.</p></td>
                </tr>
            
                <tr>
                    <td>718</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-718">Residential Energy Consumption Patterns in Urban and Rural Areas: A case study of Virginia, USA</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.520</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_718" class="editable_bid" data-pk="718" data-value="30"
                    data-url="/rev_3/paper/bid/set/718/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-718"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal">For improving energy efficiency, managing the demand side of the
energy equation is as important as managing the supply side. Demand response
and home energy management are important tools in curtailing demand and
shifting usage away from peak-time hours. For understanding the demand and
supply dynamics in urban versus rural areas of the U.S. we need to know the
detailed demand estimates of households in these areas along with their
physical characteristics. This information is lacking in the literature and so,
our research attempts to fill this gap. We use an agent-based model to build
disaggregated demand estimates for households during different seasons in both
urban and rural areas. These estimates are based on householders’ demographics,
user behavior, and ratings of appliances used in energy-related activities,
physical characteristics of the house and weather data. Using the US
Census-based classification of regions, we classify the population into urban
areas, urbanized clusters, and rural areas. An energy consumption demand
profile is created for each household based on household occupancy levels, size
of the dwelling, devices, and fuels used in undertaking energy-related
activities, and demographics of the household. Furthermore, this model is used
to perform a comparative analysis of energy demand for urban versus rural
households of Virginia. We believe that such detailed knowledge about energy
consumption profiles can help end-users adjust electricity consumption patterns
with respect to the time and level of energy used, in order to create an
optimal consumption profile that minimizes energy costs. Such profiles can also
help formulate energy policies for demand-side management.<o:p></o:p></p></td>
                </tr>
            
                <tr>
                    <td>131</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-131">Proportionally Representative Participatory Budgeting: Axioms and Algorithms</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.520</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_131" class="editable_bid" data-pk="131" data-value="30"
                    data-url="/rev_3/paper/bid/set/131/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-131"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Participatory budgeting is one of the exciting developments in deliberative grassroots democracy. We concentrate on approval elections and propose proportional representation axioms in participatory budgeting, by generalizing relevant axioms for approval-based multi-winner elections. We observe a rich landscape with respect to the computational complexity of identifying proportional budgets and computing such, and present budgeting methods that satisfy these axioms by identifying budgets that are representative to the demands of vast segments of the voters.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>237</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-237">Individual Security and Network Design with Malicious Nodes</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Noncooperative games: theory &amp; analysis<br>[Agent Societies and Societal Issues] Social networks</td>
                    
                        <td>0.520</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_237" class="editable_bid" data-pk="237" data-value="30"
                    data-url="/rev_3/paper/bid/set/237/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-237"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Networks are beneficial to those being connected but can also be used as carriers of contagious hostile attacks. These attacks are often facilitated by exploiting corrupt network users. To protect against the attacks, users can resort to costly defense. The decentralized nature of such protection is known to be inefficient but the inefficiencies can be mitigated by a careful network design. Is network design still effective when not all users can be trusted? We propose a model of network design and defense with byzantine nodes to address this question. We study the optimal defended networks in the case of centralized defense and, for the case of decentralized defense, we show that the inefficiencies due to decentralization can be fully mitigated, despite the presence of the byzantine nodes.<br></p></td>
                </tr>
            
                <tr>
                    <td>487</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-487">How Bad is Selfish Doodle Voting?</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.520</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_487" class="editable_bid" data-pk="487" data-value="30"
                    data-url="/rev_3/paper/bid/set/487/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-487"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Doodle polls allow people to schedule meetings or events based on the time preferences of participants.&nbsp; Each participant indicates on a web-based poll form which time slots they find acceptable and a time slot with the most votes is chosen. This is a social choice mechanism known as approval voting, in which a standard assumption is that all voters vote sincerely---no one votes no on a time slot they prefer to a time slot they have voted yes on. We take a game theoretical approach to understanding&nbsp; what happens in Doodle polls assuming participants vote sincerely. First we characterize Doodle poll instances where sincere pure Nash Equilibria (NE) exist, both under lexicographic tie-breaking and randomized tie-breaking.&nbsp; We then study the quality of such NE voting profiles in Doodle polls, showing that the price of anarchy and price of stability are both unbounded, even when a slot that many participants vote yes for is selected.&nbsp; Finally, we give some conditions under which the quality of the NE (and strong NE) are good.&nbsp;&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>707</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-707">A unified auction for brand and performance advertising: revenue-optimal bidding proxy for brand advertisers</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.520</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_707" class="editable_bid" data-pk="707" data-value="30"
                    data-url="/rev_3/paper/bid/set/707/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-707"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we consider the revenue maximization problem of an advertising platform that contains both brand advertisers and performance advertisers. Traditionally, the two types of advertisers are handled separately by most platforms: the performance ads are sold via ad auctions that require the advertisers to submit bids while the brand ads are mostly sold via negotiated contracts (i.e., in the form of a certain number of clicks for a posted price, plus some implicit brand effects). In fact, most brand advertisers may not even have a valuation towards a single click on their ads. It therefore remains unclear whether the platform can design a unified mechanism to sell both types of ads, in order to maximize revenue.</p><p>It turns out that it is without loss of generality to assume that the mechanism includes a bidding proxy that places bids on the behalf of the brand advertiser. We then derive the revenue optimal mechanism of this sort.</p></td>
                </tr>
            
                <tr>
                    <td>699</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-699">Estimating Shared Autonomous Vehicle Fleet Size to Meet Urban Daily Travel Demand</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.510</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_699" class="editable_bid" data-pk="699" data-value="30"
                    data-url="/rev_3/paper/bid/set/699/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-699"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Shared autonomous vehicles (SAVs) present the possibility of greatly 
reducing the number of cars in use, and consequently the required 
parking space. We present a methodology to estimate the required SAV 
fleet size to meet travel demand for a region, and develop a detailed 
synthetic population model where we model every individual in a city, 
along with typical weekday activity patterns to estimate the travel 
demand. We combine this with a simulation of SAV routing to determine 
the fleet size needed to satisfy all trips with small waiting times. Our
 results show significant reductions in both the number of vehicles on 
roads and parking demand in cities, which would result in substantial 
savings.<br></p></td>
                </tr>
            
                <tr>
                    <td>256</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-256">When Are Two Gossips the Same? Types of Communication in Epistemic Gossip Protocols</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.510</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_256" class="editable_bid" data-pk="256" data-value="30"
                    data-url="/rev_3/paper/bid/set/256/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-256"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We provide an in-depth study of the knowledge-theoretic aspects of communication in so-called gossip protocols. Pairs of agents communicate by means of calls in order to spread information---so-called secrets---within the group. Depending on the nature of such calls knowledge spreads in different ways within the group. Systematizing existing literature, we identify 18 different types of communication, and model their epistemic effects through different indistinguishability relations. We then study these relations establishing results concerning the relative informativeness of the different types of communication identified.<br></p></td>
                </tr>
            
                <tr>
                    <td>555</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-555">When Can We Approximate Voting Rules from Truncated Ballots ?</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.510</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_555" class="editable_bid" data-pk="555" data-value="30"
                    data-url="/rev_3/paper/bid/set/555/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-555"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Classical voting rules assume that voters' ballots are complete preference orders over candidates. However, when the number of candidates is large enough, it is too costly to ask the voters to rank all candidates. We suggest to fix a rank k, to ask all voters to specify their k best alternatives, and then to consider "k-truncated approximations" of rules, which take only into account the top-k candidates of each ballot. The questions are then: Are these k-truncated approximations good predictors of the approximated rule? For which values of k and under which assumptions can we expect to output the correct winner with high probability? For different voting rules (Borda, Copeland, Maximin and Kemeny), we study these questions theoretically, by giving tight aprroximation ratios, and empirically, based on randomly generated profiles and on real data.<br></p></td>
                </tr>
            
                <tr>
                    <td>408</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-408">Recoverable Team Formation: Building Teams Resilient to Change</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Coalition formation (non-strategic)<br>[Agent Cooperation] Teamwork, team formation, teamwork analysis</td>
                    
                        <td>0.510</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_408" class="editable_bid" data-pk="408" data-value="30"
                    data-url="/rev_3/paper/bid/set/408/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-408"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Team formation consists in finding the least expensive team of agents such that a certain set of skills is covered. In this paper, we formally introduce recoverable team formation (RTF), a generalization of the above problem, by taking into account the dynamic nature of the environment, e.g. after a team has been formed, agents may unexpectedly become unavailable due to failure or illness. We analyze the computational complexity of RTF, provide both complete and heuristic algorithms, and empirically evaluate their performance. Furthermore, we demonstrate that RTF generalizes robust team formation, where the task is to build a team capable of covering all required skills even after any k agents are removed. Despite the high complexity of forming a recoverable team, we argue that recoverability is a crucial feature, and experimentally show that it is more appropriate for some applications than robustness.<br></p></td>
                </tr>
            
                <tr>
                    <td>421</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-421">Buyer-optimal distribution</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.510</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_421" class="editable_bid" data-pk="421" data-value="30"
                    data-url="/rev_3/paper/bid/set/421/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-421"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider the problem of how a buyer can optimize his utility if he is flexible to choose his own valuation distribution to attend a prior-dependent auction, such as the revenue-optimal auction. The problem is motivated by and equivalent to a variation of the market segmentation problem, where a principal tries to find a subset of agents (aka. a market segment) from the set of all agents, each with a constant valuation, to attend a posted price auction for selling M identical items (for some sufficiently large M), in order to maximize the total utilities from the agents who are selected into the segment. Our results are closed-form solutions in both the single buyer case and multi-buyer case where several buyers best response to each other. Interestingly, in the two-buyer case, essentially all commitments that satisfy a certain condition are equilibria.<br></p></td>
                </tr>
            
                <tr>
                    <td>249</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-249">Balancing Asymmetry in Max-sum using Split Constraint Factor Graphs</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Other<br>[Agent Cooperation] Distributed problem solving</td>
                    
                        <td>0.510</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_249" class="editable_bid" data-pk="249" data-value="30"
                    data-url="/rev_3/paper/bid/set/249/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-249"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Max-sum is a version of Belief Propagation, used for solving DCOPs.&nbsp; On tree-structured problems, Max-sum converges to the optimal solution in linear time. Unfortunately&nbsp; when the constraint graph representing the problem includes multiple cycles (as in many standard DCOP benchmarks), Max-sum does not converge and explores low quality solutions. Damping is a method that can be used for increasing the chances that Max-sum will converge, and was recently found to produce high quality solutions for DCOP when combined with an anytime framework. Another recent study revealed that Max-sum, in contrast to most DCOP algorithms, maintains its solution quality when applied to asymmetric problems.</p><p><br></p><p>In this paper we advance the research on incomplete inference DCOP algorithms by proposing a novel method for adjusting the level of asymmetry in the factor graph, in order to achieve a balance between exploitation and exploration, when using Max-sum for solving DCOPs. By converting a standard factor graph to an equivalent split constraint factor graph (SCFG), in which each function node is split to two function nodes, we can control the level of asymmetry for each constraint.</p><p>We prove that for a factor-graph with a single constraint, if this constraint is split symmetrically, Max-sum applied to the resulting cycle is guaranteed to converge to the optimal solution and demonstrate that for an asymmetric split, convergence is not guaranteed.&nbsp;</p><p>Our empirical results demonstrate that by combining damping and asymmetry we can find high quality solutions in a small number of iterations, even without using an anytime framework.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>55</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-55">Graph theoretical properties of logic based argumentation frameworks</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Deductive, rule-based and logic-based argumentation<br>[Knowledge Representation and Reasoning] Ontologies for agents</td>
                    
                        <td>0.510</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_55" class="editable_bid" data-pk="55" data-value="30"
                    data-url="/rev_3/paper/bid/set/55/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-55"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">In this paper we present some graph theoretical properties of logic
based argumentation graphs obtained from an inconsistent knowledge base expressed using existential rules. We fully characterize
argumentation graphs obtained from knowledge bases composed of
factual knowledge and negative rules. Furthermore we provide some
structural properties for general existential rules induced argumentation graphs.&nbsp;</span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>267</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-267">High-Multiplicity Election Problems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.510</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_267" class="editable_bid" data-pk="267" data-value="30"
                    data-url="/rev_3/paper/bid/set/267/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-267"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span style="color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; display: inline !important; float: none;">The computational study of elections generally assumes that the preferences of the electorate come in as a list of votes. Depending on the context, it may be much more natural to represent the list succinctly, as the distinct votes of the electorate and their counts, i.e., high-multiplicity representation. We consider how this representation affects the complexity of election problems. High-multiplicity representation may be exponentially smaller than standard representation, and so many polynomial-time algorithms for election problems in standard representation become exponential. Surprisingly, for polynomial-time election problems, we are often able to either adapt the same approach or provide new algorithms to show that these problems remain polynomial-time in the high-multiplicity case; this is in sharp contrast to the case where each voter has a weight, where the complexity usually increases. In the process we explore the relationship between high-multiplicity scheduling and manipulation of high-multiplicity elections. And we show that for any fixed set of job lengths, high-multiplicity scheduling on uniform parallel machines is in P, which was previously known for only two job lengths. We did not find any natural case where a polynomial-time election problem does not remain in P when moving to high-multiplicity representation. However, we found one natural NP-hard election problem where the complexity does increase, namely</span><span style="color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"> winner determination for Kemeny elections.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>457</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-457">Budget-feasible Procurement Mechanisms in Two-sided Markets</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.510</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_457" class="editable_bid" data-pk="457" data-value="30"
                    data-url="/rev_3/paper/bid/set/457/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-457"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This paper considers the mechanism design problem in two-sided markets where multiple strategic buyers come with budgets to procure as much value of items&nbsp; as possible from the strategic sellers. Sellers are allowed to untruthfully bid their costs and buyers could claim their budgets, not necessarily the true ones. The goal is to seek truthful budget-feasible mechanisms that ensure sellers are rewarded enough payment and buyers' budgets are not exceeded. Prior to this work, existing budget-feasible procurement mechanisms are limited in one-sided market with a single buyer and address only sellers' truthfulness.&nbsp; We study two models,&nbsp; one with homogeneous item values and the other with heterogeneous item values.&nbsp; Our main contributions are two budget-feasible mechanisms&nbsp; with various desired theoretical guarantees like, the truthfulness both on the sellers' side and the buyers' side, and constant approximation that the total procured value of buyers approximates the optimal solution within a constant factor.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>337</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-337">Distributed Large Neighborhood Search for Solving Large-Scale DCOPs</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Distributed problem solving<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems</td>
                    
                        <td>0.500</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_337" class="editable_bid" data-pk="337" data-value="30"
                    data-url="/rev_3/paper/bid/set/337/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-337"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Distributed constraint reasoning has recently gained momentum due to its ability to handle many combinatorial problems that are naturally distributed over a set of agents. However, to date most approaches cannot handle large-scale optimization problems. On the other hand, while large neighborhood search (LNS) has been widely applied for such large-scale problems in the centralized case, little attention has been devoted to the application of LNS in a distributed setting. In this paper, we present a general anytime framework for solving distributed constraint optimization problems (DCOP) using LNS. Our approach does not make any assumption on the number of variables per agent nor the constraints of the problem. Our approach is an anytime iterative distributed incomplete&nbsp; algorithm. On each iteration, it explores multiple neighborhoods. It allows different mechanisms for selecting those neighborhoods, it supports concurrent exploration of them using different algorithms, and it allows different mechanisms for aggregating the outputs of these algorithms. Our empirical results show that large gains can be achieved through the proposed approach.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>482</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-482">Addressing Concept Drift in Reputation Assessment</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Trust and reputation<br>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)</td>
                    
                        <td>0.500</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_482" class="editable_bid" data-pk="482" data-value="30"
                    data-url="/rev_3/paper/bid/set/482/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-482"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><div>Trust, reputation and stereotype models use past interactions to predict agents' future behaviour. Such behaviour may change over time, and forgetting factors or sliding windows are typically used to give higher importance to recent interactions and discount past records. However, tuning these parameters can result in losing relevant data or retaining too much old data. In this paper, we use established concept drift techniques to identify both gradual and sudden changes in behaviour, in environments where such changes may occur non-uniformly across the population. Using our method, agents are able to exclude irrelevant and unrepresentative past interactions from calculating trust, reputation and stereotypes.</div><div><br></div><div>Our results show that our method is robust against gradual and sudden behaviour change because it retains a higher proportion of relevant data, while previous methods take several iterations to remove data that is no longer representative. Stereotypes are more sensitive to behaviour change than trust and reputation because they rely on a larger amount of historical data. Our method is particularly beneficial when agent turnover is high, since when agents have less direct experience there is more emphasis on stereotypes.&nbsp;<br></div></td>
                </tr>
            
                <tr>
                    <td>206</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-206">Ranking mechanism design for price-setting agents in e-commerce</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.500</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_206" class="editable_bid" data-pk="206" data-value="30"
                    data-url="/rev_3/paper/bid/set/206/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-206"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><pre style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;"><pre style="margin-bottom: 0px;"><pre style="margin-bottom: 0px;"><span style=" color:#000000;">Ranking algorithms of e-commerce sites take the buyer's search query and information <gs id="b0a041bf-857c-480d-bee5-57f07edc8a0e" ginger_software_uiphraseguid="5082b2cb-0b02-4d72-81b6-e95311a342fc" class="GINGER_SOFTWARE_mark">of</gs> the corresponding sellers' items as input, and output a ranking of sellers' items that maximizes sites' objectives. However, the conversion rate of each item (i.e., the probability of a completed transaction) not only depends on the ranking given by the site (which controls click-through rates), but also depends on the item price set by its seller(which controls the buyer's willingness to buy). As a result, a ranking algorithm is in fact a mechanism that deals with sellers who strategically set item prices.</span></pre><pre style="margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);">An interesting fact about this setting, at least </span><span style="color: rgb(0, 0, 0);">the </span><span style="color: rgb(0, 0, 0);">status</span><span style="color: rgb(0, 0, 0);"> </span><span style="color: rgb(0, 0, 0);">quo for the largest e-commerce sites such as Taobao, Amazon, and eBay, is that sellers are usually not given the option to report their private costs but can only communicate with the site by setting item prices. In terms of <gs id="04f088c5-5edc-4159-8219-26f3a770e83f" ginger_software_uiphraseguid="1fed0bfa-e84a-4abe-bbc3-a393998c771c" class="GINGER_SOFTWARE_mark">mechanism</gs> design, this is a setting where the designer is restricted to design a specific type of indirect mechanisms.</span></pre><pre style="margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);">We follow the framework of implementing optimal direct mechanisms by indirect mechanisms to tackle this optimal indirect ranking mechanism design problem. We firstly define a related optimal direct ranking mechanism design setting and use Myerson's characterization to optimize in that setting. We then characterize the class of direct mechanisms which could be implemented by indirect mechanisms, and construct a mapping that maps the mechanisms designed in the previous direct setting to indirect mechanisms in the original setting where sellers are allowed only to set item prices. We show that, using this technique, one can obtain mechanisms in the indirect setting that maximize expected total trading volume. We then present the mechanism employed by Taobao currently, get a Bayesian Nash Equilibrium of it and obtain the gap of the volume of Taobao and the optimal mechanism. Given real dataset from Taobao, we also simulate our optimal mechanism and Taobao's mechanism, and it shows that our mechanism outperforms Taobao's mechanism significantly.</span></pre></pre></pre></td>
                </tr>
            
                <tr>
                    <td>620</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-620">Efficient Randomized Mechanisms for Matching Under Indifference Classes</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.500</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_620" class="editable_bid" data-pk="620" data-value="30"
                    data-url="/rev_3/paper/bid/set/620/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-620"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We study the problem of assigning a set of indivisible objects to self-interested agents in the absence of transferable utilities. Under strict ordinal preferences several well-known mechanisms, such as Random Serial Dictatorship and Probabilistic Serial rule, guarantee a desirable set of properties such as Pareto efficiency, strategyproofness, and non-bossiness. However, when agents are able to specify indifferences in their preferences, these mechanisms no longer satisfy these properties. We consider specialized sub-domains of preferences, in which agents can express indifferences, and develop easy-to-implement and efficient randomized algorithms to restore efficiency, strategyproofness, and non-bossiness requirements.</p></td>
                </tr>
            
                <tr>
                    <td>386</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-386">Fair Privacy Multilateral Closed Negotiation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.500</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_386" class="editable_bid" data-pk="386" data-value="30"
                    data-url="/rev_3/paper/bid/set/386/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-386"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In multi-agent systems, a multilateral closed negotiation, where the opponent's strategy and utility are closed, is an important class of automated negotiation. Recently, stacked alternating offers protocols (SAOP) for multilateral negotiations have become an important negotiation protocol, such as in the automated negotiating agents competition (ANAC). However, most existing negotiation protocols (including SAOP) haven't addressed the privacy issues of agents. During negotiations, such private information as agents' preferences should be revealed fairly because each agent loses utility when doing so. </p><p>In this paper, we propose a negotiation protocol that addresses the fairness of revealing each agent's private information. First, we propose a new measure of revealing each agent's private information, which is based on the accuracy of the common estimating method of opponents' utility functions. Next, the negotiation protocol adjusts the number of offers by each agent based on a new measure. This adjustment encourages agents who reveal less private information than other agents to reveal more offers. In the experiments, we compare and investigate the fairness of revealing private information by tournaments among state-of-the-art agents in ANAC2016 using our proposed negotiation protocol. The experimental results demonstrate that our proposed negotiation protocol with the adjustment improves the fairness of the revealed private information.</p></td>
                </tr>
            
                <tr>
                    <td>289</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-289">Learning Others&#39; Intentional Models in Multi-Agent Settings Using Interactive POMDPs</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Agent Cooperation] Multi-user/multi-virtual-agent interaction</td>
                    
                        <td>0.500</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_289" class="editable_bid" data-pk="289" data-value="30"
                    data-url="/rev_3/paper/bid/set/289/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-289"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Interactive partially observable Markov decision processes (I-POMDPs) provide a principled framework for planning and acting in a partially observable, stochastic and multi-agent environment, extending POMDPs to multi-agent settings by including models of other agents in the state space and forming a hierarchical belief structure. In order to predict other agents' actions using I-POMDP, we propose an approach that effectively uses Bayesian inference and sequential Monte Carlo (SMC) sampling to learn others' intentional models which ascribe to them beliefs, preferences and rationality in action selection. Empirical results show that our algorithm accurately learns models of other agents and has superior performance when compared to other methods. Our approach serves as a generalized reinforcement learning algorithm that learns other agents' beliefs, and transition, observation and reward functions. It also effectively mitigates the belief space complexity due to the nested belief hierarchy.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>673</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-673">The Cost of Diversity in Multiwinner Elections</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.500</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_673" class="editable_bid" data-pk="673" data-value="30"
                    data-url="/rev_3/paper/bid/set/673/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-673"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Multiwinner elections schemes typically focus on the goal of maximizing either excellence or representation. The goal of selecting a diverse winning set usually has a lower priority, or is not considered at all, because any improvement in diversity could come at the cost of excellence or representativeness of the winning set. Programs that increase diversity and inclusion have real-world benefits for organizations that implement them. However, methods such as quotas are sometimes controversial because they can elect candidates that are unqualified. We present a metaheuristic for increasing inclusion, and give experimental results for k-Approval, and k-Borda. Our results show that inclusion can be increased at a relatively low cost to in overall voter satisfaction.<br></p></td>
                </tr>
            
                <tr>
                    <td>167</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-167">District-Based Elections: Contrasting Current, Optimal, and Likely Outcomes</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.500</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_167" class="editable_bid" data-pk="167" data-value="30"
                    data-url="/rev_3/paper/bid/set/167/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-167"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block">In many electoral systems, voters are divided into territorial subdivisions for electing members to a legislative body.  Naturally, different partitions may result in different outcomes; gerrymandering (i.e., strategic partitioning into districts) thus potentially affects election results, and has been used for many decades as an election manipulation technique by both major U.S.~political parties. Nevertheless, the United States Supreme Court has never struck down any redistricting plan, as it is difficult to distinguish accidental from intentional manipulation of district borders.

We propose an approach to evaluating likely and less likely results among different redistricting options, as a fundamental sub-problem within the broader goal of identifying remedies for this type of election control.  We examine data from two 2016 elections, for the United States House of Representatives in North Carolina and Ohio. Our analysis shows that while in North Carolina there is evidence that the current district partition is significantly better for the Republican Party, there is little evidence that either party has an advantage due to gerrymandering in Ohio.</td>
                </tr>
            
                <tr>
                    <td>109</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-109">Stability and Pareto Optimality in Refugee Allocation Matchings</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.500</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_109" class="editable_bid" data-pk="109" data-value="30"
                    data-url="/rev_3/paper/bid/set/109/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-109"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We focus on the refugee matching problem---a general ``two-sided matching under preferences'' model with multi-dimensional feasibility constraints that was formalized by Delacretaz, Kominers, and Teytelboym (2016). We propose a taxonomy of stability concepts for the problem; identify relations between them; and show that even for two natural weakenings of the standard stability concept, &nbsp;non-existence and NP-hardness results persist. We then identify several natural weaker stability concepts for which we present a polynomial-time and strategy-proof algorithm that returns a stable matching. We also examine the complexity of computing and {testing} Pareto optimal matchings.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>157</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-157">Determining acceptable points of view for ranking based argumentation semantics</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Communication and Argumentation] Deductive, rule-based and logic-based argumentation<br>[Communication and Argumentation] Other</td>
                    
                        <td>0.500</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_157" class="editable_bid" data-pk="157" data-value="30"
                    data-url="/rev_3/paper/bid/set/157/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-157"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">In this paper we consider the following research question: “What are
acceptable points of view for ranking-based argumentation semantics?” To answer this question we introduce a new generic framework that considers a selection function, a ranking on arguments
and a lifting function as its input parameters. We study the different
combinations the instantiation of these parameters yield and thus
demonstrate the modularity of our framework. We introduce a set of
postulates and study their satisfaction for the framework’s different
classes of output.&nbsp;</span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>342</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-342">Seasonal Goods and Spoiled Milk: Pricing for a Limited Shelf-Life</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis<br>[Economic Paradigms] Other</td>
                    
                        <td>0.500</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_342" class="editable_bid" data-pk="342" data-value="30"
                    data-url="/rev_3/paper/bid/set/342/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-342"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We examine the case of items with a limited shelf-life where storing an item (before consumption) may carry a cost to a buyer (or distributor). For example, eggs, milk, or Groupon coupons have a fixed expiry date, and seasonal goods can suffer a decrease in value. We show how this setting contrasts with recent results by Berbeglia et al. for items with infinite shelf-life.</p><p>We prove tight bounds on the seller's profits showing how they relate to the items' shelf-life. We show, counterintuitively, that in our limited shelf-life setting, increasing storage costs can sometimes lead to less profit for the seller which cannot happen when items have unlimited shelf-life. We also provide an algorithm that calculates optimal prices.</p><p>Finally, we examine empirically the relationship between profits and buyer utility as the storage cost and shelf-life duration change, and observe properties, some of which are unique to the limited shelf-life setting.</p></td>
                </tr>
            
                <tr>
                    <td>612</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-612">Judgment Aggregation with Rationality and Feasibility Constraints</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Theories and Models] Logics for agents and multi-agent systems</td>
                    
                        <td>0.500</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_612" class="editable_bid" data-pk="612" data-value="30"
                    data-url="/rev_3/paper/bid/set/612/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-612"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>I introduce a model of judgment aggregation that allows for an explicit distinction between rationality and feasibility constraints. The former are assumed to be satisfied by the individual agents; the latter must be met by the collective decision returned by the aggregation rule in use. Using this model, I characterise the class of combinations of rationality and feasibility constraints for which the majority rule can guarantee feasible outcomes and I propose several majoritarian aggregation rules that, in some sense, approximate the ideal of the majority when using the majority rule itself is not feasible. Finally, to illustrate the power and flexibility of the model, I show how it can be used to simulate several common voting rules in a simple and elegant manner. This includes the well-known Borda rule, for which finding a natural counterpart in judgment aggregation has long been an elusive quest.<br><br><br></p></td>
                </tr>
            
                <tr>
                    <td>553</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-553">From Individual Goals to Collective Decisions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.500</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_553" class="editable_bid" data-pk="553" data-value="30"
                    data-url="/rev_3/paper/bid/set/553/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-553"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Classical rules for collective decision-making often require agents to fully specify their preference or opinion to compute the result. In particular, judgment aggregation rules require each agent to answer a yes/no question on a set of issues and they then output a collective judgment. In this paper we relax this assumption, by letting agents express their goals by means of propositional formulas on a finite set of binary issues. We propose a number of rules for aggregating individual goals into a decision for the group. We adapt axiomatic properties from the literature on Social Choice Theory to our setting, providing a full characterisation for one of our rules. We also study computationally the problem of determining the outcome for the defined rules (i.e., winner determination), showing that the generalisation from fully specified models to individual goals does significantly increase the complexity.<br></p></td>
                </tr>
            
                <tr>
                    <td>75</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-75">Generic Integration of Personality and Mood with Emotions: A Machine Learning Approach</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Cognitive models<br>[Agent Theories and Models] Models of emotions</td>
                    
                        <td>0.490</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_75" class="editable_bid" data-pk="75" data-value="30"
                    data-url="/rev_3/paper/bid/set/75/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-75"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
  <o:PixelsPerInch>96</o:PixelsPerInch>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>EN-GB</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]-->

<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin:0cm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-fareast-language:EN-US;}
</style>
<![endif]-->



<!--StartFragment-->



<!--EndFragment--></p><p class="MsoNormal">Intelligence is not a self-contained characteristic of an
individual. This point needs to be considered when we design and develop artificially
intelligent agents. Researchers have found that emotion is a critical component
of general intelligence. An intelligent agent should be able to show different
emotional behaviours in different interaction situations. It is widely accepted
that personality and mood play an important role in modulating emotions.
However, current computational accounts of emotion for intelligent agents do not
effectively integrate the notions of personality and mood in the process of
emotion generation. Even if some attempts have been made, those are based on
designer assumptions and user-defined rules. In this paper, we present our
novel supervised machine learning approach to train a network of emotions
integrating the factors of personality and mood, that provides a high and
robust prediction accuracy. As a secondary contribution, we also present our data collection technique that can be utilised in the training and evaluation
of emotion models.<o:p></o:p></p></td>
                </tr>
            
                <tr>
                    <td>397</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-397">Constraint Composite Graph-Based Lifted Message Passing for Distributed Constraint Optimization Problems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Other<br>[Agent Cooperation] Distributed problem solving</td>
                    
                        <td>0.490</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_397" class="editable_bid" data-pk="397" data-value="30"
                    data-url="/rev_3/paper/bid/set/397/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-397"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The Distributed Constraint Optimization Problem (DCOP) offers a powerful approach for the description and resolution of cooperative multi-agent problems. In this model, a group of agents coordinates their actions to optimize a global objective function, taking into account their local preferences. <br>In the majority of the DCOP algorithms, agents operate onto three main graphical representations of the problem: (a) the constraint graph, (b) the pseudo-tree, or (c) the factor graph. In this paper, we introduce the&nbsp; Constraint Composite Graph (CCG) for DCOPs, an alternative graphical representation onto which agents can coordinate their assignment to solve the distributed problem. We propose a novel variant of Max-sum, called CCG-Max-sum which is applied to CCGs, and demonstrate the effectiveness of CCG-Max-sum on DCOP benchmarks based on several network topologies.<br></p></td>
                </tr>
            
                <tr>
                    <td>376</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-376">Surrogate Difference Evaluations with Limited Peer to Peer Communications</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Co-evolutionary algorithms</td>
                    
                        <td>0.490</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_376" class="editable_bid" data-pk="376" data-value="30"
                    data-url="/rev_3/paper/bid/set/376/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-376"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Decentralized Multiagent Systems (MAS) have distinct advantages over single agent systems including robustness, scalability and error tolerance. Credit assignment is a key component in empowering MAS and techniques such as Difference Evaluations have been used successfully to train MAS in a wide variety of applications. This success depends on frequent, if not continuous, exchange of data in the system. However, what level of success occurs when communication is severely limited?&nbsp; This paper presents the effects of limited communication on system performance when agents learn using Difference Evaluations within a Cooperative Co-Evolutionary Algorithm (CCEA). For simulation and evaluation purposes, the CCEA utilizes a barrier free Underwater Multiagent Exploration Domain (UMED).&nbsp; Communication is limited below the surface of the water, but not above the surface. Our results show a system performance degradation of less than 10% when system training utilized Difference Evaluations experiencing limited communications (99.6% reduction in communication ability) when compared with full communication within the domain.&nbsp;&nbsp; Additionally, we show that system performance increased when the system is trained utilizing Global Evaluations under limited communications when compared with full communication within the domain.<br></p></td>
                </tr>
            
                <tr>
                    <td>751</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-751">Ex-post IR dynamic auctions with cost-per-action payments</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.490</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_751" class="editable_bid" data-pk="751" data-value="30"
                    data-url="/rev_3/paper/bid/set/751/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-751"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Consider a repeated auction between one seller and many buyers, where each buyer only has an estimation of her value in each period until she actually received the item in that period. The seller is allowed to conduct a dynamic auction to sell the items but must guarantee ex-post individual rationality. In other words, if the buyer realized that her value of the item she just received is zero, she does not need to pay anything. One important application of this model is the cost-per-action (or pay-per-action) auctions in online advertising, where the buyers (advertisers) are charged only when some user clicks their ads, goes to their websites, and makes some meaningful actions (e.g., buys something). Unlike the clicks on the ads, these actions are private information only observable by the buyers (advertisers). Hence they may have incentives to misreport the user actions, because they can pay less under cost-per-action payment schemes with ex-post individual rationality guarantees.&nbsp;</p><p>In this paper, we introduce a novel structure that we call credit accounts to enable a general reduction from any incentive compatible and ex-ante individually rational dynamic auction to an approximately incentive compatible and ex-post individually rational dynamic auction with credit accounts. Our reduction can obtain stronger individual rationality guarantees at of the cost of weaker incentive compatibility. Surprisingly, our reduction works without making any common knowledge assumptions. Finally, as a complement to our reduction, we prove that there is no non-trivial auction that is exactly incentive compatible and ex-post individually rational in this setting.&nbsp;</p></td>
                </tr>
            
                <tr>
                    <td>115</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-115">Price-based Online Mechanisms for Settings with Uncertain Future Procurement Costs and Multi-Unit Demand</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.490</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_115" class="editable_bid" data-pk="115" data-value="30"
                    data-url="/rev_3/paper/bid/set/115/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-115"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We examine the use of online mechanism design in settings where consumers have multi-unit demand, goods are procured and allocated over time, and future procurement costs are uncertain and only become known at the time of allocation. An important application with such characteristics is demand response, where electricity wholesale prices depend on overall demand and the availability of renewables. We formulate this as a mechanism design problem and focus specifically on the property that the mechanism does not revoke any allocated items. For this setting, we characterise a class of price-based mechanisms that guarantee dominant-strategy incentive compatibility, individual rationality, and no cancellation. We present three specific such mechanisms in this domain and evaluate them in an electric vehicle charging setting. Using extensive numerical simulations, we show that a mechanism based on the first-come first-serve principle performs well in settings where future procurement costs can be estimated reliably or supply is very tight, while a responsive mechanism performs very well when the estimated procurement costs are highly uncertain and supply is not as tight. We moreover show that a well-defined price-based mechanism can lead to high profits for the operator of the mechanism in many real-world situations.</p></td>
                </tr>
            
                <tr>
                    <td>638</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-638">Truthful Mechanisms for Interval Scheduling with Applications to Cloud Computing</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.490</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_638" class="editable_bid" data-pk="638" data-value="30"
                    data-url="/rev_3/paper/bid/set/638/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-638"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><font face="Times New Roman, serif"><span style="font-size: 16px;">Motivated by cloud computing, we study a market-based approach for job scheduling on multiple machines where users have hard deadlines and prefer earlier completion times. In our model, completing a job provides a benefit equal to its present value, i.e., the value discounted to the time when the job finishes. Users submit job requirements to the cloud provider who non-preemptively schedules jobs to maximize the social welfare, i.e., the sum of present values of completed jobs. Using a simple and fast greedy algorithm, we obtain a (2-b</span><span style="font-size: 16px;">)/(1-b) approximation to the optimal schedule, where 0 &lt; b &lt; 1 is the discount factor shared by all jobs. Building on our approximation algorithm, we construct a pricing rule to incentivize users to truthfully report all job requirements.</span></font></p></td>
                </tr>
            
                <tr>
                    <td>85</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-85">Evaluating the Stability of Non-Adaptive Trading in Continuous Double Auctions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.490</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_85" class="editable_bid" data-pk="85" data-value="30"
                    data-url="/rev_3/paper/bid/set/85/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-85"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The continuous double auction (CDA) is the predominant mechanism in modern securities markets. Despite much prior study of CDA strategies, fundamental questions about the CDA remain open, such as: (1) to what extent can outcomes in a CDA be accurately modeled by optimizing agent actions over only a simple, non-adaptive policy class; and (2) when and how can a policy that conditions its actions on market state deviate beneficially from an optimally parameterized, but simpler, policy like Zero Intelligence (ZI). To investigate these questions, we present an experimental comparison of the strategic stability of policies found by reinforcement learning (RL) over a massive space, or through empirical Nash-equilibrium solving over a smaller space of non-adaptive, ZI policies. Our findings indicate that in a plausible market environment, an adaptive trading policy can deviate beneficially from an equilibrium of ZI traders, by conditioning on signals of the likelihood a trade will execute or the favorability of the current bid and ask. Nevertheless, the surplus earned by well-calibrated ZI policies is empirically observed to be nearly as great as what a deviating reinforcement learner could earn, using a much larger policy space. This finding supports the idea that it is reasonable to use equilibrated ZI traders in studies of CDA market outcomes.</p></td>
                </tr>
            
                <tr>
                    <td>147</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-147">Max-min Fair Allocation for the Combination of Indivisible and Divisible Goods</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.480</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_147" class="editable_bid" data-pk="147" data-value="30"
                    data-url="/rev_3/paper/bid/set/147/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-147"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Fair allocation&nbsp; is a classic problem in economics and computer science. Its application scenarios include inheritance settlement, border dispute resolution, computing resource sharing and so on. Although the problem has attracted much attention, the existing work either only focuses on the fair allocation of indivisible goods or only focuses on the fair allocation of divisible goods, but not both. However, in real applications, the allocated goods set may simultaneously include indivisible goods and divisible goods, e.g., the allocated inheritance may include indivisible houses and divisible lands. The combination of indivisible goods and divisible goods requires us to consider how to coordinate the allocations of indivisible goods and divisible goods, which has not been discussed in the existing work. Therefore, this paper investigates the more general case of fair allocation problem, where the allocated goods set consists of both indivisible goods and divisible goods. In the study, we focus on the max-min fairness, i.e., maximizing the minimum utility of any agent. First, we present a mixed-integer linear programming formulation to compute the optimal allocation strategy. Second, because the problem is NP-hard, we propose an approximation algorithm that runs in polynomial time and has provable performance guarantee. The algorithm is composed of three phases: i) we divide the divisible goods into n equal-utility virtual goods, where n is the agent number; ii) we regard the virtual goods as indivisible and fairly allocate the indivisible goods and virtual goods; iii) we adjust the allocation of divisible goods to improve the allocation strategy. Experiments conducted on real data show that the approximation algorithm produces near-optimal solutions when the goods number or the agent number is large enough.<br></p></td>
                </tr>
            
                <tr>
                    <td>32</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-32">Autonomous Object-Oriented Curriculum Generation for Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.480</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_32" class="editable_bid" data-pk="32" data-value="30"
                    data-url="/rev_3/paper/bid/set/32/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-32"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><style type="text/css">
p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 14.0px; font: 12.0px Courier; color: #000000; -webkit-text-stroke: #000000}
span.s1 {font-kerning: none}
span.s2 {text-decoration: underline ; font-kerning: none}
</style>


<p class="MsoNormal">Autonomously learning a complex task takes a very long time for Reinforcement Learning (RL) agents.&nbsp;<span style="font-size: 12pt;">One way to learn faster is by dividing a complex task into several simple subtasks and organizing them in a Curriculum that guides Transfer Learning (TL) methods to reuse knowledge in a convenient &nbsp;sequence.&nbsp;</span><span style="font-size: 12pt;">&nbsp;However, previous works do not take into account the TL method to build specialized Curricula, leaving the burden of a careful subtask selection to a human.&nbsp;</span><span style="font-size: 12pt;">We here rely on Object-Oriented task descriptions to guide both the Curriculum generation and knowledge reuse procedures, autonomously building object-based Curricula.&nbsp;</span><span style="font-size: 12pt;">We also propose a novel procedure for autonomously dividing the target task into simpler ones under minimal human supervision.&nbsp;</span><span style="font-size: 12pt;">Our experiments show that our proposal achieves a better performance using both manually given and autonomously generated subtasks when compared to the state-of-the-art technique in two different domains.</span></p><p class="MsoNormal"><o:p></o:p></p><style>
<!--
 /* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073786111 1 0 415 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
@page WordSection1
	{size:595.0pt 842.0pt;
	margin:72.0pt 72.0pt 72.0pt 72.0pt;
	mso-header-margin:35.4pt;
	mso-footer-margin:35.4pt;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style></td>
                </tr>
            
                <tr>
                    <td>632</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-632">Multi-Agent Distributed Lifelong Learning for Collective Knowledge Acquisition</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Collective intelligence<br>[Learning and Adaptation] Multiagent learning</td>
                    
                        <td>0.480</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_632" class="editable_bid" data-pk="632" data-value="30"
                    data-url="/rev_3/paper/bid/set/632/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-632"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Lifelong machine learning methods acquire knowledge over a series of consecutive tasks, continually building upon their experience.&nbsp; Current lifelong learning algorithms rely upon a single learning agent that has centralized access to all data. In this paper, we extend the idea of lifelong learning from a single agent to a network of multiple agents that collectively learn a series of tasks. Each agent faces some (potentially unique) set of tasks; the key idea is that knowledge learned from these tasks may benefit other agents trying to learn different (but related) tasks.&nbsp; Our Collective Lifelong Learning Algorithm (CoLLA) provides an efficient way for a network of agents to share their learned knowledge in a distributed and decentralized manner, while preserving the privacy of the locally observed data. We provide theoretical guarantees for robust performance&nbsp; of the algorithm and empirically demonstrate that CoLLA outperforms existing approaches for distributed multi-task learning on a variety of data sets.<br></p></td>
                </tr>
            
                <tr>
                    <td>38</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-38">Parallel Transfer Learning: Accelerating Reinforcement Learning in Multi-Agent Systems</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent-to-agent interactions (negotiation, trust, coordination)<br>[Learning and Adaptation] Multiagent learning</td>
                    
                        <td>0.480</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_38" class="editable_bid" data-pk="38" data-value="30"
                    data-url="/rev_3/paper/bid/set/38/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-38"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Many large-scale systems require autonomous control to manage their inherent complexity, scale and variability.&nbsp; Reinforcement Learning (RL) approaches are frequently used in such systems to learn the behaviours that best suit the system's operating environment. However, learning can take a significant amount of time during which an RL system's performance is necessarily suboptimal. To minimize the periods of suboptimal performance, learning experiences and interactions should be used as efficiently as possible.&nbsp;</p><p>Transfer learning (TL), a method of reusing knowledge which has been gained in one task to improve the performance in another, has been used to speed up learning in single RL agent systems. However, TL requires learning on a source task to complete before it can be transferred to a target task, i.e., transfer is done offline. In multi-agent RL, agents are learning simultaneously so any potentially useful transfers need to be done online, before learning has necessarily converged. Transfers should also be multi-directional, i.e., any agent should be able to act both as a source and as a target.</p><p>This paper presents Parallel Transfer Learning (PTL), a technique for online transfer of knowledge in multi-agent RL systems, which allows the source of learnt information and the target task to run concurrently. PTL proposes multiple methods for selecting the knowledge to be transferred, frequency and size of transfers, and multiple methods for knowledge integration into the target task. We evaluate PTL in three canonical RL examples: Cart Pole, Mountain Car, and Co-operative Predator Prey Pursuit.&nbsp;</p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>706</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-706">A Closed-Form Characterization of Buyer Signaling Schemes in Monopoly Pricing</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.480</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_706" class="editable_bid" data-pk="706" data-value="30"
                    data-url="/rev_3/paper/bid/set/706/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-706"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider a setting where a revenue maximizing monopolist sells a single item to a buyer. A mediator first collects the buyer's value and can reveal extra information about the buyer's value by sending signals. Mathematically, a signal scheme can be thought of as a decomposition of the prior value distribution into a linear combination of posterior value distributions, and based on each of them, the monopolist separately posts a price. According to the theory of Bayesian persuasion, a well designed signal scheme can lead to utility improvements for both the monopolist and the buyer.</p><p>We put forward a novel technique to analyze the effects of signal schemes of the mediator. Using this technique, we are able to construct explicitly a closed-form solution, and thus characterize the set of seller-buyer utility pairs achievable by any signal scheme, for any prior type distribution. Our result generalizes a well-known result by Bergemann et. al., who derive a characterization for the same problem but only restricted to the discrete distribution case.<br></p><p>Similar to the result derived by Bergermann et. al., we show that the set of seller and buyer utility pairs achievable form a triangle: any point within the triangle can be achieved by an explicitly constructed signal scheme and any point outside the triangle cannot be achievable by any such scheme. Our result is obtained by establishing the endpoints of the triangle: one corresponds to the point where the buyer obtains the highest utility among all schemes, another corresponds to the point where the buyer obtains zero utility and the seller has the lowest possible revenue, and the third corresponds to the point where the buyer has zero utility while the seller extracts full social surplus. We then prove that the triangle described fully characterizes all possible&nbsp; signal schemes.<br></p></td>
                </tr>
            
                <tr>
                    <td>279</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-279">On the Weakness of Strong Stackelberg Equilibrium for Security Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.480</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_279" class="editable_bid" data-pk="279" data-value="30"
                    data-url="/rev_3/paper/bid/set/279/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-279"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Strong Stackelberg Equilibrium (SSE) has become a standard solution concept in various security game applications. SSE is built upon the optimistic tie-breaking rule that the follower breaks ties in favor of the leader. The intuition behind adopting SSE in security games is the widely acknowledged assumption that the defender can induce the attacker to choose a preferred action by making an infinitesimal adjustment to her strategy and achieve an expected utility that is arbitrarily close to the prescribed value in SSE. Unfortunately, in security games with resource assignment constraints, it is possible that the defender cannot induce the desired outcome, and hence the results claimed in the security game literature may be overly optimistic. To overcome this issue, this paper provides (i) a formal definition of the utility guarantee of a defender strategy, and examples showing that the guaranteed utility of an SSE strategy can be much lower than the expected utility of SSE (claimed to be guaranteed in the security game literature); (ii) a general algorithmic operationalization of Inducible Stackelberg Equilibrium (ISE) based on the notion of inducibility (von Stengel and Zamir, 2004), where we prove that ISE always exists and leads to the highest guaranteed utility for the defender; (iii) formal comparisons between ISE and SSE together with a polynomial-time reduction from computing an ISE to computing an SSE; (iv) a novel algorithm CHASE to compute ISE for realistic-sized instances with column generation and heuristic bounds; and (v) extensive experimental evaluation unveiling significant overoptimism and sub-optimality of SSE.</p></td>
                </tr>
            
                <tr>
                    <td>485</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-485">Lenient Multi-Agent Deep Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Multiagent learning<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.480</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_485" class="editable_bid" data-pk="485" data-value="30"
                    data-url="/rev_3/paper/bid/set/485/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-485"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block">Much of the success of single agent deep reinforcement learning (DRL) in recent years can be attributed to the use of experience replay memories (ERM), which allow Deep Q-Networks (DQNs) to be trained efficiently through sampling stored state transitions. However, care is required when using ERMs for multi-agent deep reinforcement learning (MA-DRL), as stored transitions can become outdated because agents update their policies in parallel (Foerster et al., 2017). In this work we apply leniency (Panait et al., 2006)  to MA-DRL. Lenient agents map state-action pairs to decaying temperature values that control the amount of leniency applied towards negative policy updates that are sampled from the ERM. This introduces optimism in the value-function update, and has been shown to facilitate cooperation in tabular fully-cooperative multi-agent reinforcement learning problems. We evaluate our Lenient-DQN (LDQN) empirically against the related Hysteretic-DQN (HDQN) algorithm (Omidshafiei et al., 2017) as well as a modified version we call scheduled-HDQN, that uses average reward learning near terminal states. Evaluations take place in extended variations of the Coordinated Multi-Agent Object Transportation Problem (CMOTP) (Busoniu et al., 2010) which include fully-cooperative sub-tasks and stochastic rewards. We find that LDQN agents are more likely to converge on the optimal policy in a stochastic reward CMOTP compared to standard and scheduled-HDQN agents.<br></td>
                </tr>
            
                <tr>
                    <td>168</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-168">More complexity results about reasoning over (m)CP-nets</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.480</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_168" class="editable_bid" data-pk="168" data-value="30"
                    data-url="/rev_3/paper/bid/set/168/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-168"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><span id="ctl00_cph_SubmissionSummary_AbstractText" style="font-size:Small;">Aggregating preferences over combinatorial domains has several applications in AI. Due to the exponential nature of combinatorial preferences, compact representations are needed, and (m)CP-nets are among the most studied formalisms. Unlike CP-nets, which received an extensive complexity analysis, mCP-nets, as mentioned several times in the literature, lacked such a thorough characterization. In fact, an initial complexity analysis for mCP-nets was carried out only recently. In this paper, we further investigate the complexity of mCP-nets. In particular, we prove the \Sigma^P_3-completeness of the existence of Max optimal outcomes. Furthermore, we prove that various tasks known to be feasible in polynomial time are actually P-complete. This shows that these problems are inherently sequential, and hence they cannot benefit from highly parallel computation.</span><br></p></td>
                </tr>
            
                <tr>
                    <td>116</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-116">Multi-Objective Distributed Pseudo-tree Optimization</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Other<br>[Agent Cooperation] Distributed problem solving</td>
                    
                        <td>0.470</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_116" class="editable_bid" data-pk="116" data-value="30"
                    data-url="/rev_3/paper/bid/set/116/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-116"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Many real world optimization problems involve multiple criteria that should be considered separately and optimized simultaneously. Multi-Objective Distributed Constraint Optimization Problem (MO-DCOP) is a fundamental problem to formalize various multi-agent applications and is the extension of a mono-objective DCOP where the goal is to find the Pareto front. In MO-DCOPs, it is well known that the Pareto front is exponential in the size of the problem, leading to agents having to exchange an exponential amount of information. In this paper, we develop a novel MO-DCOP algorithm based on dynamic programming techniques which guarantees to find the complete Pareto front. Furthermore, we propose a bounded version of our algorithm which can reduce the size of the messages using an adjustable parameter. In our experiments, we propose a new benchmark for MO-DCOPs based on a sensor network problem and show that (i) our complete algorithm outperforms the state-of-the-art algorithm and (ii) the bounded version of our algorithm offers a significant reduction in the size of messages while still guaranteeing to find a subset of the Pareto front.<br></p></td>
                </tr>
            
                <tr>
                    <td>353</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-353">Multi-Agent Path Finding with Deadlines</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.470</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_353" class="editable_bid" data-pk="353" data-value="30"
                    data-url="/rev_3/paper/bid/set/353/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-353"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We study multi-agent path-planning problems in scenarios such as evacuation where agents have to reach their goal locations within a deadline. Specifically, we study the problem of multi-agent path finding with deadlines (MAPF-DL), where all agents try to move from their given start locations to their given goal locations within a given deadline, without colliding with each other. The task is to maximize the number of agents that can reach the goal locations within the deadline. We show that MAPF-DL and some of its generalizations are NP-hard to solve optimally. We present two classes of optimal MAPF-DL algorithms, one based on the reduction to network-flow problems and a subsequent compact ILP formulation of the multi-valued decision diagrams and one based on novel combinatorial search techniques. Our empirical results demonstrate that these solvers scale well and each performs the best in different scenarios.<br></p></td>
                </tr>
            
                <tr>
                    <td>205</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-205">Parameterized Complexity of Multiwinner Determination: An Effort Towards Fixed-Parameter Tractability</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Cooperative games: computation</td>
                    
                        <td>0.470</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_205" class="editable_bid" data-pk="205" data-value="30"
                    data-url="/rev_3/paper/bid/set/205/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-205"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">We study winner determination for the three prevalent </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-committee
selection rules Minimax approval, Proportional approval and Ap-
proval Chamberlin-Courant’s voting. It is known that winner de-
termination for these rules is NP-hard. Moreover, parameterized
complexity of the problem has also been studied with respect to
some natural parameters such as the number of candidates or the
number of votes. However, there are still numerous parameteriza-
tions that have not been considered. In this paper, we revisit the
parameterized complexity of winner determination for these three
rules by considering several important parameters. In addition, we
study various combinations of single parameters and structural pa-
rameters, aiming at detecting more parameterizations leading to
 xed-parameter tractable (FPT) results.&nbsp;</span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>172</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-172">Proportionality and Strategyproofness in Multiwinner Elections</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.470</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_172" class="editable_bid" data-pk="172" data-value="30"
                    data-url="/rev_3/paper/bid/set/172/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-172"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Multiwinner voting rules can be used to select a fixed-size committee from a larger set of candidates.&nbsp;We consider approval-based committee rules, which allow voters to approve or disapprove candidates. In this setting, several voting rules such as Proportional Approval Voting (PAV) and Phragmén's rules have been shown to produce committees that are proportional, in the sense that they proportionally represent voters' preferences; all of these rules are strategically manipulable by voters. On the other hand, a generalisation of Approval Voting gives a non-proportional but strategyproof voting rule. We show that there is a fundamental tradeoff between these two properties: we prove that no multiwinner voting rule can simultaneously satisfy a weak form of proportionality (a weakening of justified representation) and a weak form of strategyproofness. Our impossibility is obtained using a formulation of the problem in propositional logic and applying SAT solvers; a human-readable version of the computer-generated proof is obtained by extracting a minimal unsatisfiable set (MUS). We also discuss several related axiomatic questions in the domain of committee elections.<br></p></td>
                </tr>
            
                <tr>
                    <td>464</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-464">Ravel: A Microservice-based Hybrid Platform for Multi-Party Chat-Oriented Conversations</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Normative systems<br>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Agent Cooperation] Multi-user/multi-virtual-agent interaction<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.470</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_464" class="editable_bid" data-pk="464" data-value="30"
                    data-url="/rev_3/paper/bid/set/464/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-464"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9pt; font-family: LinLibertineT;">This paper presents Ravel, a microservice-based hybrid platform
aimed to integrate natural language understanding components
with orchestration components of dialogues between human beings
and agents. Ravel enables the specification of&nbsp;</span><span style="font-family: LinLibertineT; font-size: 12px;">(social) conversations</span><span style="font-size: 9pt; font-family: LinLibertineT;">&nbsp;norms,&nbsp;</span><span style="font-family: LinLibertineT; font-size: 12px;">using deontic logic, for use in contexts where multiple agents and human users are conversing in natural language.</span><span style="font-size: 9pt; font-family: LinLibertineT;">&nbsp;We demonstrate the usefulness and versatility of
Ravel using the example of fi</span><span style="font-size: 9pt; font-family: LinLibertineTI;">nch</span><span style="font-size: 9pt; font-family: LinLibertineT;">, a real-time chat-based finance
adviser system designed as a chat group of five participants: four
collaborative chatbots with two different roles (mediator and expert)
and a human or chatbot user. To orchestrate fi</span><span style="font-size: 9pt; font-family: LinLibertineTI;">nch </span><span style="font-size: 9pt; font-family: LinLibertineT;">conversations
around 15&nbsp;</span><span style="font-size: 9pt; font-family: LinLibertineT;">conversation norms based on deontic modes are successfully applied by&nbsp;</span><span style="font-size: 9pt; font-family: LinLibertineTI;">Ravel&nbsp;</span><span style="font-size: 9pt; font-family: LinLibertineT;">even in the context of several simultaneous human users.&nbsp;</span><span style="font-size: 9pt; font-family: LinLibertineT;">&nbsp;</span><br></p></div></div></div>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>104</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-104">Hybrid Evolutionary Search and Policy Transfer for Playing RoboCup Keep-Away</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Learning and Adaptation] Evolutionary algorithms<br>[Learning and Adaptation] Multiagent learning<br>[Agent Cooperation] Biologically-inspired approaches and methods</td>
                    
                        <td>0.470</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_104" class="editable_bid" data-pk="104" data-value="30"
                    data-url="/rev_3/paper/bid/set/104/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-104"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>This research evaluates comparative methods for the adaptation and transfer of multi-agent behaviors (policies) across increasingly complex RoboCup keep-away tasks.&nbsp; Reinforcement Learning (RL) and evolutionary search methods are comparatively evaluated for keep-away behavior adaptation and subsequent policy transfer to more complex tasks. Policy transfer is where keep-away behaviors are first evolved in&nbsp; a source task and then transferred for further adaptation in more complex target tasks.&nbsp; Policy transfer is coupled with keep-away behaviors adapted by HyperNEAT (directed by objective based search, novelty search or hybridized objective novelty search) or with the SARSA or Q-Learning RL methods.&nbsp; Results indicate that policy transfer coupled with HyperNEAT directed by hybridized objective-novelty is most effective across increasingly complex keep-away tasks.</p></td>
                </tr>
            
                <tr>
                    <td>121</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-121">A Deeper Look at Experience Replay</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Verification and Validation of Agent-based Systems] Testing of agent-based systems, including model-based testing</td>
                    
                        <td>0.470</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_121" class="editable_bid" data-pk="121" data-value="30"
                    data-url="/rev_3/paper/bid/set/121/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-121"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Experience replay plays an important role in the success of deep reinforcement learning (RL) by helping stabilize the neural networks. It has become a new norm in deep RL algorithms. In this paper, however, we showcase that varying the size of the experience replay buffer can hurt the performance even in very simple tasks. The size of the replay buffer is actually a hyper-parameter which needs careful tuning. Moreover, our study of experience replay leads to the formulation of the Combined DQN algorithm, which can significantly outperform primitive DQN in some tasks.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>339</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-339">Equilibrium Refinement in Security Games with Arbitrary Scheduling Constraints</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.470</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_339" class="editable_bid" data-pk="339" data-value="30"
                    data-url="/rev_3/paper/bid/set/339/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-339"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Significant research effort in security games has focused in devising strategies that perform well even when the attacker deviates from optimal (rational) behavior. In most of these frameworks, a price needs to be paid to ensure robustness against this unpredictability. However, equilibrium refinement is an attractive alternative to boost solution robustness at no cost even though it has not received as much attention in security game literature. In this framework, resources are strategically allocated to secure an optimal outcome against a rational adversary while simultaneously protecting other targets to ensure good outcomes against boundedly rational or constrained attackers. Unfortunately, existing approaches for equilibrium refinement in security games cannot effectively address scheduling constraints that arise frequently in real-world applications. In this paper, we aim to fill this gap and make several key contributions. First, we show that existing approaches for equilibrium refinement can fail in the presence of scheduling constraints. Second, we investigate the properties of the best response of the attacker. Third, we leverage these properties to devise novel iterative algorithms to compute the optimally refined equilibrium, with polynomially many calls to an LP oracle for zero-sum games. Finally, we conduct extensive experimental evaluations that showcase i) the superior performance of our approach in the face of a boundedly rational attacker and ii) the attractive scalability properties of our algorithm that can solve realistic-sized instances.</p></td>
                </tr>
            
                <tr>
                    <td>344</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-344">Pre-training Neural Networks with Human Demonstrations for Deep Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Deep learning<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.470</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_344" class="editable_bid" data-pk="344" data-value="30"
                    data-url="/rev_3/paper/bid/set/344/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-344"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Deep reinforcement learning (deep RL) has achieved superior performance in complex sequential tasks by using a deep neural network as its function approximator and by learning directly from raw images. A drawback of using raw images is that deep RL must learn the state feature representation from the raw images in addition to learning a policy. As a result, deep RL can require a prohibitively large amount of training time and data to reach reasonable performance, making it difficult to use deep RL in real-world applications, especially when data is expensive. In this work, we speed up training by addressing half of what deep RL is trying to solve --- learning features. Our approach is to learn some of the important features by pre-training deep RL network's hidden layers via supervised learning using a small set of human demonstrations. We empirically evaluate our approach using deep Q-network (DQN) and asynchronous advantage actor-critic (A3C) algorithms on the Atari 2600 games of Pong, Freeway, and Beamrider. Our results show that initializing a deep RL network with a pre-trained model provides a significant improvement in training time even when pre-training from a small number of human demonstrations.<br></p></td>
                </tr>
            
                <tr>
                    <td>162</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-162">A Transitive Trust based Incentive Scheme for Crowdsourcing</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Humans and Agents] Other</td>
                    
                        <td>0.470</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_162" class="editable_bid" data-pk="162" data-value="30"
                    data-url="/rev_3/paper/bid/set/162/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-162"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>Using gold standard tasks is a popular technique in crowdsourcing to incentivize the workers based on an estimate of the quality of their work. However, this approach is inefficient in large scale crowdsourcing because it requires an increasing number of gold tasks with known answers. Reusing gold tasks for many workers carries a risk that they are identified by colluding workers. Assigning gold tasks to workers also wastes the task budget of the requester.</p><p><br></p><p>Techniques based solely on consistency with peer reports, such as output agreement, do not require gold tasks but offer weaker incentive compatibility and are vulnerable to collusion. We propose a simple mechanism that combines the advantage of both these approaches by continuously expanding a small pool of initial gold tasks using a transitive notion of trust. The mechanism works in the common crowdsourcing settings where every worker solves multiple micro-tasks and guarantees dominant strategy incentive compatibility. We demonstrate the practical applicability of the mechanism in incentivizing the workers through simulations and experiments on Mechanical Turk.</p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>601</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-601">Incrementally Grounding Expressions for Spatial Relations between Objects</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.470</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_601" class="editable_bid" data-pk="601" data-value="30"
                    data-url="/rev_3/paper/bid/set/601/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-601"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Recognizing, reasoning about, and providing understandable descriptions of spatial relations between domain objects is an important task for robots interacting with and assisting humans. Prepositions are often used to describe such spatial relations, but it is difficult to equip a robot with comprehensive representations of these prepositions. This paper describes an architecture for incrementally learning and revising the grounding of spatial relations between objects. Specifically, Answer Set Prolog, a declarative language, is used to represent and reason with incomplete knowledge that includes prepositional relations between objects in a scene. A generic grounding of prepositions corresponding to spatial relations, human input (when available), and non-monotonic logical inference with this knowledge, are used to infer spatial relations in 3D point clouds of given scenes, incrementally acquiring and revising a specialized grounding of spatial relations and learning the level of trust associated with the two groundings. This architecture is illustrated and evaluated on a benchmark dataset of tabletop images and on simulated scenes of furniture.<br></p></td>
                </tr>
            
                <tr>
                    <td>110</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-110">Generalizing Top Trading Cycles for Housing Markets with Fractional Endowments</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Cooperative games: theory &amp; analysis</td>
                    
                        <td>0.460</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_110" class="editable_bid" data-pk="110" data-value="30"
                    data-url="/rev_3/paper/bid/set/110/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-110"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The housing market setting constitutes a fundamental model of exchange economies of goods. Most of the work concerning housing markets does not cater for randomized assignments or allocation of time-shares. Recently, house allocation with fractional endowment of houses was considered by Athanassoglou and Sethuraman (2011) who posed the open problem of generalizing Gale's Top Trading Cycles (TTC) algorithm for fractional endowments. In this paper, we present a generalization of TTC called FTTC that is polynomial-time as well as core stable and Pareto optimal with respect to stochastic dominance. For the standard setting in which each agent owns one discrete house, FTTC coincides with a state of the art strategyproof mechanism for housing markets with discrete endowments and weak preferences. We show that FTTC satisfies a maximal set of desirable properties by proving two impossibility theorems. One of the theorems implies several impossibility results in the literature.&nbsp;<br></p></td>
                </tr>
            
                <tr>
                    <td>635</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-635">Voting with Ties: Strong Impossibilities via SAT Solving</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.460</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_635" class="editable_bid" data-pk="635" data-value="30"
                    data-url="/rev_3/paper/bid/set/635/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-635"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><div>Voting rules allow groups of agents to aggregate their preferences in order to reach joint decisions. The Gibbard-Satterthwaite theorem, a seminal result in social choice theory, implies that, when agents have <i>strict</i> preferences, all anonymous, Pareto-optimal, and <i>single-valued</i> voting rules can be strategically manipulated. In this paper, we consider multi-agent voting when there can be ties in the preferences as well as in the outcomes. These assumptions are extremely natural--especially when there are large numbers of alternatives--and enable us to prove much stronger results than in the overly restrictive setting of strict preferences. In particular, we show that <i>(i)</i> all anonymous Pareto-optimal rules where ties are broken according to the preferences of a chairman or by means of even-chance lotteries are manipulable, and that <i>(ii)</i> all pairwise Pareto-optimal rules are manipulable, no matter how ties are broken. These results are proved by reducing the statements to finite--yet very large--problems, which are encoded as formulas in propositional logic and then shown to be unsatisfiable by a SAT solver. We also extracted human-readable proofs from minimal unsatisfiable cores of the formulas in question, which were in turn verified by an interactive higher-order theorem prover.</div></td>
                </tr>
            
                <tr>
                    <td>736</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-736">Learning Curriculum Policies for Reinforcement Learning</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.460</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_736" class="editable_bid" data-pk="736" data-value="30"
                    data-url="/rev_3/paper/bid/set/736/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-736"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">Curriculum learning in reinforcement learning is a training methodology that seeks to speed up learning of a difficult target task, by
first training on a series of simpler tasks and transferring the knowledge acquired to the target task. Automatically choosing a sequence
of such tasks (i.e. a </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineTI'"><i>curriculum</i></span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">) is an open problem that has been the
subject of much recent work in this area. Most existing approaches
for automated curriculum design have typically relied on heuristics
to guide the selection of source tasks. In this paper, we explore a
principled method for curriculum design that learns a more general
representation of a curriculum: a </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineTI'"><i>curriculum policy</i></span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">. We show that
learning a curriculum policy has several advantages over simply
learning a curriculum, and examine different ways of representing
such a policy. Finally, we evaluate the effectiveness of these curriculum policies for producing curricula for multiple agents in a
gridworld testbed domain.&nbsp;</span></p>
				</div>
			</div>
		</div>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>414</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-414">Feasible Negotiation Procedures for Multiple Interdependent Negotiations</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.460</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_414" class="editable_bid" data-pk="414" data-value="30"
                    data-url="/rev_3/paper/bid/set/414/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-414"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In an agent society, agents usually have different knowledge and goals and perform differently in order to achieve their individual or joint goals. Agent negotiation provides an effective solution to help agents reach agreements on their future behaviours in the society to guarantee their goals can be achieved successfully. In an agent society, agents may need to conduct Multiple Interdependent Negotiations (MIN), with different opponents and for different purposes, in order to achieve a goal. By considering the complexity of negotiation environments, interdependencies, opponents and issues in the agent society, to efficiently conduct MIN is a challenging research issue. To the best of authors' knowledge, most of the state-of-art work primarily focuses on the single negotiation scenario and tries to propose sophisticated negotiation protocols and strategies to help individual agents to succeed in the single negotiation. However, very little work has been done with consideration of interdependencies and trade-offs among multiple negotiations, so as to help both individual agents as well as the agent society, to increase their welfare. This paper promotes the research on agent negotiations from the single negotiation level to the multiple negotiations level. To effectively conduct MIN in an agent society, this paper proposes three feasible negotiation procedures, which attempt to conduct MIN in a successive way, in a concurrent way, and in a clustered way by considering different negotiation situations, respectively. A simulated agent society is built to test the proposed negotiation procedures with random experimental settings. According to the experimental results, the successive negotiation procedure produces the highest time efficiency, the concurrent negotiation procedure promises the highest profits and success rates, and the clustered negotiation procedure provides a well-balanced solution between the negotiation efficiency and effectiveness.<br></p></td>
                </tr>
            
                <tr>
                    <td>549</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-549">Conflict-Based Search with Optimal Task Assignment</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications<br>[Agent Cooperation] Multi-robot systems</td>
                    
                        <td>0.460</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_549" class="editable_bid" data-pk="549" data-value="30"
                    data-url="/rev_3/paper/bid/set/549/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-549"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider a variant of the Multi-Agent Path-Finding problem that seeks both task assignments and collision-free paths for a set of agents navigating on a graph, while minimizing the sum of costs of all agents. Our approach extends Conflict-Based Search (CBS), a framework that has been previously used to find collision-free paths for a given fixed task assignment. Our key ideas are to operate on a search forest rather than a search tree and to create the forest on demand, avoiding the factorial explosion of all possible task assignments. We show that our new algorithm, CBS-TA, is complete and optimal. The CBS framework allows us to extend our method to ECBS-TA, a bounded suboptimal version. We provide extensive empirical results comparing CBS-TA to task assignment followed by CBS, Conflict-Based Min-Cost-Flow (CBM), and an integer linear program (ILP) solution, demonstrating the advantages of our algorithm. Our results highlight a significant advantage in jointly optimizing the task assignment and path planning for very dense cases compared to the traditional method of solving those two problems independently. For large environments with many robots we show that the traditional approach is reasonable, but that we can achieve similar results with the same runtime but stronger suboptimality guarantees.</p></td>
                </tr>
            
                <tr>
                    <td>500</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-500">Trend-Following Trading Strategies and Financial Market Stability</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Game Theory for practical applications<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.460</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_500" class="editable_bid" data-pk="500" data-value="30"
                    data-url="/rev_3/paper/bid/set/500/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-500"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We describe an approach to studying financial market stability, through a combination of agent-based modeling and game-theoretic reasoning. We employ a high-fidelity simulator of financial market environments to generate data about candidate strategy profiles, and identify equilibria over heuristic trading strategies from a game model induced from that data. This approach has been employed in studies of various issues in algorithmic trading, but qualitative extensions are required to address questions of market stability. The key idea is to incorporate incomplete information about common components of value, so that agents are incentivized to learn from market information. This provides a transmission path for market shocks, which we demonstrate through a scenario in trend following. The presence of trend followers, agents that continue price trends rather than oppose them, is an economic consequence of delayed market access for background traders. We find that trend following improves price discovery and reduces volatility, metrics often associated with stable markets, but counterproductively makes the market less stable.</p></td>
                </tr>
            
                <tr>
                    <td>510</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-510">Complexity of Shift Bribery in Iterative Elections</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.450</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_510" class="editable_bid" data-pk="510" data-value="30"
                    data-url="/rev_3/paper/bid/set/510/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-510"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In iterative voting systems, candidates are eliminated in consecutive rounds until either a fixed number of rounds is reached or the set of remaining candidates does not change anymore. We focus on iterative voting systems based on the positional scoring rules plurality, veto, and Borda and study their resistance against shift bribery attacks. In constructive shift bribery, an attacker seeks to make a designated candidate win the election by bribing voters to shift this candidate in their preferences; in destructive shift bribery, the briber’s goal is to prevent this candidate’s victory. We show that many iterative voting systems, including those due to Hare (a.k.a. single transferable vote, instant-runoff voting, or alternative vote), Coombs, Baldwin, and Nanson, are resistant to these types of attack.<br></p></td>
                </tr>
            
                <tr>
                    <td>200</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-200">Two-sided Markets: Mapping Social Welfare to Gain from Trade</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.450</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_200" class="editable_bid" data-pk="200" data-value="30"
                    data-url="/rev_3/paper/bid/set/200/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-200"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Though the definition of gain from trade is an extension of social welfare from auctions to markets, from a mathematical point of view the additional dimension added by gain from trade makes it much more difficult to design a gain from trade maximizing mechanism. This paper provides a means to understand when a market designer can choose the easier path of maximizing social welfare rather than maximizing gain from trade.  

More specifically we provide and prove the first formula to convert a social welfare approximation bound to a gain from trade approximation bound that maintains the original quality of approximation, making it possible to compare solutions that approximate gain from trade with those that approximate social welfare. We evaluate the performance of our formula by using it to convert known social welfare approximation solutions to gain from trade approximation solutions.  We then compare the performance of all known two-sided markets solutions (that implement truthfulness, IR, BB, and approximate efficiency) according to the theoretical approximation bound as well as in practice.  
Surprisingly, we found that some social welfare solutions achieve a better gain from trade than other solutions designed to approximate gain from trade.
<br></p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>667</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-667">A Cloaking Mechanism to Mitigate Market Manipulation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications<br>[Agent-based Simulation] Analysis of agent-based simulations</td>
                    
                        <td>0.450</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_667" class="editable_bid" data-pk="667" data-value="30"
                    data-url="/rev_3/paper/bid/set/667/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-667"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We propose <i>a cloaking mechanism</i> to deter <i>spoofing</i>, a specific form of market manipulation designed to deceive investors by artificially affecting supply or demand with spurious orders. The cloaking mechanism works by hiding a specified number of price levels in the order book, starting from the most competitive ones, throughout the trading period. Our agent-based model includes background traders following two representative bidding strategies: the non-spoofable <i>zero intelligence</i> (ZI), which trades based on fundamental and private values, and the manipulable <i>heuristic belief learning</i> (HBL), which uses the order book to predict price outcomes. We also model an exploiter who strategically chooses to spoof and seeks to profit through buying at lower prices and later selling at higher ones. Simulation results show that the proposed cloaking mechanisms can effectively diminish spoofing in terms of price distortions and exploitation profits, but at the expense of a lower proportion of HBL traders and reduced surplus in equilibrium. By conducting <i>empirical mechanism design</i> and <i>game-theoretic analysis</i> across a variety of parametrically distinct environments, we find in markets with low or medium shocks, the benefit of cloaking in mitigating spoofing outweighs its social costs.&nbsp;In addition, we explore more sophisticated spoofing strategies which use probing to reveal cloaked information, and demonstrate the effort and risk associated with the probing may dominate the gains.</p></td>
                </tr>
            
                <tr>
                    <td>170</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-170">Heterogeneous Facility Location Games</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.450</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_170" class="editable_bid" data-pk="170" data-value="30"
                    data-url="/rev_3/paper/bid/set/170/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-170"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"><!--StartFragment-->We study heterogeneous $k$-facility location games on a line segment. In this model there are $k$ facilities to be placed on a line segment where each facility serves a different purpose. Thus, the preferences of the agents over the facilities can vary arbitrarily. Our goal is to design strategy proof mechanisms that locate the facilities in a way to maximize the minimum utility among the agents. For $k=1$, if the agents' locations are known, we prove that the mechanism that locates the facility on an optimal location is strategy proof. For $k \geq 2$, we prove that there is no optimal strategy proof mechanism, deterministic or randomized, even when $k=2$ and there are only two agents with known locations. We derive inapproximability bounds for deterministic and randomized strategy proof mechanisms. Finally, we provide strategy proof mechanisms that achieve constant approximation. All of our mechanisms are simple and communication efficient. As a byproduct we show that some of our mechanisms can be used for other objectives as the social welfare and the happiness and achieve constant approximation.</p></td>
                </tr>
            
                <tr>
                    <td>520</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-520">Probabilistic Verification for Obviously Strategyproof Mechanisms</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.450</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_520" class="editable_bid" data-pk="520" data-value="30"
                    data-url="/rev_3/paper/bid/set/520/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-520"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Obviously strategyproof (OSP) mechanisms maintain the incentive compatibility of agents that are not fully rational. They have been object of a number of studies since their recent definition. We are motivated by the result showing that OSP mechanisms without money cannot return good approximations, even if the designer monitors the agents during the execution of the mechanism, that is, she enforces the agents' utilities to be tied to their reported bids [Ferraioli&amp;Ventre, AAAI 2017].</p><p><br>We ask whether there are different (harsher) forms of punishments and novel ways for the designer to exert control over the agents that can overcome this impossibility. We define a model of probabilistic verification wherein agents are caught misbehaving with a certain probability and show how OSP mechanisms without money can return optimal solutions at the cost of either imposing very large fines for lying or verifying a linear number of agents.<br></p></td>
                </tr>
            
                <tr>
                    <td>599</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-599">Deep Learning for Revenue-Optimal Auctions with Budgets</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Learning and Adaptation] Deep learning</td>
                    
                        <td>0.440</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_599" class="editable_bid" data-pk="599" data-value="30"
                    data-url="/rev_3/paper/bid/set/599/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-599"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The design of revenue-maximizing auctions for settings with private budgets is a hard task. Even the single-item case is not fully understood, and there are no known optimal auctions, or even characterization results, for multi-item settings. In this work, we model a mechanism as a neural network, and use machine learning for the automated design of optimal auctions.&nbsp; We extend the {\em RegretNet} framework~\cite{deep-auction} to handle private budget constraints and&nbsp; Bayesian incentive compatibility.&nbsp; We discover new auctions with very close approximations to incentive-compatibility and high revenue for multi-unit auctions with private budgets, including problems with unit-demand bidders. For benchmarking purposes, we also illustrate that {\em RegretNet} can obtain essentially optimal designs for simpler settings where analytical solutions are available~\cite{CHE2000,Malakhov2008,PAI2014}.</p></td>
                </tr>
            
                <tr>
                    <td>232</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-232">On the Complexity of Optimal Correlated Auctions and Reverse Auctions</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.440</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_232" class="editable_bid" data-pk="232" data-value="30"
                    data-url="/rev_3/paper/bid/set/232/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-232"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>&nbsp;&nbsp; We investigate the problem of finding a revenue-optimal auction with correlated bidders. We give an algorithm for the exact solution for two bidders, and for a 5/3-approximation for many bidders, improving from O(n^6) runtime to O(n^3) for both problems by exploiting structural properties of this problem directly. We show that for correlated bidders, reverse auctions behave differently from auctions. For two bidders we discuss a constant-factor reduction in complexity. For k &gt;= 3 bidders, we show that the optimal reverse auction must sometimes buy k copies of the item.<br></p></td>
                </tr>
            
                <tr>
                    <td>542</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-542">Behavior Model Calibration for Epidemic Simulations</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent-based Simulation] Modelling for agent based simulation</td>
                    
                        <td>0.440</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_542" class="editable_bid" data-pk="542" data-value="30"
                    data-url="/rev_3/paper/bid/set/542/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-542"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><font color="#222222" face="arial, sans-serif"><span style="font-size: 12.8px;">Computational epidemiologists frequently employ large-scale agent-based simulations of human populations to study disease outbreaks and assess intervention strategies. The agents used in such simulations rarely capture the real-world decision-making of human beings. An absence of realistic agent behavior can undermine the reliability of insights generated by such simulations and might make them ill-suited for informing public health policies. In this paper, we address this problem by developing a methodology to create and calibrate an agent decision making model for a large multi-agent simulation, using survey data. Our method optimizes a cost vector associated with the various behaviors to match the behavior distributions observed in a detailed survey of human behaviors during influenza outbreaks. Our approach is a data driven way of incorporating decision making for agents in large-scale epidemic simulations.</span></font><br></p></td>
                </tr>
            
                <tr>
                    <td>285</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-285">Solving Hard Stable Matching Problems Involving Groups of Similar Agents</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.440</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_285" class="editable_bid" data-pk="285" data-value="30"
                    data-url="/rev_3/paper/bid/set/285/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-285"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Many important stable matching problems are known to be NP-hard, even when strong restrictions are placed on the input.&nbsp; In this paper we seek to identify simple structural properties of instances of stable matching problems which will allow the design of efficient algorithms.&nbsp; We focus on the setting in which all agents involved in some matching problem can be partitioned into k different <i>types</i>, where the type of an agent determines his or her preferences, and agents have preferences over types (which may be refined by more detailed preferences within a single type).&nbsp; This situation could arise in practice if agents form preferences based on some small collection of agents' attributes. The notion of types could also be used if we are interested in a relaxation of stability, in which agents will only form a private arrangement if it allows them to be matched with a partner who differs from the current partner in some particularly important characteristic. We show that, in this setting, many well-studied NP-hard stable matching problems (such as MAX SMTI, MAX SRTI, and MAX SIZE MIN BP SMTI) belong to the parameterised complexity class FPT when parameterised by the number of different types of agents, and so admit efficient algorithms when this number of types is small.<br></p></td>
                </tr>
            
                <tr>
                    <td>689</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-689">Adversary models account for imperfect crime data: Forecasting and planning against real-world poachers</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Development techniques, tools and platforms<br>[Engineering Multiagent Systems] Innovative agents and multiagent applications</td>
                    
                        <td>0.440</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_689" class="editable_bid" data-pk="689" data-value="30"
                    data-url="/rev_3/paper/bid/set/689/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-689"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
  <o:PixelsPerInch>96</o:PixelsPerInch>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1107305727 0 0 415 0;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073786111 1 0 415 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;}
</style>
<![endif]-->



<!--StartFragment-->



<!--EndFragment--></p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
  <o:PixelsPerInch>96</o:PixelsPerInch>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1107305727 0 0 415 0;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073786111 1 0 415 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;}
</style>
<![endif]-->



<!--StartFragment-->

<p class="MsoNormal" style="text-align:justify"><span style="font-family:&quot;Times New Roman&quot;,serif;
mso-fareast-font-family:&quot;Times New Roman&quot;">Poachers are engaged in extinction
level wholesale slaughter, so it is critical to harness historical data for
predicting poachers' behavior. However, in these domains, data collected about
adversarial actions are remarkably imperfect, where reported negative instances
of crime may be mislabeled or uncertain. Unfortunately, past attempts to
develop predictive and prescriptive models to address this problem suffer from
shortcomings from a modeling perspective as well as in the implementability of
their techniques. Most notably these models i) neglect the uncertainty in crime
data, leading to inaccurate and biased predictions of adversary behavior, ii)
use coarse-grained crime analysis and iii) do not provide a convincing
evaluation as they only look at a single protected area. Additionally, they iv)
proposed time-consuming techniques which cannot be directly integrated into low
resource outposts. In this innovative application paper, we (I) introduce
iWare-E a novel imperfect-observation aWare Ensemble (iWare-E) technique, which
is designed to handle the uncertainty in crime information efficiently. This
approach leads to superior accuracy for adversary behavior prediction (up to 34%
increase in AUC) compared to the previous state-of-the-art. We also demonstrate
the country-wide efficiency of the models and are the first to (II) evaluate
our adversary behavioral model across different protected areas in Uganda,
i.e., Murchison Fall and Queen Elizabeth National, (totaling about 7500 km2) as
well as (III) on fine-grained temporal resolutions. Lastly, (IV) we provide a
scalable planning algorithm to design fine-grained patrol routes for the rangers,
which achieves up to 150% improvement in number of predicted attacks detected.</span><o:p></o:p></p>

<!--EndFragment-->
				</div>
			</div>
		</div>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>550</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-550">Faster Reinforcement Learning Using Active Task Selection</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Engineering Multiagent Systems] Methodologies for agent-based systems<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling</td>
                    
                        <td>0.440</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_550" class="editable_bid" data-pk="550" data-value="30"
                    data-url="/rev_3/paper/bid/set/550/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-550"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this work, we propose several online methods to build a <i>learning curriculum</i> from a given set of target-task-specific training tasks in order to speed up reinforcement learning (RL). These methods can decrease the total training time needed by an RL agent compared to training on the target task from scratch. Unlike traditional transfer learning, we consider creating a sequence from several training tasks in order to provide the most benefit in terms of reducing the total time to train. Our methods utilize the learning trajectory of the agent on the curriculum tasks seen so far to decide which tasks to train on next. An attractive feature of our methods is that they are weakly coupled to the choice of the RL algorithm as well as the transfer learning method. Further, when there is domain information available, our methods can incorporate such knowledge to further speed up the learning. We experimentally show that these methods can be used to obtain suitable learning curricula that speed up the overall training time on discrete and continuous task domains.<br></p></td>
                </tr>
            
                <tr>
                    <td>82</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-82">Introspective Reinforcement Learning and Learning from Demonstration</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.440</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_82" class="editable_bid" data-pk="82" data-value="30"
                    data-url="/rev_3/paper/bid/set/82/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-82"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Reinforcement learning is a paradigm to model how an autonomous agent learns to maximize its cumulative reward by interacting with the environment. One challenge faced by reinforcement learning is that in many environments the reward signal is sparse, leading to slow improvement of the agent's performance in early learning episodes. Potential-based reward shaping is a technique to resolve the aforementioned issue of sparse reward by incorporating an expert's domain knowledge in the learning via a potential function. Past work on reinforcement learning from demonstration directly mapped (sub-optimal) human expert demonstration to a potential function, which can speed up reinforcement learning. In this paper we propose an introspective reinforcement learning agent that significantly speeds up the learning further. An introspective Reinforcement learning agent records its state-action decisions and experience during learning in a priority queue. Good quality decisions will be kept in the queue, while poorer decisions will be rejected. The queue is then used as demonstration to speed up reinforcement learning via reward shaping. A human expert's demonstration can be used to initialise the priority queue before the learning process starts. Experimental validations in the 4-dimensional CartPole domain and the 27-dimensional Super Mario AI domain show that our approach significantly outperforms state-of-the-art approaches to reinforcement learning from demonstration in both domains.<br></p></td>
                </tr>
            
                <tr>
                    <td>768</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-768">Feature Learning and Transfer Performance Predicting for Video Reinforcement Learning Tasks via Siamese Convolutional Neural Network</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Deep learning<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.440</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_768" class="editable_bid" data-pk="768" data-value="30"
                    data-url="/rev_3/paper/bid/set/768/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-768"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In this paper, we handle the negative transfer problem by a deep learning method to predict the transfer performance (positive transfer/negative transfer) between two reinforcement learning tasks. Our method directly trains a neural network from raw task descriptions without any other prior knowledge such as samples from the target task and models of tasks. We consider video reinforccement learning tasks such as video games which can be perceived by the agent with visual ability and described as iamges. The architecture of our neural network consists of two parts: a siamese convolutional neural network to learn the features of each pair of tasks and a softmax layer to predict the binary transfer performance. When the features of a pair of task images are obtained, the difference between the tasks is computed based on the feature vectors. Before passed to the softmax layer, the difference feature is mapped to a new feature by a fully-connected layer with a ReLU activation function to realize nonlinear classification. We conduct extensive experiments in two video reinforcement learning domains, the maze domain and the Ms. Pacman domain, to evaluate the performance of our method. The results show that our proposed method can accurately predict the transfer performance with around 90% accuracy and outperform the baseline methods in both domains. Especially in the Ms. Pacman domain, our method can achieve an accuracy of 94.2% and significantly outperform the methods with hand-crafted features by more than 10%.<br></p></td>
                </tr>
            
                <tr>
                    <td>383</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-383">Neither dumb nor optimal: plausible wayfinding in pedestrian agent-based models</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Emergent behaviour<br>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Analysis of agent-based simulations<br>[Agent-based Simulation] Simulation of complex systems</td>
                    
                        <td>0.440</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_383" class="editable_bid" data-pk="383" data-value="30"
                    data-url="/rev_3/paper/bid/set/383/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-383"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Extending the range of pedestrian decision making activities represented in a simulation model represents a serious challenge: different decisions are taken at distinct levels of abstraction, employing different types of information and knowledge about the environment, from path planning to the regulation of distance from other pedestrians and obstacles present in the environment. Pedestrians, moreover, are not robots: although empirical observations show that they consider congestion when planning, there are evidences that their decisions are not always optimal (even in normal situations). We present a model integrating and improving consolidated results mitigating the optimization effects of congestion aware path planning by making commonsense estimations of the effects of perceivable congestion, also embedding an imitation mechanism stimulating changes in planned decisions whenever another nearby pedestrian did the same. The model is formally described and experimented both in a validation scenario as well as in a real-world situation: an interesting counterintuitive result, in which reducing available choices and exits actually reduces overall egress time, is also presented and discussed.<br></p></td>
                </tr>
            
                <tr>
                    <td>201</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-201">Complexity of Controlling Nearly Single-Peaked Elections Revisited</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Cooperative games: computation</td>
                    
                        <td>0.440</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_201" class="editable_bid" data-pk="201" data-value="30"
                    data-url="/rev_3/paper/bid/set/201/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-201"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">We investigate the complexity of C</span><span style="font-size: 7.000000pt; font-family: 'NimbusRomNo9L'">ONSTRUCTIVE </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">C</span><span style="font-size: 7.000000pt; font-family: 'NimbusRomNo9L'">ONTROL BY
</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">A</span><span style="font-size: 7.000000pt; font-family: 'NimbusRomNo9L'">DDING</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">/D</span><span style="font-size: 7.000000pt; font-family: 'NimbusRomNo9L'">ELETING </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">V</span><span style="font-size: 7.000000pt; font-family: 'NimbusRomNo9L'">OTES </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">(CCAV/CCDV) for </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">r</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-approval, Con-
dorcet, Maximin and Copeland</span><span style="font-size: 6.000000pt; font-family: 'CMMI6'; vertical-align: 4.000000pt">α </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">in </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-axes and </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-candidate partition
single-peaked elections. In general, we prove that CCAV and CCDV
for most of the voting correspondences mentioned above are NP-
hard even when </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">is a very small constant. Exceptions are CCAV
and CCDV for Condorcet and CCAV for </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">r</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-approval in </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-axes single-
peaked elections, which we show to be fixed-parameter tractable
with respect to </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">. Whether CCDV for </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">r</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-approval in </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-axes single-
peaked elections is  xed-parameter tractable remains open. Finally,
we give a polynomial-time algorithm to recognize 2-axes elections,
resolving an open problem.&nbsp;</span></p>
				</div>
			</div>
		</div></td>
                </tr>
            
                <tr>
                    <td>504</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-504">Sequential Allocation Rules are Separable: Refuting a Conjecture on Scoring-Based Allocation of Indivisible Goods</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Bargaining and negotiation<br>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Social choice theory</td>
                    
                        <td>0.430</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_504" class="editable_bid" data-pk="504" data-value="30"
                    data-url="/rev_3/paper/bid/set/504/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-504"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Baumeister et al. [2] introduced scoring allocation correspondences and rules, parameterized by an aggregation function ⋆ (such as + and min) and a scoring vector s. Among the properties they studied is separability, a.k.a. consistency [16], a central property important in many social decision contexts. Baumeister et al. [2] show that some common scoring allocation rules fail to be separable and conjecture that “(perhaps under mild conditions on s and ⋆), no positional scoring allocation rule is separable.” We refute this conjecture by showing that (1) the family of sequential allocation rules—an elicitation-free protocol for allocating indivisible goods based on picking sequences [10]—is separable for each coherent collection of picking sequences, and (2) every sequential allocation rule can be expressed as a scoring allocation rule for a suitable choice of scoring vector and social welfare ordering.<br></p></td>
                </tr>
            
                <tr>
                    <td>214</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-214">A Condorcet-Consistent Participatory Budgeting Algorithm</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.430</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_214" class="editable_bid" data-pk="214" data-value="30"
                    data-url="/rev_3/paper/bid/set/214/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-214"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The budget is the key means for effecting policy in democracies, yet its preparation is typically an opaque and arcane process. Participatory budgeting is making inroads in municipalities, but is usually limited to a small fraction of the total budget and the produced budgets usually do not provide axiomatic guarantees.</p><p>Here we apply the Condorcet principle to a general participatory budgeting scenario that includes a budget proposal, a vote profile, and a budget limit. We devise a polynomial-time budgeting algorithm that, given such a scenario,&nbsp; produces the Condorcet winner if it exists, else a member of the Smith set. (A caveat -- our definition of dominance employs strict rather than relative majority.) Furthermore, we argue that if there is no Condorcet winner for this scenario, then the resulting budget would often be close to a weak Condorcet winner for a slightly smaller budget limit.&nbsp;</p><p>Our algorithm allows items to be quantitative, indivisible, and have arbitrary costs and allows voters to specify weak orders as their preferences. Furthermore, our algorithm supports hierarchical budget construction, thus may be applied to entire high-stakes budgets.</p></td>
                </tr>
            
                <tr>
                    <td>474</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-474">The Impact of Antagonistic Concepts on Influence Manipulation</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Societies and Societal Issues] Social networks<br>[Agent-based Simulation] Social simulation</td>
                    
                        <td>0.430</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_474" class="editable_bid" data-pk="474" data-value="30"
                    data-url="/rev_3/paper/bid/set/474/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-474"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The propagation of concepts in a population of agents is a form of influence spread, which can be modelled as a cascade from an initial set of individuals. In real-world environments there may be many concepts spreading and interacting. Previous work that investigates the spread of multiple concepts is typically limited to two concepts. In this paper, we consider the problem of indirect influence manipulation and the effect of introducing an additional concept, in the form of an antagonistic concept. Antagonistic concepts manipulate the target concept in a way that is adverse to our goal of maximising or minimising spread. We evaluate the impact of antagonistic concepts on current strategies for indirect influence manipulation. A recently established heuristic for indirectly manipulating concept spread in the presence of two concepts, MPG, is evaluated against an adaptation that accounts for the existence of antagonistic concepts. Through this evaluation, we demonstrate the resilience of MPG in multi-concept environments. <br><br></p></td>
                </tr>
            
                <tr>
                    <td>571</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-571">Interactive Reinforcement Learning with Dynamic Reuse of Prior Knowledge</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Learning and Adaptation] Reward structures for learning<br>[Humans and Agents] Human-robot/agent interaction</td>
                    
                        <td>0.430</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_571" class="editable_bid" data-pk="571" data-value="30"
                    data-url="/rev_3/paper/bid/set/571/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-571"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Reinforcement learning has enjoyed multiple successes in recent years. However, these successes typically require very large amounts of data before an agent achieves acceptable performance. This paper introduces a novel way of combating such requirements by leveraging existing (human or agent) knowledge. In particular, this paper uses demonstrations from agents and humans, allowing an untrained agent to quickly achieve high performance. We empirically compare with, and highlight the weakness of, HAT and CHAT, methods of transferring knowledge from a source agent/human to a target agent. We highlight a weakness of CHAT: its confidence measurement on transferred knowledge is focused on the source demonstration dataset. This paper introduces an effective transfer approach, DRoP, combining the offline knowledge (demonstrations recorded before learning) with online confidence-based performance analysis. DRoP dynamically involves the demonstrator's knowledge, integrating it into the reinforcement learning agent's online learning loop to achieve efficient and robust learning.<br></p></td>
                </tr>
            
                <tr>
                    <td>539</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-539">On Revenue-Maximizing Mechanisms assuming Convex Costs</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Noncooperative games: computation<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.420</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_539" class="editable_bid" data-pk="539" data-value="30"
                    data-url="/rev_3/paper/bid/set/539/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-539"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p><font color="#222222" face="arial, sans-serif"><span style="font-size: 12.8px;">We investigate revenue-maximizing mechanisms in settings where bidders' utility functions are characterized by convex costs.&nbsp; Such costs arise, for instance, in procurement auctions for energy.&nbsp; We provide a constant-factor approximation guarantee for a prior-free randomized mechanism.&nbsp; Additionally, we propose two heuristics that allocate proportionally, using either value or virtual value.&nbsp; We describe experiments which show that for randomly drawn monotone hazard rate distributions, our mechanisms can achieve near optimal performance.&nbsp;&nbsp;Perhaps surprisingly, in the convex cost setting, it is preferable to allocate to multiple relatively high bidders, rather than only to bidders with the highest (virtual) value, as is optimal in the traditional quasi-linear utility setting.</span></font><br></p></td>
                </tr>
            
                <tr>
                    <td>322</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-322">On the Distance Between CP-nets</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Knowledge Representation and Reasoning] Reasoning about knowledge, beliefs, goals and norms in multiagent systems</td>
                    
                        <td>0.410</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_322" class="editable_bid" data-pk="322" data-value="30"
                    data-url="/rev_3/paper/bid/set/322/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-322"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Preferences play a key role in decision making, whether such decision are made by a single individual or a group. In a multi-agent context, it is also important to know how to aggregate preferences to reach a collective decision. Moreover, being able to measure the distance between the preference of two individuals is important to identify the amount of disagreement and possibly reach consensus. In this paper we define a notion of distance between CP-nets, a formalism that can compactly encode conditional qualitative preferences. We consider the Kendall-tau distance between the partial orders induced by CP-nets, and we define two tractable approximations of that distance, which can be computed in time polynomial in the number of features of the CP-nets. We then perform experiments to demonstrate the quality of these approximations compared to the Kendall-tau distance. We also relate our two notions of distance to the distance rationalizability of sequential plurality voting for CP-nets.</p></td>
                </tr>
            
                <tr>
                    <td>135</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-135">Optimization-Based Voting Rule Design: The Closer to Utopia the Better</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.410</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_135" class="editable_bid" data-pk="135" data-value="30"
                    data-url="/rev_3/paper/bid/set/135/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-135"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In certain situations, such as elections in the Euclidean domain, it is possible to specify clear requirements for the operation of a multiwinner voting rule, for it to provide committees that correspond to some desirable intuitive notions (such as individual excellence of committee members or their diversity). We formally describe several such requirements, which we refer to as ``utopias''. Supplied with such utopias, we develop an optimization-based mechanism for constructing committee scoring rules that provide results as close to these utopias as possible; we test our mechanism on weakly separable and OWA-based rules. Using our method we recovered some believed connections between known multiwinner voting rules and certain applications and got other interesting insights.</p></td>
                </tr>
            
                <tr>
                    <td>331</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-331">Robust Multi-Agent Path Finding</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Knowledge Representation and Reasoning] Single and multi-agent planning and scheduling<br>[Agent Societies and Societal Issues] Coordination and control models for multiagent systems</td>
                    
                        <td>0.410</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_331" class="editable_bid" data-pk="331" data-value="30"
                    data-url="/rev_3/paper/bid/set/331/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-331"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In a multi-agent path-finding (MAPF) problem, the task is to find a plan for moving a set of agents from their initial locations to their goals without collisions. Following this plan, however, may not be possible due to unexpected events that delay some of the agents. We explore the notion of \emph{robust} MAPF, where the task is to find a plan that can be followed even if a limited number of such delays occur. Two novel forms of robust MAPF are defined. The first is called k-robust MAPF (kR-MAPF), where we seek a plan that is robust to k unexpected delays per agent.&nbsp;</p><p>This form of robustness is especially suitable for agents with a control mechanism that guarantees each agent is at most k steps from its pre-defined plan. We propose sufficient and required conditions for finding a k-robust plan, and show how to convert several MAPF solvers to find a k-robust plan with minimal cost. The second form of robust MAPF we define is called p-likely robust MAPF (pR-MAPF), where we seek a plan in which the probability that no collisions will occur is greater than a given p.&nbsp;</p><p>This form of robustness is suitable for cases where the probability of the unexpected delays is known or can be approximated.&nbsp; Finding an optimal p-likely robust solution is significantly more difficult than finding an optimal k-robust solution. As a practical solution, we propose a greedy algorithm based on the Conflict-Based Search framework. We evaluate all the proposed solvers and the two forms of robustness experimentally, showing that it is possible to find robust plans, the resulting increase in plan cost is not large, and having a robust plan indeed results in fewer re-plans during execution.</p></td>
                </tr>
            
                <tr>
                    <td>435</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-435">Truthfulness on a Budget: Trading Money for Approximation through Monitoring</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Game Theory for practical applications<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.400</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_435" class="editable_bid" data-pk="435" data-value="30"
                    data-url="/rev_3/paper/bid/set/435/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-435"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>In a budget-feasible mechanism, the total payments used by the designer to enforce incentive compatibility must be within a given budget. This is a quite realistic desideratum that we here study for generic utilitarian problems. Specifically, we aim at characterizing the minimum budget needed to truthfully implement utilitarian problems. Towards this goal, we connect two streams of work on mechanism design and look at monitoring — a novel paradigm wherein agents’ declarations are tied to their actual costs [13]. In this setting, we prove that the social cost is always a sufficient budget, even for collusion-resistant mechanisms, and, under mild conditions,a necessary budget for a large class of utilitarian problems that encompass set system problems. Furthermore, for two well-studied problem outside of this class, namely facility location and obnoxious facility location, we draw a novel picture about the relationship between approximation and frugality. While for optimal mechanisms we prove that the social cost is always a sufficient and necessary budget in both cases, for approximate mechanisms we do have a dichotomy: for the facility location problem (i.e., agents want to be close to the facilities) we show that “good” approximations still need a budget equal to the social cost; on the contrary, for obnoxious facility location (i.e. agents want to be as far away from the facilities as possible), we show that it is possible to trade approximation for a smaller budget, thus obtaining more frugal truthfulness.</p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>650</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-650">A Resilient Agent-Based Re-Organizing Traffic Environment for Urban Evacuations</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent-based Simulation] Modelling for agent based simulation<br>[Agent-based Simulation] Other</td>
                    
                        <td>0.400</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_650" class="editable_bid" data-pk="650" data-value="30"
                    data-url="/rev_3/paper/bid/set/650/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-650"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="MsoNormal"><span style="font-size: 10.5pt; line-height: 107%; font-family: Helvetica, sans-serif; background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;">Implementing effective
traffic road reversals is a complex problem: it requires clearing roads from
traffic before implementing safe road reversal operations and often results in
anomalies in the network topology. Road reversals are further complicated when,
due to unexpected events (e.g., torrential rains), roads are suddenly closed.
Current traffic road reversal approaches are based on the execution of
mathematical models which identify upfront, optimal reversal configurations for
the entire traffic network. These approaches assume that the traffic network
structure is static, and as such do not allow for dynamic road closures. In
this paper, we present a <i>resilient</i> agent-based re-organizing traffic
model for urban evacuations. Resilience refers to the traffic network's ability
to regain its evacuation function quickly and efficiently after severe
perturbations. The proposed model integrates <i>road reversal</i> and <i>zoning</i>
strategies. Experimental results show that: a) the model improves the evacuation
effort, and b) the evacuation function is able to cope quickly and effectively
with&nbsp;</span>dynamic road closures.<o:p></o:p></p></td>
                </tr>
            
                <tr>
                    <td>112</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-112">Simple Truthful Mechanisms for Broker’s Profit in Two-Sided Markets</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Noncooperative games: theory &amp; analysis</td>
                    
                        <td>0.400</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_112" class="editable_bid" data-pk="112" data-value="30"
                    data-url="/rev_3/paper/bid/set/112/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-112"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
  <o:PixelsPerInch>96</o:PixelsPerInch>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>ZH-CN</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
   <w:UseFELayout></w:UseFELayout>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="380">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]-->

<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:Calibri;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;}
</style>
<![endif]-->



<!--StartFragment-->

<p class="MsoNormal" style="text-align:justify;text-justify:inter-ideograph">We
study how to maximize the broker’s (expected) profit in a two-sided market,
where he buys items from a set of sellers and resells them to a set of buyers.
Each seller has a single item to sell and holds a private value (or
equivalently, a private cost) on her item. The buyers have additive valuations
over all sellers’ items. We consider the Bayesian setting where the players’
values are independently drawn from prior distributions, and aim at designing
dominant-strategy incentive-compatible (DSIC) mechanisms that are approximately
optimal.<o:p></o:p></p><p class="MsoNormal" style="text-align:justify;text-justify:inter-ideograph">Production-cost
markets, where each item has a publicly-known cost for it to be produced,
provide a platform for us to study two-sided markets. Briefly, we show how to
covert a mechanism for production-cost markets into a mechanism for the broker,
whenever the former satisfies cost-monotonicity. This reduction holds for general
combinatorial valuation functions of buyers. When the buyers’ valuations are
additive, we generalize an existing auction mechanism to production-cost
markets in an approximation-preserving way. We then show that the resulting
mechanism is cost-monotone and thus can be converted into an 8-approximation
mechanism for two-sided markets via our reduction.</p><p class="MsoNormal" style="text-align:justify;text-justify:inter-ideograph"><o:p></o:p></p>

<!--EndFragment--></td>
                </tr>
            
                <tr>
                    <td>130</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-130">Between Proportionality and Diversity: Balancing District Sizes under the Chamberlin–Courant Rule</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Social choice theory<br>[Economic Paradigms] Other</td>
                    
                        <td>0.390</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_130" class="editable_bid" data-pk="130" data-value="30"
                    data-url="/rev_3/paper/bid/set/130/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-130"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>The Monroe and Chamberlin–Courant (CC) multiwinner rules pro<span style="line-height: 1.42857;">ceed by partitioning the voters into virtual districts and assigning a&nbsp;</span><span style="line-height: 1.42857;">unique committee member to each district, so that the voters are as&nbsp;</span><span style="line-height: 1.42857;">satisfied with the assignment as possible. The difference between&nbsp;</span><span style="line-height: 1.42857;">Monroe and CC is that the former creates equal-sized districts, and&nbsp;</span><span style="line-height: 1.42857;">the latter has no constraints. We generalize these rules by requir</span><span style="line-height: 1.42857;">ing that the largest district can be at most X times larger than the&nbsp;</span><span style="line-height: 1.42857;">smallest one (where X is a parameter). We show that our new rules&nbsp;</span><span style="line-height: 1.42857;">inherit worst-case computational properties from their ancestors,&nbsp;</span><span style="line-height: 1.42857;">evaluate the rules experimentally (in particular, we provide their&nbsp;</span><span style="line-height: 1.42857;">visualizations, we analyze actual district sizes, and we analyze voter&nbsp;</span><span style="line-height: 1.42857;">satisfaction), and we analyze their approximability.</span></p><div><br></div></td>
                </tr>
            
                <tr>
                    <td>196</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-196">Efficient allocation mechanism with endowments and distributional constraints</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.390</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_196" class="editable_bid" data-pk="196" data-value="30"
                    data-url="/rev_3/paper/bid/set/196/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-196"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We consider an allocation problem of multiple types objects to agents, where each type of an object has multiple copies (e.g., multiple seats of a school), each agent is endowed with an object, and some distributional constraints are imposed on the allocation (e.g., minimum/maximum quotas). We develop a mechanism that is based on the Top Trading Cycles mechanism, which is strategy-proof, feasible (always satisfies distributional constraints), Pareto efficient, and individually rational, assuming the distributional constraints are represented as an M-convex set.&nbsp; The class of distributional constraints we consider contains many situations raised from realistic matching problems, including individual minimum/maximum quotas, regional maximum quotas, type-specific maximum quotas, and distance constraints.&nbsp; To the best of our knowledge, we are the first to develop a mechanism with these desirable properties.<br><br></p></td>
                </tr>
            
                <tr>
                    <td>291</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-291">Hierarchical Agent Supervision</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Logics for agents and multi-agent systems<br>[Knowledge Representation and Reasoning] Reasoning in agent-based systems<br>[Knowledge Representation and Reasoning] Reasoning about action, plans and change in multi-agent systems</td>
                    
                        <td>0.360</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_291" class="editable_bid" data-pk="291" data-value="30"
                    data-url="/rev_3/paper/bid/set/291/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-291"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Agent supervision is a form of control/customization where</p><p>a supervisor restricts the behavior of an agent to enforce certain</p><p>requirements, while leaving the agent as much autonomy</p><p>as possible. To facilitate supervision, it is often of interest</p><p>to consider hierarchical models where a high level abstracts</p><p>over low-level behavior details. We study hierarchical agent</p><p>supervision in the context of the situation calculus and the</p><p>ConGolog agent programming language, where we have a</p><p>rich first-order representation of the agent state. We define</p><p>the constraints that ensure that the controllability of individual</p><p>actions at the high level in fact captures the controllability</p><p>of their implementation at the low level. On the basis of</p><p>this, we show that we can obtain the maximally permissive</p><p>supervisor by first considering only the high-level model and</p><p>obtaining a high-level supervisor and then refining its actions</p><p>locally, thus greatly simplifying the supervisor synthesis task.</p></td>
                </tr>
            
                <tr>
                    <td>215</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-215">Inter-task Super-state Mapping for Autonomous Policy Transfer</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Theories and Models] Cognitive models<br>[Learning and Adaptation] Learning agent capabilities (agent models, communication, observation)<br>[Learning and Adaptation] Other</td>
                    
                        <td>0.350</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_215" class="editable_bid" data-pk="215" data-value="30"
                    data-url="/rev_3/paper/bid/set/215/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-215"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>Transfer learning (TL) is used to improve the learning speed in reinforcement learning tasks with large state spaces. Many TL  approaches  use  inter-task  mappings  between  source  and target tasks. The main drawback of existing approaches based on  autonomous  inter-task  mappings  (either  state-based  or state-variable  based  mappings),  is  that  one  can  either  guarantee maximal transfer efficacy or minimal mapping search time, but not both. In this paper, we present “inter-task super-state mappings” to solve this problem. We prove that (i) our approach obtains maximum transfer efficacy, and that (ii) our inter-task  super-state  mapping  approach  requires  minimum search time, given no meta-data or task-specific information of the target task.</p><p><br></p></td>
                </tr>
            
                <tr>
                    <td>283</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-283">A Large Neighboring Search Schema for Multi-Agent Optimization</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Agent Cooperation] Coalition formation (non-strategic)<br>[Agent Cooperation] Distributed problem solving</td>
                    
                        <td>0.350</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_283" class="editable_bid" data-pk="283" data-value="30"
                    data-url="/rev_3/paper/bid/set/283/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-283"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p class="p1"><span class="s1">The Distributed Constraint Optimization Problem (DCOP) is an elegant paradigm for modeling and solving multi-agent problems which are distributed in nature, and where agents cooperate to optimize a global objective within the confines of localized communication.</span></p><p class="p1"><span class="s1">Since solving DCOPs optimally is NP-hard, recent effort in the development of DCOP algorithms has focused on incomplete methods. Unfortunately, many of such proposals do not provide quality guarantees or provide a loose quality assessment.</span></p><p class="p1"><span class="s1">Thus, this paper proposes DLNS, a novel iterative local search framework to solve DCOPs, which is anytime, it provides guarantees on solution quality, refining upper and lower bounds during the iterative process.</span></p><p>




<style type="text/css">
p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; -webkit-text-stroke: #000000}
span.s1 {font-kerning: none}
</style>





</p><p class="p1"><span class="s1">We demonstrate the effectiveness of DLNS on several DCOP benchmarks on structured and unstructured domains.</span></p></td>
                </tr>
            
                <tr>
                    <td>416</td>
                    <td><a href="#" data-toggle="modal" data-target="#modal-416">Strategyproof and fair matching mechanism for ratio constraints</a></td>
                    
                    <td>Full Paper</td>
                    <td>Main (AAMAS 2018)</td>
                    <td>[Economic Paradigms] Auctions and mechanism design<br>[Economic Paradigms] Cooperative games: theory &amp; analysis<br>[Economic Paradigms] Game Theory for practical applications</td>
                    
                        <td>0.320</td>
                    

                    <td class="contains-label">
                        <a href="#" id="editable_416" class="editable_bid" data-pk="416" data-value="30"
                    data-url="/rev_3/paper/bid/set/416/" >  <span class="label label-md label-black">No Bid</span> </a> 
                    </td>
                    <td class="hidden-print"><a href="#" data-toggle="modal" data-target="#modal-416"><i
                            class="fa fa-search"></i></a></td>
                    <td class="visible-print-inline-block"><p>We introduce a new type of distributional constraints called ratio</p><p>constraints, which explicitly specify the required balance among schools in</p><p>two-sided matching.&nbsp;</p><p>Since ratio constraints do not belong to the known well-behaved class of&nbsp;</p><p>constraints called M-convex set, developing a fair and strategyproof</p><p>mechanism that can handle them is challenging.&nbsp;</p><p>We develop a novel mechanism called</p><p>Quota Reduction Deferred Acceptance (QRDA),&nbsp;</p><p>which repeatedly applies the standard DA&nbsp;</p><p>by sequentially reducing artificially introduced maximum</p><p>quotas. As well as being fair and strategyproof,</p><p>QRDA always obtains a weakly better matching for</p><p>students compared to a baseline mechanism called&nbsp;</p><p>Artificial Cap Deferred Acceptance (ACDA), which&nbsp;</p><p>uses predetermined artificial maximum quotas.&nbsp;</p><p>Experimentally, QRDA performs better in terms of student welfare</p><p>and nonwastefulness than ACDA and another fair and strategyproof</p><p>mechanism called Extended Seat Deferred Acceptance (ESDA), in which&nbsp;</p><p>ratio constraints are transformed into minimum/maximum quotas.</p></td>
                </tr>
            
        </table>
        



<div class="container-fluid hidden-print">
    <div class="row vcenter">

        <div class="col-sm-6 vcenter">
            Showing 1 to 605 of 605 rows &nbsp;
    <span class="btn-group dropup">
        <button type="button" class="btn btn-default dropdown-toggle" data-toggle="dropdown">
            <span class="page-size">all</span>
            <span class="caret"></span>
        </button>
        <ul class="dropdown-menu" role="menu">
             
                
                    <li>
                        
                        <a href="/rev_3/paper/bid/list/?limit=25&page=1">
                            25
                        </a>
                    </li>
                
                    <li>
                        
                        <a href="/rev_3/paper/bid/list/?limit=100&page=1">
                            100
                        </a>
                    </li>
                
                    <li>
                        
                        <a href="/rev_3/paper/bid/list/?limit=500&page=1">
                            500
                        </a>
                    </li>
                
                    <li>
                        
                        <a href="/rev_3/paper/bid/list/?limit=1000&page=1">
                            1000
                        </a>
                    </li>
                
                    <li>
                        
                        <a href="/rev_3/paper/bid/list/?limit=all&page=1">
                            all
                        </a>
                    </li>
                
            
        </ul>
    </span> &nbsp; rows per page
        </div>
        <div class="col-sm-6">
            <div class="pull-right">
                


    <ul class="pagination pagination-sm">

        
            <li class="prev disabled"><a>&laquo;</a></li>
        

        

        
            
                <li class="active">
                    <a>1</a>
                </li>
            
        

        

        
            <li class="last disabled">
                <a>&raquo;</a>
            </li>
        

    </ul>



            </div>
        </div>
    </div>
</div>
<div class="visible-print-block">
    Showing 1 to 605 of 605 rows
</div>


        

    <div class="modal fade" id="modal-541" tabindex="-1" role="dialog"
         aria-labelledby="modal-541-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-541-label">[Abstract] Controller Synthesis for Hierarchical Agent Interactions</h4>
                </div>
                <div class="modal-body">
                    <p class="p1">We introduce a formalism and algorithm for synthesizing controllers to coordinate interactions among hierarchically organized agents. Typical applications are, for example, in harbor or warehouse automation. The formalism models agents as hierarchical input/output automata, and models a system of interacting agents as the parallel composition of the automata. It extends the usual parallel composition operation of I/O automata with a hierarchical composition operation for refining abstract tasks into lower-level subtasks. We provide algorithms to synthesize hierarchically organized control components to coordinate the agents’ interactions in order to drive the system toward desired states. We formally define the representation and prove that the two operations of parallel and hierarchical composition are distributive, which is essential for the correctness and completeness of the synthesis algorithm.</p><style type="text/css">
p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 9.0px Helvetica}
</style>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-604" tabindex="-1" role="dialog"
         aria-labelledby="modal-604-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-604-label">[Abstract] Testing Phase Space Properties of Synchronous Dynamical Systems with Nested Canalyzing Local Functions</h4>
                </div>
                <div class="modal-body">
                    <p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">Discrete dynamical systems serve as effective formal models in many</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">contexts, including simulations of agent-based models, propagation</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">of contagions in social networks and study of biological phenomena.</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">A class of Boolean functions, called nested canalyzing functions</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">(NCFs), have been found as good models of certain biological</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">phenomena.&nbsp; Motivated by these biological applications, we study a</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">variety of analysis problems for synchronous dynamical systems</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">(SyDSs) over the Boolean domain, where each local function is a</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">nested canalyzing function. Each analysis problem involves testing</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">whether the phase space of a given SyDS satisfies a certain property.</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">Problems considered include reachability, predecessor existence,</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">fixed point existence and garden of Eden existence.&nbsp; We present</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">computational intractability results for some problems as well as efficient</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">algorithms for other problems.&nbsp; In many cases, our results provide</span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">a clear delineation between intractable and efficiently </span></p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 15px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">solvable&nbsp;</span>versions of problems.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-603" tabindex="-1" role="dialog"
         aria-labelledby="modal-603-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-603-label">[Abstract] Sensor synthesis using genetic programming</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'CMR9'">In this paper we consider the problem of sensor synthesis within an environment to determine whether some behaviour has occurred. Our model is based on the semantics
of planning, and we provide a simple formalism for describing sensors and behaviours in such a model. We investigate
heuristic techniques for performing sensor synthesis, demonstrating that such techniques perform well in complex domains.&nbsp;</span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-655" tabindex="-1" role="dialog"
         aria-labelledby="modal-655-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-655-label">[Abstract] Parity-energy ATL for qualitative and quantitative reasoning in MAS</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we introduce a new logic suitable to reason about strategic</p><p>abilities of multi-agent systems where (teams of) agents are subject to</p><p>qualitative (parity) and quantitative (energy) constraints and where goals are</p><p>represented, as usual, by means of temporal properties.</p><p>We formally define such a logic, named parity-energy-ATL (pe-ATL, for short),</p><p>and we study its model checking problem, which we prove to be decidable<span style="line-height: 1.42857;">&nbsp;with</span></p><p>different complexity upper bounds, depending on different choices for the</p><p>energy range.</p><p><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-627" tabindex="-1" role="dialog"
         aria-labelledby="modal-627-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-627-label">[Abstract] How Implicit Communication Emerges during Conversation Game</h4>
                </div>
                <div class="modal-body">
                    <p class="Abstract"><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:
&quot;Linux Libertine&quot;;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:
minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:
AR-SA">Humans can achieve implicit communication based on the ability to
predict an opponent’s response. This ability helps human coordination. Implicit
communication is also used in uncooperative tasks for detecting deception. The
emergent process of cooperation and detection of deception for agent
communication is a popular topic in multi-agent simulations. In this study, we conduct
a multi-agent evolutionary simulation to analyze how implicit communication
emerges and its effects on agent communication during a conversation game. We
use a simplified three-player Werewolf game, including two cooperative roles
called villager and seer, and one deceptive role called werewolf. In the Werewolf
game, deceptions have a significant impact on the state of the game; the strong
relationship between lie-based coordination and winning rate, and the rule of
hidden identity in the game indicate that implicit communication may be
concealed in the players’ irrational strategies. </span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:minor-latin;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">In
this paper</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:
&quot;Linux Libertine&quot;;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:
minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:
AR-SA">,</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;
line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;
mso-fareast-theme-font:minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA"> we define implicit communication as a player using
irrational strategies and predicting its cooperator telling implicit lies. Therefore,
we</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;
line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:&quot;Linux Libertine&quot;;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">
analyze the results by labeling the agents’ strategies as rational, irrational,
and ambiguous. Our analysis suggests that implicit communication appears when
at least two roles are evolved, and communication only emerges between evolved </span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;
font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">cooperative
</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;
line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:&quot;Linux Libertine&quot;;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">agents.
If the evolved agents are a villager and a seer, </span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:minor-latin;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">implicit
communication emerges and the </span><span lang="EN-US" style="font-size:9.0pt;
mso-bidi-font-size:11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;
mso-fareast-font-family:&quot;Linux Libertine&quot;;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA">seer keeps telling lies while the villager
persists in irrational strategies, to maintain their group’s victory. In the case
of evolution of both the villager and werewolf, the </span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:minor-latin;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">villager
rarely uses irrational strategies</span><span lang="EN-US" style="font-size:9.0pt;
mso-bidi-font-size:11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;
mso-fareast-font-family:&quot;Linux Libertine&quot;;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA">, and implicit communication does not </span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;
font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">emerge.</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;
font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:&quot;Linux Libertine&quot;;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">
For the condition with three agents with evolutional processes, implicit
communication </span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:
Calibri;mso-fareast-theme-font:minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA">emerges in several patterns.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-715" tabindex="-1" role="dialog"
         aria-labelledby="modal-715-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-715-label">[Abstract] Agents for Video Game Understanding Modeled with Hybrid Markov Logic Networks</h4>
                </div>
                <div class="modal-body">
                    <p>General game-playing agents often learn environment models by optimizing a reward function, but recent work has focused instead on simulating the underlying game engine. This new work hopes to further the idea of automated game understanding by developing agents with a conceptual understanding of a game world, not just an optimized execution policy learned in non-interpretable models. We address the strengths and weaknesses of current approaches through an agent-centric survey and introduce <i>Hybrid Markov Logic Networks</i>&nbsp;as a potential tool for game engine simulation. HMLNs afford greater representational power than pure logical action based systems. We show that by abstracting the rules over numeric features a game engine can be represented with a more interpretable and compact model. We also show that ordinary <i>Markov Logic Networks</i> subsume logic based approaches and additionally can handle the stochastic processes inherent in many environments.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-478" tabindex="-1" role="dialog"
         aria-labelledby="modal-478-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-478-label">[Abstract] Reasoning about Nash Equilibria with Parity Games</h4>
                </div>
                <div class="modal-body">
                    <p>Nash equilibrium is, arguably, the best known and most widely used solution concept for multi-player general-sum games. In this paper, we present a new technique to check if a concurrent and multi-agent system, modelled as a multiplayer game, has a Nash equilibrium. We consider multi-agent systems (games) where each agent (player) in the system desires to achieve a given goal expressed using a formula of Linear Temporal Logic (LTL). From a theoretical point of view, our technique can check if a given game has a Nash equilibrium in 2EXPTIME, matching the optimal upper bound of the problem. The technique relies on a reduction of the problem of checking for the existence of a Nash equilibrium to the solution of a parity game, which is then solved using Streett automata. From a practical perspective, we describe an implementation of our technique and apply it to the analysis of concurrent and multi-agent systems modelled as games in the Simple Reactive Modules Language (SRML).</p><p><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-492" tabindex="-1" role="dialog"
         aria-labelledby="modal-492-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-492-label">[Abstract] Detection of Intelligent Agent Behaviors using Markov Chains</h4>
                </div>
                <div class="modal-body">
                    <p>We consider the problem of detecting the behavior of intelligent agents operating in stochastic environments. In particular, we focus on a scenario where we are given two models for agent behaviors and we are interested in detecting whether one model is contained in the other model. This problem has applications on several domains, such as for example Active Malware Analysis (AMA) for cyber-security, where malware analyzers need to determine whether a known malware behavior appears in an application. We use Markov chains to represent the behavioral models of the agents and we propose a novel technique based on a transformation of the Markov chain that allows to apply standard methods to extract features that can be used to detect if one model is contained in the other. We empirically evaluate our approach in two scenarios: in the first one we consider well known examples of classical games with the aim of detecting known strategies in the behavior of players; in the second one, we aim at detecting known malicious behaviors or injected code for real malware samples. Results show that our approach is capable of detecting small malware injected into bigger applications, overcoming a limitation of the current AMA techniques. Moreover, the proposed algorithm can search for the existence of known behaviors both in malware models and in models of agents interacting within a general game.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-288" tabindex="-1" role="dialog"
         aria-labelledby="modal-288-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-288-label">[Abstract] Adaptive virtual organisms made by self-assembling heterogeneous components within regular 2D patterns</h4>
                </div>
                <div class="modal-body">
                    <p>The relation between a structure and the function running on that structure is of central interest in many fields, including computer science, biology (organ vs. function), psychology (brain vs. mind), architecture (designs vs. functionality), etc. Our paper addresses this question with reference to computer science recent hardware/software advances, particularly in areas as IoT, robotics, self-systems, CPS, AI-hardware, etc.&nbsp; &nbsp;<br><br>At the modeling, conceptual level, our main contribution is the introduction of the concept of ``virtual organism'', to populate the intermediary level between rigid, slightly reconfigurable, hardware agents and abstract, intelligent, adaptive software agents. A virtual organism has a structure, resembling the hardware capabilities, and it runs low-level functions, implementing the software requirements. Roughly speaking, it is an adaptive, reconfigurable, distributed, interactive, open system, consisting of a network of heterogeneous computing nodes, with a constrained structural shape, and running a bunch of overlapping functions.<br><br>Technically, the virtual organisms studied here are in two dimensions (2D) and their structures are described by regular 2D pattens. By reconfiguration, an organism may change its structure to another structure belonging to the same 2D pattern. Two classes of reconfigurations are particularly important: conservative reconfigurations (preserving the nodes, but changing the structure) and elastic reconfigurations (allowing for adding or removing nodes).<br><br>While the potential of choosing interesting structures and functions to define virtual organisms is basically unlimited, in this paper we describe only three simple organisms: (1) a tree collector organism (TC-organism); (2) a feeding cell organism, consisting of a membrane, with collecting/releasing trees attached on its external/internal side; and (3) an organism consisting of a collection of connected feeding cell organisms.<br><br>To test the benefits of reconfiguration, we implemented a simulator for TC-organisms and tested TC-organisms' behavior. A TC-organism has a tree structure and collect items from multiple sources with a flow from leafs to root, under the following constraints:&nbsp; (i) there is an upper bound on the allowed flow per node; and (ii) leafs collecting capabilities depend on their distances to sources. We tested the behavior of TC-organisms under appropriate scenarios and the quantitative results confirm the intuition that: (1) reconfigurable structures are better suited than fixed structures in dynamically changing environments; and (2)&nbsp; elastic reconfiguration is better suited than conservative reconfiguration when considering the cost of node renting and of the unit flow collected.<br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-373" tabindex="-1" role="dialog"
         aria-labelledby="modal-373-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-373-label">[Abstract] Path Planning Games</h4>
                </div>
                <div class="modal-body">
                    <p>Path planning is a fundamental problem in robotic control. While it has received a significant amount of attention from an algorithmic perspective, there has been little research investigating the issue of multiple path planners facing a possible strategic conflict. We investigate strategic interactions among several path planning agents using a game theoretic path planning framework. Our focus is on tension between two important objectives: efficiency in the agents' achieving their goals, and safety in navigating towards these. We begin by developing a novel mathematical formulation for computing a best response path for an agent given a fixed path plan of others in a stochastic environment. We use this formulation for approximating Nash equilibria in path planning games through a best response dynamics algorithm. Finally, we develop a novel multi-agent path planning formulation for computing a social welfare optimizing multi-agent path plans. Through several case studies, we show that in a path planning game, tension between efficiency and safety can be resolved in a socially suboptimal way, with safety often significantly compromised even when all agents have a strong interest in avoiding collisions.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-448" tabindex="-1" role="dialog"
         aria-labelledby="modal-448-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-448-label">[Abstract] SMT-Based Diagnosis of Multi-Agent Temporal Plans</h4>
                </div>
                <div class="modal-body">
                    <p>The paper proposes a model and methodology for diagnosing action<br>failures in the execution of Temporal Multi-Agent Plans (TMAPs).<br>Contrary to previous proposals in the literature, we characterize<br>actions with a finite set of possible execution modes, where each<br>mode prescribes not only the logic post-conditions of the actions,<br>but also a continuous interval of possible durations.<br>Diagnoses are defined as assignments of modes to the actions that<br>are consistent with the received observations and have the highest<br>rank. We study two different algorithms that exploit a Satisfiability<br>Modulo Theories (SMT) solver for the efficient computation of<br>diagnoses. An implementation of the algorithms and experimental<br>results comparing their performance are also discussed.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-221" tabindex="-1" role="dialog"
         aria-labelledby="modal-221-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-221-label">[Abstract] Repeated Triangular Trade: Sustaining Circular Cooperation with Observation Errors</h4>
                </div>
                <div class="modal-body">
                    <p>We introduce a new fundamental problem called triangular trade, which is a natural extension of the well-studied prisoner's dilemma for three (or more) players but a player cannot directly punish a seemingly defected player. More specifically, this problem deals with a situation where the power/influence of players is one-way, players would be better off if they maintain circular cooperation, but each player has an incentive to defect. We analyze whether players can sustain such circular cooperation when they repeatedly play this game and each player observes the action of another player with some observation errors (imperfect private monitoring). We confirm that no simple strategy can constitute an equilibrium within any reasonable parameter settings when there are only two actions: ``Cooperate'' and ``Defect.'' Thus, we introduce two additional actions: ``Whistle'' and ``Punish,'' which can be considered as a slight modification of ``Cooperate.'' Then, players can achieve sustainable cooperation using a simple strategy called Remote Punishment strategy (RP), which constitutes an equilibrium for a wide range of parameters. Furthermore, we show the payoff obtained by a variant of RP is optimal within a very general class of strategies that covers virtually all meaningful strategies.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-246" tabindex="-1" role="dialog"
         aria-labelledby="modal-246-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-246-label">[Abstract] The Curse of Ties in Congestion Games with Limited Lookahead</h4>
                </div>
                <div class="modal-body">
                    <p>We introduce a novel framework to model limited lookahead in congestion games. Intuitively, the players enter the game sequentially and choose an optimal action under the assumption that the <i>k</i>-1 subsequent players play subgame-perfectly. Our model naturally interpolates between outcomes of greedy best-response (<i>k</i>=1) and subgame-perfect outcomes (<i>k</i>=<i>n</i>, the number of players). We study the impact of limited lookahead (parameterized by <i>k</i>) on the stability and inefficiency of the resulting outcomes. As our results reveal, increased lookahead does not necessarily lead to better outcomes; in fact, its effect crucially depends on the existence of ties and the type of game under consideration.</p><p><br></p><p>More specifically, already for very simple network congestion games we show that subgame-perfect outcomes (full lookahead) can be unstable, whereas greedy best-response outcomes (no lookahead) are known to be stable. We show that this instability is due to player indifferences (ties). If the game is generic (no ties exist) then all outcomes are stable, independent of the lookahead <i>k</i>. In particular, this implies that the price of anarchy of <i>k</i>-lookahead outcomes (for arbitrary <i>k</i>) equals the standard price of anarchy. For special cases of cost-sharing games and consensus games we show that no lookahead leads to stable outcomes. Again this can be resolved by removing ties, though for cost-sharing games only full lookahead provides stable outcomes. We also identify a class of generic cost-sharing games for which the inefficiency decreases as the lookahead <i>k</i> increases.</p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-516" tabindex="-1" role="dialog"
         aria-labelledby="modal-516-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-516-label">[Abstract] Pooling or Sampling: Collective Dynamics for Electrical Flow Estimation</h4>
                </div>
                <div class="modal-body">
                    <p>The computation of electrical flows is a crucial primitive for many 
recently proposed optimization algorithms on weighted networks. While 
typically implemented as a centralized subroutine, the ability to 
perform this task in a fully decentralized way is implicit in a number 
of biological systems. Thus, a natural question is whether this task can 
provably be accomplished in an efficient way by a network of agents 
executing a simple protocol.
</p><p>We provide a positive answer, proposing two distributed approaches to 
electrical flow computation on a weighted network: a deterministic 
process mimicking Jacobi's iterative method for solving linear systems, 
and a randomized token diffusion process, based on revisiting a 
classical random walk process on a graph with an absorbing node.
We show that both processes converge to a solution of Kirchhoff's node 
potential equations, derive bounds on their convergence rates in terms 
of the weights of the network, and analyze their time and message 
complexity.&nbsp;</p><p><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-602" tabindex="-1" role="dialog"
         aria-labelledby="modal-602-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-602-label">[Abstract] Industrial Symbiotic Networks as Coordinated Games</h4>
                </div>
                <div class="modal-body">
                    <p style="margin-bottom:12.0pt"><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>AR-SA</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="371">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin-top:0cm;
	mso-para-margin-right:0cm;
	mso-para-margin-bottom:8.0pt;
	mso-para-margin-left:0cm;
	line-height:107%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;}
</style>
<![endif]-->

We present a framework for implementing a
specific form of collaborative industrial practices called "Industrial
Symbiotic Networks (ISNs)'' as cooperative games. The game-theoretic formulation
of ISNs enables systematic reasoning about what we call the ISN implementation problem.
Specifically, the characteristics of ISNs may lead to inapplicability of fair and
stable benefit allocation methods even if the collaboration is a collectively
desired one (from a socioeconomic and&nbsp;environmental point of view).
Inspired by realistic ISN scenarios and following the literature on normative
multi-agent systems, we consider regulations and normative socioeconomic policies
as two elements that in combination with ISN games resolve the situation and
result in the introduction of the novel concept of “Coordinated ISNs (C-ISNs)".
Applied&nbsp;regulations are mainly monetary incentive allocation rules to
enforce the desired industrial collaborations with respect to an established
policy. In our framework, employing Marginal Contribution Nets (MC-Nets) as
rule-based cooperative game representations fosters&nbsp;the combination of
regulations and ISN games with no loss in expressiveness. We develop
algorithmic methods for generating regulations that ensure the implementability
of ISNs and as a policy support, show the policy requirements that ensure the
implementability of all the desired ISNs in a balanced-budget way. </p><p>

</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-498" tabindex="-1" role="dialog"
         aria-labelledby="modal-498-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-498-label">[Abstract] GANGs: Generative Adversarial Network Games</h4>
                </div>
                <div class="modal-body">
                    <p>Generative Adversarial Networks (GAN) have become one of the most successful frameworks for unsupervised generative modeling. As GANs are difficult to train much research has focused on this. However, very little of this research has directly exploited game-theoretic techniques. We introduce Generative Adversarial Network Games (GANGs), which explicitly model an (implicitly defined) finite zero-sum game between a generator (G) and classifier (C), where the two players use mixed strategies (probability distributions over neural networks). Due to the extremely large size of these games, we cannot expect to compute exact best responses. Thus, we define resource-bounded best responses (RBBRs), and a resource-bounded Nash Equilibrium (RB-NE) as a pair of mixed strategies such that neither G or C can find a better RBBR. The RB-NE solution concept is richer than the notion of ‘local Nash equilibria’ in that it captures not only failures of escaping local optima of gradient descent, but applies to any approximate best response computations, including methods with random restarts. To validate our approach, we solve GANGs with the Parallel Nash Memory algorithm, which provably monotonically converges to an RB-NE. We compare our results to standard GAN setups, and demonstrate that our method deals well with typical GAN problems such as mode collapse, partial mode coverage and forgetting.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-296" tabindex="-1" role="dialog"
         aria-labelledby="modal-296-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-296-label">[Abstract] A Courteous Learning Rule for Ad-hoc Anti-coordination</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we investigate the problem of anti-coordination under rationality constraints in ad-hoc resource allocation settings. Inspired by human behavior, we propose a framework (CA<sup>3</sup>NONY) that enables fast convergence to efficient and fair allocations based on a simple convention of courtesy. We prove that following such convention induces a strategy which constitutes an approximate subgame-perfect equilibrium of the repeated resource allocation game with discounting. Simulation results highlight the effectiveness of CA<sup>3</sup>NONY as compared to state-of-the-art bandit algorithms, since it achieves more than two orders of magnitude faster convergence, higher efficiency, fairness, and average payoff for the agents.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-356" tabindex="-1" role="dialog"
         aria-labelledby="modal-356-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-356-label">[Abstract] Incentivizing Collaboration in a Competition</h4>
                </div>
                <div class="modal-body">
                    <p>Research and design competitions aim to promote innovation or creative production, which is often best achieved through collaboration. The nature of a competition, however, typically necessitates sorting by individual performance. This presents tradeoffs for the competition designer, between incentivizing global performance and distinguishing individual capability. We model this situation in terms of an abstract collaboration game, where individual effort also benefits neighboring agents. We formally define a distinguishability property that captures the essence of distinguishing player capability. We propose a scoring mechanism called LSWM that rewards agents based on localized social welfare. We show that LSWM indeed promotes global performance, in that social optima are equilibria of the mechanism. Moreover, we establish conditions under which the mechanism leads to increased collaboration, and under which it ensures distinguishability. Finally, through experiments we evaluate convergence equilibrium through best-response dynamics, and the degree of distinguishability achieved whether or not the conditions hold.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-657" tabindex="-1" role="dialog"
         aria-labelledby="modal-657-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-657-label">[Abstract] Measuring Simulation Effort for Brahms Models</h4>
                </div>
                <div class="modal-body">
                    <p>The most common testing mechanism for Multi-Agent Systems (MAS) is simulation. Simulation is useful insofar as interesting test cases are used that enable the simulation to explore different behaviors of the system, but simulation alone cannot be fully relied upon to adequately cover the test space, especially in the case of non-deterministic concurrent systems. We use ideas from software testing to define a coverage metric that quantifies the test effort during simulation, and aids in creating scenarios that better cover the behavior space of the system. The coverage metric is defined in terms of the Brahms language, an agent-oriented language that models MAS, and is composed of three parts: workframe coverage, communication coverage, and schedule coverage. We performed a case study on NASA's Small Aircraft Transportation System (SATS) to gauge the usefulness of the metric.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-56" tabindex="-1" role="dialog"
         aria-labelledby="modal-56-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-56-label">[Abstract] The Dynamic Maximum Coverage Problem, Towards Multi-Agent Coverage Systems Capable of Goal-Driven Planning and Tight Coordination</h4>
                </div>
                <div class="modal-body">
                    <p>This paper introduces a new problem for integrating altogether four key features within coverage problems: coordination, detailed environmental model, planning, and goal-driven optimization. We called this problem the Dynamic Maximum Coverage Problem (DMCP). The DMCP expands the classic Maximum Coverage Problem by introducing two time dynamics: the points to cover and related rewards can change over time; environmental dynamics can constrain the evolution of the probes in charge of setting up the coverage (e.g. robots with limited speed need time to reach rewarding positions). The problem consists in finding trajectories that maximize the total accumulated reward over time, while respecting environmental constraints. This paper formalizes the DMCP, introduces generic algorithms for efficiently solving it, evaluates these algorithms, and applies the DMCP on a multi-robot application.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-483" tabindex="-1" role="dialog"
         aria-labelledby="modal-483-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-483-label">[Abstract] Local Equilibria in Logic-Based Multi-Player Games</h4>
                </div>
                <div class="modal-body">
                    <p>Game theory provides a well-established framework for the analysis and verification of concurrent and multi-agent systems. In such a framework, typically, the analysis of a multi-agent system involves computing the set of equilibria in the associated multi-player game representing the behaviour of the system. In this setting, as systems grow larger, it becomes harder to find equilibria in the game -- which represent the rationally stable behaviours of the multi-agent system (the solutions of the game). To address this issue, in this paper, we study the concept of local equilibria in which we are interested in (maximal) stable coalitions of agents with<br>respect to which an equilibrium can be found. We focus on solutions given by Nash equilibria, and base our study in Boolean games and iterated Boolean games, two logic-based models of concurrent and multi-agent systems where players' goals are given by formulae in, respectively, propositional logic and LTL.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-512" tabindex="-1" role="dialog"
         aria-labelledby="modal-512-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-512-label">[Abstract] Collective vs Selfish Adaptation: The Case of Sustainable Urban Mobility</h4>
                </div>
                <div class="modal-body">
                    <p>Software systems have evolved from being 'stand-alone systems' to 'systems of systems' to meet the challenging needs of societies. Contemporary software systems such as socio-technical systems are composed of distributed and heterogeneous agents, the embedded environment, and software components. Addressing the disruptions caused due to the unprecedented behaviors of people, and exogenous changes in the environment while designing software systems remains a challenging task in practice. The literature reviewed failed to meet all the requirements in characterizing the type of systems demanded by the research problem.</p><p>In this paper, we address the challenges that impede collective adaptation in smart mobility systems by proposing a notion of ensemble. Ensembles enable systems with collective adaptability to be built as emergent aggregations of autonomous and self-adaptive agents. Adaptation in these systems is triggered by a run-time occurrence, which is known as an `issue'. The phenomenal aspect of our approach is, it allows agents affected by an issue in the context of a smart mobility scenario to adapt collaboratively with minimal impact on their own preferences through an issue resolution process. Finally, as the management of coalition is decentralized, it eliminates the single point of failure, and the potential bottleneck in the system.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-35" tabindex="-1" role="dialog"
         aria-labelledby="modal-35-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-35-label">[Abstract] Maximizing Social Welfare while Minimizing Regret in Multi-Agent Games</h4>
                </div>
                <div class="modal-body">
                    <p>In multi-agent systems (MASs), the complex interactions among selfish agents can be modelled as stochastic games, characterized by the need for cooperation and preservation of self-interest at the same time, in which the environment changes in response to agents' behaviours. Existing decision support approaches in multi-agent systems focus on minimizing individual agent's regret, but overlook maximizing social welfare. To bridge this gap, we propose the regret-minimization-social-welfare-maximization (RMSM) approach. It quantifies the magnitude and concentration of regret within an MAS population over time, and produces actionable recommendations in polynomial time to encourage agent cooperation while protecting self-interest. Through theoretical analysis, we establish a lower bound on time-averaged social welfare and an upper bound on time-averaged regret when agents follow RMSM. Extensive simulations demonstrate significant advantage of RMSM over two state-of-the-art approaches.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-229" tabindex="-1" role="dialog"
         aria-labelledby="modal-229-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-229-label">[Abstract] Concurrent Game Structures for Temporal STIT Logic</h4>
                </div>
                <div class="modal-body">
                    <p><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">The paper introduces a new semantics for STIT logic (the logic of "seeing to it that") </span><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">based on concurrent game structures (CGSs), thereby strengthening the connection </span><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">between STIT and existing logics for MAS including coalition logic, alternating-time </span><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">temporal logic and strategy logic, whose languages are usually interpreted over CGSs. Moreover, it </span><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">provides a complexity result for a rich temporal STIT language interpreted over these structures. </span><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">The language extends that of full computation tree logic CTL* by individual agency operators, </span><span style="color: rgb(38, 43, 51); font-family: monospace, fixed; font-size: 10.666666984558105px; white-space: pre-wrap;">allowing to express sentences of the form ``agent i sees to it that phi is true, as a consequence her choice''.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-554" tabindex="-1" role="dialog"
         aria-labelledby="modal-554-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-554-label">[Abstract] Fake News in Social Networks</h4>
                </div>
                <div class="modal-body">
                    <p>We model the spread of news as a social learning game on a network. Agents can either endorse or oppose a claim made in a piece of news, which itself may be either true or false. Agents base their decision on a private signal and their neighbors' past actions. Given these inputs, agents follow strategies derived via deep multi-agent reinforcement learning and receive utility from acting in accordance with the veracity of claims. Our framework yields strategies with agent utility close to a theoretical, Bayes optimal benchmark, while remaining flexible to model re-specification. Optimized strategies allow agents to correctly identify most false claims, when all agents receive unbiased private signals. However, an adversary's attempt to spread fake news by targeting a subset of agents with a biased private signal can be successful. Even more so when the adversary has information about agents' network position or private signal. When agents are aware of the presence of an adversary they re-optimize their strategies in the training stage and the adversary's attack is less effective. Hence, exposing agents to the possibility of fake news can be an effective way to curtail the spread of fake news in social networks. Our results also highlight that information about the users' private beliefs and their social network structure can be extremely valuable to adversaries and should be well protected.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-347" tabindex="-1" role="dialog"
         aria-labelledby="modal-347-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-347-label">[Abstract] Resisting Exploitation Through Rewiring In Social Networks: How Parity, Sympathy and Reciprocity Can Increase Social Welfare</h4>
                </div>
                <div class="modal-body">
                    <p>We are interested in understanding how socially desirable traits like sympathy, reciprocity and fairness can survive in environments that include aggressive and exploitative agents.&nbsp; Social scientists have long observed and theorized about ingrained motivational factors as explanations for departures from self-seeking behaviors by human subjects. Some of these factors, namely reciprocity, have also been studied extensively in the context of agent systems as tools for promoting cooperation and improving social welfare in stable societies.&nbsp; In this paper, we evaluate how other factors like sympathy and parity can be gainfully used by agents to seek out cooperation possibilities while avoiding exploitation traps in more dynamic societies.&nbsp; We evaluate the relative effectiveness of agents influenced by different social considerations when they can choose who to interact with in their environment.&nbsp; Such rewiring of social networks not only allows apparently vulnerable agents to avoid exploitation but also allows them to form gainful coalitions to leverage mutually beneficial cooperation, thereby significantly improving social welfare.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-253" tabindex="-1" role="dialog"
         aria-labelledby="modal-253-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-253-label">[Abstract] Real-Time Detection and Learning of Behavioural Anomalies for Elderly People</h4>
                </div>
                <div class="modal-body">
                    <p>In a context of a rapidly growing population of elderly people, this paper introduces a novel method for behavioural anomaly detection by multi-agent system learning using medical staff feedback. This method first models the Circadian Activity Rythm of a set of sensors and compares it to a nominal profile to determine variations in patients' activities. The anomalies are detected by a multi-agent system as a linear relation of those variations, weighted by influence parameters. The problem of adaptation to a particular patient then becomes the problem of learning the adequate influence parameters. This approach is evaluated on a synthetic environment and results show both the capacity to effectively learn influence parameters and the resilience of this system to parameter size.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-496" tabindex="-1" role="dialog"
         aria-labelledby="modal-496-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-496-label">[Abstract] Agent Strategies for Hide and Seek Game</h4>
                </div>
                <div class="modal-body">
                    <p>We are given an environment with some objects (park with trees, a city block area) and mobile agents moving in the environment. An agent (hider) can hide behind an object to be not seen by other agents (seekers) through their line of sight (visibility). These hider agents (that are hiding behind objects) can be found by seekers who explore the environment. A pragmatic example of the problem is a warehouse environment with no drones or cameras, and some culprit agents are hiding from the police agents. The aim of hiders is not to be caught for the longest time, and the aim of the seekers is catch all of them in the shortest period of time. We formulate the problem by using visibility based map abstractions. Our hiders and seeker plan their moves by utilizing multi-armed bandits UCB reward update model. We built a simulator to create environments for multiple hiders and multiple seekers to test their strategies in a hide and seek game. Simulation results indicate that our abstractions and reward models enable better exploration for seeker agents and better obstruction for hider agents. Seeker agents take lesser time to find hider agents and hider agents take more time to be discovered, on average.</p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-133" tabindex="-1" role="dialog"
         aria-labelledby="modal-133-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-133-label">[Abstract] On the time Inconsistency of Monetary Policy Game: A Differential Game Theory Approach</h4>
                </div>
                <div class="modal-body">
                    <p>The time consistency problem in an open loop Nash equilibrium is investigated by applying a differential monetary policy game model between the central bank and the public sector. By categorizing the time consistency problem into two types, behavioral and structural, we found that under variation of parameters (Lucas critique) even the open loop Nash equilibrium concept, which is generally well known as a time consistent game, degenerates into some sort of the feedback equilibrium concept. Results also show that due to controllability of both players the structural time inconsistency of monetary policy is almost always unavoidable.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-470" tabindex="-1" role="dialog"
         aria-labelledby="modal-470-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-470-label">[Abstract] Q-Learning Based, Value Driven Action Recommender to Retain Agents in Online Q&amp;A Forums</h4>
                </div>
                <div class="modal-body">
                    <pre style="margin-bottom: 0px;"><span style=" color:#000000;">People participate actively in an online Q</span><span style=" color:#800000;">&amp;A</span><span style=" color:#000000;"> community such as </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">StackOverflow</span><span style=" color:#000000;"> for different reasons ranging from altruism to building a professional resume. Each of these reasons provide a certain value for the community members. Thinking of a user's behavior in the community as a reflection of acquired value of each participant, we introduce a novel measure, Reflected Value (RV), to quantify the intensity of the acquired value. The higher commitment of a member to participate in a community indicates that he/she has acquired a higher value from the community. In a community-based question and answering (</span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">CQA</span><span style=" color:#000000;">) forum like </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">StackOverflow</span><span style=" color:#000000;">, the success of the </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">CQA</span><span style=" color:#000000;"> is heavily dependent to the regular participation of its users. Having knowledge of such user values can provide many advantages to both, the community users and the </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">CQA</span><span style=" color:#000000;">. In this paper, we first build a Hidden Markov Model (HMM) to measure RV. We then propose a novel, Q-learning based </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">recommender</span><span style=" color:#000000;"> system, Value Driven Action </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">Recommender</span><span style=" color:#000000;"> (VAR), to recommend the users the most promising strategies (action choices) to maximize their expectation of RV over time. Finally, on the real data from </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">StackOverflow</span><span style=" color:#000000;">, we conduct a statistical test to illustrate the efficacy of VAR. For every active user on </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">StackOverflow</span><span style=" color:#000000;">, we measure a </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">jaccard</span><span style=" color:#000000;"> divergence between our recommendation to the user and the actual strategy used and illustrate that higher the divergence, the higher the posterior probability of a user leaving </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">StackOverflow</span><span style=" color:#000000;">. Thus, we believe VAR is a very useful </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">recommender</span><span style=" color:#000000;"> system to increase life-span of users on the </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">CQA</span><span style=" color:#000000;">.</span></pre>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-239" tabindex="-1" role="dialog"
         aria-labelledby="modal-239-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-239-label">[Abstract] Multi-Step Multiagent Expert Advice</h4>
                </div>
                <div class="modal-body">
                    <p>Complex tasks (e.g. in natural language processing (NLP) or computer vision) often require to solve a sequence of unique steps. Usually, there exist numerous exchangeable ''learners'' for the individual tasks, each being an ''expert'' for data with certain characteristics. Different frameworks have emerged to approach the problem of learning which expert to choose for which step, such as Contextual Decision Processes (CDPs) or Expert Processes (EPs), which assume a single agent to take actions. A resulting problem is dealing with expert correlation, which reduces predictive performance.</p><p>In this work, we thus study the setup of a cooperative Multiagent System (MAS) where experts are controlled by several agents. We first extend EPs to Multiagent Expert Processes (MEPs) and define the expert coordination process (ECP). We then model relational agent features for agents to exploit learned pairwise behavior in domain-dependent neighborhoods. Our policy-based reinforcement learning (RL) approach for coordinating agents enables agents to learn non-stationary coordination policies based on action error residuals with regards to the joint action. The eventual MEP policy is adapted with regards to robustness of the ECP.</p><p>We empirically evaluate our approach on a Named Entity Recognition and Disambiguation task with real-world services as experts and standard benchmark data sets. The results suggest that we are able to compete or even outperform centralized approaches, while keeping flexibility to distribute the MEP to multiple stakeholders or coordinate redundant copies of experts to avoid system failure.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-361" tabindex="-1" role="dialog"
         aria-labelledby="modal-361-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-361-label">[Abstract] A Computationally Grounded Model of Emotional BDI-Agents</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal" style="line-height:115%"><span lang="EN-US">This
paper extends the KBDI logic by incorporating well-being emotion modalities
(joy</span><span lang="EN-US"> and </span><span lang="EN-US">distress) as described in Ortony,
Clore and Collins’s (OCC) theory and obtain an emotional KBDI logic called
KBDIE logic. We propose a new computational model of emotion triggers for BDI
agents, called the observation-based KBDIE-system model (or KBDIE-model for
short). The key point of this KBDIE-model is to express agent’s emotion</span><span lang="EN-US">s</span><span lang="EN-US">, such as joy and distress, as a set of runs
(computing paths), which is exactly a system in the interpreted system model, a
well-known agent-model due to Halpern </span><span lang="EN-US">et al</span><span lang="EN-US">. </span><span lang="EN-US">We present a sound and complete proof
system with respect to our KBDIE-model and explore how symbolic model checking
techniques can be applied to model checking emotional BDI-agent. We show that
the technique is amenable to symbolic implementation via binary decision
diagram. We introduce MCKBDIE, a toolkit based on the open-source model checker
MCKBDI which presently supports KBDI logic only, implementing the technique.
The experimental results obtained confirm that MCKBDIE can verify
specifications of finite-state multi-agent systems involving agents’ emotion</span><span lang="EN-US">al</span><span lang="EN-US"> state</span><span lang="EN-US">s</span><span lang="EN-US">.</span><span lang="EN-US"><o:p></o:p></span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-318" tabindex="-1" role="dialog"
         aria-labelledby="modal-318-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-318-label">[Abstract] Eliminating Opportunism using an Epistemic Mechanism</h4>
                </div>
                <div class="modal-body">
                    <p>Opportunism is a behavior that takes advantage of knowledge asymmetry and results in promoting agents' own value and demoting other agents' value. It is important to eliminate such a selfish behavior in multi-agent systems, as it has undesirable results for the participating agents. However, as the context we study here is multi-agent systems, system designers actually might not be aware of the value system for each agent thus they have no idea whether an agent will perform opportunistic behavior. Given this fact, this paper designs an epistemic mechanism to eliminate opportunism given a set of possible value systems for the participating agents: an agent's knowledge gets updated so that the other agent is not able to perform opportunistic behavior, and there exists a balance between eliminating opportunism and respecting agents' privacy.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-566" tabindex="-1" role="dialog"
         aria-labelledby="modal-566-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-566-label">[Abstract] A Formalism and an Algorithm for HTN Acting</h4>
                </div>
                <div class="modal-body">
                    <p>Hierarchical Task Network (HTN) planning is a practical and efficient
approach to planning when 'standard operating procedures' for a domain are available. Like Belief-Desire-Intention (BDI) agent
reasoning, HTN planning performs hierarchical and context-based
refinement of goals into subgoals and basic actions. However, while
HTN planners 'lookahead' over the consequences of choosing one
refinement over another, BDI agents interleave refinement with acting
in the real world. There has been a renewed interest in making
HTN planners behave more like BDI agent systems, e.g. to have a
unified representation for acting and planning. However, past work
on the subject has remained informal or implementation-focused.
Thus, this paper is a formal account of HTN acting, which supports
interleaved deliberation, action, and failure recovery. To this end,
we use the syntax of the most general HTN planning formalism and
build on its core machinery, and we provide an algorithm which
combines our new formalism with the continual processing of exogenous
events. We also study the properties of HTN acting and
its relation to HTN planning.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-511" tabindex="-1" role="dialog"
         aria-labelledby="modal-511-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-511-label">[Abstract] Hunting Algorithm Performance Evaluation Environment</h4>
                </div>
                <div class="modal-body">
                    <p><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:RelyOnVML></o:RelyOnVML>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:DoNotShowRevisions></w:DoNotShowRevisions>
  <w:DoNotPrintRevisions></w:DoNotPrintRevisions>
  <w:DoNotShowMarkup></w:DoNotShowMarkup>
  <w:DoNotShowComments></w:DoNotShowComments>
  <w:DoNotShowInsertionsAndDeletions></w:DoNotShowInsertionsAndDeletions>
  <w:DoNotShowPropertyChanges></w:DoNotShowPropertyChanges>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>EN-CA</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:DontVertAlignCellWithSp></w:DontVertAlignCellWithSp>
   <w:DontBreakConstrainedForcedTables></w:DontBreakConstrainedForcedTables>
   <w:DontVertAlignInTxbx></w:DontVertAlignInTxbx>
   <w:Word11KerningPairs></w:Word11KerningPairs>
   <w:CachedColBalance></w:CachedColBalance>
   <w:UseFELayout></w:UseFELayout>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="true"
  DefSemiHidden="true" DefQFormat="false" DefPriority="99"
  LatentStyleCount="267">
  <w:LsdException Locked="false" Priority="0" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="59" SemiHidden="false"
   UnhideWhenUsed="false" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" QFormat="true" Name="TOC Heading"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-qformat:yes;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
</style>
<![endif]--><span style="font-size:9.0pt;mso-bidi-font-size:11.0pt;
line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;
mso-fareast-theme-font:minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-CA;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA">While new hunting algorithms are being developed
to model pack animal hunting behaviours, these are being assessed with centralized,
algorithmic computing methods rather than decentralized, agent based ones. To
address this deficiency, this research proposed, designed, and developed a
Hunting Algorithm Performance Evaluation Environment (HAPEE) using Multi-Agent
System (MAS). Further, this research proposed to use the NetLogo MAS
environment (to implement the HAPEE) but adapt it to the Belief, Desire, and
Intent (BDI) architecture. Netlogo was customized to a number of
two-dimensional scenarios with both Hunting Agents (HA) and Prey Agents (PA)
interacting with each other and with the obstacles within the scenarios. The HAs
and PAs were developed with the flexibility to instantiate many types of
hunters and prey. The differences in both the HAs and PAs was with their skills
(communications, perception, speed, etc.) and their cognitive abilities. To
evaluate the viability of the HAPEE, it <span style="mso-spacerun:yes">&nbsp;</span>was used to evaluate two hunting algorithms:
the Lion Optimization Algorithm (LOA) and the Grey Wolf Optimization (GWO)
algorithm. The experimental results showed that the LOA was more resilient to
obstacles than was the GWO. In the presence of obstacles, the lionesses were
more reliable in completing joint convergence onto the prey. While the wolves
had a lower convergence rate, they displayed an ability to recover from the
confusion caused by obstacles to finally close in on their prey. The research thus
concluded that the NetLogo programming environment was successfully adapted to
the BDI architecture and was very effective at structuring a large MAS
(consisting of thousands of lines of code). </span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-122" tabindex="-1" role="dialog"
         aria-labelledby="modal-122-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-122-label">[Abstract] Sentient Self-organisation -- Infinite Dimensional Games</h4>
                </div>
                <div class="modal-body">
                    <p>Theoretical arguments and empirical evidence in neuroscience suggest that organisms represent or model their environment by minimizing a variational free-energy bound on the surprise associated with sensory signals from the environment. In this paper, we study phase transitions in coupled dissipative dynamical systems (complex Ginzburg-Landau equations) under a variety of coupling conditions to model the exchange of a system (agent) with its environment. We show that arbitrary coupling between sensory signals and the internal state of a system -- or those between its action and external (environmental) states -- do not enable synchronous dynamics between external and internal states: the spatial structure and the temporal dynamics of sensory signals and action (that comprise the system's Markov blanket) have to be pruned to produce synchrony. This synchrony is necessary for an agent to infer environmental states -- a pre-requisite for survival. Therefore, such sentient dynamics&nbsp; relies primarily on approximate synchronization between the agent and its niche.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-530" tabindex="-1" role="dialog"
         aria-labelledby="modal-530-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-530-label">[Abstract] Hierarchical Task Model Learning from Demonstration</h4>
                </div>
                <div class="modal-body">
                    <p>Hierarchical reactive planning frameworks require operator libraries and domain models to be authored. These approaches suffer from the knowledge acquisition bottleneck in complex domains where it is not feasible to predetermine preconditions and context conditions for operators. ABL (A Behavior Language) is one such agent authoring language designed to create believable and reactive agents. It requires expert human input to encode their planning strategies into the agent's behavior library. This is a challenging and time-consuming task. Moreover, the deterministic nature of ABL's planning algorithm makes it difficult to apply machine learning techniques for unsupervised knowledge acquisition in domains where sufficient expert demonstrations are available. We present pABL, a probabilistic modification of the ABL modeling language, and demonstrate its usefulness in the pursuit domain that has been investigated in the agents community for cognitive architectures and multi-agent teamwork problems. We then present initial results on improving ABL models with human demonstrations in a more complex domain, StarCraft:Brood War, which is a real-time strategy game. This work contributes to development of agent authoring languages that are both more interpretable in terms of decision making and powerful in terms of representation of stochastic features of complex domains.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-784" tabindex="-1" role="dialog"
         aria-labelledby="modal-784-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-784-label">[Abstract] Automatic Construction of SPS Reconfiguration Supervisors</h4>
                </div>
                <div class="modal-body">
                    <p>A reliable Shipboard Power System must be able to detect a fault, isolate it and, possibly, restore the power supply to other devices. An agent based solution has the responsibility to monitor and control the underlying electrical layer to apply changes to the electrical scheme thus to interrupt and to isolate sections of the electrical layer maintaining vessel survivability. This paper proposes a Petri Net based model for supervising LTL requirements able to detect possible violations and enact the proper reconfiguration strategy. This approach leads to the automatic construction of supervising agents.</p><p>Keywords:&nbsp;Shipboard Power System Reconfiguration, Supervisor Agent, Linear Temporal Logic</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-749" tabindex="-1" role="dialog"
         aria-labelledby="modal-749-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-749-label">[Abstract] Three body problems in evolutionary game dynamics: Convergence, Periodicity and Limit Cycles</h4>
                </div>
                <div class="modal-body">
                    <p><span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px;">We study the asymptotic behavior of replicator dynamics in settings of network interaction. We&nbsp;focus on three agent graphical games where each edge/game is either a 2x2 zero-sum or a 2x2 coordination/partnership&nbsp;game. Using tools from dynamical systems such as Lyapunov functions and&nbsp;invariant functions we establish that this simple family of games can exhibit an interesting range of behaviors such as global convergence, periodicity for all initial conditions as well as limit cycles.&nbsp;</span><font color="#222222" face="arial, sans-serif"><span style="font-size: 12.8px;">In contrast, we do not observe more complex behavior such as toroids or chaos whilst it is possible to reproduce them in slightly more complicated settings.</span></font><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-293" tabindex="-1" role="dialog"
         aria-labelledby="modal-293-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-293-label">[Abstract] Do all tournaments admit irrelevant matches?</h4>
                </div>
                <div class="modal-body">
                    <p>We consider tournaments played by a set of agents in order to establish a ranking among them.<br>We introduce the notion of irrelevant match, as a match that does not influence the ultimate ranking of the involved parties.<br>After discussing the basic properties of this notion, we seek out tournaments that have no irrelevant matches, focusing on the class of tournaments where each agent challenges each other exactly once.<br>We prove that tournaments with a static schedule and at least 5 agents always include <br>irrelevant matches. Conversely, dynamic schedules can be devised in ways that avoid irrelevant matches, at least for one of the involved agents.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-59" tabindex="-1" role="dialog"
         aria-labelledby="modal-59-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-59-label">[Abstract] A Logical Theory for Memory Management with Explicit Time in Resource-Bounded Agents</h4>
                </div>
                <div class="modal-body">
                    <p>In intelligent agents memory plays a crucial role in the choice of future course of action, as it is progressively formed by means of agent's interactions with the external environment. So, a flexible though formal approach to memory management is in order. Previous work exists concerning logical formalization of reasoning about the formation of beliefs in non-omniscient agents. In this paper we address an aspect which has been hardly considered so far, namely the notion of \as explicit time'', by introducing timed beliefs and timed inferences. This aspect is fundamental since perceptions and inferences in agents' realistic applications are inherently timed. We propose an approach which extends existing ones, and provide an example of application. <br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-759" tabindex="-1" role="dialog"
         aria-labelledby="modal-759-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-759-label">[Abstract] Constrained Swap Dynamics over a Social Network in Distributed Resource Reallocation</h4>
                </div>
                <div class="modal-body">
                    <p>We examine a resource allocation problem in which each agent is to be assigned exactly one object. Agents are initially endowed with a resource that they can swap with one another. However, not all exchanges are plausible: we represent required connections between agents with a social network, and we model their rationality via an individual preference relation over items and by assuming a greedy behaviour. Thus, agents may only perform pairwise exchanges with a limited set of neighbors and only if it brings them preferred objects. We propose to analyze this distributed process with the study of two dual questions. Is it possible for an agent to obtain a certain object if the swaps occur favourably? Can an agent be guaranteed a certain level of satisfaction irrespective of the actual exchanges? These questions are investigated under the lense of classical and parameterized complexity, focusing on budget constraints such as the number of exchanges an agent may be involved in as well as the total duration of the process.</p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-686" tabindex="-1" role="dialog"
         aria-labelledby="modal-686-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-686-label">[Abstract] Characterizing the Limits of Autonomous Systems</h4>
                </div>
                <div class="modal-body">
                    One of the goals of AI is to develop and deploy autonomous systems that are capable of operating successfully and independently in complex and uncertain environments. While much progress has been made towards this goal, human interventions still play a fundamental role in many real-world settings. In practice, however, we still do not fully understand under what conditions human input is necessary, and for when it is, we do not fully comprehend the principles for incorporating this input into an AI system such that better performance is achieved. In this paper, we answer these two questions -- when human input is needed and, if so, how it should be incorporated into an AI system. We use the language of structural causal models (Pearl, 2000) to formalize these questions and delineate the limits between fully- and semi-autonomous systems. We design two types of agents which correspond to different levels of autonomy: the first we call experimental agent, which does not consider any human input in its decision-making process, and the second we call counterfactual agent that does take human input into consideration. We study algorithms for optimizing the experimental and counterfactual agents in canonical settings. We prove that a counterfactual agent dominates an experimental agent in terms of performance. We further characterize under which conditions experimental and counterfactual agents can reach the same level of performance, which elicits the settings where full autonomy can, at least in principle, be achieved. These results suggest a trade-off between autonomy and optimality -- while full autonomy is certainly preferred, using human input could potentially improve the performance of the system. To resolve this tension, we formulate a constrained reinforcement learning problem with the goal of maximize the performance of a semi-autonomous system subject to a budget constraint over available human input. We reduce this problem to polynomial programming problem in Markov environments that can be solved efficiently. Finally,&nbsp; extensive simulations and experiments support our findings. <br>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-47" tabindex="-1" role="dialog"
         aria-labelledby="modal-47-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-47-label">[Abstract] Second-Order Know-How Strategies</h4>
                </div>
                <div class="modal-body">
                    <p>The fact that a coalition has a strategy does not mean that the coalition knows what the strategy is. If the coalition knows the strategy, then such a strategy is called a know-how strategy of the coalition. The paper proposes the notion of a second-order know-how strategy for the case when one coalition knows what the strategy of another coalition is. The main technical result is a sound and complete logical system describing the interplay between the distributed knowledge modality and the second-order coalition know-how modality.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-469" tabindex="-1" role="dialog"
         aria-labelledby="modal-469-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-469-label">[Abstract] The generalized N&amp;K value, an axiomatic mechanism for electricity trading</h4>
                </div>
                <div class="modal-body">
                    <p>We introduce a solution concept for non-cooperative games, called the generalized N&amp;K value, and apply it as a mechanism for determining appropriate financial transfers over an optimal power flow (OPF) instance in an electrical network. Specifically, we derive the generalized N&amp;K value axiomatically, for non-cooperative games with constraints on the players joint action spaces. We then develop a bi-level programming method for computing it on OPF instances, in which the joint action space couplings arise from the players' use of a shared power network. The generalized N&amp;K value rewards electrical network participants (e.g.,~generators and loads) in proportion to their competitive position for monetary compensation within the network. Given this, we highlight the merits of the generalized N&amp;K value over locational marginal pricing in the context of a test instance of an electrical network under DC approximation. This shows the generalized N&amp;K value to be significantly different in its nature, reflecting the relative bargaining power of the electrical network participants, as well as exhibiting budget-balancedness and continuity with network parameters.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-610" tabindex="-1" role="dialog"
         aria-labelledby="modal-610-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-610-label">[Abstract] Multi-Agent Systems and Blockchain: Results from a Systematic Literature Review</h4>
                </div>
                <div class="modal-body">
                    <p>Human beings are increasingly connected through uncountable interlinked electronic devices that perform ubiquitous computing. As a consequence, scientific research is pushing towards the design and development of autonomous and collaborative systems and devices that interact and compete with each other, often emulating humankind dynamics.&nbsp;&nbsp;</p><p>Multi-Agent Systems (MAS) technology is widely used for the development of intelligent distributed systems, including cases that deal with highly sensitive data (e.g., ambient assisted living, healthcare, energy trading). To foster accountability and trusted interactions, recent trends advocate the inclusion of blockchain technologies (BCT) for multi-agent systems.</p><p>Although most of these approaches have only started exploring the topic, there is an impending need for establishing a research roadmap, as well as identifying both scientific and technological challenges in this scope.</p><p>As a first necessary step towards this goal, this paper presents a systematic literature review of studies involving MAS and BCT as reconciling solutions.</p><p>Aiming at providing a comprehensive overview of their application domains, we analyze motivations, assumptions, requirements, strengths, and limitations presented in the current state of the art. Moreover, discussing the future challenges, we introduce our vision on how MAS and BCT could be combined in different application scenarios.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-423" tabindex="-1" role="dialog"
         aria-labelledby="modal-423-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-423-label">[Abstract] Automatic Synthesis of Efficient Regular Strategies in Adversarial Patrolling Games</h4>
                </div>
                <div class="modal-body">
                    <p>We give a polynomial-time algorithm for synthesizing efficient regular strategies in patrolling games with general topology. Regular strategies use finite-state automata to gather some information about the history of defender's moves, which results in substantially better protection of the targets. So far, the scope of automatic strategy synthesis was limited to positional strategies (which ignore the history) or to regular strategies where the underlying finite-state automata had to supplied manually. In this paper, we show how to synthesize the underlying finite-state automata <i>algorithmically</i>, and we also design a novel <i>gradient-based</i><b> </b>strategy improvement method which runs in polynomial time and produces high-quality strategies for patrolling games of realistic size. To evaluate the quality of these strategies, we also develop an algorithm for computing an <i>upper</i> <i>bound</i> on the best achievable protection, and compare the quality of the constructed strategies against this bound. <br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-137" tabindex="-1" role="dialog"
         aria-labelledby="modal-137-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-137-label">[Abstract] An SMT Encoding for Parsing of LL(1) Grammars</h4>
                </div>
                <div class="modal-body">
                    <p><span style="font-family: verdana, arial, helvetica; font-size: small;">In this work, we propose an end-to-end symbolic algorithm for parsing LL(1) grammars. We implement our ideas into our tool, Athena, and demonstrate its usefulness by building two applications over it: automated repair of syntax errors in Tiger programs and automated parser synthesis to automatically synthesize LL(1) parsers. Athena is able to successfully repair 80% of our benchmarks (675 buggy Tiger programs), clocking an average of 30 seconds per repair and synthesize parsers for interesting languages from examples. Like it verification conditions (encoding a program in logic) has found widespread applications in program analysis, we believe that Athena can serve as a foundation for interesting applications in parsing.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-93" tabindex="-1" role="dialog"
         aria-labelledby="modal-93-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-93-label">[Abstract] Least Distance Games</h4>
                </div>
                <div class="modal-body">
                    <p><span style="font-family: verdana, arial, helvetica; font-size: small;">In many scenarios, agents are related to one another by different forms of groups. One prevalent situation is when players try to make a choice from a set, while those in the same group try to make choices as different as possible. Such strategical interactions turn out to be key challenges in many real-world applications, including allocating wireless spectrums, scheduling advertisements or even the daily choice of which clothes to wear. We model this kind of interactions as a type of non-cooperative games on a social hypergraph, coined least distance games, where the players (vertices) utility are measured by the least distance in each hyperedge. Reducing the game to a congestion game, we prove the existence of pure Nash equilibrium and show that the price of anarchy of this game is exactly 2. These results motivate us to further investigate the problem of designing the optimal hypergraph structure. We conclude with two theorems, one finds the optimal graph structure under some conditions while the other finds an approximately optimal structure in the general case.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-282" tabindex="-1" role="dialog"
         aria-labelledby="modal-282-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-282-label">[Abstract] Distributed Collaborative Reasoning for Human Activity Recognition in Smart Homes</h4>
                </div>
                <div class="modal-body">
                    <p>Human Activity Recognition (HAR) is an important research issue for pervasive computing that aims to identify human activities in smart homes. In previous works, most reasoning approaches for HAR are based on centralized approach where a central system is responsible for processing and reasoning about sensor data in order to recognize activities. Since smart homes are open environments deploying heterogenous sensors, reasoning process for HAR needs to be distributed over a group of heterogeneous, autonomous and interacting entities in order to be more efficient. This paper proposes a fully distributed multi-agent reasoning approach where learning agents, with diverse classifiers, observe sensor data, make local predictions, communicate and collaborate to identify current activities. Experimental tests on Aruba dataset indicate an enhancement in terms of accuracy and F-measure metrics compared to the centralized approach and also compared to a distributed approach existing in the literature.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-770" tabindex="-1" role="dialog"
         aria-labelledby="modal-770-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-770-label">[Abstract] Optimal Multiphase Investment Strategies for Influencing Opinions in a Social Network</h4>
                </div>
                <div class="modal-body">
                    <p>We study the problem of optimally investing in nodes of a social network in a competitive setting, where two camps aim to maximize adoption of their opinions by the population. In particular, we consider the possibility of campaigning in multiple phases, where the final opinion of a node in a phase acts as its initial biased opinion for the following phase. Using an extension of the popular DeGroot-Friedkin model, we formulate the utility functions of the camps, and show that they involve what can be interpreted as multiphase Katz centrality. Focusing on two phases, we analytically derive Nash equilibrium investment strategies, and the extent of loss that a camp would incur if it acted myopically. Our simulation study affirms that nodes attributing higher weightage to initial biases necessitate higher investment in the first phase, so as to influence these biases for the terminal phase. We then study the setting in which a camp's influence on a node depends on its initial bias. For single camp, we present a polynomial time algorithm for determining an optimal way to split the budget between the two phases. For competing camps, we show the existence of Nash equilibria under reasonable assumptions, and that they can be computed in polynomial time.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-515" tabindex="-1" role="dialog"
         aria-labelledby="modal-515-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-515-label">[Abstract] Shaping Opinion Dynamics in Social Networks</h4>
                </div>
                <div class="modal-body">
                    <p>A networked opinion diffusion process that usually involves extensive spontaneous discussions between connected users, is often propelled by external sources of news or feeds recommended<br>to them. In many applications like marketing design, or product<br>launch, etc., corporations often post curated news or feeds on social<br>media in order to steer the users’ opinions in a desired way. We<br>call such scenarios as opinion shaping or opinion control whereby<br>a few select users called control users post opinionated messages<br>to drive the others’ opinion to reach a given state. In this paper,<br>we propose SmartShape, an opinion control package that jointly<br>selects the control users, as well as computes the optimum rate of<br>control messages, thereby driving the networked opinion dynamics<br>to the desired direction. Furthermore, our proposal also includes a<br>robust shaping suit which makes our control framework resilient<br>to stochastic fluctuations of opinion dynamics, orginating from<br>several sources of randomness. Experiments on several synthetic<br>and real datasets gathered from Twitter, show that SmartShape<br>can accurately determine the quality of a set of control users as<br>well as shape the opinion dynamics more effectively than several<br>baselines.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-164" tabindex="-1" role="dialog"
         aria-labelledby="modal-164-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-164-label">[Abstract] Modelling Theory of Mind and Deception in Agent-Oriented Programming Languages</h4>
                </div>
                <div class="modal-body">
                    <p><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">Since the emergence of BDI architectures for agent-based systems, the AI community&nbsp;</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">has</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">given</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;a lot of attention to Theory of Mind. Theory of Mind&nbsp;</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">provides us with the opportunity</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;to create intelligent machines that are able to model other agents' minds (machines and humans). Another important topic in AI research,&nbsp;</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">which</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;stems from problems such as negotiation, is the ability&nbsp;</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">for a machine</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;to deceive. In this paper</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">,</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;we propose an approach for modelling deception and Theory of Mind in an Agent-Oriented Programming Language inspired by the BDI architecture. Our work aims to show the compatibility between Theory of Mind and the BDI architecture. It also aims to extend an AOPL in order to allow agents to model other agents' minds by enabling&nbsp;</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">those</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">&nbsp;agents to use Theory of Mind in their reasoning and decision-making</span><span style="font-family: &quot;Segoe UI&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 13.3333px;">. Using an approach for modelling deception based on dynamic epistemic logic, we show how agents can use Theory of Mind to deceive other agents. To the best of our knowledge, this work is one of the first attempts to model deception in multi-agent systems.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-708" tabindex="-1" role="dialog"
         aria-labelledby="modal-708-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-708-label">[Abstract] A Geometric Least Squares Method for Peer Assessment</h4>
                </div>
                <div class="modal-body">
                    <p><font face="verdana, arial, helvetica" size="2">In the peer assessment problem, a set of agents give evaluations to each other, and we are going to combine these peer assessments together to construct an overall evaluation. In contrast with the normal score aggregation problem, the peer assessment problem has incomplete information about the scores: each agent has a missing score that should be given by itself. &nbsp;In this paper, we propose a geometric least squares method (GLS) to find an aggregate scoring overall agents for the peer assessment problem. Our method is based on the following observation. Since each agent has a missing score, we consider the missing score as a variable and then each agent can be regarded as a line in an $n$-dimensional vector space. The final aggregate scores can also be regarded as points on a line vector, called the \emph{projection vector}.&nbsp;</font><span style="font-family: verdana, arial, helvetica; font-size: small;">Thus, we treat the peer assessment problem as an optimization problem of selecting a projection vector with minimum total squared distance to all the $n$ lines. This method will not only find an `optimal' aggregate evaluation of the agents, but also recover a value for each missing score accordingly. We will see that this aggregate method has some advantages compared with the simple average method. One advantage is that, when the scores given by each agent (even ignoring the magnitude of the agent) are close to a groundtruth, the new method finds the groundtruth with the highest expectation.</span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-710" tabindex="-1" role="dialog"
         aria-labelledby="modal-710-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-710-label">[Abstract] A Multi-agent Bayesian Decision Model for Multiple Environments</h4>
                </div>
                <div class="modal-body">
                    <p><span style="font-size:14.5pt;line-height:107%;
font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family:&quot;Times New Roman&quot;;
color:#222222;mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:
AR-SA">Multi-games and their uniform variant have been previously introduced as
a class of Bayesian games to model simultaneous competition in a number of
different environments or basic games.&nbsp; Each agent invests a portion of
its resources, regarded as private information or type, in each basic
game.&nbsp;&nbsp;We show that a mixed Bayesian Nash equilibrium (BNE) can be
computed from any set of Nash equilibria for all the basic games. For uniform
multi-games, where each agent plays the same strategy in all the basic games,
we introduce a notion of regularity and show that if the multi-game is regular
on the extreme types of the agents then a BNE can be constructed for it in
constant time.&nbsp;&nbsp;We also derive an algorithm, constant with respect to
the number of types, that checks if a multi-game is regular on its extreme
types. In the second part, we develop a design mechanism for the type space of
a double game and provide an algorithm to compute its BNE in linear time with
respect to the number of types of the agents. Finally, we show that our results
for MGs can be extended to networks.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-594" tabindex="-1" role="dialog"
         aria-labelledby="modal-594-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-594-label">[Abstract] Planning with Dead-Ends via Model Checking</h4>
                </div>
                <div class="modal-body">
                    <p>In probabilistic planning, states with no trajectory to the goal, called <i>dead-end states</i>, can compromise the termination of a planner. Usually, the planner needs to infer if a state is a dead-end while planning which has a tremendous impact on planning performance.&nbsp; In this paper, we formally characterize via model checking: (i) the complete set of dead-end states of a planning task and (ii) different classes of probabilistic planning tasks with dead-ends. This is done by using a temporal logic whose semantics takes into account the actions. We also show how this formal characterization can be used to implement an efficient dead-end detection method via symbolic preimage operations. To evaluate the proposed dead-end detection method, we adapt LRTDP and HMDPP, state-of-the-art probabilistic planners, to&nbsp; run experiments over domains from the IPPC 2008 and their extended versions with dead-ends harder to be detected. The empirical results show a significant reduction in planning time, specially on domains with hard to detect dead-end states.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-39" tabindex="-1" role="dialog"
         aria-labelledby="modal-39-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-39-label">[Abstract] Managing Communication Costs under Temporal Uncertainty</h4>
                </div>
                <div class="modal-body">
                    <p>In multi-agent temporal planning, individual agents cannot know a priori when other agents will execute their actions and so treat those actions as uncertain. Only when others communicate the results of their actions can that uncertainty be resolved. If a full communication protocol is specified ahead of time, then delay controllability can be used to assess the feasibility of the temporal plan. However, agents often have flexibility in choosing when to communicate the results of their action. In this paper, we address the question of how to choose communication protocols that guarantee the feasibility of the original temporal plan subject to some cost associated with that communication. To do so, we introduce a means of extracting delay controllability conflicts and show how we can use these conflicts to more efficiently guide our search. We then present three conflict-directed search algorithms and explore the theoretical and empirical tradeoffs between the different approaches.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-392" tabindex="-1" role="dialog"
         aria-labelledby="modal-392-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-392-label">[Abstract] Playing Stackelberg Opinion Optimization with Randomized Algorithms for Combinatorial Strategies</h4>
                </div>
                <div class="modal-body">
                    <p>From a perspective of designing or engineering for opinion formation games in social networks, the opinion maximization (or minimization) problem has been studied mainly for designing subset selecting algorithms.We furthermore define a two-player zero-sum Stackelberg game of competitive opinion optimization by letting the player under study as the first-mover minimize the sum of expressed opinions by doing so-called "internal opinion design", knowing that the other adversarial player as the follower is to maximize the same objective by also conducting her own internal opinion design.</p><p>We propose for the min player to play the follow-the-perturbed-leader algorithm in such Stackelberg game, obtaining losses depending on the other adversarial player’s play. Since our strategy of subset selection is combinatorial in nature, the probabilities in a distribution over all the strategies would be too many to be enumerated one by one. Thus, we design a randomized algorithm to produce a (randomized) pure strategy. We show that the strategy output by the randomized algorithm for the min player is essentially an approximate equilibrium strategy against the other adversarial player.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-584" tabindex="-1" role="dialog"
         aria-labelledby="modal-584-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-584-label">[Abstract] Succeeding in Complex Domains by Learning to Delegate</h4>
                </div>
                <div class="modal-body">
                    <p>Large state and action spaces present many challenges to reinforcement learning. <br>In order to succeed on complex domains, a decision-maker may rely on a team of agents, selecting a team member to act on her behalf in each environment state.<br>Thus, she must learn to delegate, by finding a performance-maximizing mapping from states to agents. <br>In this paper we investigate several aspects of this model, showing the conditions under which learning to delegate outperforms directly learning to act. <br>We present synthetic experiments to further study such systems. <br>Finally, we demonstrate learning to delegate in a very complex domain: real time strategy games, where we significantly outperform state-of-the-art approaches. <br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-585" tabindex="-1" role="dialog"
         aria-labelledby="modal-585-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-585-label">[Abstract] Vocabulary Alignment for Collaborative Agents:  a Study with Real-World Multilingual How-to Instructions</h4>
                </div>
                <div class="modal-body">
                    <p>Collaboration between heterogeneous agents typically requires the ability to communicate meaningfully. This can be challenging in open environments where participants may use different languages. Previous work proposed a technique to infer alignments between different vocabularies that uses only information about the tasks&nbsp; being executed, without any external resource. Until now, this approach has only been evaluated with artificially created data. <br>We propose an adaptation of this technique to protocols written by humans in natural language, which we extract from instructional webpages. In doing so, we not only are able to evaluate these techniques on real human-crafted protocols but also show how to take into account challenges that arise when working with natural language labels.<br>The quality of the alignments obtained with our technique is evaluated in terms of their precision and of their effectiveness in enabling successful collaborations, using a translation dictionary as a baseline. We show how our technique outperforms the dictionary when used to interact.<br><br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-359" tabindex="-1" role="dialog"
         aria-labelledby="modal-359-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-359-label">[Abstract] Interpretable Robust Decision Making</h4>
                </div>
                <div class="modal-body">
                    <p>Interpretable decision making frameworks allow us to easily imbue agents with specific goals, risk tolerances, and understanding. Existing decision making systems either forgo interpretability, or pay for it with severely reduced efficiency and large memory requirements. In this paper, we outline DeepID, a neural network approximation of Influence Diagrams, that avoids such pitfalls. We further demonstrate how the framework allows for the introduction of robustness in a very transparent and interpretable manner, without increasing the complexity class of the decision problem.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-125" tabindex="-1" role="dialog"
         aria-labelledby="modal-125-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-125-label">[Abstract] Towards Partial Order Reductions for Strategic Ability</h4>
                </div>
                <div class="modal-body">
                    <p>We propose a general semantics for strategic abilities of agents in asynchronous systems, with and without perfect information. Based on the semantics, we show some general complexity results for verification of strategic abilities in asynchronous interaction. More importantly, we develop a methodology for <i>partial order reduction</i> in verification of agents with imperfect information, based on the notion of <i>traces</i>. We show that the reduction preserves an important subset of strategic properties, both with and without the fairness assumption. Interestingly, the reduction does not work for strategic abilities under perfect information.<br><br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-580" tabindex="-1" role="dialog"
         aria-labelledby="modal-580-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-580-label">[Abstract] Autonomous Decision Making for Search and Tracking with Multiple Coordinated UAVs</h4>
                </div>
                <div class="modal-body">
                    <p>Search-and-tracking is the problem of locating a moving target and following it to its destination. In this work, we consider a scenario in which the target moves across a large geographical area by following a road network and the search is performed by multiple unmanned aerial vehicles (or drones) with limited endurance. We address the problem of distributed autonomous search-and-tracking by leveraging generic high-level decision-making techniques: AI task planning and constraint programming. In exploiting a model-and-solve paradigm, these techniques grant access to a range of high-performance optimisation solvers, while offering a flexible extension of the model according to different mission specifications. We give a formulation of the problem that lends itself to both planning and constraint programming encodings and then use off-the-shelf solvers to find solutions. We explore two alternative approaches to coordinate our team of observers: a centralised architecture, in which one agent solves the problem centrally and assigns tasks to the other agents in the team, and a decentralised architecture, in which each agent decides its own behaviour. We prove that the objective function of the problem is submodular and implement a greedy algorithm that, thanks to this property, presents remarkably good performance. Given the rapid increase of the problem size with the number of observers, our experimental evaluation studies the scalability of the different techniques and identifies the conditions under which a decentralised approach becomes preferable to a centralised one.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-341" tabindex="-1" role="dialog"
         aria-labelledby="modal-341-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-341-label">[Abstract] Maximizing Impact in an Agent Reputation Network under Uncertainty</h4>
                </div>
                <div class="modal-body">
                    <p><span style=" color:#000000;">Many multi-agent systems (</span><span style=" text-decoration: underline; color:#000000;">MASs</span><span style=" color:#000000;">) are situated in stochastic environments. Some such systems that are based on the partially observable Markov decision process (</span><span style=" text-decoration: underline; color:#000000;">POMDP</span><span style=" color:#000000;">) do not take the benevolence of other agents for granted. We propose a new </span><span style=" text-decoration: underline; color:#000000;">POMDP</span><span style=" color:#000000;">-based framework which is general enough for the specification of a variety of stochastic MAS domains involving the impact of agents on each other's reputations. A unique feature of this framework is that actions are specified as either undirected (regular) or directed (towards a particular agent), and a new directed transition function is provided for </span><span style=" text-decoration: underline; color:#000000;">modeling</span><span style=" color:#000000;"> the effects of reputation in interactions. Assuming that an agent must maintain a good enough reputation to survive in the network, a planning algorithm is developed for an agent to select optimal actions in stochastic </span><span style=" text-decoration: underline; color:#000000;">MASs</span><span style=" color:#000000;">. Preliminary evaluation is provided via an example specification and by determining the algorithm's complexity.</span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-608" tabindex="-1" role="dialog"
         aria-labelledby="modal-608-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-608-label">[Abstract] Event-Based and Scenario-Based Causality for Computational Ethics</h4>
                </div>
                <div class="modal-body">
                    <p>This paper makes use of high-level action languages to investigate aspects of causality that are central to ethical reasoning. We identify properties that causal relations assume and that determine how, as well as to what extent, we may ascribe ethical responsibility on their basis. The paper is structured in three parts. First, we present an extension of the Event Calculus that enables the agent to generate plans of actions, with the particularity that they integrate both actions and omissions. Second, we present an account of \textit{event-based} causality that is grounded in the architecture of event preconditions and effects, and that distinguishes four types of causal relations contingent on the nature of the entities that compose them. Namely, it discriminates actions and omissions from automatic events, and produced outcomes from avoided ones. Third, we examine notions of \textit{scenario-based} causality whose role it is to scrutinise and buttress the causal relations previously identified. Inquiring into the other possible versions of modelled scenarios, we account for simple counter-factual validity ("Had I not acted so, would this outcome still be true?"), criticality ("Could anything else have led to this outcome?"), extrinsic necessity ("Had I not produced it, was this outcome even avoidable?"), and elicited necessity ("Have I made this outcome unavoidable?"). The model is implemented in Answer Set Programming.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-694" tabindex="-1" role="dialog"
         aria-labelledby="modal-694-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-694-label">[Abstract] Onboard Mission Planning for an Autonomous Satellite</h4>
                </div>
                <div class="modal-body">
                    <p>Satellite autonomy can help overcome the limitations imposed by the ground segment and enhance the responsiveness that attracts much attention from researchers in the last decades. In reality, the limited computational resource presents a challenge for the onboard mission planning. In this paper, we study the onboard mission planning problem for an autonomous satellite. A continuous planning architecture and a dynamic graph model are developed, then an improved label-setting algorithm with three acceleration strategies is proposed to maximize the total profit. The experimental result demonstrates that our method can solve the onboard mission planning problem in much less time.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-434" tabindex="-1" role="dialog"
         aria-labelledby="modal-434-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-434-label">[Abstract] Resource Logics with a Diminishing Resource</h4>
                </div>
                <div class="modal-body">
                    <p style="margin-bottom: 0px; line-height: normal; font-family: Courier;"><span style="font-variant-ligatures: no-common-ligatures">Model-checking resource logics with production and consumption of resources is a computationally hard and often undecidable problem. We introduce a simple and realistic assumption that there is at least one diminishing resource, that is, a resource that cannot be produced and every action has a non-zero cost on this resource. An example of such resource is time. We show that, with this assumption, problems that are undecidable even for the underlying Alternating Time Temporal Logic, such as model-checking under imperfect information and perfect recall, become decidable for resource logics with a diminishing resource.</span></p><div><span style="font-variant-ligatures: no-common-ligatures"><br></span></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-430" tabindex="-1" role="dialog"
         aria-labelledby="modal-430-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-430-label">[Abstract] Balanced outcomes in wage bargaining</h4>
                </div>
                <div class="modal-body">
                    <p>Balanced outcomes are a subset of core outcomes that take into consideration fairness and agents’ power in bargaining networks. In this paper, following the seminal works by (Cook and Yamagishi 1992) and (Kleinberg and Tardos 2008) on modeling and computing balanced outcomes in unit-capacity trading networks, we explore this concept further by considering its generalization in the so-called wage bargaining network where agents on one side (the employers side) may have multiple capacity. It turns out that previous definitions do not trivially extend to this setting. Our first contribution is to incorporate insights from the bargaining theory and define a generalized notion of balanced outcomes in wage bargaining networks.</p><p>We then consider computational aspects of this newly proposed solutions. We show that there are polynomial-time combinatorial algorithms to compute such solutions in both unweighted and weighted graphs. Our algorithms and proofs are enabled by novel generalizations of techniques proposed by Kleinberg and Tardos and an original technique proposed in this paper called “loose chain”.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-726" tabindex="-1" role="dialog"
         aria-labelledby="modal-726-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-726-label">[Abstract] Minimax-Regret Querying on Side Effects for Safe Optimality in Factored Markov Decision Processes</h4>
                </div>
                <div class="modal-body">
                    <p><font color="#222222" face="arial, sans-serif"><span style="font-size: 12.8px;">When a robot is tasked by a human operator to change some state features of the environment&nbsp;to achieve a goal (e.g., making a room clean), the actions the robot must or should take may also change other state features (e.g., moving furniture). When the human operator has not, or cannot, specify for every feature whether changing it is permissible, the robot risks causing negative side effects (e.g., breaking a vase while cleaning).&nbsp; A robot that can be trusted to safely operate in its environment should err on never causing negative side effects.&nbsp; We formalize this problem and develop an algorithm that avoids negative side effects based on what the robot knows about the operator's preferences.&nbsp; Furthermore, we formulate a minimax-regret querying strategy for the robot to selectively ask the operator about potential side effects.&nbsp; Our empirical results show that our strategy has computational advantages over a more exhaustive approach, and poses better queries than using a heuristic.</span></font><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-140" tabindex="-1" role="dialog"
         aria-labelledby="modal-140-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-140-label">[Abstract] Multi-agent simulation with heuristic optimization of air pollution dynamics in a city</h4>
                </div>
                <div class="modal-body">
                    <p><span lang="EN-GB" style='font-family: "Times New Roman",serif; font-size: 10pt; mso-fareast-font-family: "Times New Roman"; mso-ansi-language: EN-GB; mso-fareast-language: EN-US; mso-bidi-language: AR-SA;'><font color="#000000">The synthesis of
environmental control systems which allow the best ecological trade-offs to be
identified on rational greening of a city for reducing the daily concentration
of air pollution is an important problem that has not been solved hitherto. We have
developed a multi-agent simulation of air pollution dynamics for optimal tree
cluster allocation in a city and applied it using the city of Yerevan, Armenia
as a case study. The Pareto optimal solutions on greening in the city were computed
with the help of the suggested heuristic optimization algorithm taking into
account the complex absorptive-diffusive interaction between agent-trees and
air pollutants produced by agent-enterprises and agent-vehicles located in the
city.</font></span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-534" tabindex="-1" role="dialog"
         aria-labelledby="modal-534-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-534-label">[Abstract] Reciprocal Strategies in Repeated Games</h4>
                </div>
                <div class="modal-body">
                    <p>In repeated play against a single opponent, an agent must address the fact that, in addition to immediate effects, its actions may also affect the opponent's future behavior. We have developed a class of sequential extensive form games, in which participants take turns acting, for studying the effects of one agent's action on an opponent's future actions.The main reasons for an agent to make its strategy conditional on the opponents previous actions is to learn the opponent's strategy, or to teach the opponent to play a preferred outcome. We describe a class of reciprocal strategies for this environment that can perform well against a learning opponent.&nbsp; We also demonstrate a method for finding the optimal reciprocal strategy for a given opponent.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-656" tabindex="-1" role="dialog"
         aria-labelledby="modal-656-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-656-label">[Abstract] Distributed Strategy Adaptation with a Prediction Function in Multi-Agent Task Allocation</h4>
                </div>
                <div class="modal-body">
                    <p>Coordinating multiple agents to complete a set of tasks under time constraints is a complex problem. Distributed consensus-based task allocation algorithms address this problem without the need for human supervision. With such algorithms, agents add tasks to their own schedule according to specified allocation strategies. Various factors, such as the available resources and number of tasks, may affect the efficiency of a particular allocation strategy. The novel idea we suggest is that each individual agent can predict the best task inclusion strategy locally, based on the limited task assignment information communicated among networked agents. Using supervised classification learning, a function is trained to predict the most appropriate strategy between two well known insertion heuristics. Using the proposed method, agents are shown to correctly predict and select the optimal insertion heuristic to achieve the overall highest number of task allocations. The adaptive agents consistently match the performances of the best non-adaptive agents across a variety of scenarios. This study aims to demonstrate the possibility and potential performance benefits of giving agents greater decision making capabilities to independently adapt the task allocation process in line with the problem of interest.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-388" tabindex="-1" role="dialog"
         aria-labelledby="modal-388-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-388-label">[Abstract] Please be an Influencer? Contingency-Aware Influence Maximization</h4>
                </div>
                <div class="modal-body">
                    <p>Most previous work on influence maximization in social networks assumes that the chosen influencers (or seed nodes) can be influenced with certainty (i.e., with no contingencies). In this paper, we focus on using influence maximization in public health domains for assisting low-resource communities, where contingencies are common. It is very difficult in these domains to ensure that the seed nodes are influenced, as influencing them entails contacting/convincing them to attend training sessions, which may not always be possible.&nbsp; Unfortunately, previous state-of-the-art algorithms for influence maximization are unusable in this setting. This paper tackles this challenge via the following four contributions: (i) we propose the Contingency Aware Influence Maximization problem and analyze it theoretically; (ii) we cast this problem as a Partially Observable Markov Decision Process and propose CAIMS (a novel POMDP planner) to solve it, which leverages a natural action space factorization associated with real-world social networks; and (iii) we provide extensive simulation results to compare CAIMS with existing state-of-the-art influence maximization algorithms. Finally, (iv) we provide results from a real-world feasibility trial conducted to evaluate CAIMS, in which key influencers in homeless youth social networks were influenced in order to spread awareness about HIV.<b></b><i></i><u></u><sub></sub><sup></sup><strike></strike><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-83" tabindex="-1" role="dialog"
         aria-labelledby="modal-83-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-83-label">[Abstract] Coordination of Mobile Agents for Wireless Sensor Network Maintenance</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we study the problem of wireless sensor network (WSN)</p><p>maintenance using a team of collaborative autonomous mobile agents.</p><p>The agents are deployed in the area of the WSN in such a way that would minimize the time it takes them to reach a failed sensor and repair it. </p><p>The team must constantly optimize its collective deployment to account for occupied agents.</p><p>The objective is to define the optimal deployment and task allocation strategy, that minimize the solution cost.</p><p>The solution cost is a linear combination of the weighted sensors' downtime, the agents' traveling distance and penalties incurred due to unrepaired sensors within a certain time limit.</p><p>A constrained variation of the problem where agents are subject to capacity constrains is also considered.</p><p>Our solutions are inspired by research in the field of computational geometry and the design of our algorithms is based on state of the art approximation algorithms for the classical problem of facility location.</p><p>We empirically compare and analyze the performance of several proposed algorithms.<br></p><p>The sensitivity of the algorithms' performance to the following parameters is analyzed: agents to sensors ratio, sensors' sparsity, frequency of failures and repair duration.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-129" tabindex="-1" role="dialog"
         aria-labelledby="modal-129-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-129-label">[Abstract] Understanding Social Capital in an Intra-Organizational Dependency Network</h4>
                </div>
                <div class="modal-body">
                    <p>In a complex open multi-agent system, agents' interactions as well as their actions are not predictable. They collaborate beneficently with one another for mutual actions that are beyond the ones current capabilities. Repeated pattern of interactions shape a feature of their organizational structure when those agents self-organize themselves for a long-term objective. We aim to understand <i>social capital</i> in organizations that are open membership multi-agent systems with an emphasis in our formulation on the dynamic network of social interactions that, in part, elucidate evolving structures and impromptu topologies of networks. We provide analysis of how social capital can be created within this type of organizations and drive to a measurement for its value. We empirically evaluate the proposed model through an example of an open-source project development.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-787" tabindex="-1" role="dialog"
         aria-labelledby="modal-787-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-787-label">[Abstract] Autonomy Reconsidered: Toward Developing Multi-Agent Systems</h4>
                </div>
                <div class="modal-body">
                    <p>The Church-Turing thesis suggests that the notion of autonomy, applied to robots or artificial agents, must be encoded as an algorithm or set of algorithms. The thesis of this paper is that autonomy is algorithms.&nbsp;&nbsp; More specifically, an agent's autonomy is the set of physically and computationally grounded algorithms that can be performed by that agent.&nbsp;&nbsp;A precise definition of this thesis leads to two useful notions related to autonomy, namely&nbsp;behavior potential and success potential. These two notions lead to a measure of how well an agent fulfills its&nbsp; potential, which we call fulfillment.&nbsp; &nbsp;Fulfillment and success potential induce partial and total orderings of possible algorithms, leading to algorithm-based, capability-centered definitions of levels of autonomy that complement common uses of this phrase.&nbsp;&nbsp;We argue that (a) because the success potential of a&nbsp;multi-agent system can exceed the success potentials of individual&nbsp;agents through synergy effects and (b) the fulfillment of an&nbsp;&nbsp;individual can be augmented through interactions with others,&nbsp;though (c) possibly interfering in the fulfillment of the&nbsp;other agents. Interaction algorithms enable multiple agents to coordinate, communicate, or exchange information; these algorithms enable and constrain tradeoffs between augmenting and diminishing other agents. Short case studies are presented to illustrate how the algorithm-based definitions can be used to understand existing systems.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-151" tabindex="-1" role="dialog"
         aria-labelledby="modal-151-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-151-label">[Abstract] The Power of Context in Networks: Ideal Point Models with Social Interactions</h4>
                </div>
                <div class="modal-body">
                    <p>Game theory has been widely used for modeling strategic behaviors in networked multiagent systems. However, the context within which these strategic behaviors take place has not received much attention. We present a model of strategic behavior in networks that incorporates the behavioral context. We focus on the contextual aspects of Senate voting. A senator's decision to vote <i>yea</i>&nbsp;or <i>nay</i>&nbsp;on a bill comes as a result of their ideologies, agendas, and their interactions with other senators. One salient model in political science is the <i>ideal point model</i>, which assigns each senator and each bill a number on the real line of political spectrum. These points then allow for prediction of future voting behavior. We extend the classical ideal point model with network-structured interactions among senators. In contrast to the ideal point model's prediction of individual voting behavior, we predict <i>joint voting behaviors</i>&nbsp;in a game-theoretic fashion. Our model also includes the characteristics of a bill. This allows it to outperform previous models that solely focus on the networked interactions among senators with no bill-specific parameters. We focus on two fundamental questions: learning the model using real-world data and computing <i>stable outcomes</i>&nbsp;of the model in order to predict joint voting behaviors. We demonstrate the effectiveness of our model through experiments using data from the 114th U.S. Congress.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-466" tabindex="-1" role="dialog"
         aria-labelledby="modal-466-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-466-label">[Abstract] Planning Using a Portfolio of Reduced Models with Cost Adjustments</h4>
                </div>
                <div class="modal-body">
                    <p>Reduced models such as determinization help autonomous agents cope with the complexity of planning under uncertainty. Existing reduced model techniques employ a uniform outcome selection principle for all state-action pairs to simplify a problem. But it is often hard to identify which outcome selection principle will work well across all problems in a domain. In this paper, we aim to create robust reduced models that can yield near-optimal solutions. First, we introduce<i> planning using a portfolio of reduced models</i>, a framework that provides flexibility in reduced model formulation by using a portfolio of outcome selection principles. Secondly, we propose <i>planning using cost adjustment</i>, a technique to improve solution quality by accounting for the outcomes ignored in the reduced model, and analyze conditions under which it can achieve optimal action selection. Finally, we demonstrate the benefits of the approach on three different domains that include an electric vehicle charging problem with stochastic parking duration, using real-world data from a university campus, and two benchmark problems from the planning literature.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-662" tabindex="-1" role="dialog"
         aria-labelledby="modal-662-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-662-label">[Abstract] BDI Model of Connected and Autonomous Vehicles</h4>
                </div>
                <div class="modal-body">
                    <p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;" id="docs-internal-guid-de50807b-a835-4ccf-a721-63b0d2f0f566"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;">It is expected that connected and autonomous vehicles (CAVs) will become a regular mean of transportation by the year 2022. To fully leverage the potential of this new technology it is necessary to equip such cars with efficient algorithms permitting them to drive in a safe and possibly optimal manner. Thereby we aim to design and implement tools for evaluation of strategies for driving and interactions in various settings.</span><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;">In this paper we present results of the first stage of our research on a simulation framework of CAVs.</span></p><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;" id="docs-internal-guid-de50807b-a835-4ccf-a721-63b0d2f0f566"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;"><br></span></p><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;">A search for balance between huge complexity of representing of real-world CAVs and comprehensibility of the solution led us to the paradigm of multi-agent systems. In particular, the concept of BDI, Beliefs-Desires-Intentions, offers useful abstractions for activities of a single self-driving car and a whole systems of such vehicles. However the existing BDI-systems either do not address certain problems related to simulation of CAVs or introduce significant overhead in programming resources.</span></p><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;"><br></span></p><p><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;">Our approach, on the other hand, in a simple way combines two distinct natures of a self-driving car: its reactiveness and proactiveness. Moreover, modularity of the resulting architectures for an individual CAV and urban traffic induced by these cars makes the design easily extensible and resilient. Finally, we also consider technical aspects of implementation even on a large scale of hundreds and thousands vehicles and verify its feasibility by preparing a prototype of a CAV simulating tool.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-160" tabindex="-1" role="dialog"
         aria-labelledby="modal-160-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-160-label">[Abstract] Preference-Guided Planning: An Active Elicitation Approach</h4>
                </div>
                <div class="modal-body">
                    <p>Planning with preferences has been employed extensively to quickly generate high-quality plans.&nbsp;</p><p>However, it may be difficult for the human expert to supply this information without knowledge of the reasoning employed by the planner and the distribution of planning problems. We consider the problem of actively eliciting preferences from a human expert during the planning process. Specifically, we study this problem in the context of the Hierarchical Task Network (HTN) planning framework as it allows easy interaction with the human.</p><p>Our experimental results on several diverse planning domains show that the preferences gathered using the proposed approach improve the quality and speed of the planner, while reducing the burden on the human expert.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-325" tabindex="-1" role="dialog"
         aria-labelledby="modal-325-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-325-label">[Abstract] Imitation Learning of Optimal Strategies in Differential Games</h4>
                </div>
                <div class="modal-body">
                    <p>The ability of a vehicle to navigate safely through any environment relies on its driver having an accurate sense of the future positions and goals of other vehicles on the road. A driver does not navigate around where an agent is, but where it is going to be. To avoid collisions, autonomous vehicles should be equipped with the ability to to derive appropriate controls using future estimations for other vehicles, pedestrians, or otherwise intentionally moving agents in a manner similar to or better than human drivers. Differential game theory provides one approach to generate a control strategy by modeling two players with opposing goals. Environments faced by autonomous vehicles, such as merging onto a freeway, are complex, but they can be modeled and solved as a differential game using discrete approximations; these games yield an optimal control policy for both players and can be used to model adversarial driving scenarios rather than average ones, so that autonomous vehicles will be safer on the road in more situations. Further, discrete approximations of solutions to complex games that are computationally tractable and provably asymptotically optimal have been developed, but may not produce usable results in an online fashion. To retrieve an efficient, continuous control policy, we use deep imitation learning to model the discrete approximation of a differential game solution. We successfully learn the policy generated for two games of different complexity, a fence escape and merging game, and show that the imitated policy generates control inputs faster than the differential game generated policy.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-727" tabindex="-1" role="dialog"
         aria-labelledby="modal-727-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-727-label">[Abstract] A Stitch in Time - Autonomous Model Management via Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <pre style="margin-bottom: 0px;"><span style=" color:#000000;">Concept drift - a change, either sudden or gradual, in the underlying</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">properties of data - is one of the most prevalent challenges to</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">maintaining high-performing learned models over time in autonomous</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">systems.  In the face of concept drift, one can hope that the old model</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">is sufficiently representative of the new data despite the concept</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">drift, one can discard the old data and retrain a new model with (often</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">limited) new data, or one can use transfer learning methods to combine</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">the old data with the new to create an updated model.  Which of</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">these three options is chosen affects not only near-term decisions, but</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">also future needs to transfer or retrain.  In this paper, we thus model</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">response to concept drift as a sequential decision making problem and</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">formally frame it as a Markov Decision Process.  Our reinforcement</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">learning approach to the problem shows promising results on one</span></pre><pre style="margin-bottom: 0px;"><span style=" color:#000000;">synthetic and two real-world </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">datasets</span><span style=" color:#000000;">.</span></pre><p>













</p><pre style="margin-bottom: 0px;"><br></pre>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-465" tabindex="-1" role="dialog"
         aria-labelledby="modal-465-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-465-label">[Abstract] Evolving Coverage Behaviours For MAVs Using NEAT</h4>
                </div>
                <div class="modal-body">
                    <p>There has been an increasing interest in the use of robotic swarms for the purpose of surveillance and mapping of complex environments. This is mainly due to the fact that swarm systems have a number of desirable properties over single agent systems: robustness, scalability and the ability to solve a problem in parallel. Although progress has been made in this area, there is still a long way to go before these technologies are deployed in a real world environment. This paper offers a real world, robotic solution to an important sub-task in surveillance: dynamic coverage - the problem of covering an area evenly and continuously in order to visit all areas of interest. This work provides a novel solution in that it achieves this in a completely decentralised manner with no reliance on GPS, meaning it is achieved using a relative positioning system as opposed to a global positioning system. This is especially important for deployment in hazardous, uncertain environments where GPS may be unavailable and communication links stand a high chance of being severed. Previous works either rely on a centralised command unit, require the use of GPS or simply do not realise the simulation results on real robots. This work uses NEAT, which is a neuroevolutionary algorithm that evolves neural network structure as well as the synapse weights through the use of a genetic algorithm. The robotic controllers are first realised via accurate simulation and then transferred to Micro-Aerial Vehicles (MAVs). The MAVs are modified to include a Ultra-Wideband Frequency (UWB) chip which use radio waves to communicate inter drone distances to one another.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-73" tabindex="-1" role="dialog"
         aria-labelledby="modal-73-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-73-label">[Abstract] Distributed Multi-resource Allocation with Little Communication Overhead</h4>
                </div>
                <div class="modal-body">
                    <p><span style="white-space:pre">	</span>We propose a distributed algorithm to solve a special&nbsp;distributed multi-resource allocation problem with no direct&nbsp;inter-agent communication. We do so by extending a recently introduced&nbsp;additive-increase multiplicative-decrease (AIMD) algorithm, which only&nbsp;uses very little communication between the system and agents. Namely,&nbsp;a control unit broadcasts a one-bit signal to agents whenever one of&nbsp;the allocated resources exceeds capacity. Agents then respond to this&nbsp;signal in a probabilistic manner. In the proposed algorithm, each&nbsp;agent is unaware of the resource allocation of other agents. We also&nbsp;propose a version of the AIMD algorithm for multiple binary&nbsp;resources (e.g., parking spaces). Binary resources are indivisible&nbsp;unit-demand resources, and each agent either allocated one unit of the&nbsp;resource or none.&nbsp; In empirical results, we observe that in both&nbsp;cases, the average allocations converge over time to optimal allocations.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-637" tabindex="-1" role="dialog"
         aria-labelledby="modal-637-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-637-label">[Abstract] Coordination and Common Knowledge on Communication Networks</h4>
                </div>
                <div class="modal-body">
                    <p>Protest is a collective action problem and can be modeled as a coordination game in which two or more people each take an action with the potential to achieve shared mutual benefits, only if their actions coincide. In the context of protest participation, successful coordination requires that people know each others' willingness to participate, and that this information is common knowledge.&nbsp; Social networks can facilitate the creation of common knowledge through the flow of messages.&nbsp; Although there is a rich experimental literature that documents behavior in coordination games with and without communication, little is known about how people coordinate behaviors within a social network and how different types of communication structures affect behavior.</p><p>In this paper, we develop a theoretically based on-line experiment with Amazon Mechanical Turk participants to characterize the emergence of common knowledge and coordination through interactions within a network. Our experiment is designed to identify the effects of both social network topology and communication and to falsify the game-theoretic predictions.&nbsp; Our data reveal that choices are affected by the network structure and they move towards the theoretical predictions with communication. We use our behavioral findings to simulate dynamics in more complex networks through agent-based modeling. Thus, we combine human behaviors identified in experiments with realistic social network structures to reveal patterns not previously observed.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-213" tabindex="-1" role="dialog"
         aria-labelledby="modal-213-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-213-label">[Abstract] Information Exchanging and Non-Cooperative Computation among Rational Agents</h4>
                </div>
                <div class="modal-body">
                    <p>We study mechanism design in the setting where agents are rewarded using information only. This is an interesting setting motivated, among other things, by the increasing interest in secure multi party computation techniques. Moreover this is a very challenging setting, since information (as opposed to money) can be easily replicated and is not \emph{fungible} i.e., the same piece of information might have different values for different agents. More specifically, we consider the setting of a joint computation where different agents have inputs of different \emph{quality} or \emph{value}, and their utility incorporates both&nbsp; \emph{correctness} and \emph{exclusiveness}, i.e. every agent is interested in improving the quality of his own piece of information while preventing other agents from doing so.</p><p>Then we ask the question of whether we can design mechanisms that motivate all agents (even those with high-quality input) to participate in the computation. We begin answering this fascinating question by proposing mechanisms for natural joint computation tasks such as intersection, union, and average.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-87" tabindex="-1" role="dialog"
         aria-labelledby="modal-87-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-87-label">[Abstract] Belief Shadowing</h4>
                </div>
                <div class="modal-body">
                    <p>Belief change/update/revision typically requires deep and/or complex modifications of belief bases.</p><p>In this paper we present a novel, lightweight and tractable approach to a new kind of belief change which we call&nbsp;<i>belief shadowing</i>. It can be seen as a transient swap of beliefs. Namely, a belief base can be shadowed by another belief base representing new observations and/or beliefs of superior agents/teams. However, no changes to belief bases are required. Therefore, this approach can substantially improve the performance of agent systems relying on doxastic reasoning.</p><p>In order to address important phenomena, also those related to adequate modeling of dynamic environment, our approach is based on a carefully chosen four-valued paraconsistent logic with truth values representing truth, falsity, incompleteness and inconsistency.&nbsp; Moreover, potentially undesired or forbidden conclusions are prevented by integrity constrains together with their shadowing machinery.&nbsp;&nbsp;</p><p>As an implementation environment we have chosen a recently developed four-valued query language, based on the same logic and providing necessary reasoning tools. Importantly, the presented shadowing techniques are general enough to be embedded in any reasoning environment&nbsp; addressing related phenomena.&nbsp;</p><p>The approach is illustrated by a medical emergency room scenario exhibiting a fair level of dynamism and complexity.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-420" tabindex="-1" role="dialog"
         aria-labelledby="modal-420-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-420-label">[Abstract] A Coordination Mechanism to Replicate Large-Scale Multi-Agent Systems</h4>
                </div>
                <div class="modal-body">
                    <p>Distributed cooperative applications are now increasingly designed as Multi-Agent Systems (MASs). Such applications may be open, very dynamic, large scale and, being decentralized, exhibit heterogeneous and dynamic agent criticalities.These characteristics create new challenges to the traditional approaches of fault-tolerance. We focus on replication-based preventive approaches. The aim is to dynamically and automatically adapt the agent replication strategy (number of replicas and their location), in order to maximize the MAS reliability (guarantee of continuity of computation w.r.t the agents criticalities) while not significantly impacting the system performances. In this paper, we describe a decentralized coordination mechanism for dynamically optimizing&nbsp; the replication strategy of a large-scale and open MAS. We then provide theoretical validation and report on experimental validation by comparing to a top-of-the-art DCOP algorithm.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-419" tabindex="-1" role="dialog"
         aria-labelledby="modal-419-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-419-label">[Abstract] Reinforcement Learning based on Sequential Information in the Iterated Prisoner&#39;s Dilemma</h4>
                </div>
                <div class="modal-body">
                    <p>The Iterated Prisoner's Dilemma (IPD) has been studied for exploring human social interactions, and many strategies have been designed for it to achieve better total payoffs. However, there is no single strategy suitable for playing against all other agents since the performance of an IPD strategy depends largely on the opponent's strategy. We develop a new strategy for the IPD that uses lifelong Reinforcement Learning (RL) and is based on the novel concept of sequential information of recent moves, which is able to find optimal responses against different opponents. In our RL framework, the Markov Decision Process (MDP) is built upon the history of the IPD, and the lifelong training SARSA is used to select the actions. The state of the Q-table employs, for the first time, the number of sequential cooperation in recent rounds, which evaluates the response of the opponent to the agent's recent moves and stores its features. Meanwhile, the Q-table acquires knowledge throughout the agent's lifetime in which playing against each new opponent strategy is considered as a new RL task associated with a new MDP. Our RL strategy is the new state-of-the-art which wins both the round-robin and the ecological tournaments. Moreover, it enhances the performance of the opponents, and has similar top scores in other repeated games.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-227" tabindex="-1" role="dialog"
         aria-labelledby="modal-227-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-227-label">[Abstract] Solving the Capacitated Open Vehicle Routing Problem, Based on Probability Distribution Analysis of Saving Matrix Values</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal" style="margin-top:6.0pt;margin-right:0cm;margin-bottom:0cm;
margin-left:0cm;margin-bottom:.0001pt">











<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1107305727 0 0 415 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin-top:0cm;
	margin-right:0cm;
	margin-bottom:4.0pt;
	margin-left:0cm;
	text-align:justify;
	mso-pagination:widow-orphan;
	font-size:9.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-bidi-language:AR-SA;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-size:10.0pt;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;}
@page WordSection1
	{size:612.0pt 792.0pt;
	margin:72.0pt 72.0pt 72.0pt 72.0pt;
	mso-header-margin:36.0pt;
	mso-footer-margin:36.0pt;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>






Same day last mile parcels delivery services
are recently gaining a great deal of attention in the autonomous agents
community. In the Tel-Aviv metropolitan area, Gett and other companies provide
delivery services for small parcels using a scooters fleet.<span style="mso-spacerun:yes">&nbsp; </span>Scooter couriers deliver the parcels from the
local post offices to the final customers. Since a scooter has limited capacity
and is paid with respect to the total traveling distance, the problem can be
formulated as a Capacitated Open Vehicle Routing Problem (COVRP). The proposed
approach is based on the high sparseness of the Clarke-Wright (CW) saving matrix for
COVRP in case of parcels delivery from post offices. In this case the CW algorithm
can be separated to construction of all feasible Hamiltonian paths at the first
phase and its optimal combination at the second phase. Computational results
show that the proposed algorithm is competitive, over performs classical CW in the
Tel-Aviv metropolitan area by 42% on average and improves known benchmark
results on some instances.</p><p>





<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-636" tabindex="-1" role="dialog"
         aria-labelledby="modal-636-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-636-label">[Abstract] Dynamic Traveling Repairmen Bounty Hunters</h4>
                </div>
                <div class="modal-body">
                    <p>Vehicle routing problems such as the multiagent Dynamic Traveling Repariman Problem (DTRP) are of interest to many fields and of increasing practical importance in light of advances in autonomous vehicles.&nbsp; DTRP is NP-hard, making approximation methods attractive.&nbsp; However current heuristic approaches do not adequately consider issues special to DTRP, such as fairness and variance, discontiguous-space scenarios, or approaches to equitably partitioning the task space.&nbsp; We tackle this problem in a novel way, using a multiagent task allocation technique loosely called <i>bounty hunting</i>.&nbsp; In bounty hunting, agents compete to perform tasks non-exclusively in return for reward, and rapidly learn which agents are more adept at various tasks than others, divvying up the task space.&nbsp; &nbsp; We demonstrate that bounty hunting can perform efficiently in discontiguous environments, and can improve the bias and variance of the system while minimally affecting average waiting time.&nbsp; We show that Bounty Hunting consistently performs as well as or statistically better than the current state-of-the-art heuristic, and is particularly good in large-scale scenarios.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-476" tabindex="-1" role="dialog"
         aria-labelledby="modal-476-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-476-label">[Abstract] A Generalised Method for Empirical Game Theoretic Analysis</h4>
                </div>
                <div class="modal-body">
                    <p>This paper provides theoretical bounds for empirical game theoretical analysis of complex multi-agent interactions. More precisely, we provide insights on the empirical, or meta game, showing that a Nash equilibrium of the meta-game is an approximate Nash equilibrium of the true underlying game. We provide insights on how many data samples are required to obtain a close enough approximation of the underlying game. Additionally, we extend the meta-game analysis methodology to asymmetric games. The state-of-the-art has only considered empirical games in which agents have access to the same strategy sets and the payoff structure is symmetric, implying that agents are interchangeable. Finally, we carry out an empirical illustration of the generalised method in several domains, illustrating the theory and evolutionary dynamics of several versions of the \textit{AlphaGo} algorithm (symmetric), the dynamics of the Colonel Blotto game played by human players on Facebook (symmetric), and an example of a meta-game in Leduc Poker (asymmetric), generated by the PSRO multi-agent learning algorithm.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-577" tabindex="-1" role="dialog"
         aria-labelledby="modal-577-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-577-label">[Abstract] Combating Behavioral Deviance via User Behavior Control</h4>
                </div>
                <div class="modal-body">
                    <p>Compared to traditional behavioral deviance, online deviant behavior (like cyberbullying) is more likely to spread over online social communities since it is not restricted by time and space, and can occur more frequently and intensely. To control risks associated with the spread of deviant and anti-normative behavior, it is essential to understand online users’ reaction when they interact with other users. In this paper, we model online users’ behavior interaction as an evolutionary game on a graph and analyze users’ behavior dynamics under different network conditions. Based on this theoretical framework, we then investigate behavior control strategies that aim to eliminate behavioral deviance. Finally, we use a real world dataset from a social network to verify the accuracy of our model’s hypothesis.We also and test the performance of our behavior control strategy through simulations based on both real and synthetically generated data. The experimental results demonstrate that our behavior control methods can effectively eliminate the impact of bullying behavior even when the proportion of bullying messages is higher than 60%.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-148" tabindex="-1" role="dialog"
         aria-labelledby="modal-148-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-148-label">[Abstract] HIGHLIGHTS: Summarizing Agent Behaviors to People</h4>
                </div>
                <div class="modal-body">
                    <p><span id="docs-internal-guid-845b1209-9c0c-9dd0-f805-d5c9b062b001"></span></p><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><font face="Arial"><span style="font-size: 14.6667px; white-space: pre-wrap;">People increasingly interact with autonomous agents. This paper introduces and formalizes the problem of automatically generating a summary of an agent's behavior with the goal of increasing people's familiarity with the agent's capabilities and limitations. In contrast with prior approaches&nbsp; which developed methods for explaining a single decision made by an agent, our approach aims to provide users with a summary that describes the agent's behavior in different situations. We hypothesize that reviewing such summaries could help people in tasks such as choosing between agents or determining the level of autonomy to grant to an agent. We develop ``HIGHLIGHTS'', an algorithm that produces a summary of an agent's behavior by extracting important trajectories from simulations of the agent.&nbsp;</span></font><span style="font-size: 14.6667px; white-space: pre-wrap; font-family: Arial;">We conducted a human-subject experiment to evaluate whether HIGHLIGHTS summaries help people assess the capabilities of agents. Our results show that participants were more successful at evaluating the capabilities of agents when presented with HIGHLIGHTS summaries compared to baseline summaries, and rated them as more helpful. We also explore a variant of the HIGHLIGHTS algorithm which aims to increase the diversity of states included in the summary, and show that this modification further improves people's ability to assess agents' capabilities.</span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-198" tabindex="-1" role="dialog"
         aria-labelledby="modal-198-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-198-label">[Abstract] Diversity Constraints in Public Housing Allocation</h4>
                </div>
                <div class="modal-body">
                    <p>The state of Singapore operates a national public housing program, accounting for over $80\%$ of its residential real estate. Singapore uses its housing allocation program to ensure ethnic diversity in its neighborhoods; it does so by imposing ethnic quotas: every ethnic group must not own more than a certain percentage in a housing project, thus ensuring that every neighborhood contains members from each ethnic group. However, imposing diversity constraints naturally results in some welfare loss. Our work studies the tradeoff between diversity and social welfare from the perspective of computational economics. We model the problem as a an extension of the classic assignment problem, with additional diversity constraints. While the classic assignment program is poly-time computable, we show that adding diversity constraints makes the problem computationally intractable; however, we identify a $\tfrac{1}{2}$-approximation algorithm, as well as reasonable agent utility models which admit poly-time algorithms. In addition, we study the {\em price of diversity}: this is the loss in welfare incurred by imposing diversity constraints; we provide upper bounds on the price of diversity as a function of natural problem parameters; next, we analyze public data from Singapore's Housing Development Board, and create a simulated framework testing the welfare loss due to diversity constraints in realistic large-scale scenarios.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-676" tabindex="-1" role="dialog"
         aria-labelledby="modal-676-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-676-label">[Abstract] Adaptive Stress Testing for Autonomous Vehicles</h4>
                </div>
                <div class="modal-body">
                    <p><span style="font-size:12.8px">A critical problem for autonomous 
vehicles is efficient safety validation in simulation. Naively sampling 
scenarios to find failures is intractable. This paper uses adaptive 
stress testing, a method for validating the safety of autonomous 
vehicles that perturbs stochastic elements in the environment in a 
directed way until the vehicle is involved in a collision. The problem 
of finding the most likely failure scenario can be modeled as a Markov 
decision process, and reinforcement learning algorithms can be used to 
efficiently solve the problem. We use Monte Carlo tree search (MCTS), 
which has been used previously to test aircraft collision avoidance 
systems. We also present a more scalable deep reinforcement learning 
approach and show that it can find more likely failure scenarios than 
MCTS while requiring fewer calls to the simulator. A simulation scenario
 involving a vehicle approaching a crosswalk is used to demonstrate the 
validity of the framework and the approaches used. However, the 
framework presented in this paper can be generalized to other scenarios,
 given appropriate models of the vehicle and the environment.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-369" tabindex="-1" role="dialog"
         aria-labelledby="modal-369-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-369-label">[Abstract] Action Selection for Transparent Planning</h4>
                </div>
                <div class="modal-body">
                    <p>We introduce a novel framework to formalise and solve <i>transparent planning tasks</i>&nbsp;by executing actions selected in a suitable and timely fashion. A <i>transparent planning task</i>&nbsp;is defined as task where the objective of the agent is to communicate its true goal to observers, thereby making its intentions and its action selection <i>transparent</i>. We formally define and model these tasks as <i>Goal POMDP</i> where the state space is the Cartesian product of the states of the world and a given set of hypothetical goals. Action effects are deterministic in the world states of the problem but probabilistic in the observer's beliefs. Transition probabilities are obtained from making a call to a model-based plan recognition algorithm, which we refer to as an <i>observer stereotype</i>. We propose an action selection strategy via on-line planning that seeks actions to quickly convey the goal being pursued to an observer assumed to fit a given stereotype. In order to keep run-times feasible, we propose a novel model-based plan recognition algorithm that approximates well-known probabilistic plan recognition methods. The resulting on-line planner, after being evaluated over a diverse set of domains and three different observer stereotypes, is found to convey goal information faster than purely goal-directed planners.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-700" tabindex="-1" role="dialog"
         aria-labelledby="modal-700-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-700-label">[Abstract] New Algorithms for Inference in Graph Sequence Models</h4>
                </div>
                <div class="modal-body">
                    <p>Although the computational and statistical trade-offs for modeling single graphs are relatively well understood, extending such results to sequences of graphs is difficult. In this work, we propose two models for such sequences that capture: link persistence between nodes across time, and community persistence of each node across time. In the first model, we assume that the latent community of each node does not change, and in the second model we relax this assumption. For both models, we propose computationally efficient inference algorithms, which leverage community detection methods that work on single graphs. We provide simulation results validating their performance.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-481" tabindex="-1" role="dialog"
         aria-labelledby="modal-481-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-481-label">[Abstract] Diversified Strategies in Games: Learning and Properties</h4>
                </div>
                <div class="modal-body">
                    <pre id="code" class="brush: ; plain-text" style="margin-bottom: 0px; padding: 10px;"><font color="#000000"><span style="font-size: 12px; white-space: pre-wrap;">In this work we consider online decision-making settings in which players have an additional constraint that at each time step they must play a diversified mixed strategy: one that does not put too much weight on any one action. This constraint is motivated by applications such as finance, routing, and resource allocation, in which one would like to limit the chance of catastrophic failure while still performing well in typical cases. We explore properties of diversified strategies in both zero-sum and general-sum games, and provide algorithms for minimizing regret within the family of diversified strategies as well as methods for using taxes or fees to guide standard regret-minimizing players towards diversified strategies. We also analyze equilibria produced by diversified strategies in general-sum games. We show that surprisingly, requiring diversification can actually lead to higher-quality equilibria, and give strong guarantees on both price of anarchy and the social welfare produced by regret-minimizing diversified agents. We additionally give algorithms for finding optimal diversified strategies in distributed settings where one must limit communication overhead.<br></span></font></pre>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-243" tabindex="-1" role="dialog"
         aria-labelledby="modal-243-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-243-label">[Abstract] A normal modal logic for trust in the sincerity</h4>
                </div>
                <div class="modal-body">
                    <p>In the field of multi-agent systems, as some agents may be not reliable or honest, a particular attention is paid to the notion of trust. There are two main approaches for trust: trust assessment and trust reasoning. Trust assessment is often realized with fuzzy logic and reputation systems which aggregate testimonies -- individual agents' assessments -- to evaluate the agents' global reliability. In the domain of trust reasoning, a large set of works focus also on trust in the reliability as for instance Liau's BIT modal logic where trusting a statement means the truster can believe it. However, very few works focus on trust in the sincerity of a statement -- meaning the truster can believe the trustee believes it. Consequently, we propose in this article a modal logic to reason about an agent's trust in the sincerity towards a statement formulated by another agent. We firstly introduce a new modality of trust in sincerity and then we prove that our system is sound and complete. Finally, we extend our notion of individual trust about the sincerity to shared trust and we show that it behaves like a KD system. <br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-591" tabindex="-1" role="dialog"
         aria-labelledby="modal-591-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-591-label">[Abstract] FActCheck: Keeping Activation of Fake News at Check</h4>
                </div>
                <div class="modal-body">
                    <p>The diffusion of fake news has become a crucial problem in recent years as social media have become prime sources of news, and the preferred mechanism for dissemination of&nbsp; opinions and ideas. To improve the reliability of content shared on social media, effective strategies for mitigating the diffusion of fake news are increasingly necessary. One way to battle the dissemination of fake news is to propagate the corresponding real news, since people who receive the real news in tandem with the fake news are less likely to believe in fake news. To achieve this goal, we propose to find a set of individuals of a pre-defined size to pass the real news to the maximum number of nodes in the network. They are likely to receive the fake news so that they can test its credibility, and when they propagate the corresponding real news, it is likely to reach a large number of individuals. This problem, termed Fake News Activation Checking (FActCheck), is fundamentally different from works for (i) preventing the spread of rumors by removing nodes or blocking edges, and (ii) competitive influence maximization in social networks, that have been well studied in the literature. We prove that FActCheck is NP-Hard with a monotone and submodular objective, leading to a polynomial time greedy algorithm (AFC) which provides (1-1/e-\epsilon)-approximation. We further optimize the runtime of AFC by developing a fast graph-pruning heuristic (RAFC) that performs as well as AFC in checking the spread of fake news. Our experiments on real-world networks demonstrate that our approach outperforms popular methods in social network analysis literature.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-587" tabindex="-1" role="dialog"
         aria-labelledby="modal-587-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-587-label">[Abstract] Combining Opinion Pooling and Evidential Updating for Multi-Agent Consensus</h4>
                </div>
                <div class="modal-body">
                    <p>The evidence available to a multi-agent system can take at least two distinct forms. There can be direct evidence from the environment resulting, for example, from sensor measurements or from running tests or experiments. In addition, agents also gain evidence from individuals in the population with whom they are interacting. We, therefore, envisage agents' beliefs as a probability distribution over a set of hypotheses of interest, which are update either on the basis of direct evidence using Bayesian updating, or by taking account of the probabilities of other agents using opinion pooling. This paper investigates the relationship between these two processes in a multi-agent setting. We show that pooling operators can provide a mechanism by which a limited amount of direct evidence can be efficiently propagated through a population of agents so that an appropriate consensus is reached. A number of axioms are introduced relating to the evidence preservation properties of pooling operators. In particular, we show that evidence preservation characterises the product pooling operator. We also consider possible Bayesian justifications for pooling operators in this context. Finally, we present simulation experiments which investigate the convergence properties of a parameterised family of operators with a range of evidence propagation strengths.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-312" tabindex="-1" role="dialog"
         aria-labelledby="modal-312-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-312-label">[Abstract] Data-driven Multiagent Email Generators</h4>
                </div>
                <div class="modal-body">
                    <p>Multi-agent simulation of communication is often required by network traffic generation systems for application testing and user training.&nbsp; This domain creates a set of constraints on the simulation components: the decision models must be distributed, the agent decisions must be data-driven, explainable, and configurable, and the resulting communication graphs must be measurably realistic.&nbsp; The methodology described here works within these constraints, and is developed on email communications.&nbsp; Topic modeling and named entity recognition on an email corpus create reusable templates for individual emails; topic inference and thread extraction creates email thread graphs which are then compiled into a distributed thread model; the email templates and thread models are then used by agents.&nbsp; Then, social network analysis measures compare system-generated with human-generated email data.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-86" tabindex="-1" role="dialog"
         aria-labelledby="modal-86-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-86-label">[Abstract] A Differential Privacy Mechanism with Network Effects for Crowdsourcing Systems</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">In crowdsourcing systems, it is important for the crowdsource campaign initiator to incentivize users to share their data to produce
results of the desired computational accuracy. This problem becomes especially challenging when users are concerned about the
privacy of their data. To overcome this challenge, existing work
often aims to provide users with differential privacy guarantees to incentivize privacy-sensitive users to share their
data. However, this work neglects the network effect that a user
enjoys greater privacy protection when he aligns his participation behaviour with that of other users. To explore the network effect
and provide a differential privacy guarantee, we design PINE (Privacy Incentivization with Network Effects). PINE is a mechanism
that maximizes the initiator’s payoff while providing participating
users with privacy protections. Numerical simulations show that
PINE improves the initiator’s expected payoff by up to </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">40%</span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">, compared to a differential privacy mechanism that does not consider
this effect.&nbsp;</span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-445" tabindex="-1" role="dialog"
         aria-labelledby="modal-445-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-445-label">[Abstract] An Optimal Rewiring Strategy for Reinforcement Social Learning in Cooperative Multiagent Systems</h4>
                </div>
                <div class="modal-body">
                    <p><span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">Multiagent coordination in cooperative multiagent systems <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">(MASs) has been widely studied in both fixed-agent repeated <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">interaction setting and the static social learning framework. <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">However, two aspects of dynamics in real-world multiagent <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">scenarios are currently missing in existing works. First, the <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">network topologies can be dynamic where agents may change <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">their connections through rewiring during the course of interactions. Second, the game matrix between each pair of agents <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">may not be static and usually not known as a prior. Both the <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">network dynamics and game uncertainty increase the coordination difficulty among agents. In this paper, we consider<br><span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">a multiagent dynamic social learning environment in which <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">each agent can choose to rewire potential partners and interact with randomly chosen neighbors in each round. We propose an optimal rewiring strategy for agents to select most <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">beneficial peers to interact with for the purpose of maximizing the accumulated payoff in repeated interactions. We empirically demonstrate the effectiveness and robustness of our <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">approach through comparing with benchmark strategies. The <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">performance of three representative learning strategies under <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">our social learning framework with our optimal rewiring are <span style="font-family: NimbusRomNo9L-Regu;font-size:8pt;color:rgb(0,0,0);font-style:normal;font-variant:normal;">investigated as well.</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><br style=" font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: -webkit-auto; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; "></span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-311" tabindex="-1" role="dialog"
         aria-labelledby="modal-311-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-311-label">[Abstract] Preference Elicitation with Interdependency and User Bother Cost</h4>
                </div>
                <div class="modal-body">
                    <p>Agent-based scheduling systems, such as automated systems that schedule meetings for users and systems that schedule smart devices in smart homes, require the elicitation of user preferences in order to operate in a manner that is consistent with user expectations. Unfortunately, interactions between such systems and users can be limited as human users prefer to not be overly bothered by such systems. As such, a key challenge is for the system to efficiently elicit key preferences without bothering the users too much.&nbsp;</p><p>To tackle this problem, we propose a cost model that models the cognitive or bother cost associated with asking a question. We incorporate this model into our iPLEASE system, an interactive preference elicitation system. iPLEASE represents a user's preferences as a matrix, called preference matrix, and uses heuristics to select, from a given set of questions, an efficient sequence of questions to ask the user such that the total bother cost incurred to the user does not exceed a given bother cost budget. The user's response to those questions will partially populate the preference matrix. It then performs an exact matrix completion via convex optimization to approximate the remaining preferences that are not directly elicited. We empirically apply iPLEASE on randomly-generated problems as well as on a real-world dataset for the smart device scheduling problem to demonstrate that our approach outperforms other non-trivial benchmarks in eliciting user preferences.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-722" tabindex="-1" role="dialog"
         aria-labelledby="modal-722-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-722-label">[Abstract] Clustering Behavior to Recognize Subjective Beliefs in Human-Agent Teams</h4>
                </div>
                <div class="modal-body">
                    <p>Trust is critical to the success of human-agent teams, and one of the critical antecedents to trust is transparency. To best interact with human teammates, an agent must be able to explain itself so that they understand its decision-making process. However, individual differences among human teammates require that the agent dynamically adjust its explanation strategy based on their current unobservable subjective beliefs. We therefore need methods by which an agent can recognize its teammates' subjective beliefs relevant to trust-building (e.g., their understanding of the agent's capabilities and process). We leverage a nonparametric method to enable an agent to use its history of prior interactions as a means for recognizing and predicting a new teammate's subjective beliefs. We first gather data combining observable behavior sequences with survey-based observations of typically unobservable perceptions. We then use a nearest-neighbor approach to identify the prior teammates most similar to the new one. We use these neighbors' responses to infer the likelihood of possible beliefs, as in collaborative filtering. The results provide insights into the types of beliefs that are easy (and hard) to infer from purely behavioral observations.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-772" tabindex="-1" role="dialog"
         aria-labelledby="modal-772-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-772-label">[Abstract] On the Shapley Value of Boolean Games</h4>
                </div>
                <div class="modal-body">
                    <p>The Shapley value is a fair method for dividing the payoff of a cooperative game. Computing the Shapley value is a \#P-complete problem; however, in few games, we can overcome this exponential time complexity and obtain efficient algorithms. Here, we study boolean function games, where the characteristic function of the cooperative game is a boolean function. For a read-once function game, we give an $O(n^4)$ time algorithm to find the Shapley value of all players. We also study the Banzhaf index of this problem, which is another method for dividing the payoff. Furthermore, we show that a slight relaxation of the read-once assumption leads to a \#P-complete problem, including a boolean game with a twice-read monotone function or a thrice-read monotone bipartite planar boolean function. We also study the parameterized complexity of boolean games. We define a new parameter called rooted treewidth and we find the Shapley value of a boolean game in time $O(2^r n^4)$, which is a generalization our previous algorithm. The model of boolean games is a general framework which is useful for many cooperative games in various fields.<br></p><p>Moreover, we assume the issue that sometime the boolean function is unknown at first, and we want to find it by looking at the payoff of some coalitions. For a depth three monotone read-once function, we present an algorithm that looks at the payoff of $O(n\log n)$ coalitions to reconstruct the function.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-704" tabindex="-1" role="dialog"
         aria-labelledby="modal-704-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-704-label">[Abstract] Real-time Prediction of Intermediate-horizon Automotive Collision Risk</h4>
                </div>
                <div class="modal-body">
                    <p><font face="Arial"><span style="font-size: 14.6667px; white-space: pre-wrap;">Advanced collision avoidance and driver hand-off systems can benefit from the ability to accurately predict, in real time, the probability a vehicle will be involved in a collision within an intermediate horizon of 10 to 20 seconds. The rarity of collisions in real-world data poses a significant challenge to developing this capability because, as we demonstrate empirically, intermediate-horizon risk prediction depends heavily on high-dimensional driver behavioral features. As a result, a large amount of data is required to fit an effective predictive model. In this paper, we assess whether simulated data can help alleviate this issue. Focusing on highway driving, we present a three-step approach for generating data and fitting a predictive model capable of real-time prediction. First, high-risk automotive scenes are generated using importance sampling on a learned Bayesian network scene model. Second, collision risk is estimated through Monte Carlo simulation. Third, a neural network domain adaptation model is&nbsp; trained on real and simulated data to address discrepancies between the two domains. Experiments indicate that simulated data can mitigate issues resulting from collision rarity, thereby improving risk prediction in real-world data.</span></font><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-507" tabindex="-1" role="dialog"
         aria-labelledby="modal-507-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-507-label">[Abstract] A New Algorithm for Allocating Temporally Constrained Tasks with Collision-Free Trajectories in Multi-Robot Systems</h4>
                </div>
                <div class="modal-body">
                    <p><i>Multi-robot systems (</i>MRS<i>)</i> are a reference solution for many real-world applications of crucial practical importance, e.g. management of warehouses. Efficiently and dynamically assigning to robots tasks having deadlines, i.e. constraints on when the execution must take place, in such a way that some objective functions of interest (e.g. makespan, number of performed tasks, distance traveled) are optimized is perhaps one of the most fundamental primitives of such systems. Although the corresponding computational problem is known to be both NP–Hard and hard to approximate, few effective and practical solutions are known in the literature. However, none of them guarantees that collision-free trajectories are used by the robots under relatively general hypotheses.</p><p>In this paper, we present a new algorithm that is able to allocate tasks having deadlines while, at the same time, providing collision-free trajectories under more general assumptions. We provide an extensive experimental evaluation, conducted on meaningful synthetic datasets, to assess the effectiveness of the new approach and to show that it outperforms state-of-the-art methods in terms of quality of the computed solutions.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-385" tabindex="-1" role="dialog"
         aria-labelledby="modal-385-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-385-label">[Abstract] Opponent Modeling in Data Collection Game using Deep Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p>Data-collection Game (DCG) is proposed to model the scenario where a robotic agent needs to collect digital data in an environment containing an opponent. The opponent can disable the data-collecting agent and may use various strategies. Deep reinforcement learning is employed to train the data-collecting agent, where deep neural networks are used both to encode the agent's policy and to model the opponent's strategy. Four networks that model the opponent in various ways are proposed and evaluated. Experiments show explicit opponent modeling using a separate network greatly improves the performance of the data-collecting agent.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-199" tabindex="-1" role="dialog"
         aria-labelledby="modal-199-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-199-label">[Abstract] Gossip Gradient Descent</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we consider a problem of learning a linear regression model distributively with a network of $N$ interconnected agents which receive private streaming data. Each agent (e.g., a mobile sensor) can deploy an online learning algorithm, e.g. stochastic gradient descent, to learn adaptively the regression model using its receiving private data. The goal is to devise an algorithm for each agent, under the constraint that each of them can communicate only with its neighboring agents based on a communication graph, to enable each agent converge to the true model with a performance comparable to that of the traditional centralized solution. We propose an algorithm called \emph{gossip gradient descent}, and establish $O\bigl ( \sqrt{\frac{\log t}{(1-\lambda_2)N t}}\bigr)$ convergence in expectation and mean square, where $\lambda_2$ is the second largest eigenvalue of the expected gossip matrix corresponding to the underlying communication graph, and $t$ is the time step of the algorithms. For the case when agents are privacy sensitive, we propose a differentially private variant of the algorithm, which achieves $\epsilon$-differential privacy and $O\bigl (\sqrt{\frac{\log^2 t }{\epsilon \cdot (1-\lambda_2)N t}}\bigr)$ convergence speed.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-226" tabindex="-1" role="dialog"
         aria-labelledby="modal-226-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-226-label">[Abstract] Learning Temporal Strategic Relationships using Generative Adversarial Imitation Learning</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">This paper presents a novel framework for automatic learning of
complex strategies in human decision making. We observe temporal
relationships at the subtask level of expert demonstrations, and
determine the different strategies employed in order to successfully
complete a task. To capture the relationship between the subtasks
and the overall goal, we utilise two external memory modules, one
for capturing dependencies within a single expert demonstration,
such as the sequential relationship among different sub tasks, and
a global memory module for modelling task level characteristics
such as best practice employed by different humans based on their
domain expertise. Furthermore, we demonstrate how the hidden
state representation of the memory can be used as a reward signal
to smooth the state transitions, eradicating subtle changes. We
evaluate the effectiveness of the proposed model for an autonomous
highway driving application, where we demonstrate its capability
to learn different expert policies and outperform state-of-the-art
methods.&nbsp;</span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-422" tabindex="-1" role="dialog"
         aria-labelledby="modal-422-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-422-label">[Abstract] Formalising Oughts and Practical Knowledge without Resorting to Action Types</h4>
                </div>
                <div class="modal-body">
                    <p>We show how the logical modelling of puzzles concerning epistemic oughts, such as the ones put forward by Horty &amp; Pacuit and the Miner's Scenario by Parfit, are solved without introducing action types in the logical language. The problem of epistemic oughts is a fundamental one. Without exaggeration, we can say that the nature of the relation between agency, action, knowledge, and normativity is central to the understanding of responsibility, a main topic in Artificial Intelligence nowadays. In the setting we propose here, bringing together these four components of responsibility requires that we blend (1) a theory of action and agency, (2) a theory of knowledge / epistemic indistinguishability in action, and (3) deontic orderings along which we distinguish right from wrong. We will accomplish this by using <i>stit</i> theory and by lifting a deontic ordering over histories to the level of actions that an agent can knowingly perform. We compare the resulting definition for subjective (epistemic) oughts with Horty's definition of objective oughts. We will demonstrate our findings by modelling the Miner's Scenario and other examples.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-40" tabindex="-1" role="dialog"
         aria-labelledby="modal-40-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-40-label">[Abstract] Extending the Efficiency Improvement Advisor Concept to Deal with Certain Knowledge</h4>
                </div>
                <div class="modal-body">
                    <p>The efficiency improvement advisor can improve the quality of the emergent solutions created by self-organizing emergent multi-agent systems by identifying recurring tasks that the agents in the self-organizing system do not solve well. This knowledge is used to create exception rules for the appropriate agents that improve their task-fulfilling behaviour. In this paper, we present an extension to the advisor that allows it to use certain knowledge about future tasks in addition to the (somewhat uncertain) knowledge gained from the system history. By now creating groups of exception rules for each expected task, the self-organizing emergent system can achieve near optimal solutions for static problem instances and good solutions for a range of expected tasks, while still being able to deal with dynamic (and unpredicted) tasks, as shown by experiments in a pickup-and-delivery scenario.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-769" tabindex="-1" role="dialog"
         aria-labelledby="modal-769-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-769-label">[Abstract] StarCraft as a Testbed for Engineering Complex Distributed Systems Using Cognitive Agent Technology</h4>
                </div>
                <div class="modal-body">
                    <p>Multi-agent systems and cognitive agent technologies have been advocated as the next generation model for engineering complex, distributed systems, but there is no testbed available to demonstrate the added value of such systems. It has been argued that the evaluation of cognitive agent systems requires richer benchmark problems. We think that real-time strategy (RTS) games like StarCraft can offer such a testbed, as AI for RTS requires the design of complicated strategies for coordinating hundreds of units that need to solve a range of challenges (incl. long-term high-level planning but also short-term control of individual units). It also allows us to evaluate whether current agent technologies (infrastructures, tools, languages) are sufficient to live up to this challenge. RTS games moreover offer an opportunity to show the potential of cognitive agent technologies for addressing the challenges such environments provide, as multi-agent systems offer a combination of advanced reasoning and decision making capabilities with built-in communication mechanisms for coordination.</p><p>In this paper, we report on the design and development of the first multi-agent connector that provides full access to StarCraft (Brood War). We provide a new interface that is dedicated to a multi-agent approach by connecting each unit in the game to a cognitive agent. Our aim with such an interface is to provide a tool to the agent community for demonstrating the added value of cognitive technologies.</p><p>Two main challenges are addressed in this work. First, we decide on the right level of abstraction for unit control by means of agents, designing for instance the percepts that are available to units. Second, a sufficient level of performance needs to be ensured in order to allow a large variety of multi-agent implementations to be successful at tackling challenges of RTS AI. The resulting open-source connector readily supports the hundreds of agents that can come and go during the game. Based on the development of the connector and its initial use by 200 students, we already gained valuable insights such as the benefits of using publish-subscribe based messaging and the challenges of debugging large sets of agents.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-364" tabindex="-1" role="dialog"
         aria-labelledby="modal-364-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-364-label">[Abstract] Towards a &quot;Master Algorithm&quot; for Forming Faster Conventions On Various Networks</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p class="MsoNormal"><span style="font-size:10.5pt;font-family:&quot;Helvetica Neue&quot;;
mso-fareast-font-family:&quot;Times New Roman&quot;;mso-bidi-font-family:&quot;Times New Roman&quot;;
color:black;background:white">In this paper, we argue the importance of
developing a “Master Algorithm” that forms a faster social convention among
software agents on any network topology. We hypothesize that one possible
approach for building this “Master Algorithm” is to embed network awareness in
agent’s decision-making process. As a first step towards this algorithm, we
present a novel network aware convention formation (NACF) algorithm that equips
agents with network awareness to create faster conventions. In NACF, agents
have access to a battery of algorithms suitable for different network
topologies. We enrich this battery of convention algorithms by including some
existing state-of-the-art algorithms as well as by designing two new algorithms
for scale-free and planar topologies. NACF enables agents to use only local
information to predict the global network structure and choose the appropriate
convention algorithm to converge into a single convention at a faster rate. An
extensive simulation is done on different network topologies, both static and
dynamic, with varying network configurations. The results show that NACF
successfully forms convention on various network scenarios. We also identify
the limitations of NACF and provide insights for improvement.&nbsp;</span><span style="font-size:10.0pt;font-family:Times;mso-fareast-font-family:&quot;Times New Roman&quot;;
mso-bidi-font-family:&quot;Times New Roman&quot;"><o:p></o:p></span></p><p>






<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Revision>0</o:Revision>
  <o:TotalTime>0</o:TotalTime>
  <o:Pages>1</o:Pages>
  <o:Words>187</o:Words>
  <o:Characters>1071</o:Characters>
  <o:Company>University of Nebraska-Lincoln</o:Company>
  <o:Lines>8</o:Lines>
  <o:Paragraphs>2</o:Paragraphs>
  <o:CharactersWithSpaces>1256</o:CharactersWithSpaces>
  <o:Version>14.0</o:Version>
 </o:DocumentProperties>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>JA</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
   <w:UseFELayout/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="true"
  DefSemiHidden="true" DefQFormat="false" DefPriority="99"
  LatentStyleCount="276">
  <w:LsdException Locked="false" Priority="0" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 9"/>
  <w:LsdException Locked="false" Priority="35" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" Priority="10" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" Priority="11" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" Priority="22" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" Priority="59" SemiHidden="false"
   UnhideWhenUsed="false" Name="Table Grid"/>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" QFormat="true" Name="TOC Heading"/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:Times;
	panose-1:2 0 5 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"ＭＳ 明朝";
	mso-font-charset:78;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1791491579 18 0 131231 0;}
@font-face
	{font-family:"ＭＳ 明朝";
	mso-font-charset:78;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1791491579 18 0 131231 0;}
@font-face
	{font-family:Cambria;
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073743103 0 0 415 0;}
@font-face
	{font-family:"Helvetica Neue";
	panose-1:2 0 5 3 0 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-452984065 1342208475 16 0 1 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:Cambria;
	mso-ascii-font-family:Cambria;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:"ＭＳ 明朝";
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:Cambria;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-family:Cambria;
	mso-ascii-font-family:Cambria;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:"ＭＳ 明朝";
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:Cambria;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.25in 1.0in 1.25in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:Cambria;
	mso-ascii-font-family:Cambria;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Cambria;
	mso-hansi-theme-font:minor-latin;}
</style>
<![endif]-->



<!--StartFragment-->





<!--EndFragment--></p><p class="MsoNormal"><o:p>&nbsp;</o:p></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-258" tabindex="-1" role="dialog"
         aria-labelledby="modal-258-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-258-label">[Abstract] Design of Coalition Resistant Credit Score Functions for  Online Discussion Forums</h4>
                </div>
                <div class="modal-body">
                    <p>Motivated by the need to design robust, trustworthy online discussion forums (ODFs), we design a manipulation resistant credit scoring function to assign scores to agents interacting on a typical ODF.<br>The setting we consider is that of an ODF where the agent utilities are determined by credit scores obtained by the agents in the form of popularity indicators such as upvotes, ratings, shares, and likes. Agents can potentially manipulate the credit scores by strategically awarding the popularity indicators to other agents in order to maximize their own credit score. We focus on a specific but very common form of manipulation, namely, coalition formation. We propose a credit function that discourages formation of coalition(s) by the<br>agents. Our idea is to design such a credit function with the use of community detection algorithms that find an agent set partition by maximizing a community detection metric. Our contribution is to find a characterization for coalition identifying community detection metrics and to show that one can design coalition resistant credit<br>functions with such a metric. In particular, we investigate the modularity metric and show that it is coalition identifying, and show that the proposed credit function with modularity metric is coalition resistant. We validate our theoretical findings with simulations on illustrative datasets.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-527" tabindex="-1" role="dialog"
         aria-labelledby="modal-527-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-527-label">[Abstract] Learning Policy Representations in Multiagent Systems</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">Modeling agent behavior is central to understanding the emergence of complex phenomena in multiagent systems. Prior work in
agent modeling has largely been task-specific and driven by hand-engineering domain-specific prior knowledge. In this work, we
propose a general learning framework for modeling agent behavior
in any multiagent system using only a few episodes of interaction data. Our framework casts agent modeling as a representation
learning problem. Consequently, we design a novel objective based
on imitation learning and agent identification for unsupervised
learning of representations of agent policies. We introduce criteria
for evaluating the generalization performance of the learned representations and design methods for using these representations in a
wide range of downstream tasks. We demonstrate empirically the
utility of the proposed representation learning algorithm on (i) a
challenging high-dimensional competitive environment for continuous control and (ii) a cooperative environment for communication
on supervised predictive tasks, unsupervised clustering, and policy
optimization using deep reinforcement learning.&nbsp;</span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-616" tabindex="-1" role="dialog"
         aria-labelledby="modal-616-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-616-label">[Abstract] Timing Reliability for Local Schedulers in Multi-Agent Systems</h4>
                </div>
                <div class="modal-body">
                    <p>In the last decades, the use of Multi-Agent Systems (MAS) resulted in being the most relevant approach to foster the development of systems performing distributed reasoning, automated/autonomous actions, and regulating component interactions in unpredictable and uncertain scenarios. The scientific community provided numerous innovative contributions about resource and task allocation seeking for optimal/sub-optimal solutions. The adoption of MAS in Cyber-Physical Systems (CPS) is producing outstanding results.</p><p>However, in current MAS, the actual task execution is still delegated to traditional general-purpose scheduling algorithms running within the agent (local scheduler of behaviors). The main consequence is the incapability to enforce compliance with strict timing constraints (i.e., the impossibility of providing any guarantee about the system's behavior in the worst-case scenario).&nbsp;</p><p>Therefore, the adoption of MAS is hampered, excluding significant application scenarios such as safety-critical environments. </p><p>This paper proposes the schedulability analysis of various tasks-sets, that are feasible using real-time schedulers, on top of traditional general-purpose solutions.&nbsp;</p><p>In particular, the study of deadline-missing rate occurring in general-purpose setups, evaluated on an agent-based simulator developed on OMNET++, is presented.</p><p>The obtained results strengthen the motivations for adopting and adapting real-time scheduling mechanisms as the local scheduler within agents.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-666" tabindex="-1" role="dialog"
         aria-labelledby="modal-666-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-666-label">[Abstract] Tractable Reasoning about Agent Programming in Dynamic Preference Logic</h4>
                </div>
                <div class="modal-body">
                    <p>An interpretation of mental attitudes of a BDI programming language is given as a mapping of program states to a BDI logic. This mapping help us to understand how<br>the semantics of the constructs of the language relate to the<br>concepts of the BDI paradigm. While several BDI logic have been proposed for this effect, it is not clear how models in some of these logics can be connected to the agent programs they are supposed to specify. More yet, being based on modal logic, the reasoning problems in theses logics are not tractable in general, limiting their usage to tackle real-world problems. In this work, we use of Dynamic Preference Logic to provide a semantic foundation to BDI agent programming languages and investigate tractable expressive fragments of this logic to reason about agent programs. With that, we aim to provide a way of implementing semantically grounded agent programming languages with tractable reasoning cycles.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-745" tabindex="-1" role="dialog"
         aria-labelledby="modal-745-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-745-label">[Abstract] Privacy-preserving social choice methods for multiagent systems</h4>
                </div>
                <div class="modal-body">
                    <p>Social choice provides methods for collective decisions. They include methods for voting and for aggregating rankings. These methods are used in multiagent systems for similar purposes when decisions are to be made by agents. Votes and rankings are sensitive information. Because of that, privacy mechanisms are needed to avoid the disclosure of sensitive information. <br><br>Cryptographic techniques can be applied in centralized environments to avoid the disclosure of sensitive information. A trusted third party can then compute the outcome. In distributed environments we can use a secure multiparty computation approach for implementing a collective decision method. Other privacy models exist as e.g. differential privacy and k-anonymity. They provide models that are complementary to multiparty computation approaches, and solutions that can be combined with the crytographic ones thus providing additional privacy guarantees. <br><br>In this paper we propose the use of probabilistic social choice methods to achieve differential privacy. We use the method called random dictatorship and prove that under some circumstances differential privacy is satisfied and propose a variation that is compliant with this privacy model. <br><br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-272" tabindex="-1" role="dialog"
         aria-labelledby="modal-272-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-272-label">[Abstract] Online Coalition Structure Generation in Graph Games</h4>
                </div>
                <div class="modal-body">
                    <p>We consider the online version of the coalition structure generation in graph games problem, where agents are vertices in a graph. After each step $t$, in which the $t$-th agent appears in an online fashion, agents are partitioned into $c(t)$ coalitions $\clust(t)=\{\C_1^t, \C_2^t, \ldots, \C_{c(t)}^t \}$, such that every agent belongs to exactly one coalition $C_i^t$. When an agent appears, it may either join an existing coalition or form a new one having it as the only agent. The profit of a such a coalition structure $\clust(t)$ is the sum of the profits of its coalitions. We consider two cases for the profit of a coalition: (1) the sum of the weights of its edges (which represents the total profit of the agents in the coalition), and (2) the sum of the weights of its edges divided by its size (which represents the average profit of the agents in the coalition). Such coalition structures appear in a variety of application in AI, multi-agent systems, networks, as well as in social networks, data analysis, computational biology, game theory, and scheduling.</p><p>For each of the profit functions we consider the bounded and unbounded cases depending on whether or not the size of a coalition can exceed a given value $\alpha$. Furthermore, we consider the case of limited number of coalitions and various weight functions for the edges, namely the cases of unrestricted, positive and constant weights. We show tight or nearly tight bounds for the competitive ratio in each case.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-306" tabindex="-1" role="dialog"
         aria-labelledby="modal-306-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-306-label">[Abstract] Multi-Agent Norm Learning from Observations</h4>
                </div>
                <div class="modal-body">
                    <p>We study the problem of automatically identifying and learning a set of norms from observations in a multi-agent environment. We currently lack effective methods that (a) allow for an explicit context-sensitive norm representation, and (b) avoid making onerous assumptions about the individuals being observed. In this paper, we propose a Dempster-Shafer-based learning approach to address these challenges and evaluate the approach using multi-agent simulations.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-41" tabindex="-1" role="dialog"
         aria-labelledby="modal-41-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-41-label">[Abstract] Motor Fault Detection Based on Multi-Agent Classifier System</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal" style="text-align:justify;line-height:normal"><span style="font-size:12.0pt;font-family:&quot;Times New Roman&quot;,&quot;serif&quot;;mso-ascii-theme-font:
major-bidi;mso-hansi-theme-font:major-bidi;mso-bidi-theme-font:major-bidi">An
early detection of component faults is crucial for motors. In this paper, we
present a novel framework to detect and identify fault conditions of
three-phase induction motors using an ensemble of classifiers. The Q-Learning
Multi-Agent Classifier System (QMACS) is a multi-agent system, which uses the
trust-negotiation-communication (TNC) reasoning scheme. Hybrid models of the
Q-learning and online neural networks (NNs) are used as learning agents of the
multi-agent system. The effectiveness of QMACS for detecting and identifying
motor faults is evaluated through experiments. Time-domain statistical features
are extracted and fed into QMACS for classification. Experiment results
demonstrate that QMACS is able to achieve a superior performance with a
decision fusion of its constituents.<o:p></o:p></span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-709" tabindex="-1" role="dialog"
         aria-labelledby="modal-709-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-709-label">[Abstract] Recognizing Plans by Learning Embeddings from Observed Action Distributions</h4>
                </div>
                <div class="modal-body">
                    <p>

</p><p style="margin:0in;font-family:Calibri;font-size:11.0pt">Recent advances in
visual activity recognition have raised the possibility of applications such as
video surveillance. Effective approaches for such problems however require the
ability to recognize the plans of the agents from video information. Although
traditional plan recognition algorithms depend on access to sophisticated
domain models, one recent promising direction involves learning shallow models
directly from the observed activity sequences, and using them to
recognize/predict plans. One limitation of such approaches is that they expect
observed action sequences as training data. In many cases involving vision or
sensing from raw data, there is considerably uncertainty about the specific
action at any given time point. The most we can expect in such cases is
probabilistic information about the action at that point. The training data
will then be sequences of such observed action distributions. In this paper, we
focus on doing effective plan recognition with such uncertain observations. Our
contribution is a novel extension of word vector embedding techniques to
directly handle such observation distributions as input. This involves
computing embeddings by minimizing the distance between distributions (measured
as KL-divergence). We will show that our approach has superior performance when
the perception error rate (PER) is higher, and competitive performance when the
PER is lower. We will also explore the possibility of using importance sampling
techniques to handle observed action distributions with traditional word vector
embeddings. We will show that although such approaches can give good
recognition accuracy, they take significantly longer training time and their
performance will degrade significantly at higher perception error rate.</p><p>

<b></b><i></i><u></u><sub></sub><sup></sup><strike></strike><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-729" tabindex="-1" role="dialog"
         aria-labelledby="modal-729-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-729-label">[Abstract] Collaborative Planning for Mixed-Autonomy Lane Changing</h4>
                </div>
                <div class="modal-body">
                    <p><span id="docs-internal-guid-f275bb16-a99d-6cc2-6a7e-e93911adf0ff"><span style="font-size: 10.5pt; font-family: Arial; vertical-align: baseline; white-space: pre-wrap;">Driving in traffic can be viewed as a challenging multi-agent non-zero-sum game. In this paper we consider mixed-autonomy traffic where autonomous and human-driven vehicles drive together. For this, we propose a planning framework to navigate the Autonomous Vehicle (AV) where its degree of cooperation with the other agents can be controlled. This degree determines the effect of the other agent’s goals on its actions. We test this approach in a finite length two-lane highway where the AV and human car attempt to merge into each other’s lanes. Our algorithm, with six cooperation factors, was evaluated in a user-study involving 21 participants in a simulation environment. The study showed that our approach was successful in the lane-changing task for most of the factors. We also found that the overall system performed better when the cooperation factor was used that fairly considered the goals of both the AV's and the human car.</span></span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-499" tabindex="-1" role="dialog"
         aria-labelledby="modal-499-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-499-label">[Abstract] An Other Regarding Preference Model for Group Recommendation: an Empirical Evaluation</h4>
                </div>
                <div class="modal-body">
                    <p>		 	 	 		</p><div class="page" title="Page 1">			<div class="layoutArea">				<div class="column">					<p>		 	 	 		</p><div class="page" title="Page 1">			<div class="layoutArea">				<div class="column">					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">Group Recommendation Systems (GRSs) provide support to a group decision-making process by trying to suggest items that can be of interest to each group member. General approaches for GRSs start from the individual recommendations and merge them in a way to determine the best choice for the whole group. The results presented in the literature showed that traditionally aggregation techniques do not seem to capture all the features of real-world scenarios. Furthermore, recent studies in Behavioral Economics evidence the necessity to define utility models that are not compatible with the self-interested utility maximizing behavior of the traditional economic paradigm. In this work, starting from an Other-Regarding Preference model, we extend it in order to deal with the strength of the relationship and the presence of interpersonal conflicts. Furthermore, in order to define the magnitude of the two aspects on the proposed model, we conducted an experiment on the Amazon Mechanical Turk platform, using the results to derive the values of the model’s parameters. The conducted study evidenced that the agent’s utility, when in the presence of another agent, is strictly correlated with its utility, when it is considered alone, and also to the utility of the other agent. The model showed different behaviors in relation to the strength and the status of the relationship. This suggests that we can use different parameters for the model in relation to such factors characterizing the relationship.&nbsp;</span></p>				</div>			</div>		</div>				</div>			</div>		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-100" tabindex="-1" role="dialog"
         aria-labelledby="modal-100-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-100-label">[Abstract] Socially Friendly and Group Protecting Coalition Logics</h4>
                </div>
                <div class="modal-body">
                    <p>We consider extensions of Coalition Logic (CL) which can express statements about inter-related powers of coalitions to achieve their respective goals. In particular, we introduce and study two new extensions of CL. One of them is the ``Socially Friendly Coalition Logic'' SFCL, which is also a multi-agent extension of the recently introduced ``Instantial Neighborhood Logic'' INL. The logic SFCL can express the claim that a coalition has a collective strategy to guarantee achieving its explicitly stated goal while acting in a `socially friendly way', by enabling the remaining agents to achieve other (again, explicitly stated) goals of their choice. The other new extension is the ``Group Protecting Coalition Logic'' GPCL which enables reasoning about entire coalitional goal assignments, in which every group of agents has its own specified goal. &nbsp;GPCL can express &nbsp;claims to the effect that there is an action profile of the grand coalition such that, by playing it, every sub-coalition of agents can guarantee satisfaction of its own private goal (and thus, protect its own interests) while acting towards achievement of the common goal of the grand coalition. For each of these logics, we discuss its expressiveness, introduce the respective notion of bisimulation and prove bisimulation invariance and Hennessy-Milner property. We then also present sound and complete axiomatic systems and prove decidability for both logics.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-323" tabindex="-1" role="dialog"
         aria-labelledby="modal-323-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-323-label">[Abstract] A Unified Framework for Opinion Dynamics</h4>
                </div>
                <div class="modal-body">
                    <p><span class="im"><p><span class="im">Opinion dynamics is the study of how large groups 
interact with one another and reach consensus, with applications to 
various areas such as computer networks, politics, and sociology. It is 
typically explored using agent-based modeling, with a wide variety of 
available models.</span></p><p><span class="im"><br></span><span class="im">Numerous opinion dynamics models have been 
proposed, but it has been pointed out that there is a lack of a shared 
framework. We extend earlier attempts and provide a unified framework. 
The advantages of such a framework include the reduction of duplication 
and the identification of unexplored parameter space.</span></p><p><span class="im"><br></span>Our framework is implemented in a modular simulator which is then used to verify the validity of the framework. We show that the modular approach we propose is able to perfectly replicate results from purpose-built, stand-alone simulators for two widely used models, namely Relative Agreement and CODA.</p></span></p><p><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-345" tabindex="-1" role="dialog"
         aria-labelledby="modal-345-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-345-label">[Abstract] Incorporating Chorus Line Effect into A Cucker-Smale System for Fast Manoeuvre Tracking</h4>
                </div>
                <div class="modal-body">
                    <p>It has been observed empirically that a flock of birds is able to turn and change direction rapidly as a single unit.</p><p>The "chorus-line hypothesis'' was proposed in 1984 by Potts to explain this phenomenon.</p><p>It puts forward the idea that those birds that are further down the line from the initiator can predict the</p><p>movement from those nearer the initiator, thereby reducing their response time.</p><p>The same effect is observed in a human chorus-line.&nbsp;&nbsp;</p><p>This paper proposes an implementation of the chorus-line effect in a Cucker-Smale multiple agent system.</p><p>We study the time it takes for the rest of the agents to follow an abrupt change in direction executed by one of the flock members.</p><p>Through mathematical analysis and computer simulation, we found that the time required for this</p><p>kind of maneouvre tracking is indeed reduced compared with the standard Cucker-Smale model.&nbsp;</p><p>Moreover, it is more effective than using a finite-time controlled Cucker-Smale system that has been studied earlier.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-378" tabindex="-1" role="dialog"
         aria-labelledby="modal-378-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-378-label">[Abstract] C-C-C control strategy for systematic teamwork in multi-robot systems</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal" style="text-align:justify"><span style="font-size:12.0pt;
mso-bidi-font-size:11.0pt;line-height:115%">There is a considerable demand for
the use of multi-robot systems, due to characteristics such as flexibility,
robustness, scalability, parallelism, these systems are projected as novel
tools to help humans in hazardous activities such as humanitarian demining,
search and rescue, handling of dangerous materials, and others. However,
controlling the motion and behavior of large teams of robots is not a trivial
task. This paper presents a distributed control strategy based in
Consent-Coordination-Cooperation (CCC) to let robots describe teamwork
collective behaviours that could be useful in different applications. In the
current state of art there is no clear distinction between the role played by
coordination and cooperation, or the importance of conformity in the system,
but all these elements are essential to achieve collective teamwork. The
propose considers the so called consent variables whose values are defined for
the group of robots in a consensus way, then, those values are used for a
coordination mechanism to achieve commons means and efforts, and finally, the
cooperation is realized using local interactions and sharing information, in
consequence, the robots work together for the same purpose, by this way, the
team of robots work in a sistematic way&nbsp;
to solve a task. To validate the proposal, the <i>Robotarium</i> platform has
been used, showing the teamwork achieved in an orderly manner, by a group of
robots.<o:p></o:p></span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-222" tabindex="-1" role="dialog"
         aria-labelledby="modal-222-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-222-label">[Abstract] Pricing lottery outcomes via conditional posted prices -- evidences from ride-sharing and beyond</h4>
                </div>
                <div class="modal-body">
                    <p>How to price a lottery, i.e., a randomized outcome, has been one of the central research agendas in economics and decision theory. Recently, the problem has become even more important due to the emergence of sharing economies. For example, in a typical ride-sharing context, a passenger may end up with riding a car alone or sharing the car with another passenger, with a posted price paid upfront to the trip. Such an ex ante posted price is simple in design and thus prevalently adopted by most ride-sharing applications. In this paper, we explore the possibility of pricing a lottery using the so-called conditional posted pricing, a pricing scheme that prices separately each possible realization of the lottery. Independent of the ride-sharing context, we first show in theory that the conditional posted pricing strictly dominates the ex ante posted pricing in the sense that it increases the expected utility of the agents without decreasing their expected payments, under certain reasonable conditions. We then validate our theory both in a questionnaire survey and in an online field experiment based on a major ride-sharing platforms. Both the survey and the online field experiment confirm our proposed theory. In addition, we show how to find the conditional posted price in order to achieve the maximum expected utility of each agent, under some further conditions.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-193" tabindex="-1" role="dialog"
         aria-labelledby="modal-193-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-193-label">[Abstract] Pushing the Frontier in Exploratory Learning for Extending the Range of Delivery Drones</h4>
                </div>
                <div class="modal-body">
                    <p>Delivery drones have a fairly short range due to their lim- ited battery life. We propose to use learning techniques to ex- tend the range of drones by taking advantage of buildings and structures in urban environments. This paper describes new exploration strategies to generate paths for a drone to reach its destination while learning about the energy consumption on each edge on its path in order to optimize its range for future missions. We evaluated the performance of our exploration strategies in finding the set of all reachable destinations in a city, and found that exploring locations near the boundary of the reachable sets according to the current energy model can speed up the learning process.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-209" tabindex="-1" role="dialog"
         aria-labelledby="modal-209-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-209-label">[Abstract] Smoother bidding strategy for dynamic reservation values</h4>
                </div>
                <div class="modal-body">
                    <p><span style="color: rgb(51, 51, 51); font-family: monospace; font-size: 14.16px; text-size-adjust: auto; background-color: rgb(253, 252, 250);">Negotiation is an important component of interaction process among humans. With increasing automation, autonomous agents are expected to take over a lot of this interaction process. Much of automated negotiation literature focuses on agents having static and known reservation values. In many situations involving dynamic environments e.g., an agent negotiating on behalf of human regarding a meeting or a pair of automated vehicles in traffic negotiating for a section of road can have reservation values that vary with time. This throws up a different set of challenges that may need additional reasoning about the concession behavior. In this paper, we build upon the ONAC (Optimal Non-Adaptive Concession) strategy which uses amount of time to deadline as a primary criteria to influence the concession behavior of a negotiating agent. The ONAC strategy works on settings where the reservation value of the agent is fixed and known. Although the ONAC strategy can encode dynamic reservation values as we demonstrate in this paper, it may not make for a smoothly conceding agent. We therefore propose the ONAC-S (Optimal Non-Adaptive Concession with Smoothing) strategy that attenuates the fluctuations in bidding i.e. smoothens the bidding strategy so negotiators (esp. human negotiators) can feel that they are part of a rational negotiation. In particular, we propose to use one of Counter, Exponential or Bayesian Learning with Regression Analysis on top of ONAC to develop the ONAC-S strategy. We then use a poly-fit function to identify the best fit curve and compute the RSS as a measure of smoothness. Using this procedure, our experiments could show that ONAC-S indeed provides a much smoother negotiation compared to ONAC.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-271" tabindex="-1" role="dialog"
         aria-labelledby="modal-271-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-271-label">[Abstract] An Observation Dimension-Weighted U-Tree Algorithm</h4>
                </div>
                <div class="modal-body">
                    <p><span lang="EN-US" style='margin: 0px; font-family: "Calibri",sans-serif; font-size: 10.5pt;'>Instance-based
methods are a class of effective algorithms for solving reinforcement learning
problems. U-Tree algorithm presents the state space from instance chains
effectively, which is very beneficial to solve the reasonable Q-value of
actions. However, the complexity of the construction of suffix tree in U-Tree
algorithm is exponential. A new observation dimension-weighted algorithm
ODWU-Tree for optimizing the expansion of fringe of suffix tree is presented in
the paper. ODWU-Tree algorithm obtains the heuristic information of
environments by simple heuristic exploration, evaluates the weight coefficient
of observation dimensions, and expands the fringes by the most important
observation dimensions for reasonable leaf state. Experiment results of New
York Driving show that both the efficiency and the effect have been improved significantly
by ODWU-Tree algorithm compared to U-Tree algorithm.</span><b></b><i></i><u></u><sub></sub><sup></sup><strike></strike><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-68" tabindex="-1" role="dialog"
         aria-labelledby="modal-68-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-68-label">[Abstract] A Kinetic Model of the Dynamics of Compromise in Large Multi-Agent Systems</h4>
                </div>
                <div class="modal-body">
                    <div>Compromise is one of the primary phenomena that govern the dynamics of the opinion in multi-agent systems. In this paper, compromise is isolated from other phenomena, and it is studied using a statistical framework designed to investigate collective properties of large multi-agent systems. The proposed framework is completed with the details needed to model compromise, and differential problems that describe the dynamics of the opinion under suitable hypotheses are presented. Long-time asymptotic solutions of obtained differential problems are discussed to confirm that compromise makes multi-agent systems tend to reach consensus. It is proved that compromise make all agents tend to share the same opinion, and that the value of the asymptotic opinion can be expressed in terms of the initial distribution of the opinion and of other characteristics of the multi-agent system. Obtained analytic results are confirmed by independent simulations in exemplificative cases.</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-494" tabindex="-1" role="dialog"
         aria-labelledby="modal-494-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-494-label">[Abstract] Design of Influencing Agents to Aid Flock Formation in Low-Density Settings</h4>
                </div>
                <div class="modal-body">
                    <p>Flocking is a coordinated collective behavior that results from local sensing between individual agents who have a tendency to orient towards each other. Flocking is common amongst animal groups and could also be useful in robotic swarms. In the interest of learning how to control flocking behavior, several pieces of recent work in the multiagent systems literature have explored the use of influencing agents for guiding flocking agents to face a target direction. However, the existing work in this domain has focused on simulation settings of small areas with toroidal shapes. In such settings, agent density is high, so interactions are common, and flock formation occurs easily. In our work, we study new environments with lower agent density, wherein interactions are more rare. We study the efficacy of placement strategies and influencing agent behaviors drawn from the literature, and find that the behaviors that have been shown to work well in high-density conditions tend to be much less effective in the environments we introduce. The source of this ineffectiveness is a tendency of influencing agents explored in prior work to face directions intended for maximal influence that actually separate the influencing agents from the flock. We find that in low-density conditions maintaining a connection to the flock is more important than rushing to orient towards the desired direction. We use these insights to propose new placement strategies and influencing agent behaviors that overcome the difficulties posed by our new environments. The best influencing agents we identify act like normal members of the flock to achieve positions that allow for control, and then exert their influence. We dub this strategy "follow-then-influence."</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-725" tabindex="-1" role="dialog"
         aria-labelledby="modal-725-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-725-label">[Abstract] Population-based incremental learning for optimal coalition generation on smart grids</h4>
                </div>
                <div class="modal-body">
                    <p><span style="color: rgb(33, 33, 33); font-size: 10pt;">Coalition structure
generation&nbsp;has long been a&nbsp;challenging problem in multi-agent systems
and cooperative game theory because of its&nbsp;NP-hardness in computational
complexity. In this paper, we propose a stochastic optimization approach using
a modified&nbsp;Population Based Incremental Learning (PBIL) algorithm with
top-k merit weighting to find&nbsp;the&nbsp;optimal coalition structure for
smart grids. Empirical results show that the proposed algorithm gives
competitive performance compared with state-of-the-art&nbsp;solutions such
as&nbsp;genetic algorithm and&nbsp;dynamic programming.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-365" tabindex="-1" role="dialog"
         aria-labelledby="modal-365-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-365-label">[Abstract] A Learning and Masking Approach to Secure Learning</h4>
                </div>
                <div class="modal-body">
                    <p>Deep Neural Networks (DNNs) have been shown to be vulnerable against adversarial examples, which are data points cleverly constructed to fool the classifier. Such attacks can be devastating in practice, especially as DNNs are being applied to ever increasing critical tasks like image recognition in autonomous driving. In this paper, we introduce a new perspective on the problem. We do so by first defining robustness of a classifier to adversarial exploitation. Next, we show that the problem of adversarial example generation can be posed as learning problem. We also categorize attacks in literature into high and low perturbation attacks; well-known attacks like FGSM and also out attack produce higher perturbation adversarial examples while the more potent but computationally inefficient Carlini-Wagner (CW) attack is low perturbation. Next, we show that the dual approach of the attack learning problem can be used as a defensive technique that is effective against high perturbation attacks. Last but not the least, we show that a classifier masking method achieved by adding noise to the a neural network's logit output protects against low distortion attacks such as the Carlini-Wagner attack. We also show that both our learning and masking defense can work simultaneously to protect against many attacks. We demonstrate the efficacy of our techniques by experimenting with the MNIST and CIFAR-10 datasets.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-48" tabindex="-1" role="dialog"
         aria-labelledby="modal-48-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-48-label">[Abstract] Privacy Sensitive Environment Re-Decomposition for Junction Tree Agent Organization Construction</h4>
                </div>
                <div class="modal-body">
                    <p>A number of frameworks for decentralized probabilistic reasoning, constraint reasoning,&nbsp;</p><p>and decision theoretic reasoning assume a junction tree (JT) agent organization.</p><p><span style="white-space:pre">	</span>A natural decomposition of agent environment may not admit a JT organization.</p><p><span style="white-space:pre">	</span>Hence, re-decomposition of the environment is necessary.</p><p><span style="white-space:pre">	</span>Unfortunately, re-decomposition incurs loss of agent privacy&nbsp;</p><p>that ultimately translates to loss of intellectual property of agent suppliers.</p><p><span style="white-space:pre">	</span>Few work is known to protect agent privacy during JT organization construction.</p><p><span style="white-space:pre">	</span>We propose a novel algorithm suite DAER that re-decomposes the environment</p><p>to enable a JT organization, while minimizing agent privacy loss by a greedy approach.</p><p><span style="white-space:pre">	</span>Advantage of DAER over alternative methods includes that it does not suffer from&nbsp;</p><p>any privacy loss on private variables.<span style="white-space:pre">	</span></p><p><span style="white-space:pre">	</span>Formal analysis as well as empirical evaluation of DAER are reported.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-501" tabindex="-1" role="dialog"
         aria-labelledby="modal-501-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-501-label">[Abstract] Learning and Updating User Models for Subpopulations in Persuasive Argumentation Using Beta Distributions</h4>
                </div>
                <div class="modal-body">
                    <p>Persuasion is an activity that involves one party (the persuader) trying to induce another party (the persuadee) to believe or do something. It is an important and multifaceted human facility both in professional life (e.g., a doctor persuading a patient to give up smoking) and everyday life (e.g., some friends persuading another to join them in seeing a film). Recently, some proposals in the field of computational models of argument have been made for probabilistic models of what the persuadee knows about, or believes. However, they cannot efficiently model uncertainty on the belief of individuals and cannot represent populations. We propose to use mixtures of beta distributions and apply them on real data gathered by linguists. We show that we can represent the belief and its uncertainty using beta mixtures and that we can predict the evolution of this belief after an argument is given. We also present examples of how to use the mixtures in practice to replace general belief update functions.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-410" tabindex="-1" role="dialog"
         aria-labelledby="modal-410-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-410-label">[Abstract] The Dynamics of Opinion Evolution in Gossiper-Media Model with WoLS-CALA Learning</h4>
                </div>
                <div class="modal-body">
                    <p><span style="font-family: verdana, arial, helvetica; font-size: small;">In social networks, media outlets such as TV, newspapers, blogs adjust their opinions to cater to the public's interest to increase the number of followers. Meanwhile, the evolution of the public's opinions are affected by both the media and the peers they interact with. In this work, we investigate how the interactions between mainstream media affect the dynamics of the public's opinions in social networks. We propose a reinforcement learning framework to model the interactions between the public (aka gossipers) and the media agents. We model each gossiper as an individually rational agent, which updates its opinion using the Bounded Confidence Model (BCM). Each media agent is interested in maximizing the number of following gossipers competitively, and an adaptive WoLS-CALA (Win or Learn Slow Continuous Action Learning Automaton) algorithm is proposed to achieve that goal. We theoretically prove that WoLS-CALA can guarantee convergence towards Nash equilibria for any two-agent games with continuous action space. Besides, the opinion dynamics of both gossipers and media are theoretically analyzed. Extensive empirical simulation reveals the opinion dynamics of our framework facilitates the consensus of opinions and confirms the theoretical analysis.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-630" tabindex="-1" role="dialog"
         aria-labelledby="modal-630-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-630-label">[Abstract] Capacity-aware Sequential Recommendations</h4>
                </div>
                <div class="modal-body">
                    <p>Personalized recommendations are increasingly important to engage users and guide them through large systems, for example when recommending points of interest to tourists visiting a popular city. To maximize long-term user experience it is imperative to consider issuing a sequence of recommendations, given that by observing the user's response to a recommendation, the recommender system can update its estimate of the user's (latent) interests. However, when considering a large number of users and capacity limits (e.g., maximum attendance of a museum), the recommender system should not only consider the users' interests, but also the effect of recommendations on the available capacity.<br><br>The structure in such a constrained, multi-agent, partially observable decision problem can be exploited by a novel belief-space sampling algorithm which bounds the size of the state space by a limit on regret. This algorithm is significantly more scalable than state-of-the-art approximate POMDP planners. Moreover, by explicitly considering the information value of actions, this algorithm significantly improves the quality of recommendations over an extension of Thompson sampling to the multi-agent, constrained case. We show how&nbsp; constraint satisfaction can be decoupled from sequential recommendation policies, resulting in algorithms that compute recommendations for thousands of agents while respecting capacity limits.<br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-544" tabindex="-1" role="dialog"
         aria-labelledby="modal-544-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-544-label">[Abstract] But-for causality revisited</h4>
                </div>
                <div class="modal-body">
                    <p>Using the Halpern-Pearl framework for causal modelling, the paper formalises the generalised but-for test, according to which X is a cause of Y if Y would not have happened <i>in the way it did</i> but for X. The resulting notion of causality is shown to be more permissive about what counts as a contributing cause than existing definitions of causality in the HP framework. The paper then proposes some natural restrictions on counterfactual reasoning within the HP framework, which prevent the generalised but-for test from becoming too permissive when applied to structural equations. A unique causal theory that can be computed effectively is shown to satisfy the restrictions. The paper argues that this theory does better than existing definitions of causality on problematic examples, especially when the theory is used to assign causal responsibility to individuals for effects brought about by a collective.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-124" tabindex="-1" role="dialog"
         aria-labelledby="modal-124-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-124-label">[Abstract] Optimal Constraint Collection for Core-selecting Path Mechanism</h4>
                </div>
                <div class="modal-body">
                    <p abs_visibility="true">
		
	
	
		</p><div title="Page 1" class="page">
			<div class="layoutArea">
				<div class="column">
					<p><span style='font-family: "LinLibertineT"; font-size: 9pt;'>In path auctions, strategic bidders make bids for commodities. Each
edge of the graph stands for a commodity and the weight on the
edge represents the prime cost. Auctioneer needs to purchase a
sequence of edges in order to get a path from one vertex to another at a low cost. Path auctions can be considered as a kind of
combinatorial reverse-auctions. Computing prices in core-selecting
combinatorial auctions is a computationally hard problem, the same
is true in core-selecting path auctions. This problem can be solved
by core constraint generation(CCG) algorithm. However, we  nd
that there are many redundant constraints and the constraint col-
lection can be conciser in core-selecting path mechanism. In this
paper, </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>1</span><span style='font-family: "txsys"; font-size: 9pt;'>) </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>we put forward a new approach to get the constraint collection, and reduce the constraint number from exponential </span><span style='font-family: "LinLibertineI"; font-size: 9pt;'>O </span><span style='font-family: "txsys"; font-size: 9pt;'>(</span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>2</span><span style='font-family: "LinLibertineI7"; font-size: 7pt; vertical-align: 3pt;'>n </span><span style='font-family: "txsys"; font-size: 9pt;'>)
</span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>to polynomial </span><span style='font-family: "LinLibertineI"; font-size: 9pt;'>O</span><span style='font-family: "txsys"; font-size: 9pt;'>(</span><span style='font-family: "LinLibertineI"; font-size: 9pt;'>n</span><span style='font-family: "LinLibertineT"; font-size: 7pt; vertical-align: 3pt;'>2</span><span style='font-family: "txsys"; font-size: 9pt;'>)</span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>, where </span><span style='font-family: "LinLibertineI"; font-size: 9pt;'>n </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>is the network diameter; </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>2</span><span style='font-family: "txsys"; font-size: 9pt;'>) </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>we prove
that the new constraint collection is not only equivalent to the original collection, but also has no redundant constraint in the worst
case; </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>3</span><span style='font-family: "txsys"; font-size: 9pt;'>) </span><span style='font-family: "LinLibertineT"; font-size: 9pt;'>we validate our approach on real-world datasets and obtain
excellent results. Furthermore, we provide new insights to think
over the core-selecting mechanism in combinatorial auctions.&nbsp;</span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-149" tabindex="-1" role="dialog"
         aria-labelledby="modal-149-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-149-label">[Abstract] A Natural Language Text Interface for Increased Situation Awareness of Remote Autonomous Systems</h4>
                </div>
                <div class="modal-body">
                    <p>Autonomous systems are designed to carry out activities without the need for operators to micro-manage them. It is, however, essential that operators maintain situation awareness in order to monitor vehicle status and unforeseen circumstances that may affect their intended behaviour, such as a change in the environment. The Anon-Brand autonomy framework is a vehicle-agnostic platform supporting multi-vehicle missions, primarily for Autonomous Underwater Vehicles (AUVs). We have combined this C2 interface with a novel approach of interacting with the vehicle through a natural language chat interface. ANON-NEW-SYS offers a fluid and natural way for operators to gain information on vehicle status and faults, mission and objectives status and to set reminders. We describe the system and an evaluation study providing evidence that such an interactive multimodal interface can assist in maintaining situation awareness for operators of autonomous systems.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-701" tabindex="-1" role="dialog"
         aria-labelledby="modal-701-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-701-label">[Abstract] Execution Skill Estimation</h4>
                </div>
                <div class="modal-body">
                    <p>In domains with continuous action spaces, one important characteristic of an agent is their precision in executing intended actions. An agent's execution skill has a large impact on their success as it determines how much executed actions deviate from intended actions. We introduce the problem of estimating an agent's execution skill level in domains with continuous action spaces, given only observations of their executed actions. The main difficulty is that while executed actions are observed, the intended actions are not observed, and therefore the amount of action deviation due to imperfect execution skill is not obvious. We explore this problem in a simple experimental domain with continuous actions that contains the essential features that make the problem challenging. We first introduce a naive method for this domain that focuses on estimating the long-term average reward of the agent which can then be used to estimate the agent's execution skill level. We then present a novel method that is able to accurately estimate the execution skill of a perfectly rational agent and show experimentally that it is more accurate than the naive estimator with limited observations. Finally, these results are experimentally validated in an actual domain that features imperfect execution skill, the game of computational billiards.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-277" tabindex="-1" role="dialog"
         aria-labelledby="modal-277-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-277-label">[Abstract] Faster Policy Adaptation in Environments with Exogeneity: A State Augmentation Approach</h4>
                </div>
                <div class="modal-body">
                    <p>The reinforcement learning literature typically assumes fixed state transition functions for the sake of tractability. However, in many real-world tasks, the state transition function changes over time, and this change may be governed by exogenous variables outside of the control loop. This can make policy learning difficult. In this paper, we propose a new algorithm to address the aforementioned challenge by embedding the state transition functions at different timestamps into a Reproducing Kernel Hilbert Space; the exogenous variable, as the cause of the state transition evolution, is estimated by projecting the embeddings into the subspace that preserves maximum variance. By augmenting the observable state vector with the estimated exogenous variable, standard RL algorithms such as Q-learning are able to learn faster and better. Experiments with both synthetic and real data demonstrate the superiority of our proposed algorithm over standard and advanced variants of Q-learning algorithms in dynamic environments.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-684" tabindex="-1" role="dialog"
         aria-labelledby="modal-684-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-684-label">[Abstract] Multiagent Bidirectionally-Coordinated Nets in Playing Startcraft Micro Combat Games</h4>
                </div>
                <div class="modal-body">
                    <p>Many artificial intelligence (AI) applications often require multiple intelligent agents to work in a collaborative effort. Efficient learning for intra-agent communication and coordination is an indispensable step towards general AI. In this paper, we take StarCraft combat game as a case study, where the task is to coordinate multiple agents as a team to defeat their enemies. To maintain a scalable yet effective communication protocol, we introduce a Multiagent Bidirectionally-Coordinated Network (BiCNet) with a vectorised extension of actor-critic formulation.&nbsp; We show that BiCNet can handle different types of combats with arbitrary numbers of AI agents for both sides. Our analysis demonstrates that without any supervisions such as human demonstrations or labelled data, BiCNet could learn various types of advanced coordination strategies that have been commonly used by experienced game players. In our experiments, we evaluate our approach against multiple baselines under different scenarios; it shows state-of-the-art performance, and possesses potential values for large-scale real-world applications.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-166" tabindex="-1" role="dialog"
         aria-labelledby="modal-166-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-166-label">[Abstract] Information Design in Crowdfunding under Thresholding Policies</h4>
                </div>
                <div class="modal-body">
                    <p>In crowdfunding,&nbsp; an entrepreneur often has to decide how to disclose the campaign status in order to collect as many contributions as possible.&nbsp; We propose information design as a tool to help the entrepreneur to improve revenue by influencing backers' beliefs. We introduce a heuristic algorithm to dynamically compute information-disclosure policies for the entrepreneur, followed by an empirical evaluation to demonstrate its competitiveness over the widely-adopted immediate-disclosure policy. Our results demonstrate that despite its ease of implementation, the immediate-disclosure policy is not optimal when backers follow thresholding policies. With appropriate heuristics, an entrepreneur can benefit from dynamic information disclosure. Our work sheds light on information design in a dynamic setting where agents make decisions using thresholding policies.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-90" tabindex="-1" role="dialog"
         aria-labelledby="modal-90-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-90-label">[Abstract] Modeling behaviours to extend contextual goal models for self-adaptive systems</h4>
                </div>
                <div class="modal-body">
                    <span style=" color:#000000;">The adaptation of self-adaptive systems is caused by context changes, leading to changes of the software behaviours. The missing control of context may lead to unforeseen changes of system. Many proposals rely on variants of goal models to support monitoring and adaptation functions. Contextual goal models consider the effect of context on reconfiguring system to reach requirements and quality measures. They serve as mechanisms in terms of how systems decide to make strategy and rationale of adaptive system. We argue that existing proposals do not consider the influence the runtime system behaviours on context. In this paper, we provide a different description of software behaviours for extending goal model that may be applied to self-adaptive systems. Software behaviours are </span><span style=" text-decoration: underline; color:#000000;">modeled</span><span style=" color:#000000;"> and </span><span style=" text-decoration: underline; color:#000000;">analyzed</span><span style=" color:#000000;"> along with changes and uncertainty of self-adaptive systems. We develop an operations semantics corresponding to the extend model and demonstrate on a detailed smart airport manage scenario.</span><span style=" color:#000000;"></span>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-108" tabindex="-1" role="dialog"
         aria-labelledby="modal-108-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-108-label">[Abstract] Controlling Elections through Social Influence</h4>
                </div>
                <div class="modal-body">
                    <p>Election control considers the problem of an adversary who attempts to tamper with a voting process, in order to either ensure that their favored candidate wins (constructive control) or another candidate loses (destructive control). As online social networks have become significant sources of information for potential voters, a new tool in an attacker's arsenal is to effect control by harnessing social influence, for example, by spreading fake news and other forms of misinformation through online social media.</p><p>We consider the computational problem of election control via social influence, studying the conditions under which finding good adversarial strategies is computationally feasible. We consider two objectives for the adversary in both the constructive and destructive control settings: probability and margin of victory (POV and MOV, respectively). We present several strong negative results, showing, for example, that the problem of maximizing POV is inapproximable for any constant factor. On the other hand, we present approximation algorithms which provide somewhat weaker approximation guarantees, such as bicriteria approximations for the POV objective and constant-factor approximations for MOV. Finally, we present mixed integer programming formulations for these problems. Experimental results show that our approximation algorithms often find near-optimal control strategies, indicating that election control through social influence is a salient threat to election integrity.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-572" tabindex="-1" role="dialog"
         aria-labelledby="modal-572-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-572-label">[Abstract] MTDeep: Boosting the Security of Deep Neural Nets Against Adversarial Attacks with Moving Target Defense</h4>
                </div>
                <div class="modal-body">
                    <p>Recent works on gradient based attacks and universal perturbations can adversarial modify images to bring down the accuracy of state-of-the-art classification techniques based on deep neural networks to as low as 10% on popular data-sets like MNIST and ImageNet. The design of general defense strategies against a wide range of such attacks remains a challenging problem. In this paper, we derive inspiration from recent advances in the fields of cybersecurity and multi-agent systems and propose to use the concept of <i>Moving Target Defense (MTD)</i>&nbsp;for increasing the robustness of a set of deep networks against such adversarial attacks. To this end, we formalize and exploit the notion of <i>differential immunity</i> of an ensemble of networks to specific attacks. To classify an input image, a trained network is picked from this set of networks by formulating the interaction between a Defender (who hosts the classification networks) and their (Legitimate and Malicious) Users as a repeated <i>Bayesian Stackelberg Game (BSG)</i>. We empirically show that our approach, MTDeep reduces misclassification on perturbed images for MNIST and ImageNet data-sets while maintaining high classification accuracy on legitimate test images. Lastly, we demonstrate that our framework can be used in conjunction with any existing defense mechanism to provide more resilience to adversarial attacks than those defense mechanisms by themselves.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-304" tabindex="-1" role="dialog"
         aria-labelledby="modal-304-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-304-label">[Abstract] An interactive multi-agent computational semiotic model for sentiment analysis</h4>
                </div>
                <div class="modal-body">
                    <p>For Peircean semiotics, a sign is not a dyadic entity, composed of a word and its meaning. Instead, meaning-making is a process of signification borne of a strictly triadic relationship; in which a representative of a sign (word(s)) stands for its object (or meaning,) but never in a vacuum, and always for an interpretant, with respect to a ground (convention or context.) For Peirce, it is this third, this interpretant through which the sign displays its meaning. What is even more important is that this rational process of signification is never being carried out by a single Mind, it requires a community of reasoners. In semiotic terms this article translates the sentiment analysis problem as follows: A sentence/comment is a representamen which has a sentiment value (its object) for an evolving community of agents (interpretant) with respect to their dynamic memories (ground.) This article presents an interactive multi-agent model for this semiotic based approach towards sentiment analysis, tests it on an original student evaluation of teachers dataset, and aims to establish semiotics as a reparative alternative to the dominant dichotomies - rule-based and data-based camps within computational linguistics.<br style=" font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: -webkit-auto; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; "><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-391" tabindex="-1" role="dialog"
         aria-labelledby="modal-391-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-391-label">[Abstract] Empathy in artificial intelligence leads to intrinsic moral behaviors</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:RelyOnVML/>
  <o:AllowPNG/>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>ZH-CN</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
   <w:UseFELayout/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:宋体;
	mso-font-charset:134;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:3 680460288 22 0 262145 0;}
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1107305727 0 0 415 0;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073786111 1 0 415 0;}
@font-face
	{font-family:等线;
	mso-font-charset:134;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:-1610612033 953122042 22 0 262159 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:等线;
	mso-ascii-font-family:等线;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:宋体;
	mso-hansi-font-family:等线;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-size:10.5pt;
	mso-ansi-font-size:10.5pt;
	mso-bidi-font-size:11.0pt;
	font-family:等线;
	mso-ascii-font-family:等线;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:等线;
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:等线;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-font-kerning:1.0pt;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.5pt;
	mso-bidi-font-size:11.0pt;
	font-family:等线;
	mso-ascii-font-family:等线;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:等线;
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:等线;
	mso-hansi-theme-font:minor-latin;
	mso-font-kerning:1.0pt;}
</style>
<![endif]-->



<!--StartFragment-->



<!--EndFragment--></p><p class="MsoNormal"><span style="font-family:&quot;Calibri&quot;,sans-serif;mso-fareast-language:
ZH-CN">Ethical concerns of artificial intelligence have recently drawn
extensive interest in both academia and industry. Building an intrinsic sense
of morality is one potential way of regulating and promoting desirable
prosocial behaviors and reduce unethical behaviors. Incorporating ideas found
in social neuroscience, we hardwired a theoretical model of empathy in rational
reinforcement learning-based agents. Empathy was modeled to enable affective
state sharing between agents and their behavioral dynamics were tested and
analyzed in multiple game settings. Empathetic agents showed increased
cooperation compared to rational agents in iterated prisoner dilemma. They also
exhibited sympathetic concern in the altruism games, in which agents had to
either sacrifice its own reward in order to rescue its partner’s loss or gain
reward while its partner was punished. Moreover, they showed a sense of
fairness and primitive targeted helping behavior in the ultimatum game that
tests fairness and its multiagent variant. In summary, our model illustrates
that empathy can act as a fundamental affective drive underlying moral and
prosocial behaviors including cooperation, altruism, sympathy and fairness.
This provides novel methods and insights in regulating AI behaviors in
multiagent systems, as well as artificial subjects in psychology and behavioral
economics experiments. <o:p></o:p></span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-346" tabindex="-1" role="dialog"
         aria-labelledby="modal-346-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-346-label">[Abstract] Strategy Generation for Multi-Unit Real-Time Games via Voting</h4>
                </div>
                <div class="modal-body">
                    <p>Real-time strategy (RTS) games are a challenging application for Artificial Intelligence (AI) methods. This is because they involve simultaneous play and adversarial reasoning that is conducted in real time in large state spaces. Many AI methods for playing RTS games rely on hard-coded strategies designed by human experts. The drawback of using such strategies is that they are often unable to adapt to new scenarios during gameplay. The contribution of this paper is a new approach, called &nbsp;Strategy Creation via Voting (SCV), that uses a voting method to generate a large set of novel strategies from existing expert-based ones. Then, SCV uses during the game an opponent modeling scheme to choose which strategy from the generated pool of possibilities to use. By repeatedly choosing which strategy to use, SCV is able to adapt to different scenarios that might arise during the game. The approach is applied to MicroRTS, which is a recognized RTS testbed used to evaluate AI methods. The results of a detailed empirical study show that our approach is able to outperform all approaches tested. Although we applied SCV to an RTS game, the method is in principle applicable to any domain in which one controls a group of units to jointly solve tasks.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-297" tabindex="-1" role="dialog"
         aria-labelledby="modal-297-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-297-label">[Abstract] Comparing Multi-Armed Bandit Algorithms and Q-learning for Multiagent Action Selection: a Case Study in Route Choice</h4>
                </div>
                <div class="modal-body">
                    <p>The multi-armed bandit (MAB) problem is concerned with an agent choosing which arm of a slot machine to play seeking to optimize its reward.</p><p>A family of reinforcement learning algorithms exists to tackle this problem, including a few variants that consider more than one agent (thus, characterizing a repeated game) and non-stationary variants.</p><p>In this paper, we seek to evaluate the performance of some of these MAB algorithms and compare them with Q-learning when applied to a non-stationary repeated game, where commuter agents have the task of learning how to choose a route that minimizes their travel times.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-528" tabindex="-1" role="dialog"
         aria-labelledby="modal-528-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-528-label">[Abstract] Foundations of MASTDEAL : A new MultiAgent application for Islamic finance</h4>
                </div>
                <div class="modal-body">
                    <p class="AbstractText" style="margin-top:0cm;margin-right:284.25pt;margin-bottom:
0cm;margin-left:0cm;margin-bottom:.0001pt"><span lang="EN-US">This paper
describes the foundations of a new Multi-Agent platform in the Islamic Banking
field that can be integrated with any Bank platform. This platform is based on
a collection of agents collaborating to support the decision making of many
actors in the banking field, such as customers, companies and bank agency’s
<gs id="c0aae7de-5211-4e5c-8068-942bde633dce" ginger_software_uiphraseguid="5b1823eb-3aea-4798-9c15-1a2ce443cf4e" class="GINGER_SOFTWARE_mark">responsibles</gs>. The platform is described and the belief and behavior of each
agent are highlighted.<o:p></o:p></span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-326" tabindex="-1" role="dialog"
         aria-labelledby="modal-326-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-326-label">[Abstract] Deep Pseudo-Convolutional Reinforcement Learning for Spatial Decision Making</h4>
                </div>
                <div class="modal-body">
                    <p><span style="font-size: 10.5pt; font-family: &quot;Helvetica Neue&quot;;">In many applications, such as in forest management, road network design, and ecosystem management, decision makers are required to plan actions over large spatial domains and long time periods. These spatial planning problems are often characterized by a large state space, with a large discrete action space, and therefore, directly applying conventional reinforcement learning approaches quickly becomes intractable. We introduce a novel reinforcement learning framework –&nbsp;</span><span style="font-size: 10.5pt; font-family: &quot;Helvetica Neue&quot;;"><span style="font-size: 10.5pt;">Deep&nbsp;<i>Pseudo-Convolutional Reinforcement learning</i></span>&nbsp;-- which generalizes the use of translational invariance from CNNs more broadly to policy networks such as those concerning spatial planning. The key observation underlying our method is that effects of actions in spatial planning problems typically are local, and hence, sharing one deep policy network across spatial dimensions allows for extremely compact network parametrization. We evaluate our framework on an important problem in computational sustainability -- biological control of an invasive&nbsp; species&nbsp;&nbsp;across an ecosystem spanning eastern North America. Our method consistently outperforms competing reinforcement learning methods and a heuristic combinatorial method in terms of learning speed and performance, showing how our framework successfully can be used for large-scale spatial planning problems.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-69" tabindex="-1" role="dialog"
         aria-labelledby="modal-69-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-69-label">[Abstract] Safe transfer learning for risk-sensitive applications.</h4>
                </div>
                <div class="modal-body">
                    <p><font color="#212121" face="sans-serif"><span style="font-size: 13px;">This paper tackles the problem of transfer learning for risk-sensitive applications. The goal is to quickly adapt to a new environment acknowledging the risk dimension of the interactions done with it. Previous works do not use a safe strategy during the cold-start phase of the learning process. We believe that for most real life applications, in the first interactions, it's more important to be risk-aware than being average. For that, we propose to transfer a safe strategy learned among different source environments thanks to epsilon-safe a novel algorithm. The safe strategy is learnt with CFTQ a novel algorithm for Constrained Markov decision processes. Benchmarks show that the safe strategies are more efficient in the very first steps of the learning but also speed up significantly the learning process.</span></font><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-631" tabindex="-1" role="dialog"
         aria-labelledby="modal-631-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-631-label">[Abstract] Reinforcement Learning for Heterogeneous Teams with PAC Bounds</h4>
                </div>
                <div class="modal-body">
                    <div>We explore reinforcement learning for heterogeneous teams in which rewards for an agent are decomposed into local costs, stimuli unique to each agent, and global rewards, those shared by all agents in the domain. Such domains include heterogeneous teams of robots, where each robot may incur different costs for the same action, but share an overall goal. We introduce two templates for learning in this setting with factored rewards: a straightforward extension of Perkins' Monte Carlo exploring starts for POMDPs to canonical MPOMDPs, with a single policy mapping joint observations of all agents to joint actions (MCES-MP); and another with each agent individually mapping joint observations to their own action (MCES-FMP). We use probably approximately correct (PAC) bounds to analyze sample complexity, instantiating these templates to PAC learning. We promote scalability by including a policy search space pruning technique, and evaluate the two approaches on three domains with heterogeneous agents demonstrating that MCES-FMP yields comparable policies in less time and samples.</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-111" tabindex="-1" role="dialog"
         aria-labelledby="modal-111-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-111-label">[Abstract] GEESE: Grammatical Evolution Algorithm for Evolution of Swarm Behaviors</h4>
                </div>
                <div class="modal-body">
                    <p>Animals such as bees, ants, birds, fish, and others are able to perform complex coordinated tasks like foraging, nest-selection, flocking, and escaping predators efficiently without centralized control or coordination. Conventionally, mimicking these behaviors with robots requires researchers to study actual behaviors, derive mathematical models, and implement these models as algorithms. We purpose a distributed algorithm, Grammatical Evolution algorithm for Evolution of Swarm bEhaviors (GEESE), that extends the literature on using genetic methods to generate collective behaviors for robot swarms. GEESE uses grammatical evolution to evolve a primitive set of human-provided rules into productive individual behaviors. The GEESE algorithm is evaluated in two different ways. First, GEESE is compared to state-of-the-art genetic algorithms on the canonical Santa Fe Trail problem. Results show that GEESE outperforms the state-of-the-art by (a) providing better solution quality given sufficient population size while (b) utilizing fewer evolutionary steps. Second, we compare GEESE output with hand-coded solutions and solutions generated by conventional Grammatical Evolution to show that GEESE can be used successfully for evolving collective swarm behavior for a foraging task.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-308" tabindex="-1" role="dialog"
         aria-labelledby="modal-308-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-308-label">[Abstract] Eliciting Truthful Unverifiable Information</h4>
                </div>
                <div class="modal-body">
                    <p>In many situations, an uninformed agent (UA) needs to elicit information from an informed agent (IA), typically when the latter has some unique expertise or knowledge related to some opportunity available to the UA. In many of those situations, the correctness of the information cannot be verified by the UA, and therefore it is important to guarantee that the information-elicitation mechanism incentivizes the IA to report truthfully.&nbsp; </p><p>This paper presents and studies several information-elicitation mechanisms that guarantee truthful reporting, differing in the type of costs the IA incurs in producing and delivering the information. We show that with no such costs truthful information elicitation is possible with a positive but arbitrarily small expense for the UA.&nbsp; When information-delivery is costly, truthful information elicitation is possible where the extra expense for the UA (above the unavoidable cost of delivery) is arbitrarily small.&nbsp; Finally, when the information-production is costly, under some realistic condition related to the ratio between the expected gain of the IA from true reporting and the information-production cost, truthful information elicitation is possible where the extra expense for the UA (above the unavoidable cost of production) is arbitrarily small. <br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-531" tabindex="-1" role="dialog"
         aria-labelledby="modal-531-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-531-label">[Abstract] A Fairness Criterion for Identifying Illegal Market Systems</h4>
                </div>
                <div class="modal-body">
                    <p>According to U.S. and U.K. law, corporate directors must use their power for the commercial benefit of their company and its members. Yet some business leaders, in trying to maximize their benefits, may operate market systems that cross a moral, ethical, or legal line. For example, Ponzi schemes are fraudulent and illegal, even if they maximize a company's benefit. In contrast, other market systems, like fist-price auctions with transaction fees, are considered appropriate business mechanisms.</p><p><br></p><p>Between these clear endpoints, a number of market systems fall into a gray area. Penny auctions, lotteries, and gambling games, for example, are outlawed in some jurisdictions, legal in others, and have controversial rules of questionable fairness. We know of no overarching criteria to distinguish legitimate market systems from deceptive tricks; each is treated separately and often inconsistently in the law. Betting on sports, betting on elections, and betting on financial stocks are all logically equivalent, yet treated differently in the court of law. Rather than examining every market system case by case, we propose a simple, general criterion for measuring fairness of a market system, allowing society to consistently identify which market systems to allow and which to ban. Our fairness criterion measures how rewards are distributed among market participants. If each participant on average gets back from the market a constant factor of the information, skill, time, and/or money that she puts in, then the market is fair. If, on the other hand, one or more participants consistently earn rewards that far outpace what they put in, then the market is unfair and, in our opinion, should be considered for legal sanction.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-178" tabindex="-1" role="dialog"
         aria-labelledby="modal-178-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-178-label">[Abstract] Integrated Hybrid Planning and Programmed Control for Real–Time UAV Maneuvering</h4>
                </div>
                <div class="modal-body">
                    <p>The automatic generation of realistic behaviour such as tactical intercepts for <i>Unmanned Aerial Vehicle</i>s (<b>UAV</b>) in air combat is a&nbsp;challenging problem. State-of-the-art solutions propose hand--crafted&nbsp;algorithms and heuristics whose performance depends heavily on the initial&nbsp;conditions and aerodynamic properties of the UAVs involved. This&nbsp;paper shows how to employ domain--independent planners, embedded into professional&nbsp;multi--agent simulations, to implement <i>Model Predictive Control</i> (<b>MPC</b>) two--level&nbsp;hybrid control systems for UAVs. Width-based search techniques,&nbsp;taken off-the-shelf from the literature in <i>classical planning over simulators</i>,&nbsp;are used to generate <i>real--time control signals</i> that steer&nbsp;<span style="white-space: pre;">	</span>simulated aircraft as best suits the situation. We compare experimentally the controllers&nbsp;using planners with a behaviour tree that implements tactics widely&nbsp;accepted and used in the real world. Our results indicate hybrid planners derive novel and effective tactics from <i>first principles</i> inherent to the dynamical constraints UAVs are subject to.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-560" tabindex="-1" role="dialog"
         aria-labelledby="modal-560-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-560-label">[Abstract] Interactive Agent that Understands the User</h4>
                </div>
                <div class="modal-body">
                    <p>Our work uses the notion of theory of mind to enable<br>an interactive agent to keep track of the state of knowledge,<br>goals and intentions of the human user, and to<br>engage in and initiate sophisticated interactive behaviors<br>using decision-theoretic paradigm of maximizing<br>expected utility. Currently, systems like Google Now<br>and Siri mostly react to user’s requests and commands<br>using hand-crafted responses, but they cannot initiate<br>intelligent communication and plan for longer term interactions.<br>The reason is that they lack a clearly defined<br>general objective of the interaction. Our main premise is<br>that communication and interaction are types of action,<br>so planning for communicative and interactive actions<br>should be based on a unified framework of decision theoretic<br>planning. To facilitate this, the system’s state<br>of knowledge (a mental model) about the world has to<br>include probabilistic representation of what is known,<br>what is uncertain, and how things change as different<br>events transpire. Further, the state of user’s knowledge<br>and intentions (the theory of the user’s mind) needs to<br>include precise specification of what the system knows,<br>and how uncertain it is, about the user’s mental model,<br>and about her desires and intentions. The theories of<br>mind may be further nested to form interactive beliefs.<br>Finally, decision-theoretic planning proposes that desirability<br>of possible sequences of interactive and communicative<br>actions be assessed as expected utilities of alternative<br>plans. We describe our preliminary implementation<br>using the Open CYC system, called MARTHA,<br>and illustrate it in action using two simple interactive<br>scenarios.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-141" tabindex="-1" role="dialog"
         aria-labelledby="modal-141-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-141-label">[Abstract] Assigning Tasks to Workers based on Historical Data: Online Task Assignment Problem with Two-sided Arrivals</h4>
                </div>
                <div class="modal-body">
                    <p>Efficient allocation of tasks to workers is a central problem in crowdsourcing. In this paper, we consider a special setting inspired from spatial crowdsourcing platforms where both workers and tasks arrive dynamically. Additionally, we assume all tasks are&nbsp; heterogeneous&nbsp; and each worker-task assignment brings a distinct reward. The natural challenge lies in how to incorporate the uncertainty in the arrivals from both workers and tasks into our online allocation policy such that the total expected rewards are maximized. To attack this challenge,&nbsp; we assume the arrival patterns of worker "types" and task "types" are not erratic and can be predicted from historical data. To be more specific, we consider a finite time horizon T and assume in each time-step, a single worker and task are sampled (i.e., "arrive") from two respective distributions independently, and this sampling process repeats identically and independently for the entire T online time-steps.</p><p><br></p><p>Our model, called Online Task Assignment Problem with Two-Sided Arrival (OTAP-TSA), is a significant generalization of the classical online task assignment problem where the set of tasks is assumed to be available offline.&nbsp; For the general version of OTAP-TSA, we present an optimal non-adaptive algorithm which achieves an online competitive ratio of 0.295. For the special case of OTAP-TSA&nbsp;where the reward is a function of just the worker type, we present an improved algorithm (which is adaptive) and achieves a competitive ratio of at least 0.345. On the hardness side, along with showing that the ratio obtained by our non-adaptive algorithm is the best possible among all non-adaptive algorithms, we further show that no (adaptive) algorithm can achieve a ratio better than 0.581 (unconditionally), even for the special case of OTAP-TSA&nbsp;with homogenous tasks (i.e., all rewards are same). At the heart of our analysis lies a new technical tool (which is a refined notion of the birth-death process), called the two-stage birth-death process, which may be of independent interest. Finally, we perform numerical experiments on two real-world datasets obtained from crowdsourcing platforms to complement our theoretical results.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-536" tabindex="-1" role="dialog"
         aria-labelledby="modal-536-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-536-label">[Abstract] Expressive Power of Coalition Announcement Logic</h4>
                </div>
                <div class="modal-body">
                    <p><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">Coalition Anouncement Logic (CAL) studies the strategic interaction between public announcements</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">made by agents, and its effect on agents' knowledge. The main modality of CAL stands for</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">`agents in group $G$ have an announcement such that whatever other announcements agents from outside $G$</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">make at the same time,&nbsp;</span><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">property $\phi$ holds after this joint announcement'.</span><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">&nbsp;CAL is similar to the</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">Group Announcement Logic (GAL), which can express that `agents in group $G$ have an announcement such that</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">property $\phi$ holds after this announcement</span><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">'. It has been an open problem for some time whether CAL</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">modalities are definable in GAL. We answer this question positively for the case of</span><br style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;"><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 13.3333px;">finite models. We also investigate expressive power of fragments of CAL.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-184" tabindex="-1" role="dialog"
         aria-labelledby="modal-184-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-184-label">[Abstract] Optimizing network structure for preventative health</h4>
                </div>
                <div class="modal-body">
                    <p>Diseases such as heart disease, stroke, or diabetes affect hundreds of millions of people. Such conditions are strongly impacted by obesity, and establishing healthy lifestyle behaviors is a critical public health challenge with many applications. Changing health behaviors is inherently a multiagent problem since people's behavior is strongly influenced by those around them. Hence, practitioners often attempt to modify the social network of a community by adding or removing edges in ways that will lead to desirable behavior change. To our knowledge, no previous work considers the algorithmic problem of finding the optimal set of edges to add and remove. We propose the RECONNECT algorithm, which efficiently finds high-quality solutions for a range of different network intervention problems. We evaluate RECONNECT in a highly realistic simulated environment based on the Antelope Valley region in California which draws on demographic, social, and health-related data. We find the RECONNECT outperforms an array of baseline policies, in some cases yielding a 150% improvement over the best alternative.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-165" tabindex="-1" role="dialog"
         aria-labelledby="modal-165-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-165-label">[Abstract] Empirically Evaluating the Application of POMDP vs. MDP Towards the Induction of Pedagogical Strategies</h4>
                </div>
                <div class="modal-body">
                    <p>Intelligent Tutoring Systems (ITSs) have been shown to be highly
effective at improving student learning in real classrooms, approaching
that of human tutors, through scaffolding and intelligent contextualized
feedback adapted to individual learners. Despite the high
payoffs of ITSs, significant barriers remain. To design an effective
ITS, developers must form the basic core of the system and then
determine what to teach and how to teach it. Pedagogical strategies
are policies used by the system to decide what tutorial action to take
when multiple actions are available given user input and the current
learning context. Prior research has shown that when the content
(what) is controlled to be equivalent, there is little evidence that pedagogical
decisions (how) will affect students’ learning. In this work,
however, we applied Reinforcement Learning (RL) to induce effective
pedagogical policies directly from pre-existing student-system
interaction data. When applying RL to ITSs, we face two major challenges:
first, measurements of student learning (reward) are often
delayed; and second, there are many factors that may affect learning
which are not well understood (state representation). We report two
empirical studies in which we compare two frameworks: Markov
Decision Processes (MDPs) vs. Partially Observable Markov Decision
Processes (POMDPs) for policy induction and deterministic
vs. stochastic for the policy execution. Our results show that when
the contents are controlled to be equivalent, effective pedagogical
strategies will improve students’ learning. More specifically, the
POMDP framework is more suitable for the task of pedagogical
policy induction than the MDP framework and stochastic policy
executions can outperform deterministic executions.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-524" tabindex="-1" role="dialog"
         aria-labelledby="modal-524-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-524-label">[Abstract] The Rationale behind Bounded Rational Agents in Retail Markets</h4>
                </div>
                <div class="modal-body">
                    <p>In retail markets, sellers offer competitive prices to attract buyers and increase profits. Reacting to these prices human buyers are not rational, i.e., they do not always choose the optimal available option (cheapest price). In practice, the rationality of buyers is bounded due to cognitive limitations or time constraints. Recent advancements in artificial intelligence and e-commerce enable market participation by agents that are (almost) perfectly rational due to their computational capacity. However, receding characteristics of human buyers, such as bounded rationality, might have unfavorable effects on markets with regards to the stability of competition and prices. In this paper, we study the consequences of varying degrees of buyers' rationality on markets where sellers compete in price for identical items. We model the level of buyers' rationality using the multinomial logit function. We use hierarchical reasoning to model the competition of sellers, where each seller computes its best response strategy (price) with regards to its belief over opponent sellers of lower levels of reasoning. We derive the best response strategy of a reasoning seller with regards to the degree of buyers' rationality, and show the existence of an optimal degree of rationality for buyers. We use evolutionary dynamics over reasoning levels to show that perfect rationality allows higher reasoning sellers to eliminate competition, and thus results in monopolistic behavior. Our results suggest that perfect rationality leads to unstable evolutionary dynamics and price spikes, decreasing the utility of buyers in retail markets. In contrast to perfect rationality, we show that bounded rationality stimulates competition among sellers of varying reasoning levels, yielding benefits for buyers.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-570" tabindex="-1" role="dialog"
         aria-labelledby="modal-570-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-570-label">[Abstract] Adversarial Classification on Social Networks</h4>
                </div>
                <div class="modal-body">
                    <p>The spread of unwanted or malicious content through social me-<br>dia has become a major challenge. Traditional examples of this<br>include social network spam, but an important new concern is the<br>propagation of fake news through social media. A common ap-<br>proach for mitigating this problem is by using standard statistical<br>classification to distinguish malicious (e.g., fake news) instances<br>from benign (e.g., actual news stories). However, such an approach<br>ignores the fact that malicious instances propagate through the<br>network, which is consequential both in quantifying consequences<br>(e.g., fake news diffusing through the network), and capturing de-<br>tection redundancy (bad content can be detected at different nodes).<br>An additional concern is evasion attacks, whereby the generators of<br>malicious instances modify the nature of these to escape detection.<br>We model this problem as a Stackelberg game between the defender<br>who is choosing parameters of the detection model, and an attacker,<br>who is choosing both the node at which to initiate malicious spread,<br>and the nature of malicious entities. We develop a novel bi-level<br>programming approach for this problem, as well as a novel solution<br>approach based on implicit function gradients, and experimentally<br>demonstrate the advantage of our approach over alternatives which<br>ignore network structure.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-78" tabindex="-1" role="dialog"
         aria-labelledby="modal-78-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-78-label">[Abstract] Service-Oriented Robot Software Development Framework for Distributed Heterogeneous Platforms</h4>
                </div>
                <div class="modal-body">
                    <p>In the near future, it will be common that a variety of robots are cooperating to perform a mission in various fields. A key technical challenge to realize this vision is software challenge on how to specify the mission at the user level and how to program each robot separately. In this paper, we propose a novel software development framework that separates mission specification and robot behavior programming. For mission specification, a novel script language is proposed with the expression capability of dynamic mode change and multi-tasking. For robot behavior programming, an extended dataflow model is used for task-level behavior specification that does not depend on the robot hardware platform. In the proposed framework, the actual robot software is automatically generated from the model. The viability of the proposed framework is demonstrated with two real-life experiments.&nbsp;&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-174" tabindex="-1" role="dialog"
         aria-labelledby="modal-174-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-174-label">[Abstract] Quasi-random Agents for Image Transition and Animation</h4>
                </div>
                <div class="modal-body">
                    <p>Quasi-random walks show similar features as standard random walks, but with much less randomness. We utilize this established model from discrete mathematics and show how agents carrying out quasi-random walks can be used for image transition and animation. The key idea is to generalize the notion of quasi-random walks and let a set of autonomous agents perform quasi-random walks painting an image. Each agent has one particular target image that they paint when following a sequence of directions for their quasi-random walk. The sequence can easily be chosen by an artist and allows them to produce a wide range of different transition patterns and animations.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-475" tabindex="-1" role="dialog"
         aria-labelledby="modal-475-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-475-label">[Abstract] Stable Planning Mechanisms for Self Interested Agents</h4>
                </div>
                <div class="modal-body">
                    <p>This paper considers a multi-agent planning setting where actions
are owned by self interested agents, and the agents have
private information about their action costs. Given a planning
task, our goal is to buy a cost-optimal plan for the task from
these self-interested agents. The well-known Vickery-ClarkGroves
(VCG) mechanism is the unique solution that guarantees
both truthfulness and efficiency. However, we show
that all truthful planning mechanisms including VCG can be
forced to pay an \Omega(n) factor more than the cost of the second
cheapest plan, where n is the number of agents. This overpayment
can often lead to coalition manipulations and false
name manipulations. To address these problems, we present
stable planning mechanisms in this paper. The stable planning
mechanism is based on the core solution concept and
can eliminate coalition manipulations and false name manipulations.
We then give a novel core formulation which needs
only O(k^2) constraints for a cost optimal plan with k actions.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-161" tabindex="-1" role="dialog"
         aria-labelledby="modal-161-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-161-label">[Abstract] Online Replanning in Dec-POMDPs for Model Error</h4>
                </div>
                <div class="modal-body">
                    <p>The Decentralized Partially Observable Markov Decision Process (Dec-POMDP) is a powerful framework for decentralized planning under uncertainty. While there are many methods for solving Dec-POMDPs, they all assume the model is correct. In practice, it is very difficult to generate a complete and correct model. Therefore, our approach deals with model error by allowing each agent to replan separately when model differences are detected. This decentralized replanning approach considers two methods for updating solutions and communicating model knowledge. In both cases, we consider the effect of these updates and communications on the other agents’ behavior. We demonstrate these contributions in a search and rescue domain where agents use incorrect a priori environment models for planning. Our methods represent the first Dec-POMDP-based approaches for dealing with model error and the first Dec-POMDP-based replanning methods.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-338" tabindex="-1" role="dialog"
         aria-labelledby="modal-338-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-338-label">[Abstract] Gavel: A Sanctioning Enforcement Framework</h4>
                </div>
                <div class="modal-body">
                    <p>Sanctioning is one of the most adopted enforcement mechanisms in the governance&nbsp;</p><p>of multiagent systems. Current enforcement frameworks, however, restrict agents&nbsp;</p><p>to reason about and make sanctioning decisions. We developed the Gavel framework,&nbsp;</p><p>an adaptive sanctioning enforcement framework that enables agents to decide for&nbsp;</p><p>the most appropriate sanction to apply depending on various decision factors. The&nbsp;</p><p>potential benefits and use of the framework is shown using a Public Goods Game</p><p>in which agents are endowed with different strategies combining material and</p><p>reputational sanctions.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-188" tabindex="-1" role="dialog"
         aria-labelledby="modal-188-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-188-label">[Abstract] A Tree Traverse Algorithm To Compute Distance Between Lexicographic Preferences</h4>
                </div>
                <div class="modal-body">
                    <p>Very often, we have to look into more than one agents' preferences and compare or aggregate them. In a simple situation, the agents may go through and consider each possible alternative. However, this approach becomes impractical when it involves a combinatorial domain, where the number of alternatives grows exponentially as the number of decision attributes increases. In this paper, we consider a well-known compact model, namely, lexicographic preference trees (LP-trees), for representing agents' preferences. We tackle the problem of computing the dissimilarity/distance between agents' preferences represented by LP-trees. In particular, we investigate how the differences on attribute importance and local attribute preferences between agents would affect the distance in their final ranking over the outcome space. We propose an efficient algorithm LpDis to compute the number of disagreed pairwise preferences between agents by traversing their LP-trees. The proposed algorithm can be applied to any classes of LP-trees and allows agents to have different importance structures and preference dependencies. Furthermore, it neither needs to generate any outcome nor to query agents' LP-trees over outcome pairs. Experimental results show that the proposed algorithm hugely reduced the computation time compared to an exhaustive query method.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-712" tabindex="-1" role="dialog"
         aria-labelledby="modal-712-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-712-label">[Abstract] Designing Incentives to Maximize the Adoption of Rooftop Solar Technology</h4>
                </div>
                <div class="modal-body">
                    <p>Household level rooftop solar technology adoption has increased rapidly in many regions, driven by a multitude of factors, including falling prices and incentives such as tax breaks. It has also been shown in recent research that peer effects have an important role in the spread of solar adoption. The existence of peer effects leads to a natural problem of how to design incentives to maximize adoption in such a model. While this is an instance of an "influence maximization" problem, prior results from the influence maximization literature cannot be used directly. In this work, we extend prior results from the literature on the use of submodularity to obtain a greedy approximation. We use this new result to do optimal "seed set" selection for a highly detailed data-driven agent-based model of household rooftop solar adoption.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-145" tabindex="-1" role="dialog"
         aria-labelledby="modal-145-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-145-label">[Abstract] Multiplex Network Structure Enhances the Role of Generalized Reciprocity in Promoting Cooperation</h4>
                </div>
                <div class="modal-body">
                    <p>Recent studies suggest that the emergence of cooperative behavior can be explained by <i>generalized reciprocity</i>, a behavioral mechanism based on the principle of "help anyone if helped by someone". In multi-agent systems, the cooperative dynamics is largely determined by the network structure which dictates the interactions among neighboring agents. These interactions often exhibit multidimensional features, either as relationships of different types or temporal dynamics, both of which may be modeled as a "multiplex" network. Against this background, here we advance the research on cooperation models inspired by generalized reciprocity by considering a multidimensional networked society. Our results reveal that a multiplex network structure effectively enhances the role of generalized reciprocity in promoting cooperation by acting as a latent support, even when the network parameters in some of the separate network dimensions suggest otherwise (i.e. favor defection). As a result, generalized reciprocity forces the cooperative contributions of the individual agents to concentrate in the dimension which is most favorable for the existence of cooperation.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-370" tabindex="-1" role="dialog"
         aria-labelledby="modal-370-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-370-label">[Abstract] Toward Understanding the Impact of User Participation in Dynamic Ridesharing</h4>
                </div>
                <div class="modal-body">
                    <p>Understanding the impact of user participation in ridesharing systems is crucial for stakeholders to take appropriate actions toward achieving desired outcomes. To date, however, a careful study that quantifies the impact and its extent of user participation on the efficiency of dynamic ridesharing systems is missing. One of the main obstacles is that there is lack of modular approaches for simulating dynamic ridesharing systems at scale. To bridge the gap, we present&nbsp; SpaceTime for Dynamic Ridesharing (STDR) - a platform for large-scale dynamic ridesharing simulations. By conducting experiments on the platform with over three million ride requests extracted from the New York City taxi trip dataset, we present the first empirical study to investigate how and to what extent user participation influences the efficiency of dynamic ridesharing systems. We demonstrate how specific configurations (e.g., fleet size, vehicle capacity, and the maximum waiting time) of dynamic ridesharing systems can be identified to counter the effect of user participation on the system efficiency. Stakeholders should base decisions regarding system configurations on insights from data-driven simulations and make tradeoffs between system efficiency and price of anarchy for desired outcomes.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-677" tabindex="-1" role="dialog"
         aria-labelledby="modal-677-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-677-label">[Abstract] Discovering Blind Spots in Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p>Agents trained in simulation often make errors in the real world, due to mismatches between training and testing environments. These mistakes can be dangerous and difficult to discover because the agent cannot a priori predict them. In this work, we propose using oracle feedback to learn a predictive model of these blind spots to reduce costly errors in real world execution. We focus on blind spots in reinforcement learning that occur due to incomplete state representation: The agent does not have the appropriate features to represent the true state of the world and thus cannot distinguish many states from each other. We formalize the problem of discovering blind spots in RL as a noisy supervised learning problem with class imbalance. Our learning methodology combines techniques for label aggregation, calibration, and supervised learning to reason explicitly about various forms of noise emerging from different forms of oracle feedback, including oracle demonstrations and corrections, to predict blind spots in unseen regions of the state space. We evaluate our approach on two domains and show that its predictive performance achieves higher performance than baseline approaches, and that the learned model can be used to selectively query the oracle at execution time to prevent errors. We also empirically analyze the biases of various forms of oracle feedback, including demonstrations and corrections, and how they impact the discovery of blind spots.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-564" tabindex="-1" role="dialog"
         aria-labelledby="modal-564-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-564-label">[Abstract] On Structures and Stabilities of Weighted Allocations and Linear Network Flows</h4>
                </div>
                <div class="modal-body">
                    <p>We consider a more general case of the stable allocation problem in which workers and firms have positive weights over contracts. A weighted allocation is stable if there are no worker-firm pairs can mutually benefit by privately signing an unsaturated contract. We show that weighted stable allocations (WSA) possess a natural lattice structure. We also study the structure of a variant of stable network flow, the linear mapping stable flow (LMSF). Instead of the traditional Kirchhoff's law, requiring the outflow is equal to the inflow, there is a linear relation between the outflow and the inflow for each agent. A flow is stable if no group of vertices can mutually benefit by&nbsp; rerouting the flow along a path contained in the group. By the bidirectional reducibility between WSA and LMSF, not only can we find a WSA in polynomial time, but we also investigate the roll of each agent in a market network and the structure of LMSF. Furthermore, we study the structure of monotone piecewise linear mapping stable flow (MPLMSF), where the relation between inflow and outflow is piecewise linear for each agent. Eventually, we present a fast path augmenting algorithm for LMSF and MPLMSF by using dynamic trees.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-70" tabindex="-1" role="dialog"
         aria-labelledby="modal-70-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-70-label">[Abstract] Distributed, Private, and Derandomized Allocation Algorithm for EV Charging</h4>
                </div>
                <div class="modal-body">
                    <p>Efficient resource allocation is challenging when privacy of users is important. Distributed solution approaches have recently been used extensively to find a solution for such problems. In this work, we study the efficiency of distributed AIMD algorithm for allocation of subsidized goods. To this end, we assign each user a suitable utility function describing the amount of satisfaction that it has from allocated resource. We define the resource allocation as a total utilitarianism problem that is an optimization problem of sum of users utility functions subjected to capacity constraint. Recently, a stochastic state-dependent variant of AIMD algorithm is used for allocation of common goods among users with strictly increasing and concave utility functions. We improve this algorithm to allocate subsidized goods to users with concave and nonmonotonous utility functions as well as users with Sigmoidal utility functions. We also derandomize the AIMD algorithm and compare its efficiency with the stochastic version. To illustrate the effectiveness of the proposed solutions, we present simulation results for a public renewable-energy powered charging station in which the electric vehicles (EV) compete to be recharged.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-384" tabindex="-1" role="dialog"
         aria-labelledby="modal-384-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-384-label">[Abstract] A Deep Policy Inference Q-Network for Multi-Agent Systems</h4>
                </div>
                <div class="modal-body">
                    <p>We present DPIQN, a deep policy inference Q-network that targets multi-agent systems composed of controllable agents, collaborators, and opponents that interact with each other. We focus on one challenging issue in such systems---modeling agents with varying strategies---and propose to employ "policy features" learned from raw observations (e.g., raw images) of collaborators and opponents by inferring their policies. DPIQN incorporates the learned policy features as a hidden vector into its own deep Q-network (DQN), such that it is able to predict better Q values for the controllable agents than the state-of-the-art deep reinforcement learning models. We further propose an enhanced version of DPIQN, called deep recurrent policy inference Q-network (DRPIQN), for handling partial observability. Both DPIQN and DRPIQN are trained by an adaptive training procedure, which adjusts the network's attention to learn the policy features and its own Q-values at different phases of the training process. We present a comprehensive analysis of DPIQN and DRPIQN, and highlight their effectiveness and generalizability in various multi-agent settings. Our models are evaluated in a classic soccer game involving both competitive and collaborative scenarios. Experimental results performed on 1 vs. 1 and 2 vs. 2 games show that DPIQN and DRPIQN demonstrate superior performance to the baseline DQN and deep recurrent Q-network (DRQN) models. We also explore scenarios in which collaborators or opponents dynamically change their policies, and show that DPIQN and DRPIQN do lead to better overall performance in terms of stability and mean scores.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-460" tabindex="-1" role="dialog"
         aria-labelledby="modal-460-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-460-label">[Abstract] Epistemic Foundations for Generalised Planning with Nondeterminism</h4>
                </div>
                <div class="modal-body">
                    <p>In an influential paper, Levesque proposed a formal specification for analysing the correctness of program-like plans, such as conditional plans, iterative plans, and knowledge-based plans. He motivated a logical characterisation within the situation calculus that included binary sensing actions. While the characterisation does not immediately yield a practical algorithm, the specification serves as a general skeleton to explore the synthesis of program-like plans for reasonable, tractable fragments.&nbsp;</p><p><br></p><p>Increasingly, classical plan structures are being applied to stochastic environments such as robotics applications. This raises the question as to what the specification for correctness should look like, since Levesque's account makes the assumption that sensing is exact and actions are deterministic. Building on a situation calculus theory for reasoning about</p><p>degrees of belief and noise, we revisit the execution</p><p>semantics of generalized plans. The specification is then used to</p><p>analyse the correctness of example plans.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-665" tabindex="-1" role="dialog"
         aria-labelledby="modal-665-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-665-label">[Abstract] Learning to Trade: Exploiting Market Forces to Increase Social Welfare in Multi-Agent Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">Recent work on learning in multi-agent systems (MAS) is concerned
with questions on the ability to learn social interaction skills like
learning to communicate, learning to cooperate or the preservation
of cooperation. These are key challenges to make MAS applicable
in real world settings that possibly include interaction with other
systems and also humans. In this work, we contribute an algorithm
for </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineTI'">learning to trade</span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">. We consider trade to be a central feature in
domains where a given amount of resources needs to be allocated
to a group of agents. We motivate this from the first fundamental
theorem of welfare economics according to which competitive
markets tend towards Pareto efficient allocations. To study the
emergence of trading behavior in MAS, we use Deep Reinforcement
Learning with independent, self-interested learners and provide
them with the ability of exchanging resources to realize trading. We
propose ’Action Traders’, which refers to agents that can trade their
atomic actions in exchange for environmental reward. For empirical
evaluation we implemented action trading in the Coin Game - and find that trading significantly increases social efficiency in terms of
overall reward compared to agents without action trading.&nbsp;</span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-77" tabindex="-1" role="dialog"
         aria-labelledby="modal-77-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-77-label">[Abstract] Selfish Behavior is Ubiquitous: Maximize Selfish Group’s Income in Multi-agent Pursuit-Evasion Problem</h4>
                </div>
                <div class="modal-body">
                    <p><span lang="EN-US">We are </span><span lang="EN-US">interested</span><span lang="EN-US"> in multi-agent pursuit-evasion
problem, where the pursuers’ goal is to round up the evader, and the evader’s goal
is to avoid being captured by the pursuers. Existing related studies usually
consider the condition that all the pursuers are not self-interested and
willing to cooperate closely. However, the reality is that selfish behavior is ubiquitous in multi-agent
systems, and some selfish agents collude together to maximize their group’s
income. Therefore, the analysis of selfish pursuers’
strategy is meaningful and may be conductive to the follow-up research on promoting
cooperation. As we all know, the pursuers’ selfish behavior
is influenced by the reward allocation mechanism that developed for awarding pursuers
after the process of pursuit, thus we propose a problem: what is the suitable
strategy that the selfish group will take when faced with different reward allocation
mechanism. To the best of our knowledge, this is the
first paper that studies this problem. Our contributions are as follows: First,
we formally define this problem. Second, we analyze this problem, and propose two
suitable algorithms based on the analyses: one is an algorithm
designed according to the main idea of the greedy strategy; the other one is a novel
heuristic algorithm that tears a gap in the encircled formation deliberately
with the purpose of attracting the evader to move towards the gap. Finally, we extensively
evaluate our algorithms in simulation,</span><span lang="EN-US"> demonstrating that the
efficacy of our algorithm in improving selfish group’s total income. Our
results in this paper can facilitate the follow-up research on how to design
reward allocation mechanism to promote cooperation and detect the selfish
behavior.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-207" tabindex="-1" role="dialog"
         aria-labelledby="modal-207-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-207-label">[Abstract] A Homophily-Free Community Detection Framework for Roaming Taxis</h4>
                </div>
                <div class="modal-body">
                    <p>Taxi service is the best candidate for replacing private vehicles in most cities; however, finding customers by roaming the street is a major source of inefficiency. To obtain information about customer demand and/or surge pricing at different locations, taxi drivers typically form communities (through messaging applications and phone conversations). Taxi companies can exploit the knowledge of such communities to pass on demand or price information effectively and efficiently. Given the continuous and constant presence of such surges in major cities like Singapore, this can serve to significantly reduce wait times for customers or increase revenue for taxi drivers.</p><p>As it is difficult to get data about observable interactions such as messages or calls among individuals, this paper provides an innovative application where in we infer all relationships from visitations to physical locations. However, such inferences are subject to spatial homophily (similar location preferences will be inferred as relationships), and detection of the actual community structure can thus be extremely challenging. To that end, we make the following key contributions: (1) We introduce a four-phase framework, which by way of using quantified impacts excludes homophily. We execute this framework on a real-world data set of more than 6,000 taxis in Singapore; (2) To validate the framework, we first generate a synthetic dataset based on an input community structure and then infer that community structure; (3) Finally, we also implement a baseline approach without the homophily-elimination design and show that our framework can extract communities at much finer scale.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-354" tabindex="-1" role="dialog"
         aria-labelledby="modal-354-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-354-label">[Abstract] Variational BEJG Solvers for Marginal-MAP Inference with Accurate Approximation of B-conditional Entropy</h4>
                </div>
                <div class="modal-body">
                    <p>Previously proposed variational techniques for approximate MMAP inference in complex graphical models of high-order factors relax a dual variational objective function to obtain its tractable approximation, and further perform MMAP inference in the resulting simplified graphical model, where the sub-graph with decision variables is assumed to be a disconnected forest. In contrast, we developed novel variational MMAP inference algorithms and proximal convergent solvers, where we can improve the approximation accuracy while better preserving the original MMAP query by designing such a dual variational objective function that an upper bound approximation is applied only to the entropy of decision variables. We evaluate the proposed algorithms on both simulated synthetic datasets and diagnostic Bayesian networks taken from the UAI inference challenge, and our solvers outperform other variational algorithms in a majority of reported cases. Additionally, we demonstrate the important real-life application of the proposed variational approaches to solve complex tasks of policy optimization by MMAP inference, and performance of the implemented approximation algorithms is compared.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-589" tabindex="-1" role="dialog"
         aria-labelledby="modal-589-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-589-label">[Abstract] Probabilistic Auction for Distributed, Robust Resource Optimization (PADRE)</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-family: LinLibertineT; font-size: 12px;">Large scale resource allocation problems occur in military information collection, air campaign planning, logistics networks, energy grids, etc.. Optimal solutions require that demand, resource status, and allocation decisions are shared via messaging between geographically distributed nodes in the network, whether allocation decisions are made by one or a few auctioneer nodes or negotiated via distributed winner determination. Jamming of wireless links and cyber attacks on the network interfere with messaging and, thus, the quality of the allocation decisions. Therefore, optimizing decision quality requires selecting the appropriate decision network architecture. Our contribution described in the paper is a decentralized resource allocation architecture and algorithm that is robust to significant message loss and to uncertain demand arrival, and provides fine-grained, many-to-many combinatorial task allocation. Most importantly, it enables a conscious choice of the best level of decentralization under the expected degree of communications denial and quantifies the benefits of approximating status of peer nodes using proxy agents during temporary communications loss. Current solutions address one or two, but not all of these concerns. We present an auction-based resource allocation algorithm whose winner determination includes a constrained clustering algorithm. Hard and soft constraints ensure temporal and spatial requirements are met, while also honoring task priorities and dependencies, anticipating future needs, and minimizing ripple effects of allocation changes. We derive theoretical performance bounds for various degrees of decentralization. We show via extensive empirical analysis that our algorithmic implementation compares well to these theoretical bounds. Our results reveal the optimal degree of decentralization for any level of communications denial.&nbsp;</span><br></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-412" tabindex="-1" role="dialog"
         aria-labelledby="modal-412-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-412-label">[Abstract] SCC-rFMQ learning in Cooperative Markov Games with Continuous Actions</h4>
                </div>
                <div class="modal-body">
                    <p><span style="font-family: verdana, arial, helvetica; font-size: small;">Although many reinforcement learning algorithms have been proposed for learning the optimal solutions in single-agent continuous action domains, multiagent coordination domains with continuous action have received relatively few investigations. Coordination problems in traditional multiagent domains, such as non-stationarity and stochasticity problem, still remain challenging for the continuous action multiagent domains. In this paper, we propose an independent learner hierarchical method, named Sample Continuous Coordination with recursive Frequency Maximum Q-Value (SCC-rFMQ), which divides the coordination problem in the continuous action cooperative Markov games into two layers. One layer samples a finite set of actions from the continuous action spaces by a sampling mechanism with variable exploratory rate, and the other layer evaluates the actions in the sampled action set and updates the policy using a reinforcement learning coordination method. By constructing coordination mechanisms at both levels, SCC-rFMQ can avoid the nonstationarity and stochasticity problem in continuous action cooperative Markov games effectively. The effectiveness of SCC-rFMQ is demonstrated on two well-designed games experimentally, i.e., a continuous version of the climbing game and a cooperative version of the boat problem. And the experimental results show that SCC-rFMQ outperforms other reinforcement learning algorithms in terms of dealing with the coordination problem in continuous action cooperative Markov games.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-683" tabindex="-1" role="dialog"
         aria-labelledby="modal-683-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-683-label">[Abstract] An Election Game with a Polynomial-time Algorithm for Equilibrium Computation</h4>
                </div>
                <div class="modal-body">
                    <p>We present a game-theoretic model for issue-based elections when voter opinions form natural clusters, approximating the continuous multi-dimensional solution space (as in the classic Hotelling-Downs model) to a finite discrete one. We show that this game can be reduced to a variation of network cost-sharing game with additional non-shareable costs. The flexibility offered by this reduction permits our model to capture several variations of the Hotelling-Downs model simultaneously, including ones with limited attraction, ability of candidates to enter and exit any time during the campaign or abstain from the race, the restriction on candidates to access certain stance positions, and the operational cost considerations of running a campaign. We show that a pure Nash equilibrium (PNE) always exists in our model, and we provide a polynomial-time algorithm for computing a PNE, which is in general PLS-Hard for network cost-sharing games. The results can also be extended to spatio-temporal games with similar structure, such as in location games with placement of commercial facilities.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-234" tabindex="-1" role="dialog"
         aria-labelledby="modal-234-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-234-label">[Abstract] On Collusion and Coercion: Agent Interconnectedness and In-Group Behaviour</h4>
                </div>
                <div class="modal-body">
                    <p>The interconnectedness of actors is an antecedent for collective corruption, which in turn can lead to endemic corruption in a society. As a testbed for studying the effects of social interconnectedness on corrupt behaviours, we examine the domain of maritime customs. Taking an extant agent-based simulation, we add to the simulation a nuanced model of actor relatedness, consisting of clan, in-group (sect), and town of origin, and encode associated behavioural norms. We examine the effects of social interconnectedness on domain performance metrics such as revenue, container outcomes, time, coercive demands, and collusion. Results confirm that, when corruption is widespread, localized punitive- or incentive-based policies are weakened, and that the effect of process re-engineering is frustrated when interconnectedness increases beyond a critical point, for two out of three forms of homophily connections. Our work connects with and provides a complementary methodology to works in the political economy literature.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-336" tabindex="-1" role="dialog"
         aria-labelledby="modal-336-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-336-label">[Abstract] A Decentralised Planning Framework for Multi-Agent Systems</h4>
                </div>
                <div class="modal-body">
                    <p><font color="#222222" face="arial, sans-serif"><span style="font-size: 12.8px;">Multi-agent platforms typically provide various mechanisms for runtime coordination. In this context, decentralised multi-agent planning can be efficient as well as effective, especially in loosely-coupled domains, besides also ensuring important properties in agent systems such as privacy and autonomy. However, little work has been done to explore this in practice. In this paper, we address this issue by putting forward an approach to online multi-agent planning that combines goal allocation, individual planning, and coordination during runtime in order to support the achievement of social goals in multi-agent systems. In particular, we present a planning and execution framework called Decentralised Online Multi-Agent Planning (DOMAP). Experiments with two loosely-coupled planning domains, one classical and one novel, show that DOMAP outperforms four other state-of-the-art multi-agent planners with regards to both planning and execution time, particularly in the most difficult problems.</span></font><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-568" tabindex="-1" role="dialog"
         aria-labelledby="modal-568-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-568-label">[Abstract] RAIL: Risk-Averse Imitation Learning</h4>
                </div>
                <div class="modal-body">
                    <p>Imitation learning algorithms learn viable policies by imitating an expert's behavior when reward signals are not available. Generative Adversarial Imitation Learning (GAIL) is a state-of-the-art algorithm for learning policies when the expert's behavior is available as a fixed set of trajectories. We evaluate in terms of the expert's cost function and observe that the distribution of trajectory-costs is often more heavy-tailed for GAIL-agents than the expert at a number of benchmark continuous-control tasks. Thus, high-cost trajectories, corresponding to tail-end events of catastrophic failure, are more likely to be encountered by the GAIL-agents than the expert. This makes the reliability of GAIL-agents questionable when it comes to deployment in risk-sensitive applications like robotic surgery and autonomous driving. In this work, we aim to minimize the occurrence of tail-end events by minimizing tail risk within the GAIL framework. We quantify tail risk by the Conditional-Value-at-Risk (CVaR) of trajectories and develop the Risk-Averse Imitation Learning (RAIL) algorithm. We observe that the policies learned with RAIL show lower tail-end risk than those of vanilla GAIL. Thus the proposed RAIL algorithm appears as a potent alternative to GAIL for improved reliability in risk-sensitive applications.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-358" tabindex="-1" role="dialog"
         aria-labelledby="modal-358-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-358-label">[Abstract] Inverse Reinforcement Behavior Learning for the Decision-Making Model of Crowd Simulation</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we present a behavior model of agent-base crowd simulation and a framework to adapt the model to re-generate observed real behaviors using inverse reinforcement learning (IRL). Crowd simulation has been recently the subject of study due to its application in the fields of disaster evacuation, smart town planning and business strategic placing. However as any type of simulation, the data obtained from it is as good as its degree of realism, so not only physics interactions but intelligent crowd behavior is needed to give meaningful results. However, to obtain patterns in order to model this behavior is not a trivial task, especially in case of crowds, as it requires an enormous quantity of observation data, something hardly feasible in many scenarios due to practical and legal reasons. A method to replicate human behavior is using machine learning techniques, using a small training data set to generate cues allowing crowd agents to react to similar situations accordingly. We implement a BDI-based behavioral agent model into CrowdWalk, a large-scale crowd simulator, and, apply IRL to obtain suitable reward values for each sub-goal in BDI. The goal of the system is to provide a reliable way for the agents to behave, based in learned patterns around environment features and also a way to orient themselves in the scenario without knowing its layout.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-767" tabindex="-1" role="dialog"
         aria-labelledby="modal-767-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-767-label">[Abstract] Ordered Preference Elicitation Strategies for Supporting Multi-Objective Decision Making</h4>
                </div>
                <div class="modal-body">
                    <p>In multi-objective decision planning and learning, much attention is paid to producing optimal solution sets that contain an optimal policy for every possible user preference profile. We argue that the step that follows, i.e, determining which policy to execute by maximising the user's intrinsic utility function over this (possibly infinite) set, is under-studied. This paper aims to fill this gap. We build on previous work on Gaussian processes and pairwise comparisons for preference modelling, extend it to the multi-objective decision support scenario, and propose new ordered preference elicitation strategies based on ranking and clustering. Our main contribution is an in-depth evaluation of these strategies using computer and human-based experiments. We show that our proposed elicitation strategies outperform the currently used pairwise methods, and found that users prefer ranking most. Our experiments further show that utilising monotonicity information in GPs by using a linear prior mean at the start and virtual comparisons to the nadir and ideal points, increases performance. We demonstrate our decision support framework in a real-world study on traffic regulation, conducted with the city of [blinded for review].</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-739" tabindex="-1" role="dialog"
         aria-labelledby="modal-739-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-739-label">[Abstract] Competitive Cloud Pricing for Long-Term Revenue Maximization</h4>
                </div>
                <div class="modal-body">
                    <p>We also develop approximation algorithms for immediate profit calculation so as to further improve the efficiency of our algorithms. Experimental results show that the MPE strategy leads to much higher profits for providers compared with existing policies and our algorithms are efficient for solving large-size problems.<br>We decompose the problem into two subtasks: (1) dividing the stochastic game into many normal-forma games and calculating their Nash equilibria, for which we design an algorithm ensuring to converge, and (2) computing the MPE of the original game, which is efficiently solved by an algorithm combining the Nash equilibria based on a mild assumption. We first propose a comprehensive model for the real-world cloud market and formulate it as a stochastic game. Then we apply the Markov Perfect Equilibrium (MPE) solution concept to describe providers' optimal pricing policies, which is difficult to compute due to the incomplete information, the large number of users, and the large state space of the stochastic game.<br>Pricing policy optimization is a very important problem for cloud providers. We study this problem while considering three properties of the real-world cloud market: (1) providers have only incomplete information about the market; (2) it is in evolution due to the increasing number of users and decreasing marginal cost of providers; (3) it is fully competitive because of providers' and users' revenue-driven nature. However, there is no existing work investigating providers' optimal pricing policies under such realistic settings.<span class="fontstyle0"></span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-598" tabindex="-1" role="dialog"
         aria-labelledby="modal-598-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-598-label">[Abstract] Propagating, Revising, and Updating Probabilistic Beliefs for Assertive Announced Changes</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'">We consider a robot that learns knowledge about its environment through dialog
interaction. The robot needs to "understand" speech from humans, </span><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'; font-style: italic">i.e.</span><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'">, convert a
speech to a pre-defined frame with a set of natural language terms labeled with
frame elements and ground these labeled terms to robot’s internal values. Then
the robot requires a probabilistic model that grounds a variable, </span><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'; font-style: italic">i.e.</span><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'">, a labeled
natural language term, to the internal value. In this paper, we consider how to
learn and adjust such a probability model according to new speech, especially
when the speech assertively announces the changing of the environment. We
divide variables into two categories, </span><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'; font-style: italic">i.e.</span><span style="font-size: 10.000000pt; font-family: 'NimbusRomNo9L'">, multi-valued and singled-valued, and
treat them differently during the process. We respectively provide methods to
propagate probabilistic beliefs for multi-valued variables, revise beliefs for single-valued variables, and update beliefs when the environment has changed. At last,
we evaluate the performance of our approach in a rich human-robot interaction
setup. We show that, when the robot receives an assertive announced change, its
probabilistic beliefs should be modified radically.&nbsp;</span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-401" tabindex="-1" role="dialog"
         aria-labelledby="modal-401-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-401-label">[Abstract] PICA: Proactive Intelligent Conversational Agent for Interactive Narratives</h4>
                </div>
                <div class="modal-body">
                    <p>A narrative relies on imperfect knowledge to stimulate the interactions between the different characters and this imperfect knowledge is ultimately used as a plot device to drive the narrative. This motivates our exploration of ways to encode this information, provide means for a user to both query and influence the knowledge, and guide the user based on a model of their experience. We developed PICA: a proactive intelligent conversational agent for interactive narratives. Our hybrid sub-symbolic architecture allows for encoding belief models for multiple users and autonomous agents in addition to the actual story knowledge. We also developed a discourse module using behavior trees to intuitively design the proactive and reactive capabilities of PICA. We demonstrate PICA in the context of an existing interactive narrative system, and our results reveal the promise of using our approach to encode time and uncertainty to represent evolving belief models of both users and autonomous agents experiencing a narrative.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-216" tabindex="-1" role="dialog"
         aria-labelledby="modal-216-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-216-label">[Abstract] Optimal Resource Allocation inWork-flows: Crowds, Clouds and Beyond</h4>
                </div>
                <div class="modal-body">
                    <p>In many applications such as crowd-sourcing or<br>cloud computing, a challenging problem for businesses<br>is to choose the right assignment of resources<br>to the various tasks so that the overall requirements<br>of the process (such as accuracy, deadlines<br>and cost) are satisfied. These tasks are part<br>of complex workflows, and even for simple workflows,<br>determining whether certain requirements<br>are feasible is NP-hard. We formalize the workflow<br>optimization problem (WOPT) for a set of<br>workflows that appear in real world problems. For<br>requirements that arise in such applications, we<br>provide a set of fast algorithms that guarantedly<br>achieve close to optimal solutions. We rigorously<br>compare our approach with plethora of previous efforts,<br>solutions to tackle these problems.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-335" tabindex="-1" role="dialog"
         aria-labelledby="modal-335-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-335-label">[Abstract] Learning System-Efficient Equilibria in Route Choice Using Tolls</h4>
                </div>
                <div class="modal-body">
                    <p>We consider the route choice problem using multiagent reinforcement learning. In this problem, each driver-agent individually learns which routes minimise its expected travel costs. Such a selfish behaviour results in the so-called User Equilibrium (UE), which is inefficient from the system's perspective. In order to reduce the impact of selfishness, a well-known alternative is the use of tolls. We employ the so-called marginal-cost tolling (MCT) scheme, in which each driver is charged according to the cost it imposes on others. The use of MCT leads agents to behave in a socially-desirable way so that the system optimum (SO) is achieved. In contrast to previous works, we formulate an MCT scheme in which drivers are charged <i>a posteriori</i>, i.e., at the end of their trips. In this sense, as compared to previous works, our mechanism is more flexible (it does not depend on specialised infrastructure), fairer (agents pay for their actual marginal costs), and avoids unrealistic assumptions (agents have limited knowledge). We provide a general formulation of the toll values for univariate, homogeneous polynomial cost functions, which comprise the most commonly-used cost functions in the literature. Furthermore, we deliver theoretical results, showing that our approach converges to the a system-efficient UE, i.e., the SO.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-333" tabindex="-1" role="dialog"
         aria-labelledby="modal-333-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-333-label">[Abstract] Efficient Cooperative Inverse Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p>Our goal is for AI systems to correctly identify and act according to their human user's objectives. Cooperative Inverse Reinforcement Learning (CIRL) formalizes this <i>value alignment</i> problem as a two-player game between a human and robot, in which only the human knows the parameters of the reward function: the robot needs to learn them as the interaction unfolds. Previous work showed that CIRL can be solved as a POMDP, but with an action space size exponential in the size of the reward parameter space. In this work, we exploit a specific property of CIRL: the human is a full information agent. This enables us to derive an optimality-preserving modification to the standard Bellman update, which reduces the complexity of the problem by an exponential factor. Additionally, we show that our modified Bellman update allows us to relax CIRL's assumption of human rationality. We apply this update to a variety of POMDP solvers, including exact methods, point-based methods, and Monte Carlo Tree Search methods. We find that it enables us to scale CIRL to non-trivial problems, with larger reward parameter spaces, as well as larger action spaces for the robot and the human. In solutions to these larger problems, the human exhibits pedagogical (teaching) behavior, while the robot interprets it as such and attains higher value for the human.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-592" tabindex="-1" role="dialog"
         aria-labelledby="modal-592-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-592-label">[Abstract] Expertise Drift in Referral Networks</h4>
                </div>
                <div class="modal-body">
                    <p>Learning-to-refer is a challenge in expert referral networks, wherein Active Learning helps experts (agents) estimate the skills of other connected experts for different categories of tasks that the initial expert cannot solve and therefore must seek referral to experts with more appropriate expertise. Prior research has investigated different reinforcement action selection algorithms to assess viability of the learning setting both with uninformative priors and with partially available noisy priors, where experts are allowed to advertise a subset of their skills to their colleagues. Prior to this work, time-varying expertise drift (e.g., experts learning with experience) has not been considered though it is an aspect that may often arise in practice. This paper addresses the challenge of referral learning with time-varying expertise, proposing&nbsp; Hybrid, a novel combination of Optimistic Thompson Sampling, Pessimistic Thompson Sampling and Distributed Interval Estimation Learning (DIEL). In our extensive empirical evaluation, considering both biased and unbiased drift, the proposed algorithm outperforms the previous state-of-the-art (DIEL) and approaches the drift-aware oracle upper bound.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-286" tabindex="-1" role="dialog"
         aria-labelledby="modal-286-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-286-label">[Abstract] Constrained-Based Differential Privacy for Mobility Services</h4>
                </div>
                <div class="modal-body">
                    <p>Ubiquitous mobile and wireless communication systems have the potential to revolutionize transportation systems, making accurate mobility traces and activity-based patterns available to optimize the design and operations of mobility systems. However, these rich data sets also pose significant privacy risks, potentially revealing highly sensitive information about individual agents.</p><p>This paper studies how to use <i>differential privacy</i> to release mobility data for transportation applications. It shows that existing approaches do not provide the desired fidelity for practical uses. To remedy this limitation, the paper proposes the idea of <i>Constraint-Based Differential Privacy</i> (CBDP) that casts the production of a private data set as an optimization problem that redistributes the noise introduced by a randomized mechanism to satisfy fundamental constraints of the original data set.</p><p>The CBDP has strong theoretical guarantees: It is a constant factor away from optimality and, when the constraints capture categorical features, it runs in polynomial time. Experimental results show that CBDP ensures that a city-level multi-modal transit system has similar performance measures when designed and optimized over the real and private data sets and improves state-of-art privacy methods by an order of magnitude.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-405" tabindex="-1" role="dialog"
         aria-labelledby="modal-405-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-405-label">[Abstract] A Game-Theoretic Approach for Overlapping Community Detection via Frequency Graphs</h4>
                </div>
                <div class="modal-body">
                    <p>We introduce an interaction-based game-theoretic approach to study the similarities between rational individuals in a complex network, and demonstrate how it can be used to reveal community and overlapping community structure of the network. In particular, we consider a simple network coordination game as a proxy for strategic interactions between individuals, and use the frequency that two agents adopt the same strategy in a Nash equilibrium of such game to reflect the likelihood that these two agents belong to the same community. The result is a frequency graph that highlights the similarities between agents through their coordination behaviors. Based on this frequency graph, we design simple and efficient algorithms for both community detection and overlapping community detection problems. We evaluate these algorithms on datasets of real-world networks and benchmark test networks. Results show that these algorithms are able to effectively identify both disjoint and overlapping communities, and are often more accurate than the other state-of-the-art methods when many people belong to multiple communities.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-45" tabindex="-1" role="dialog"
         aria-labelledby="modal-45-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-45-label">[Abstract] Group Conformity Model of Diffusion in Social Networks</h4>
                </div>
                <div class="modal-body">
                    <p>Diffusion in social networks is a result of agent's natural desire to conform to the behavioral patterns of their peers. Unlike the existing models of diffusion, the more fine-grained model presented in this paper accounts for conformity to different social groups that the same agent might belong to, rather than conformity to society as whole. This new model of diffusion is one of the two major contributions of this paper.</p><p><br></p><p>The other contribution is a sound and complete logical system describing the properties of the influence relation in the proposed model. The logical system is an extension of Armstrong's axioms from database theory by one new axiom that captures the topological structure of the network.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-578" tabindex="-1" role="dialog"
         aria-labelledby="modal-578-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-578-label">[Abstract] When Rigging a Tournament, Let Greediness Blind You</h4>
                </div>
                <div class="modal-body">
                    <p>A knockout (or single-elimination) tournament, being a standard format of competition, is ubiquitous in sports competitions, elections and decision making. Such a competition consists of several rounds. In each round, all players that have not yet been eliminated are paired up. Each pair entails a match, where losers are eliminated. Winners proceed to the next round, until only a single winner exists. Given that we can correctly predict the outcome of each potential match, a seeding of the tournament deterministically determines its winner. In this regard, having a favorite player v in mind, it is natural to ask whether there exists a seeding that will make v the winner, and if yes--find such a seeding. Aziz et al. [AAAI, 2014] showed that this problem, called Tournament Fixing Problem (TFP), is NP-hard, thus resolving a longstanding open problem in the area. As a natural next step, they initiated the study of the parameterized complexity of TFP with respect to the feedback arc set number $k$ of the tournament encoding outcomes of matches. As a first result, they presented an XP-algorithm, which is simple but extremely inefficient. Recently, Ramanujan and Szeider [AAAI, 2017] showed that the problem is FPT by developing a significantly better algorithm whose running time is bounded by $ 2^{\Oh(k^2\log k)}n^{\Oh(1)}$. At the heart of this algorithm, lies the translation of the problem into an algebraic system of equations that is solved in a black box fashion by an ILP solver. Having greediness in mind, we present a fresh, purely combinatorial solution to this problem. Our solution relies on new insights into TFP itself, and in fact even results in the better running time bound of $2^{\Oh(k\log k)}n^{\Oh(1)}$. While the analysis of our algorithm is intricate, the algorithm itself is surprisingly simple.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-92" tabindex="-1" role="dialog"
         aria-labelledby="modal-92-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-92-label">[Abstract] Greedy Algorithms for Maximizing Nash Social Welfare</h4>
                </div>
                <div class="modal-body">
                    <p>We study the problem of fairly allocating a set of indivisible goods among agents with additive valuations. The extent of fairness of an allocation is measured by its Nash social welfare, which is the geometric mean of the valuations of the agents for their bundles. While the problem of maximizing Nash social welfare is known to be APX-hard in general, we study the effectiveness of <i>simple</i>, <i>greedy </i>algorithms in solving this problem in two interesting special cases.<br><br>First, we show that a simple, greedy algorithm provides a 1.061-approximation guarantee when agents have <i>identical </i>valuations, even though the problem of maximizing Nash social welfare remains NP-hard for this setting. Second, we show that when agents have <i>binary </i>valuations over the goods, an exact solution (i.e., a Nash optimal allocation) can be found in polynomial time via a greedy algorithm. Our results in the binary setting extend to provide novel, exact algorithms for optimizing Nash social welfare under <i>concave </i>valuations. Notably, for the above mentioned scenarios, our techniques provide a <i>simple </i>alternative to several of the existing, more sophisticated techniques for this problem such as constructing equilibria of Fisher markets or using real stable polynomials.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-411" tabindex="-1" role="dialog"
         aria-labelledby="modal-411-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-411-label">[Abstract] Timing Rating Requests for Maximizing Obtained Rating</h4>
                </div>
                <div class="modal-body">
                    <p>This paper studies methods for timing requests for user rating. The problem can be found in various domains, and has gained much importance in recent years as the accessibility of the public to the ratings received increased and became an important consideration affecting customers' decisions.&nbsp; The paper proposes a new method for issuing a rating request, based on optimal stopping principles, while assuming an exponentially diminishing effect of all prior user experiences with the system over the user satisfaction.&nbsp; We show that the expected-rating-maximizing timing strategy under this assumption is threshold-based and propose an efficient Monte-Carlo-based method which&nbsp; facilitates the thresholds extraction. The analysis of the ratings achieved through the use of the proposed method compared to issuing random rating requests (which is highly common in apps and by service companies nowadays) in two different experimental infrastructures reveals a significant improvement in the average rating received.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-212" tabindex="-1" role="dialog"
         aria-labelledby="modal-212-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-212-label">[Abstract] Balancing the Pain and Gain of Hobnobbing: Utility-Based Network Building over Attributed Social Networks</h4>
                </div>
                <div class="modal-body">
                    <p><span class="fontstyle0">The establishment of interpersonal ties is a pivotal problem in the structural analysis of social networks. In particular, link recommendation problem asks for valuable future links to establish by an individual. Existing methods for this problem rely on link prediction that evaluates the likelihood of successful tie creation between<br>two individuals. Such methods do not consider the social capital gained by agents, nor do they concern with the required cost of&nbsp;this process. In light of this limitation, we propose a utility-based network building problem, with an aim to strike a balance between the gained social capital – in the form of closeness centrality – and the cost of establishing ties. We propose algorithms to solve this problem over networks whose nodes may or may not be labelled with attributes, and test their performance on a range of synthesized and real-world social networks. By having multiple agents adopting utility-based network building strategies, we propose a suite of models of&nbsp; network formation and demonstrate empirically that the they capture important structural properties. In particular, we investigate the emergence of a core/periphery structure as a joint result of preferential attachment and network building strategies</span>&nbsp;.<br style="line-height: normal; text-align: -webkit-auto; text-size-adjust: auto;"></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-489" tabindex="-1" role="dialog"
         aria-labelledby="modal-489-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-489-label">[Abstract] Leveraging Statistical Multi-Agent Online Planning with Emergent Value Function Approximation</h4>
                </div>
                <div class="modal-body">
                    <p>Making decisions is a great challenge in distributed autonomous environments due to enormous state spaces and uncertainty. Many online planning algorithms rely on statistical sampling to avoid searching the whole state space, while still being able to make acceptable decisions. However, planning often has to be performed under strict computational constraints making online planning in multi-agent systems highly limited, which could lead to poor system performance, especially in stochastic domains.</p><p>In this paper, we propose <i>Emergent Value function Approximation&nbsp;</i><i>for Distributed Environments (EVADE)</i>, an approach to integrate global experience into multi-agent online planning in stochastic domains to consider global effects during local planning. For this purpose, a value function is approximated online based on the emergent system behaviour by using methods of reinforcement learning.</p><p>We empirically evaluated EVADE with two statistical multi-agent online planning algorithms in a highly complex and stochastic smart factory environment, where multiple agents need to process various items at a shared set of machines. Our experiments show that EVADE can effectively improve the performance of multi-agent online planning, while offering efficiency w.r.t. the breadth and depth of the planning process.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-766" tabindex="-1" role="dialog"
         aria-labelledby="modal-766-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-766-label">[Abstract] State Abstraction Synthesis for Discrete Models of Continuous Domains</h4>
                </div>
                <div class="modal-body">
                    <pre style="margin-bottom: 0px; padding: 0px; line-height: 1.4; background-color: rgb(255, 255, 255);"><pre style="padding: 0px; margin-bottom: 0px; line-height: 1.4; background-color: rgb(255, 255, 255);"><font color="#172b4d" face="SFMono-Medium, SF Mono, Segoe UI Mono, Roboto Mono, Ubuntu Mono, Menlo, Courier, monospace"><span style="font-size: 12px;">  Reinforcement Learning (RL) is a paradigm for enabling autonomous learning
  wherein rewards are used to influence an agent's action choices in various 
  states. As the number of states and actions available to an agent increases,
  so it becomes increasingly difficult for the agent to quickly learn the
  optimal action for any given state. One approach to mitigating the detrimental
  effects of large state spaces is to represent collections of
  states together as encompassing ``abstract states".

  State abstraction itself leads to a host of new challenges for an agent. One
  such challenge is that of automatically identifying new abstractions that
  balance generality and specificity; the agent must identify both the
  similarities and the differences between states that are relevant to its
  goals, while ignoring unnecessary details that would otherwise hinder the
  agent's progress. We call this problem of identifying useful abstract states
  the Abstraction Synthesis Problem (ASP). 

  State abstractions can provide a significant benefit to model-based agents by
  simplifying their models. T-UCT, a hierarchical model-learning algorithm
  for discrete, factored domains, is one such method that leverages state
  abstractions to quickly learn and control an agent's environment. Such
  abstractions play a pivotal role in the success of T-UCT; however, T-UCT's
  solution to ASP requires a fully discrete state space.

  In this work we develop and compare enhancements to T-UCT that relax its
  assumption of discreteness. We focus on solving ASP in domains with
  multidimensional, continuous state factors, using only the T-UCT agent's
  limited experience histories and minimal knowledge of the domain's structure.
  Finally, we present a new abstraction synthesis algorithm, RCAST, and compare
  this algorithm to existing approaches in the literature. We provide the
  algorithmic details of RCAST and its subroutines, and we show that RCAST
  outperforms earlier approaches to ASP by enabling T-UCT to accumulate
  significantly greater total reward with minimal expert configuration and
  processing time.</span></font>
</pre><div><br></div></pre>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-327" tabindex="-1" role="dialog"
         aria-labelledby="modal-327-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-327-label">[Abstract] Multi-sided Advertising Markets: Dynamic Mechanisms and Incremental User Compensations</h4>
                </div>
                <div class="modal-body">
                    <p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;"><!--StartFragment-->Online advertising has motivated has motivated companies to collect vast amounts of information about users, which increasingly creates privacy concerns. </p><p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;">One way to answer these concerns is by enabling end users to choose which aspects of their private information can be collected. Based on principles suggested by Feldman and Gonen (2016), we introduce a new online advertising market model which uses information brokers to give users such control.</p><p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;">Unlike (Feldman and Gonen 2016), our model is dynamic and involves multi-sided markets where all participating sides are strategic. We describe a mechanism for this model which is theoretically guaranteed to (approximately) maximize the gain from trade, avoid a budget deficit and incentivize truthfulness and voluntary participation. As far as we know, this is the first known dynamic mechanism for a multi-sided market having these properties.</p><p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;"><br></p><p>




</p><p style="margin-bottom: 0px;">We experimentally examine and compare our theoretical results by using real world advertising bid data. The experiments suggest that our mechanism performs well in practice even in input regimes for which our theoretical guarantee is weak or meaningless.<!--EndFragment--></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-99" tabindex="-1" role="dialog"
         aria-labelledby="modal-99-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-99-label">[Abstract] A Scheduling-Based Approach to Multi-Agent Path Finding with Weighted and Capacitated Arcs</h4>
                </div>
                <div class="modal-body">
                    <p>Multi-agent path finding (MAPF) deals with the problem of finding a collision-free path for a set of agents. The agents are located at nodes of a directed graph, they can move over the arcs, and each agent has its own destination node. It is not possible for two agents to be at the same node at the same time. The usual setting is that each arc has length one so at any time step, each agent either stays in the node, where it is, or moves to one of its neighboring nodes.</p><p><br></p><p>This paper suggests to model the MAPF problem using scheduling techniques, namely, nodes and arcs are seen as resources. The concept of optional activities is used to model which nodes and arcs an agent will visit. We first describe a model, where each agent can visit each node at most once. Then, we extend the model to allow agents re-visiting the nodes.</p><p><br></p><p>The major motivation for the scheduling model of MAPF is its capability to naturally include other constraints. We will study particularly the problems, where the capacity of arcs can be greater than one (more agents can use the same arc at the same time), and the lengths of arcs can be greater than one (moving between different pairs of nodes takes different times). These extensions make the model closer to reality than the original MAPF formulation. We compare the efficiency of models experimentally.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-532" tabindex="-1" role="dialog"
         aria-labelledby="modal-532-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-532-label">[Abstract] Adversarial Task Allocation</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal">The problem of allocating tasks to workers is of
long-standing fundamental importance. Examples of this include the classical
problem of assigning computing tasks to nodes in a distributed computing
environment, as well as the more recent problem of crowdsourcing where a broad
array of tasks are slated to be completed
by human workers. Extensive research into this problem
generally addresses important issues such
as uncertainty and, in crowdsourcing, incentives. However, the problem of adversarial tampering with the task
allocation process has not received as much attention. <o:p></o:p></p><p>

</p><p class="MsoNormal">We are concerned with particular
adversarial setting in task allocation where an attacker may target a specific worker in order
to prevent the tasks assigned to this worker from being completed. &nbsp;We consider two attack models: one in which
the attacker observes the actual allocation decision, and the second in which
the adversary observes only the
allocation policy (which may be randomized). For the case when all tasks are
homogeneous, we provide efficient algorithms for both settings. When tasks are heterogeneous, however, we show the adversarial
allocation problem to be NP-Hard, Our
experiments show, surprisingly, that the difference between the level of
robustness in the two attack models is minimal: deterministic allocation can
achieve nearly as much utility as randomized.<o:p></o:p></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-442" tabindex="-1" role="dialog"
         aria-labelledby="modal-442-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-442-label">[Abstract] Near-Optimal Mechanism for Ordinal Peer Assessment</h4>
                </div>
                <div class="modal-body">
                    <p>Peer assessment serves as a major method for evaluating employee true performance, accessing the contributions of individuals within a group, making social decisions and many other scenarios.</p><p>The idea is to ask the individuals of the same group to assess the performance of others. Scores or ordering are determined based on these evaluations.</p><p>However, peer assessment can be biased and manipulated, especially when people have a conflict of interests. In this paper, we consider the problem of eliciting the underlying ordering of $n$ strategic agents with respect to their performances (e.g., quality of work, contributions, scores, etc.).</p><p>We first prove that there is no deterministic mechanism which obtains the underlying ordering in dominant-strategy implementation.</p><p>Then, we propose a \emph{Two-Stage Mechanism} in which truth-telling is the \emph{unique} strict Nash equilibrium yielding the underlying ordering, except that there is an arbitrarily small probability of the disorder between the last two agents.</p><p>Moreover, our mechanism needs only $n+1$ queries.</p><p>We prove a simple $\Omega(n)$ lower bound of query complexity for any mechanism,&nbsp;</p><p>which indicates that our mechanism is nearly optimal.</p><p>Besides, we conduct the experiments on several scenarios to demonstrate the proposed mechanism is robust.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-51" tabindex="-1" role="dialog"
         aria-labelledby="modal-51-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-51-label">[Abstract] Transformations from SARL Metamodel to Object Oriented Metamodel</h4>
                </div>
                <div class="modal-body">
                    <p>SARL is a general-purpose agent-oriented programming language.</p><p>This language aims at providing the fundamental abstractions for dealing with concurrency, distribution, interaction, decentralization, reactivity, autonomy and dynamic reconfiguration that are usually considered as essential for implementing agent-based applications.</p><p>Every programming language specifies an execution model.</p><p>In the case of SARL, this execution model is defined based upon the object-oriented paradigm, e.g. a run-time environment written in Java.</p><p>Accordingly, and by default, the SARL programs are transformed into their equivalent object-oriented programs.</p><p>The goal of this paper is the explanation of the mapping between the agent paradigm and the object-oriented paradigm, and the definition of transformations from the SARL constructs to the standard object-oriented constructs.</p><p>They enable the SARL developer understanding the SARL statements, and the mapping to executable entities.</p><p>The transformations in this paper could also serve as the basis for creating a compiler extension for targeting any object-oriented programming language.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-262" tabindex="-1" role="dialog"
         aria-labelledby="modal-262-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-262-label">[Abstract] Phase Transition of the 2-Choices Dynamics on Core-Periphery Networks</h4>
                </div>
                <div class="modal-body">
                    <p>Consider the following process on a network: Each agent initially holds either opinion <i>blue</i>&nbsp;or <i>red</i>; then, in each round, each agent looks at two random neighbors and, if the two have the same opinion, the agent adopts it. This process is known as the <i>2-Choices</i>&nbsp;dynamics and is arguably the most basic non-trivial <i>opinion dynamics</i>&nbsp;modeling voting behavior on social networks. Despite its apparent simplicity, 2-Choices has been analytically characterized only on networks with a strong expansion property - under assumptions on the initial configuration that establish it as a fast <i>majority consensus</i> protocol.&nbsp;</p><p>In this work, we aim at contributing to the understanding of the 2-Choices dynamics by considering its behavior on a class of networks with Core-Periphery structure, a well-known topological assumption in social networks. In a nutshell, assume that a densely-connected subset of agents, the <i>core</i>, holds a different opinion from the rest of the network, the <i>periphery</i>. Then, depending on the strength of the cut between the core and the periphery, a phase-transition phenomenon occurs: Either the core's opinion rapidly spreads among the rest of the network, or a <i>metastability</i>&nbsp;phase takes place, in which both opinions coexist in the network for superpolynomial time. The interest of our result is twofold. On the one hand, by looking at the 2-Choices dynamics as a simplistic model of competition among opinions in social networks, our theorem sheds light on the <i>influence</i>&nbsp;of the core on the rest of the network, as a function of the core's connectivity towards the latter. On the other hand, to the best of our knowledge, we provide the first analytical result which shows a heterogeneous behavior of a simple dynamics as a function of structural parameters of the network. Finally, we validate our theoretical predictions with extensive experiments on real networks.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-233" tabindex="-1" role="dialog"
         aria-labelledby="modal-233-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-233-label">[Abstract] Multiagent Reinforcement Learning for Coordinated Autonomous Driving</h4>
                </div>
                <div class="modal-body">
                    <p>Autonomous driving is a typical multi-agent setting where each vehicle must take into account its surrounding vehicles for taking specific driving maneuvers. Although a large number of studies have successfully applied reinforcement learning techniques in low-level control of driving maneuvers such as acceleration, deceleration and steering, or higher level of strategic decision makings such as lane changing and overtaking, little work has been done to investigate how co-existing autonomous vehicles would interact with each other and how reinforcement learning can be helpful in such situations. This paper tries to answer this question by applying multiagent reinforcement learning techniques for high-level strategic decision making of following or overtaking within a group of autonomous vehicles in highway situations. Learning in such situations is challenging due to the unique feature of vehicular mobility, which renders it infeasible to directly applying existing coordinated MARL approaches. To solve this problem, we propose two basic coordination models to enable distributed learning of coordinated maneuvers in a group of vehicles and then come up with several extended mechanisms to make these models workable in more complex and realistic settings with any number of vehicles. Experimental evaluation has verified the benefits of the proposed coordinated learning approach, compared to other approaches that learn without coordination or rely on some expert driving rules.</p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-261" tabindex="-1" role="dialog"
         aria-labelledby="modal-261-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-261-label">[Abstract] The importance of fairness in increasing the adoption of autonomous group buying agents</h4>
                </div>
                <div class="modal-body">
                    <span id="docs-internal-guid-d2508946-aaef-7f18-3c97-e51b83a8208e"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span id="docs-internal-guid-d2508946-b678-915d-c109-9681653406cd"></span></p><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:#ffffff;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;">There has been growing interest in studying how people interact with autonomous agents and how to design interfaces for autonomous agents. We are interested in the opportunity to inform such design by concepts and research methods from behavioural economics, particularly around the idea of fairness amongst people. In this paper, we report on a lab study where participants experienced how autonomous shopping prototypes facilitate group buying, and where their shopping performance (i.e. savings) was linked to their experimental reward. In particular, we compared two different design choices for autonomous group buying agents:</span><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;"> one designed around fairness, and the other around economically rational utility maximisation. Our findings revealed that a fair agent is more likely to be accepted and trusted than a rational one, suggesting that</span><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:#ffffff;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;"> including fairness in the design of autonomous agents can increase the adoption and acceptance of such technology. </span></p></span>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-609" tabindex="-1" role="dialog"
         aria-labelledby="modal-609-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-609-label">[Abstract] Architectural Middleware that Supports Building High-performance, Scalable, Ubiquitous, Intelligent Personal Assistants</h4>
                </div>
                <div class="modal-body">
                    <p>Intelligent Personal Assistants (IPAs) are software agents that can perform tasks on behalf of individuals and assist them on many of their daily activities. IPAs capabilities are expanding rapidly due to the recent advances on areas such as natural language processing, machine learning, artificial cognition, and ubiquitous computing, which equip the agents with competences to understand what users say, collect information from everyday ubiquitous devices (including not only smartphones but also wearables, tablets, personal computers, cars, clothes, household appliances, etc.), learn user preferences, deliver data-driven search results, and make decisions based on user's context. Apart from the inherent complexity of building such IPAs, there are serious architectural and technical challenges (such as low-latency, high-performance, scalability, concurrency, interoperability, code mobility, support to the heterogeneity of objects and the diversity of communication protocols, among others) that need to be addressed since they divert developers and researchers from their main goal: building IPAs. Thus, our contribution in this paper is twofold: 1) we propose a platform-agnostic multi-session architecture that alleviates the burdensome task of dealing with low-level design details when building an IPA by adding multiple abstraction layers that hide the underlying complexity; and 2) we propose a high-performance middleware which concretizes the aforementioned architecture and allows the development of high-level capabilities while scaling the system up to hundreds of thousands of IPAs with no extra effort.&nbsp; We demonstrate the powerfulness of our framework by analyzing software metrics of its complexity, size, effort, performance, cohesion and coupling when developing a conversational IPA.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-245" tabindex="-1" role="dialog"
         aria-labelledby="modal-245-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-245-label">[Abstract] Opponent Modelling of Non-Stationary Agents with Deep Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p>Humans, like all animals, both cooperate and compete with each other. Through these interactions we learn to observe, act, and manipulate to maximise our utility function, and continue doing so as others learn with us. This is a decentralised non-stationary learning problem, where to survive and flourish an agent must adapt to the gradual changes of other agents as they learn, as well as capitalise on sudden shifts in their behaviour. To learn in the presence of such non-stationarity, we introduce the Switching Agent Model (SAM) that combines traditional deep reinforcement learning -- which typically performs poorly in such settings -- with opponent modelling, using uncertainty estimations to robustly switch between multiple policies. We empirically show the success of our approach in a multi-agent continuous action environment, demonstrating SAM's ability to identify, track, and adapt to both gradual and sudden changes in the behaviour of non-stationary agents<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-36" tabindex="-1" role="dialog"
         aria-labelledby="modal-36-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-36-label">[Abstract] Modelling Multiple Influences Diffusion in On-line Social Networks</h4>
                </div>
                <div class="modal-body">
                    <p>In on-line social networks, innovations in the presence of one or more influences disseminate through the topological structure of the networks rapidly. In reality, various influences normally coexist in the same context and have subtle relations, such as supportive, contradictory and competitive relations, affecting the users' decisions of adopting any innovations. Therefore, modelling diffusion process of multiple influences is an important, yet challenging research question. By employing the agent-based modelling, in this paper, a distributed approach has been proposed to model the diffusion process of multiple influences in social networks. The proposed model has been applied in the undesirable influence minimisation problem, where the time series is taken into consideration. The experimental results show our model can be utilised to minimise the adverse impact of a certain influence by injecting other influences. Furthermore, the proposed model also sheds light on understanding, investigating and analysing multiple influences in social networks<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-101" tabindex="-1" role="dialog"
         aria-labelledby="modal-101-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-101-label">[Abstract] Gaussian process vector calculus for identifying sources and sinks in the presence of multiple agents</h4>
                </div>
                <div class="modal-body">
                    We build a model using Gaussian processes to infer a spatio-temporal field from observed agent trajectories, representing a value, or influence, function. Significant landmarks or influence points in agent surroundings are jointly derived through vector calculus operations that indicate the presence of sources and sinks in the field. We evaluate these influence points by using the Kullback-Leibler divergence between the posterior and prior Laplacian of the inferred spatio-temporal field. Through locating significant features that influence trajectories, our model aims to give greater insight into underlying causal influence functions that help explain agent decision-making. A key feature of our model is that it infers a joint Gaussian process over the observed trajectories, the time-varying field of potential functions and corresponding canonical vector calculus operators. We apply our model to both synthetic data and GPS data of pelagic seabirds, demonstrating the applicability of our technique in the presence of multiple agents.
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-244" tabindex="-1" role="dialog"
         aria-labelledby="modal-244-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-244-label">[Abstract] Design of  strategy proof market platforms with blockchain based, game theory inspired smart contracts</h4>
                </div>
                <div class="modal-body">
                    <p abp="356">Trusted collaboration without revelation of business sensitive information is a key requirement for any business to business (B2B) platform. Platforms that satisfy these requirements of trust, privacy and collaboration have been difficult to build and therefore most B2B platforms are far more limited than business to customer (B2C) platforms. Our work investigates novel ways in which ideas from game theory, blockchain and cryptography can be harnessed to enable such trusted and privacy-preserving collaborative B2B platforms. As a prototypical example of the type of problems that our work aims to address, we consider an online welfare maximizing platform involving strategic enterprise buyers and sellers. </p><p abp="356">We model, using repeated games, the strategic interactions between buyers and sellers on such a collaborative B2B platform and deduce conditions under which&nbsp; high quality offerings constitute an equilibrium. Our proposed mechanism induces honest behavior by all the players. We also show that the technology of permissioned blockchains provides an excellent way of robustly implementing the proposed mechanism on an online platform. The blockchain deploys a smart contract that implements the business logic in a given mechanism and is supported by two cryptograpically sound regulation protocols to provide trust and privacy in all the collaborations. Thus, we believe, our work is a key step in the direction of building a powerful collaborative B2B platform.<br></p><p>&nbsp;</p><p abp="356"><br abp="357"></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-360" tabindex="-1" role="dialog"
         aria-labelledby="modal-360-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-360-label">[Abstract] Facility Location with Variable and Dynamic Populations</h4>
                </div>
                <div class="modal-body">
                    <p><font face="Lucida Grande, Verdana, Arial, Helvetica, sans-serif"><span style="font-size: 13px; background-color: rgb(240, 254, 255);">Facility location is a well-studied problem in social choice literature, where agents' preferences are restricted to be singlepeaked. When the number of agents is considered as a variable (e.g., it is not observable a priori), a social choice function must be defined so that it can take any possible number of preferences as input. Furthermore, there exist cases where multiple choices must be made continuously while agents dynamically dynamically arrive/leave. Under such variable/ dynamic populations, a social choice function needs to give each agent an incentive to sincerely report her existence (e.g., participation/no-hiding). In this paper we consider facility location models with variable/dynamic populations. For a static (one-shot), variable population model, we provide a necessary and sufficient condition for a social choice function to satisfy participation, as well as truthfulness, anonymity, and Pareto efficiency. It is considered as a further restriction of median voter schemes. For a dynamic model, we first propose an online social choice function, which is optimal for the total sum of the distances between the choices in previous and current periods, among any Pareto efficient functions.We then define a generalized class of online social choice functions and compare their performance in both theoretical and experimental way.&nbsp;</span></font></p><p><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-321" tabindex="-1" role="dialog"
         aria-labelledby="modal-321-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-321-label">[Abstract] CityScope Andorra: A multi-level interactive and tangible agent-based visualization</h4>
                </div>
                <div class="modal-body">
                    <p>This study proposes a novel information visualization approach&nbsp; developed and deployed in the state of Andorra. We present a framework to analyze and represent individuals flow through a multi-level interactive and tangible agent-based visualization. The presented model, developed to simulate movement and behavior of visitors in Andorra, is embedded in the MIT CityScope framework, a Tangible User Interface platform used for civic engagement, urban development, and decision making. The model as well as other peripheral tools depicted here, were tested in concert during multiple real-life engagements.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-659" tabindex="-1" role="dialog"
         aria-labelledby="modal-659-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-659-label">[Abstract] Teaching Multiple Tasks to an RL Agent using LTL</h4>
                </div>
                <div class="modal-body">
                    <p>This paper examines the problem of how to teach multiple tasks to an agent that learns using Reinforcement Learning (RL). To this end, we propose the use of Linear Temporal Logic (LTL) as a compelling language for teaching multiple tasks to an RL agent in a manner that supports composition of learned skills. We also propose a novel algorithm that exploits LTL progression and off-policy RL to speed up learning without compromising convergence guarantees. Experiments over randomly generated Minecraft-like grids illustrate our superior performance relative to the state of the art.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-307" tabindex="-1" role="dialog"
         aria-labelledby="modal-307-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-307-label">[Abstract] Collective Schedules: Scheduling Meets Computational Social Choice</h4>
                </div>
                <div class="modal-body">
                    <p>When scheduling public works or events in a shared facility one needs to accomodate preferences of a population.&nbsp; We formalize this problem by introducing the notion of a collective schedule. We show how to extend fundamental tools from the social choice theory---the Kemeny rule and the Condorcet principle---to collective scheduling. We study the computational complexity of finding collective schedules. We also perform simulations demonstrating that optimal collective schedules can be found for instances with realistic sizes.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-695" tabindex="-1" role="dialog"
         aria-labelledby="modal-695-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-695-label">[Abstract] A Knowledge Engineering Methodology for Applications of Argumentation</h4>
                </div>
                <div class="modal-body">
                    <p>This paper proposes a general knowledge engineering methodology for developing real-life applications for dynamic decision making, expressible within Hierarchical Argumentation Frameworks (HAF). The methodology builds on a systematic analysis of application scenarios of increasing specificity. The application expert is able to express his/her preferences on the final desired outcome or behavior of the application system by considering the increasing specificity of the problem at different levels and resolving at a higher level, conflicts between arguments that appear at a lower level of specificity. The methodological process generates directly an argumentation theory that models declaratively the application at hand, with a high degree of modularity and flexibility. Several theoretical properties of the methodology, that depend only on the general properties of HAFs, are studied. An associated tool is presented and real world applications that have used our methodology and tool in different domains (i.e. data sharing, medical diagnosis support) are discussed.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-80" tabindex="-1" role="dialog"
         aria-labelledby="modal-80-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-80-label">[Abstract] Diffusion in Social Networks with Recalcitrant Agents</h4>
                </div>
                <div class="modal-body">
                    <p>The paper generalizes the standard threshold models of diffusion in social networks by introducing the notion of recalcitrant agents that are resistant to the diffusion. The focus of the paper is on a ternary influence relation between groups of agents: one group can indirectly influence another group in spite of the third group being recalcitrant. The main technical result is a sound and complete axiomatization of this relation.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-139" tabindex="-1" role="dialog"
         aria-labelledby="modal-139-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-139-label">[Abstract] ER-Agent Communication Languages and Protocol for Large-Scale Emergency Responses</h4>
                </div>
                <div class="modal-body">
                    <p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>MS</w:LidThemeOther>
  <w:LidThemeAsian>ZH-TW</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" Priority="0" SemiHidden="true"
   UnhideWhenUsed="true" Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" Priority="0" SemiHidden="true"
   UnhideWhenUsed="true" Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="0" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"/>
 </w:LatentStyles>
</xml><![endif]-->

<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin-top:0cm;
	mso-para-margin-right:0cm;
	mso-para-margin-bottom:8.0pt;
	mso-para-margin-left:0cm;
	line-height:107%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-ansi-language:MS;
	mso-fareast-language:EN-US;}
</style>
<![endif]-->



<!--StartFragment--><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;,serif;mso-fareast-font-family:
Calibri;mso-fareast-theme-font:minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA">We have introduced a new agent communication
language ​​(ER-ACL) and a corresponding protocol (ER-ACP) to be used in
multi-agent systems (MAS) to assist large-scale emergency responses as part of
an Emergency Response Communication Framework (Mobile Kit Disaster Assistance)</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;,serif;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">.
Four types of agent are assumed: victims, carers (medical &amp; social workers),
families &amp; friends, and ER-rescuers &amp; helpers (members of the public,
NGOs, government agencies etc.). The advantages of ER-ACL and ER-ACP are that
they provide a well-defined foundation to connect victims with potential
helpers, thereby enabling crowdsourcing via effective communication based on
precise semantics. The ER-ACL represents a significant extension and
specialisation of the FIPA ACL (2002)</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;,serif;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">&nbsp;for applications in emergency response scenarios now that great technical
advances have been made in telecommunication (including image and video
reporting). We have also added new message constructs from the Common Alerting
Protocol</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;,serif;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">.
In today’s uncertain world, we believe a well-managed and personalised
communication system is vital to organise unstructured resources and save
lives. Not having found one in existence to-date, we hope our efforts can help
close this gap.</span>&nbsp; &nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-270" tabindex="-1" role="dialog"
         aria-labelledby="modal-270-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-270-label">[Abstract] SSCUSM: An Improved Algorithm for Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    Instance-based methods are a class of effective algorithms for solving reinforcement learning problems. USM (Utile Suffix Memory) algorithm represents the state space from instance chains effectively, which is very beneficial to solve the reasonable Q-value of actions. However, the state space of USM is exponentially expanded and includes many redundant states. A new state space-compressed algorithm SSCUSM is presented in the paper. SSCUSM algorithm obtains the heuristic information of environments by blind exploration, improves the construction of suffix tree by limiting the maximum length of the observation-reward sequence and uses the frequency of observations to improve the efficiency of exploration. Experiment results of three well-known benchmarks show that both the efficiency and the effect have been improved a lot by SSCUSM algorithm compared to USM algorithm.
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-730" tabindex="-1" role="dialog"
         aria-labelledby="modal-730-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-730-label">[Abstract] Leveraging Observational Learning for Exploration in Bandits</h4>
                </div>
                <div class="modal-body">
                    <p>Imitation learning has been widely used to speed up learning of novice agents, by allowing them to leverage existing data from experts. In this paper, we study this problem in the context of bandits. More specifically, we consider that an agent, a learner, who is interacting with a bandit-style decision task,&nbsp; has access to a teacher, or target policy, interacting with the same environment. The learner is able to observe the actions that the teacher performs on the environment but not the rewards obtained. Our goal is to leverage the teacher data in order to guide the agent's exploration.</p><p>We propose a method that expands upon the Upper Confidence Bound algorithm by making use of conditional optimism contingent upon the actions of the teacher. We prove a regret upper-bound of order O(lnT) for problems with two-actions and derive the dependency on the expected regret of a general target policy. We provide empirical results showing both great benefits as well as certain limitations of using imitation in the multi-armed bandit setting.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-320" tabindex="-1" role="dialog"
         aria-labelledby="modal-320-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-320-label">[Abstract] Robust Deep Reinforcement Learning with Adversarial Attacks</h4>
                </div>
                <div class="modal-body">
                    <p>This paper proposes adversarial attacks for Reinforcement Learning (RL) and then improves the robustness of Deep Reinforcement Learning algorithms (DRL) to parameter uncertainties with the help of these attacks. We show that even a naively engineered attack successfully degrades the performance of DRL algorithm. We further improve the attack using gradient information of an engineered loss function which leads to further degradation in performance. These attacks are then leveraged during training to improve the robustness of RL within robust control framework. We show that this adversarial training of DRL algorithms like Deep Double Q learning and Deep Deterministic Policy Gradients leads to significant increase in robustness to parameter variations for RL benchmarks such as Cart-pole, Mountain Car, Hopper and Half Cheetah environment.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-190" tabindex="-1" role="dialog"
         aria-labelledby="modal-190-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-190-label">[Abstract] Providing Smart Emergency Responses for Small-Scale Incidents Through Agent-Based Resource Management</h4>
                </div>
                <div class="modal-body">
                    <p>In metropolitan regions, small-scale emergency incidents are characterised by their unpredictability, uncertainty and variability. Handling the emergency responses for these incidents usually require multiple emergency departments to collaborate with each other to generate efficient and effective resource allocation plans within a short time limit, which poses tremendous pressures and challenges on current emergency response systems. In this paper, an agent-based smart emergency response system is proposed to coordinate emergency departments to automatically and intelligently generate resources allocation plans to emergency incidents with the consideration of multiple objectives. In the experiment, an emergency resource allocation simulation system based on GoogleMaps is developed for testing the proposed system along with real-world rescue resource allocation data around the urban area of San Francisco.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-403" tabindex="-1" role="dialog"
         aria-labelledby="modal-403-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-403-label">[Abstract] Slim-DP: A Multi-Agent System for Communication-Efficient Distributed Deep Learning</h4>
                </div>
                <div class="modal-body">
                    <p>To afford the huge computational cost, large-scale deep neural networks (DNN) are usually trained on the distributed system, especially the widely-used parameter server architecture, consisting of a parameter server as well as multiple local workers with powerful GPU cards. During the training, local workers frequently pull the global model and push their computed gradients from/to the parameter server. Due to the limited bandwidth, such frequent communication will cause severe bottleneck for the training acceleration. As recent attempts to address this problem, quantization methods have been proposed to compress the gradients for efficient communication. However, such methods overlook the effects of compression on the model performance such that they either suffer from a low compression ratio or an accuracy drop. In this paper, to better address this problem, we investigate the distributed deep learning as a multi-agent system (MAS) problem. Specifically, 1) local workers and the parameter server are separate agents in the system; 2) the objective of these agents is to maximize the efficacy of the learned model through their cooperative interactions; 3) the strategy of the agents describes how they take actions, i.e. communicate their computed gradients or the global model, given the certain state; 4) rational agents always select the best-response strategy with the optimal utility. Inspired by this, we design a MAS approach for distributed training of DNN. In our method, the agents first estimate the utility (i.e., the benefit to help improve the model) of each action (i.e., transferring a subset of the gradients or the global model), and then take the best-response strategy based on their estimated utilities mixed with $\epsilon$-random exploration. We call our new method \emph{Slim-DP} as it, being different from the standard data-parallelism, only communicates a subset of the gradient or the global model. Our experimental results demonstrate that our proposed Slim-DP can reduce more communication cost and achieve better speedup without loss of accuracy than the standard data parallelism and its quantization version.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-746" tabindex="-1" role="dialog"
         aria-labelledby="modal-746-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-746-label">[Abstract] Fall if it lifts your team-mate: a novel type of candidate manipulation</h4>
                </div>
                <div class="modal-body">
                    <p>We present a new interpretation of the traditional computational social choice<br>framework, where what are traditionally the candidates are considered as the<br>agents.<br>The particular implementation in mind is the proposed system for determining the<br>medal winners for Sports Climbing in the 2020 Olympic games.<br>We consider how this change in interpretation of who the agents are within the<br>model affects traditional questions, in particular the issue of manipulation by<br>agents within the system.<br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-407" tabindex="-1" role="dialog"
         aria-labelledby="modal-407-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-407-label">[Abstract] Modeling Assistant&#39;s Autonomy Constraints as a Means for Improving Autonomous Assistant-Agent Design</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper we introduce and experimentally evaluate a new&nbsp; sub-optimal decision-making design to be used by autonomous agents acting on behalf of a user in repeated tasks, whenever the agent's autonomy level is continuously controlled by the user. This mode of operation is common and can be found whenever user's perception of the agent's competence is affected by the nature of the outcomes resulting from the agent's decisions rather than the optimality of the decisions made, e.g., in spam filtering, CV filtering, poker agents, and robotic vacuum cleaners as well as in newly arriving systems such as autonomous cars. Our proposed design relies on choosing the action that offers the best tradeoff between decision optimality and the influence over future allowed autonomy, where the latter is predicted using standard machine learning techniques. The design is found to be highly effective compared to following the theoretic-optimal decision rule, over various measures, through extensive experimentation with a virtual investment agent, making virtual investments on behalf of 679 subjects using Amazon Mechanical Turk.</p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-432" tabindex="-1" role="dialog"
         aria-labelledby="modal-432-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-432-label">[Abstract] An Approach for Large-Scale Online Ridesharing</h4>
                </div>
                <div class="modal-body">
                    <p>Ridesharing is a prominent collective intelligence application producing significant benefits both for individuals (reduced costs) and for the entire community (reduced pollution and traffic). We establish the online ridesharing (ORS) problem as an online stochastic combinatorial optimisation problem with the objective of forming cost-effective shared rides among commuters that submit requests to be served in a short time period (i.e., in a few minutes). We propose the first approach that can tackle large-scale ORS problems originating from real-world data (i.e., with ∼400 requests per minute). Specifically, we evaluate our approach on a real-world dataset, i.e., the New York City taxi dataset. Results show that our online approach computes solutions with an average competitive ratio of 90.9% (i.e., wrt the optimal offline solution assuming complete knowledge of the future) for problem sizes that allow to compute such an optimal solution in a feasible amount of time. On large-scale instances (i.e., when the optimal cannot be computed), our online approach provides solutions whose quality is comparable with those of our offline approach. Finally, our experiments show that our approach produces a 42% reduction in the car fleet.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-488" tabindex="-1" role="dialog"
         aria-labelledby="modal-488-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-488-label">[Abstract] Efficient Interdiction of Urban Criminals with the Aid of Real-time Information</h4>
                </div>
                <div class="modal-body">
                    <span class="fontstyle0">Most violent crimes happen in urban and suburban cities. With emerging tracking techniques, law enforcement officers can have real-time location information of the escaping criminals and dynamically adjust the security resource allocation to interdict them. Unfortunately, existing work on urban network security games ignores such information. In this context, we make several key contributions. First, we show that ignoring the real-time information can have arbitrarily large loss of efficiency. To mitigate this loss, we propose a novel </span><span class="fontstyle2">Network Pursuit Game (NEST) </span><span class="fontstyle0">model to capture the interaction between an escaping adversary and a defender with real-time information available. Second, solving NEST is proven to be NP-hard. Third, to overcome the complexity barrier, several novel algorithms are provided, including (i) the </span><span class="fontstyle2">ﬂow representation </span><span class="fontstyle0">of the defender strategy which transforms the non-convex optimization to a linear program, and (ii) an iterative algorithm to repeatedly solve the restricted NEST with smaller scale and output the optimal solution. Fourth, to further improve the scalability, we propose a heuristic approach which solves a restricted NEST with only actions towards exit nodes and min-node-cut. Finally, extensive experimental evaluation shows that our solution significantly outperforms baselines in pursuit quality and can scale up to realistic-sized instances</span>&nbsp;.
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-60" tabindex="-1" role="dialog"
         aria-labelledby="modal-60-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-60-label">[Abstract] A Site-Push Based Majority Winner Monitoring Algorithm for Distributed Elections</h4>
                </div>
                <div class="modal-body">
                    <p><br></p><div>The problem of distributed election majority-winner monitoring for 
checkpoint-based protocols has been under discussion from some time now,
 and the approach that most of the major algorithms have taken in this 
is the center-based pull from all voting sites
in conjunction with a count-tracker, to continually monitor the 
information about the incoming voter stream.&nbsp; This article presents an 
alternative solution to this problem, using site-based voter information
 push to the center, to reduce the communication complexity,
using a unique sampling technique.&nbsp; This technique is utilized to come 
up with a winner or an approximate winner with very high probability for
 Approval-based and Scoring-based rules.</div><div><br></div><div>The site-push based algorithm introduced here has been validated 
with correctness results, and has also been analyzed for different 
scenarios to prove the improvement in the number of communication units 
initiated, in comparison to the center based pull
algorithm considered for a checkpoint-based protocol by Filtser and 
Talmon [17].&nbsp; The effect of this algorithm is 
to reduce the communication complexity by a factor of 
$(1+\frac{\log{k}}{\log{\frac{n}{k}}})$ in comparison to the center-pull
algorithm (where $k$ is the number of voting sites, and $n$ the number 
of voters), which can be significant as $k &lt;&lt; n$.&nbsp; Also, to 
realize more realistic scenarios, simulation results are presented to 
show how the algorithm fares under a randomized voter assignment
scenario, with variations of the value of total voters, total sites and 
$\epsilon$.</div><p><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-65" tabindex="-1" role="dialog"
         aria-labelledby="modal-65-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-65-label">[Abstract] Repeated win-lose coordination games</h4>
                </div>
                <div class="modal-body">
                    <p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;">We study repeated win-lose coordination games and analyse when they are 'solvable' without preplay communication on the given game amongst the players. We identify classes of coordination games in which coordination cannot be guaranteed in a single round by rational reasoning only, but can eventually be achieved in several rounds by following various coordination principles. In particular, we study coordination under some natural assumptions, including, inter alia, priority hierarchies amongst players, different patience thresholds and invariance of strategies under structural symmetries of games.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-649" tabindex="-1" role="dialog"
         aria-labelledby="modal-649-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-649-label">[Abstract] How to Stop Violence among Homeless: Extensions to Voter Model and Intervention Strategies</h4>
                </div>
                <div class="modal-body">
                    <p>Violence is a phenomenon that severely impacts homeless youth who are at an increased risk of experiencing it as a result of many contributing factors such as traumatic childhood experiences, involvement in delinquent activities and exposure to perpetrators due to street-tenure. Reducing violence in this population is necessary to ensure that the individuals can safely and successfully exit homelessness and lead a long productive life. Interventions to reduce violence in this population are difficult to&nbsp; implement due to the its complex nature. However, a peer-based intervention approach would likely be a worthy approach as previous research has shown that individuals who interact with more violent individuals are more likely to be violent, suggesting a contagious nature of violence. We propose Uncertain Voter Model to represent the complex process of diffusion of violence over a social network, that captures uncertainties in links and time over which the diffusion of violence takes place. Assuming this model, we define Violence Minimization problem where the task is to select a predefined number of individuals for intervention so that the expected number of violent individuals in the network is minimized over a given time-frame. We also extend the problem to a probabilistic setting, where the success probability of converting an individual into non-violent is a function of the number of ``units'' of intervention performed on her. We provide algorithms for finding the optimal intervention strategies for both scenarios. We demonstrate that our algorithms perform significantly better than interventions based on popular centrality measures in terms of reducing violence.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-503" tabindex="-1" role="dialog"
         aria-labelledby="modal-503-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-503-label">[Abstract] Coordination of Electric Vehicle Aggregators: A Coalitional Approach</h4>
                </div>
                <div class="modal-body">
                    <p style="margin-bottom: 0px;"><span style="white-space: pre-wrap;">Given the rapid rise of electric vehicles (EVs) worldwide, and the ambitious targets set for the near future, the smart charging of an EV fleet must be seen as a priority. Specifically, we study a scenario where EV charging is managed through self-interested EV aggregators (e.g. car parks or electricity suppliers) who compete in the day-ahead market in order to purchase the electricity needed to meet their clients' requirements. In order to reduce electricity costs and lower the impact on electricity markets, we study the possibility of inter-aggregator cooperation. Specifically, we model the system as a coalitional game and prove that the resulting game is superadditive and balanced, hence having a non-empty core. However, due to the game not being convex, the Shapley value is not guaranteed to lie in the core. As an alternative, we propose employing the payment mechanism provided by the least-core, which we show to be in the core in our setting. Furthermore, a realistic empirical evaluation is presented, using real market and driver data from the Iberian Peninsula. The simulations show that large payment reductions can be achieved when using the coordination mechanism. Moreover, we show that the individual payments of the least-core are very close to the Shapley value, suggesting that the payment mechanism is both fair and stable.</span><br></p><p style="margin-bottom: 0px;"><!--EndFragment--></p><p style="margin-bottom: 0px;"><!--EndFragment--></p><p style="margin-bottom: 0px;"><!--EndFragment--></p><p style="margin-bottom: 0px;"><!--EndFragment--></p><p style="margin-bottom: 0px;"><!--EndFragment--></p><p style="margin-bottom: 0px;"><!--EndFragment--></p><p style="margin-bottom: 0px;"><!--EndFragment--></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-634" tabindex="-1" role="dialog"
         aria-labelledby="modal-634-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-634-label">[Abstract] Fairness in multiagent resource allocation with dynamic and partial observations</h4>
                </div>
                <div class="modal-body">
                    <p><span style="font-family: Helvetica; font-size: 12px; text-size-adjust: auto;">We investigate fairness issues in distributed resource allocation of indivisible goods. While the notion of envy-freeness has been widely studied to assess the fairness of a multi-agent resource allocation, it is usually computed in a centralized way and assumes perfect knowledge of the whole allocation. In this paper, we consider distributed allocation protocols where each agent has limited visibility of the other agents. Starting &nbsp;from a situation where each agent has (the same) number of items, and completely ignores how the rest of the resources are allocated, pairwise encounters occur as the result of the agents' decisions.</span><br style="font-family: Helvetica; font-size: 12px; text-size-adjust: auto;"><span style="font-family: Helvetica; font-size: 12px; text-size-adjust: auto;">As they do so, agents both observe the bundle currently held by the other agent, and try to agree on rational deals (swaps). Hence, agents have a partial and uncertain view of the entire allocation, that they maintain throughout the process, and which allows them to have different estimates of their envy.</span><br style="font-family: Helvetica; font-size: 12px; text-size-adjust: auto;"><span style="font-family: Helvetica; font-size: 12px; text-size-adjust: auto;">We provide a fully distributed protocol allowing to guarantee termination despite the limited knowledge of agents, and study some of its properties. We furthermore investigate experimentally the performance of this system, testing in particular several heuristics governing agents' decision-making both at the agent's selection and bilateral negotiation stage.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-374" tabindex="-1" role="dialog"
         aria-labelledby="modal-374-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-374-label">[Abstract] Enhanced Delta-tolling:  Traffic Optimization via Policy Gradient Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p>The prospect of widespread deployment of autonomous vehicles invites the reimagining of the multiagent systems protocols that govern traffic flow in our cities.&nbsp; One such possibility is the introduction of micro-tolling for fine-grained traffic flow optimization.&nbsp; In the micro-tolling paradigm, different toll values are assigned to different links within a congestable traffic network. Self-interested agents then select minimal cost routes, where cost is a function of the travel time and tolls paid. A centralized system manager sets toll values with the objective of inducing a user equilibrium that maximizes the total utility over all agents. A recently proposed algorithm for computing such tolls, denoted Delta-tolling, was shown to yield up to 32% reduction in total travel time in simulated traffic scenario compared to when there are no tolls. Delta-tolling includes two global parameters: 'beta' which is a proportionality parameter, and 'R' which influences the rate of change of toll values across all links. This paper introduces a generalization of Delta-tolling which allows different 'beta' and 'R' values on each link in the network.&nbsp; While this Enhanced Delta-tolling algorithm requires setting significantly more parameter, we show that they can be tuned effectively via policy gradient reinforcement learning. Experimental results from several traffic scenarios indicate that Enhanced Delta-tolling reduces total travel time by up to 49% compared to the original Delta-tolling algorithm, and by up to 111% compared to no tolling.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-514" tabindex="-1" role="dialog"
         aria-labelledby="modal-514-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-514-label">[Abstract] Towards the Mirror World: Mixed Reality Knowledge Representation for Context-Aware Agents</h4>
                </div>
                <div class="modal-body">
                    <p>In order to act intelligently within real world scenarios, which are shared by agents and humans and are subject to constant change, an agent requires a great amount of contextual knowledge. To achieve this, we propose a <i>Mirror World</i> metaphor which combines smart and virtual environments. The <i>Mirror World</i> serves as a real-time mixed reality knowledge representation and visualization for single and multiagent systems, providing tools to infer knowledge at runtime. Both physical and virtual sensors provide data which is processed by a semantics-based rule system. A coupled 3D game engine constitutes the capability for spatial and physical reasoning. Combined, these techniques provide a continuum of knowledge, ranging from low-level sensory data to high-level semantic facts. In this contribution, we present the concept behind the <i>Mirror World</i> and its implementation. Our system aims at being 1) flexible enough to adapt to dynamic changes, 2) easily expandable for developers to adjust to new domains, and 3) transparent and comprehensible for users. In line with our aims, we examine our system in a three staged evaluation: from the perspectives of the system, the developer, and the user.<br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-63" tabindex="-1" role="dialog"
         aria-labelledby="modal-63-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-63-label">[Abstract] Fairly Dividing a Cake after Some Parts Were Burnt in the Oven</h4>
                </div>
                <div class="modal-body">
                    <p>There is a heterogeneous resource that contains both good parts and bad parts, for example, a cake with some parts burnt, a land-estate with some parts heavily taxed, or a chore with some parts fun to do. The resource has to be divided fairly among n agents, each of whom has a personal value-density function on the resource. The value-density functions can accept any real value --- positive, negative or zero. Can standard cake-cutting procedures, developed for positive valuations, be adapted to this setting? This paper focuses on the question of envy-free cake-cutting with connected pieces. It is proved that such a division exists for 3 agents. <br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-96" tabindex="-1" role="dialog"
         aria-labelledby="modal-96-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-96-label">[Abstract] An Argumentation-based Conversational Recommender System for Recommending Learning Objects</h4>
                </div>
                <div class="modal-body">
                    <p style="margin-bottom: 0px; font-stretch: normal; font-size: 12px; line-height: normal; font-family: &quot;Helvetica Neue&quot;;">With the current proliferation of online learning resources, many students have much more information available than they can consume in an efficient way.&nbsp;</p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 12px; line-height: normal; font-family: &quot;Helvetica Neue&quot;;">Consequently, students do not always find adaptive learning material for their needs and preferences. In this paper, we present an argumentation-based Conversational Educational Recommender System (C-ERS), which helps students to find the more suitable learning resources considering their learning objectives and profile.&nbsp;</p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 12px; line-height: normal; font-family: &quot;Helvetica Neue&quot;;">The recommendation process is based on an argumentation-based technique, which selects those learning objects (LOs) for which it is able to generate a greater number of arguments justifying their suitability. Our system includes a simple and intuitive communication interface with the user that provides an explanation to any recommendation.&nbsp;</p><p style="margin-bottom: 0px; font-stretch: normal; font-size: 12px; line-height: normal; font-family: &quot;Helvetica Neue&quot;;">This allows the user to interact with the system and accept or reject the recommendations, providing reasons for such behavior. In this way, the user is able to inspect the system's operation and understand the recommendations, while the system is able to elicit the actual preferences of the user. The system has been tested online with a real group of undergraduate students in the Universidad Nacional de Colombia, showing promising results.</p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-287" tabindex="-1" role="dialog"
         aria-labelledby="modal-287-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-287-label">[Abstract] Probably Almost Stable Strategy Profiles in Simulation-Based Games</h4>
                </div>
                <div class="modal-body">
                    <p>Empirical studies of strategic settings commonly model player interactions under supposed game-theoretic equilibrium behavior, as a way of predicting what outcomes would result among rational agents. But in sufficiently complex settings, analysts cannot solve for exact equilibria, and may resort to solving a restricted game where agents are limited to a tractable subset of strategies. This provides a solution, but one with unclear strategic stability in the original game. We propose a search and evaluation method that can guarantee a well-defined strategic stability property in the profile that it yields, even if only a small subset of possible strategies in a game have been analyzed. The method achieves this result by combining statistical confidence interval estimation, a multiple test correction, and empirical game-theoretic analysis. We demonstrate efficacy in two example settings: the first-price sealed-bid auction, and a cybersecurity game.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-231" tabindex="-1" role="dialog"
         aria-labelledby="modal-231-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-231-label">[Abstract] Model Checking Multi-Agent Systems against LDLK Specifications on Finite Traces</h4>
                </div>
                <div class="modal-body">
                    <p>We introduce the logic LDL f K, a variant of the epistemic logic LDLK, interpreted on finite traces of multi-agent systems. We explore the verification problem of multi-agent systems against LDL f K specifications and give algorithms for the reduction of LDL f K model checking to LDLK verification on a different model and different specification. We analyse the resulting complexity and show it to be PSPACE-complete. We report on a full implementation of the algorithm and assess its performance on a number of examples.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-540" tabindex="-1" role="dialog"
         aria-labelledby="modal-540-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-540-label">[Abstract] Generating Sensor Events using Agent-based Simulation of Smart Home</h4>
                </div>
                <div class="modal-body">
                    <p>Smart Homes are currently one of the hottest topic on the market of sensor systems, IoT, augmented living, embedded AI. Yet, for really providing high-level intelligent solutions, algorithms are needed to detect what the human inhabitant's current activity is, what she intends to do, even how many persons are in the home. Based on that intelligent control and planning can be developed to support human activity in many ways. One of the major reasons why the development of such tools is not proceeding as much as&nbsp; expected and Smart Home applications remain on the level of simple systems with more or less direct feedback loops, is the lack of publicly available data to test and train such algorithms.<br>In this contribution we present concepts and solutions for generating high-quality data using a flexible agent-based simulation tool. Hereby, we integrate the simulation of a sensorized apartment with human behaviour modelling. Out of the many options for capturing human activities, we selected an intelligent, constraint-based planning approach for producing a sequence of daily activities of a human inhabitant. The overall set-up is shown to produce data that exhibits the same relevant properties like a comparable real-world scenario and thus can be used replacing expensive data collection campaigns.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-561" tabindex="-1" role="dialog"
         aria-labelledby="modal-561-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-561-label">[Abstract] An Operational Semantics for a Fragment of PRS</h4>
                </div>
                <div class="modal-body">
                    <p>The Procedural Reasoning System (PRS) was arguably the first implementation
of the Belief–Desire–Intention (BDI) approach to programming
autonomous agents. PRS remains extremely influential,
directly or indirectly inspiring the development of many subsequent
BDI-based agent programming languages. Many of these “successor
languages” implement only a subset of the features supported by
PRS. However, perhaps surprisingly given its centrality in the BDI
paradigm, PRS lacks a formal operational semantics, which makes
it difficult to determine the expressive power of PRS relative to other
BDI-based agent programming languages. In this paper, we take a
first step towards closing this gap, by giving a formal semantics for a
significant fragment of PRS. We prove key properties of the semantics
relating to PRS-specific programming constructs, and show that
even the fragment of PRS we consider is strictly more expressive
than the plan constructs found in typical BDI languages.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-687" tabindex="-1" role="dialog"
         aria-labelledby="modal-687-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-687-label">[Abstract] Crossmodal Attentive Skill Learner</h4>
                </div>
                <div class="modal-body">
                    <p>This paper introduces the Crossmodal Attentive Skill Learner (CASL), integrated with the recently-introduced Asynchronous Advantage Option-Critic (A2OC) architecture to enable hierarchical reinforcement learning across multiple sensory inputs. We provide concrete examples where the approach not only improves performance in a single task, but accelerates transfer to new tasks. We demonstrate the attention mechanism anticipates and identifies useful latent features, while filtering irrelevant sensor modalities during execution. We modify the Arcade Learning Environment to support audio queries, and conduct evaluations of crossmodal learning in the Atari games H.E.R.O. and Amidar. Finally, building on the recent work of Babaeizadeh et al. (2016), we open-source a fast hybrid CPU-GPU implementation of CASL.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-381" tabindex="-1" role="dialog"
         aria-labelledby="modal-381-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-381-label">[Abstract] End-to-End Influence Maximization in the Field</h4>
                </div>
                <div class="modal-body">
                    <p>This work is aims to overcome the challenges in deploying influence maximization to support community driven interventions. Influence maximization is a crucial technique used in preventative health interventions, such as HIV prevention amongst homeless youth. Drop-in centers for homeless youth train a subset of youth as peer leaders who will disseminate information about HIV through their social networks. The challenge is to find a small set of peer leaders who will have the greatest possible influence. While many algorithms have been proposed for influence maximization, none can be feasibly deployed by a service provider: existing algorithms require costly surveys of the entire social network of the youth to provide input data, and high performance computing resources to run the algorithm itself. Both requirements are crucial bottlenecks to widespread use of influence maximization in real world interventions.</p><p>To address the above challenges, this innovative applications paper introduces the CHANGE agent for influence maximization. CHANGE handles the end-to-end process of influence maximization, from data collection to peer leader selection. Crucially, CHANGE only surveys a fraction of the youth to gather network data and minimizes computational cost while providing comparable performance to previously proposed algorithms. We carried out a pilot study of CHANGE in collaboration with a drop-in center serving homeless youth in a major U.S. city. CHANGE surveyed only 18\% of the youth to construct its social network. However, the peer leaders it selected reached just as many youth as previously field-tested algorithms which surveyed the entire network. This is the first real-world study of a network sampling algorithm for influence maximization. Simulation results on real-world networks also support our claims.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-211" tabindex="-1" role="dialog"
         aria-labelledby="modal-211-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-211-label">[Abstract] Cognitive Agent Models for Major Depression and its Treatment by Adaptive Temporal-Causal Networks</h4>
                </div>
                <div class="modal-body">
                    <p class="Abstract"><span lang="EN-US">This paper presents neurologically inspired cognitive
agent models for the field of Major Depressive Disorder. These cognitive agent
models are based on an (adaptive) temporal-causal network modelling approach
incorporating a dynamic perspective on mental states and causal relations. First
a basic cognitive agent model shows differences of mental states and their
connections between healthy subjects and those suffering Major Depression
Disorder. Next an adaptive temporal-causal network modelling approach is used
to address how a Deep Brain Stimulation treatment used for this disorder can
have its effect by a Hebbian learning effect. The models have turned out to
produce simulation patterns as are expected from the literature. Moreover
verification by mathematical analysis has shown correctness with respect to the
formal mathematical specifications.<o:p></o:p></span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-418" tabindex="-1" role="dialog"
         aria-labelledby="modal-418-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-418-label">[Abstract] A Structural Approach to Activity Selection</h4>
                </div>
                <div class="modal-body">
                    <p>The general task of finding an assignment of agents to activities under certain stability and rationality constraints has led to the introduction of two prominent problems in the area of computational social choice: Group Activity Selection (GASP) and Stable Invitations (SIP). In the former, we are given a set of agents with preference lists and the task is to assign these to certain distinct activities; in the latter there is only a single activity to assign to, but agents have friends and enemies which provide additional restrictions on valid assignments. Here we introduce and study the Comprehensive Activity Selection Problem, which naturally generalizes both of these problems: it is equivalent to SIP extended to more than 1 activity, and also equivalent to GASP with the addition of information about friends and enemies of agents.<br><br>We study CAS through the lens of the parameterized complexity paradigm, which has already been employed for SIP and GASP. In particular, previous work has focused nearly exclusively on parameterizing by the solution size (i.e., the number of assigned agents), and a number of mostly negative results have been obtained already for these less general problems. Instead of solution size, here we focus on parameters which capture the complexity of agent-to-agent interactions. Our results include a comprehensive complexity map for CAS under various restrictions on the number of activities in combination with restrictions on the complexity of agent interactions (measured by well-established graph parameters such as treewidth). We conclude with a fixed-parameter algorithm which exploits the sparsity of agent interactions to circumvent negative results obtained in previous work on SIP.<br><br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-647" tabindex="-1" role="dialog"
         aria-labelledby="modal-647-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-647-label">[Abstract] Representing and deriving explicit agent expectations</h4>
                </div>
                <div class="modal-body">
                    <p>Expectations can be viewed as hopeful waiting rather than mere predictions or forecasts about future states and events. When an agent has an expectation, it has a set of beliefs about the future along with a preference for one state of affairs over another. If agents are to reason about their expectations and those of others, then there is a benefit to making those expectations explicit, so that they may be monitored for fulfilment or expiry, and communicated to other agents so that mutual expectations can be formed. Monitoring requires being able to express expectations in a particular way, in terms of the observable events in a system. In this paper, we present an agent architecture for creating and updating explicit expectations. We propose an events-based model for agent expectations and introduce the concepts of abstract expectations, those not tied to a specific situation, and active expectations, which are triggered by specific events.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-436" tabindex="-1" role="dialog"
         aria-labelledby="modal-436-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-436-label">[Abstract] Learning to Schedule Deadline- and Agent-Sensitive Tasks</h4>
                </div>
                <div class="modal-body">
                    The centralized allocation of deadline sensitive tasks to agents is a difficult optimization problem. The problem becomes even more difficult when tasks arrive dynamically and each task has different requirements and valuation. This problem is essential to&nbsp; collaboration of dynamic agent teams. We present an online machine-learning-based algorithm which learns to rank the possible task allocations with the objective of maximizing the obtained value from completed tasks.
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-34" tabindex="-1" role="dialog"
         aria-labelledby="modal-34-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-34-label">[Abstract] An Empirical Game-Theoretic Analysis of the One-Day Ad Exchange Game</h4>
                </div>
                <div class="modal-body">
                    <p style="text-align: justify; "><font face="Open Sans, Arial, sans-serif">We introduce the one-day advertisement exchange (one-day AdX) game,&nbsp;</font><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">where agents play the role of ad networks competing in an&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">ad exchange for advertisement display opportunities needed to fulfill contracts&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">(i.e., advertising campaigns) from advertisers (e.g., retailers).&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">We perform an extensive empirical game-theoretical analysis&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">when many agents play two types of strategies in this game:&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">one in which an agent computes an approximate&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">Walrasian equilibrium of the combinatorial market induced by&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">the game, and bids accordingly;&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">and a natural heuristic we call the Waterfall in which&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">an agent simultaneously computes an allocation and bids by simulating the many&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">second-price auctions that unfold in the game.</span></p><p style="text-align: justify; "><font face="Open Sans, Arial, sans-serif">Our analysis is restricted to the case in which agents play only pure&nbsp;</font><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">strategies, a natural consideration in settings such as ours where agents&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">implement heuristic strategies and commit to them for some period of time.&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">Since a Nash equilibrium in pure strategies need not exist, we adopt&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">sink equilibria of the best-response graph associated with the game as our solution&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">concept, and present a simple sampling heuristic to efficiently compute&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">these equilibria. We demonstrate in a wide range of experimental&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">settings that our sampling procedure produces stable equilibria for this game.</span></p><p style="text-align: justify; "><font face="Open Sans, Arial, sans-serif">Then, having solved the game, we turn to the&nbsp;</font><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">empirical mechanism design question of how to set a reserve price to&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">maximize the market maker's (i.e., the exchange's) revenue, in light&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">of the fact that agents can change their behavior (and consequently, the&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">equilibria) in response to a change in the reserve price. We demonstrate&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">in extensive experiments that our methods are capable of identifying not&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">only sink equilibria for a given reserve,&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">but also a revenue-maximizing reserve price at the same time,&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">thereby finding a total equilibrium, i.e., an equilibrium between the players and&nbsp;</span><span style="font-family: &quot;Open Sans&quot;, Arial, sans-serif;">the market maker.</span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-404" tabindex="-1" role="dialog"
         aria-labelledby="modal-404-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-404-label">[Abstract] Efficient Mechanisms for Peer Grading and Dueling Bandits</h4>
                </div>
                <div class="modal-body">
                    <p>Many scenarios in our daily life require us to infer some ranking over items or people based on limited information. In this paper, we consider two such scenarios, one for ranking student papers in massive online open courses and one for identifying the best player (or team) in sports tournaments. For the peer grading problem, we design a mechanism with a new way of matching graders to papers. This allows us to aggregate partial rankings from graders into a global one, with an accuracy rate matching the best in previous works, but with a much simpler analysis. For the winner selection problem in sports tournaments, we cast it as the well-known dueling bandit problem and identify a new measure to minimize: the number of parallel rounds, as one normally would not like a large tournament to last too long. We provide mechanisms which can determine the optimal or an almost optimal player in a small number of parallel rounds and at the same time using a small number of competitions.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-719" tabindex="-1" role="dialog"
         aria-labelledby="modal-719-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-719-label">[Abstract] Bi-Directional Information Exchange in Decentralized Schedule-Driven Traffic Control</h4>
                </div>
                <div class="modal-body">
                    <span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px;">Recent work in decentralized, schedule-driven traffic control has demonstrated the ability to improve the efficiency of traffic flow in complex urban road network. In this approach, a scheduling agent is associated with each intersection. Each agent senses the traffic approaching its intersection and in real-time constructs a schedule that minimizes the cumulative wait time of vehicles approaching the intersection over the current look-ahead horizon. In order to achieve network level coordination in a scalable manner, scheduling agents communicate only with their direct neighbors. Each time an agent generates a new intersection schedule it communicates its expected outflows to its downstream neighbors as a prediction of future demand and these outflows are appended to the downstream agent’s locally perceived demand. In this paper, we extend this basic coordination protocol to additionally incorporate the complementary flow of information reflective of an intersection’s current congestion level to its upstream neighbors. We present an asynchronous decentralized algorithm for updating intersection schedules and congestion level estimates based on these bi-directional information flows. By relating this algorithm to the self-optimized decision making of basic protocol, we are able to approach network-wide optimality and reduce the inefficiency due to strictly self-interested intersection control decisions.</span>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-661" tabindex="-1" role="dialog"
         aria-labelledby="modal-661-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-661-label">[Abstract] Investigating the Impact of Rationality in an Agent-Based Model of the Electricity Market</h4>
                </div>
                <div class="modal-body">
                    <p>We extend an existing agent-based model of the Italian electricity market. In that model, the agents determine their strategies thanks to a genetic algorithm. One of the particularities of the model is that it assumes all the power plants of a generating company, which are situated in the same zone and which use the same technology, to use the same strategy. We show that relaxing such hypothesis does not worsen the quality of the results. We show that the new "relaxed" model is a correct generalization of the existing model we extend.<br>We compare it to a baseline model where the agent’s economical rationality is implemented through a Monte Carlo method. Finally, we show that replacing the genetic algorithm with particle swarm optimization increases the accuracy of the model.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-509" tabindex="-1" role="dialog"
         aria-labelledby="modal-509-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-509-label">[Abstract] Group Activity Selection parameterized by the Number of Agent Types</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we study the parameterized complexity of GASP and its variant gGASP w.r.t. the number of different agent types as a parameter. We show that GASP can be solved in polynomial time if the number of agent types is constant and complement this result with a strong parameterized hardness result, showing that GASP is unlikely to be fixed-parameter tractable even when combining this parameter with the number of activities. In the case of gGASP we provide an even stronger hardness result showing that gGASP is unlikely to be fixed-parameter tractable parameterized by the number of agent types, the number of activities, and the vertex cover number of the network. This nicely complements (and resolves an open question) the result of Gupta et al. [SAGT 17] showing that gGASP is fixed-parameter tractable parameterized by the number of activities if the network has constant treewidth.<br><br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-240" tabindex="-1" role="dialog"
         aria-labelledby="modal-240-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-240-label">[Abstract] SILC: Smoother Imitation with Lipschitz Costs</h4>
                </div>
                <div class="modal-body">
                    <p>One of the difficulties in building a reinforcement learning agent is specifying an appropriate reward function to capture the requirements of a task. One approach for overcoming this difficulty is Imitation Learning, where the agent learns to solve a task by imitating an expert's behaviour. Generative Adversarial Imitation Learning (GAIL) presents a specific approach to the task of imitating an expert by jointly modelling the environment's reinforcement signal and the imitating agent's policy. GAIL provides state-of-the-art results in imitating complex behaviours in large, high dimensional environments. However, the algorithm often suffers from instability during the training and high variance in the returns and the trajectories. In this work, we propose SILC, a GAIL-like framework for learning smoother imitation and achieving consistently meaningful learning gradients. By smoother imitation, we mean that the learned policies and hence, the trajectories are smooth. SILC constrains the cost functions to be Lipschitz continuous, which in turn, results in learning a policy which minimizes the Wasserstein distance between the agent's and the expert's policies. Smooth intermediate costs induce smoothness in the policy space with respect to the input, a claim that we prove theoretically and empirically. The learned policy also achieves better performance than the existing methods in terms of closeness to the expert trajectories and the value of the true returns. We propose metrics to evaluate for the better imitation of the expert and the smoothness of the learned policies. We empirically evaluate the algorithm on simulated continuous control tasks from MuJoCo.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-102" tabindex="-1" role="dialog"
         aria-labelledby="modal-102-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-102-label">[Abstract] Limited Knowledge Prediction of Financial Timeseries</h4>
                </div>
                <div class="modal-body">
                    <p>We perform an empirical investigation about how simulated annealing and agent based simulation, as implemented in the L-FABS system, can model financial time series under two main experimental setups: without knowing the previous day value and with access to it. Goal of the reported case study is to show how a machine learning system can exploit significant information about a time series and how the exploitation will reduce the approximation error rate.<br>The reported experiments are performend on the Nasdaq Composite Index and on the SPDR Silver Trust timeseries.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-334" tabindex="-1" role="dialog"
         aria-labelledby="modal-334-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-334-label">[Abstract] Local Wealth Redistribution Promotes Cooperation in Multiagent Systems</h4>
                </div>
                <div class="modal-body">
                    <p>Designing mechanisms that promote cooperation in Multiagent Systems has been a long-lasting goal in artificial intelligence. The task is especially challenging when agents are selfish, lack common goals and face social dilemmas, i.e., situations in which individual interest conflicts with social welfare. Past works explored mechanisms that explain cooperation in biological and social systems, providing important clues for the aim of designing cooperative artificial societies. In particular, several works show that cooperation is able to emerge when specific network structures underlie agents' interactions. Notwithstanding, social dilemmas in which defection is highly tempting still lack mechanisms that allow cooperation to be effectively sustained. Here we propose a new redistribution mechanism that can be applied in structured populations of agents. Importantly, we show that, when implemented locally (i.e., agents share a fraction of their wealth surplus with their nearest neighbors), redistribution excels in promoting cooperation under regimes where, before, only defection prevailed.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-171" tabindex="-1" role="dialog"
         aria-labelledby="modal-171-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-171-label">[Abstract] Recognising Assumption Violations in Autonomous Systems Verification</h4>
                </div>
                <div class="modal-body">
                    <p>When applying formal verification to a system that interacts with<br>the real world we must use a model of the environment. This model<br>represents an abstraction of the actual environment, but is necessarily incomplete and hence presents an issue for system verification.<br>If the actual environment matches the model, then the verification<br>is correct; however, if the environment falls outside the abstraction<br>captured by the model, then we cannot guarantee that the system<br>is well-behaved. A solution to this problem consists in exploiting<br>the model of the environment for statically verifying the system’s<br>behaviour and, if the verification succeeds, using it also for validating the model against the real environment via runtime verification.<br>The paper discusses this approach and demonstrates its feasibility<br>by presenting its implementation on top of a framework integrating<br>the Agent Java PathFinder model checker. Trace expressions are<br>used to model the environment for both static formal verification<br>and runtime verification.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-138" tabindex="-1" role="dialog"
         aria-labelledby="modal-138-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-138-label">[Abstract] A Near-Optimal Node-to-Agent Mapping Heuristic for GDL-based DCOP Algorithms in Multi-Agent Systems</h4>
                </div>
                <div class="modal-body">
                    Distributed Constraint Optimization Problems (DCOPs) can be used
to model a number of multi-agent coordination problems. The conventional DCOP model assumes that the subproblem that each agent
is responsible for (i.e. the mapping of nodes in the constraint graph
to agents) is part of the model description. While this assumption is
often reasonable, there are many applications where there is some
ﬂexibility in making this assignment. In this paper, we focus on
this gap and make the following contributions: (1) We formulate
this problem as an optimization problem, where the goal is to fnd
an assignment that minimizes the completion time of the DCOP
algorithm (e.g. Action-GDL or Max-Sum) that operates on this mapping. (2) We propose a novel heuristic, called MNA, that can be
executed in a centralized or decentralized manner. (3) Our empirical evaluation illustrates a substantial reduction in completion time,
ranging from 16% to 40%, without affecting the solution quality of
the algorithms, compared to the current state-of-the-art. In addition,
we observe empirically that the completion time obtained from our
approach is near-optimal; it never exceeds more than 10% of what
can be achieved from the optimal node-to-agent mapping.
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-230" tabindex="-1" role="dialog"
         aria-labelledby="modal-230-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-230-label">[Abstract] Hedonic games with multiple solution concepts</h4>
                </div>
                <div class="modal-body">
                    <p>In multi-agent systems, agents must decide with whom to cooperate, knowing that all of them prefer some agents over some others. This problem is called hedonic game where agents seek to form stable coalitions. To this end, a solution concept characterizes the stability of outcomes with respect to the agents' preferences, and expresses an a priori about the behaviour of all agents. For instance, Nash stability models agents which join the coalitions they prefer without any considerations about the other agents' preferences. However, in the some games, we might have both individualistic agents with Nash stable behaviour and more respectful agents which deviates if, and only if, it is accepted by the other agents. Thus, in this article, we propose a new model of hedonic games where agents are heterogeneous in their way to form stable coalitions. We define a specific solution concept for this game and provide some properties and complexity results. Then, we extend this model to agents which express preferences both on coalitions and on sets of solution concepts. We define a last solution concept, leximax stability, to characterize stable solution in such games.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-380" tabindex="-1" role="dialog"
         aria-labelledby="modal-380-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-380-label">[Abstract] Learning Agents in Financial Markets: Consensus Dynamics on Volatility</h4>
                </div>
                <div class="modal-body">
                    <p>Black-Scholes (BS) is the standard mathematical model for European option pricing in financial markets. Option prices are calculated using an analytical formula whose main inputs are strike (at which price to exercise) and&nbsp; volatility. The BS framework assumes that volatility remains constant across all strikes, however, in practice it varies. How do traders come to learn these parameters?</p><p>We introduce natural models of learning agents, in which they update their beliefs about the true implied volatility based on the opinions of other traders. We prove exponentially fast convergence of these opinion dynamics using techniques from control theory and leader-follower models, thus providing a resolution between theory and market practices. We allow for two different models, one with feedback and one with an unknown leader.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-696" tabindex="-1" role="dialog"
         aria-labelledby="modal-696-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-696-label">[Abstract] Felm\&quot;{e} : A New Theory of Emotions for Emotionally Intelligent Robots</h4>
                </div>
                <div class="modal-body">
                    <p>Numerous computational models of emotion have been proposed ab antiquo. &nbsp;While proficient in their intended but limited field of use, we have found these models to be insufficient for modeling robots that are genuinely emotionally intelligent. &nbsp;Hence we introduce a new model of emotion, Felm\"{e}, a linguistically-grounded Ortony-Collins-Clore (OCC) Theory-based formalization of emotions.\footnote{The OCC Theory (of Emotions) is set out in \cite{occ1989}.} Felm\"{e} is the affective extension to the multi-sorted quantified modal logic \DCEC and attempts to build a proof-theoretic system for an extended OCC theory. &nbsp;In addition, we take the first steps toward designing a relevant and novel AI system: one that navigates the linguistic aspects of a test of Emotional Intelligence (EI). &nbsp;The test in question is an established and much-used EI test: the Mayer Salovey Caruso Emotional Intelligence Test (MSCEIT). &nbsp;This paper explores the various sections of this test, and outlines algorithms for each section based on Felm\"{e} that, to varying degrees of accuracy, are able to determine correct answers in each section.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-447" tabindex="-1" role="dialog"
         aria-labelledby="modal-447-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-447-label">[Abstract] Towards Designing Optimal Reward Functions in Multi-Agent Reinforcement Learning Problems</h4>
                </div>
                <div class="modal-body">
                    <p>Defining a reward function that, when optimized, results in a rapid acquisition of an optimal policy, is one of the most challenging problems involved when deploying reinforcement learning algorithms. The existing works on the optimal reward problem (ORP) propose mechanisms to design reward functions but their application is limited to specific sub-classes of single or multi-agent reinforcement learning problems.&nbsp;</p><p>Moreover, these methods identify which rewards should be given in which situation, but not which aspects of the state or environment should be used when defining the reward function. Those methods also do not directly model how quickly an optimal policy can be learned by optimizing a given candidate reward function.</p><p>In this paper, we define the <i>extended</i> optimal reward problem (EORP) which:</p><p>i) can identify both features and reward signals that compose the reward function;</p><p>ii) is general enough to deal with single and multi-agent reinforcement learning problems;</p><p>iii) is scalable to problems with large number of agents learning simultaneously;&nbsp;</p><p>iv) incorporates a learning effort metric in the evaluation of reward functions allowing the discovery of reward functions that result in faster learning.</p><p>Experimental results on gridworld-like and traffic assignment scenarios are used to evaluate the efficiency of our approach in designing effective reward functions.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-107" tabindex="-1" role="dialog"
         aria-labelledby="modal-107-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-107-label">[Abstract] Value-Decomposition Networks For Cooperative Multi-Agent Learning Based on Team Reward</h4>
                </div>
                <div class="modal-body">
                    <p>We study the problem of cooperative multi-agent reinforcement learning with a single joint reward signal. This class of learning problems is difficult because of the often large combined action and observation spaces. In the fully centralized and decentralized approaches, we find the problem of spurious rewards and a phenomenon we call the ``lazy agent'' problem, which arises due to partial observability.&nbsp; We&nbsp; address these problems by training individual agents with a novel value decomposition network architecture, which learns to decompose the team value function into&nbsp; agent-wise value functions. We perform an experimental evaluation across a range of partially-observable multi-agent domains and show that learning such value-decompositions leads to superior results, in particular when combined with weight sharing, role information and communication channels. In fact, value-decomposition by itself and all evaluated combinations of techniques including value-decomposition, outperform individual learners and centralization.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-538" tabindex="-1" role="dialog"
         aria-labelledby="modal-538-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-538-label">[Abstract] Modelling the Social Practices of an Emergency Room to Ensure Staff and Patient Wellbeing</h4>
                </div>
                <div class="modal-body">
                    <p>Understanding the impact of activities is important for emergency rooms (ER) to ensure patient wellbeing and staff satisfaction. Decision support tools, such as agent-based simulations and formal reasoners, could contribute to this understanding by identifying possible problems. An ER though is a complex social multi-agent system where staff members should understand the needs of patients, what their colleagues expect of them and how the treatment usually goes about. Social practices aim to capture this social dimension by focussing on the shared routines in a system, such as diagnosing or treating the patient. This paper uses the Web Ontology Language (OWL) to formalize social practices and then applies it to the ER domain. This results in an ontology that can be used as a basis for simulations and formal reasoning. The latter is demonstrated by verifying a number of properties for our use case. These results serve not only as a first step to better decision-support tools for ER, but also serves as an example for formalizing the social dimension of other multi-agent systems.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-88" tabindex="-1" role="dialog"
         aria-labelledby="modal-88-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-88-label">[Abstract] Synthesizing Efficient Solutions for Patrolling Problems in the Internet Environment</h4>
                </div>
                <div class="modal-body">
                    <p>We propose an algorithm for constructing efficient patrolling strategies in the Internet environment, where the protected targets are nodes connected to the network and the patrollers are software agents capable of detecting/preventing undesirable activities on the nodes. The algorithm is based on a novel compositional principle designed for a special class of strategies, and it can quickly construct (sub)optimal solutions even if the number of targets reaches hundreds of millions.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-43" tabindex="-1" role="dialog"
         aria-labelledby="modal-43-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-43-label">[Abstract] A Multi-Agent System Framework for Miniaturized Satellite Systems</h4>
                </div>
                <div class="modal-body">
                    <p>Developing newer satellite missions faces increased onboard software complexity. Next generations of small satellites need to enable the infrastructure for implementation of concurrent and deterministic onboard algorithms for mission coordination and control. Multi-agent-based architectures are a new developing approach adopted in the software engineering field due to its flexibility, scalability, and adaptability to dynamic operating environments. This paper describes the design and implementation of a deterministic multi-agent system framework to develop applications for highly constrained embedded computers used in small satellite missions. As a result of the implementation of this framework the user coding effort for describing complex onboard software applications is reduced up to 50\% with minimum impact on CPU load and program memory allocation. This paper also shows a set of benchmarks that demonstrate not only the feasibility of MAS-based software for small satellite missions but its value to achieve aggressive development schedules.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-518" tabindex="-1" role="dialog"
         aria-labelledby="modal-518-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-518-label">[Abstract] Trade-off and Winners Selection for Pareto Optimal QoS Compositions in Competitive Negotiations</h4>
                </div>
                <div class="modal-body">
                    <p>		 	 	 		</p><div class="page" title="Page 1">			<div class="layoutArea">				<div class="column">					<p>		 	 	 		</p><div class="page" title="Page 1">			<div class="layoutArea">				<div class="column">					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">QoS-based service composition allows for the development of complex business applications composed of services that need to be selected, among the ones available, according to end-to-end QoS constraints set, when the application is required. In fact, for each component service, more candidates are available that may differ for their QoS referring to non-functional characteristics of services, such as cost, execution time, reliability. Automated negotiation is proposed as an enabling mechanism to select component services in a dynamic market of services, where provided QoS values may vary according to different market strategies depending on the considered market sector. Nevertheless, when dealing with multiple QoS attributes, multiple service providers, and no shared information, that are typical characteristics of a market of services, it is difficult to guarantee formal properties of the negotiation outcomes. In the present work, we propose a trade-off strategy that exploits both the competition due to the number of services providing the same functionality but with different QoS, and the cooperation needed among the providers of component services in order to make it possible to meet the required end-to-end QoS constraints. The proposed strategy allows selecting the component services by determining the winners of the negotiation that reached a Pareto-optimal agreement consisting in the composition of their local QoS values.&nbsp;</span></p>				</div>			</div>		</div>				</div>			</div>		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-204" tabindex="-1" role="dialog"
         aria-labelledby="modal-204-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-204-label">[Abstract] Surprise in Elections</h4>
                </div>
                <div class="modal-body">
                    <p>Elections involving a very large voter population often lead to outcomes that surprise many. This is particularly important for the elections in which results affect the economy of a sizable population. A better prediction of the true outcome helps reduce the surprise (or shock) and keeps the voters prepared. </p><p>This paper starts from the basic observation that individuals in the underlying population build estimates of the distribution of preferences of the whole population based on their local neighborhoods. The outcome of the election leads to a surprise/shock if these local estimates contradict the outcome of the election for some fixed voting rule. To get a quantitative understanding, we propose a simple mathematical model of the setting where the individuals in the population and their connections (through geographical proximity, social networks etc.) are described by a random graph with connection probabilities that are biased based on the preferences of the individuals. Each individual also has some estimate of the bias in their connections.</p><p>We show that the election outcome leads to a surprise if the discrepancy between the estimated bias and the true bias in the local connections exceeds a certain threshold, and confirm the phenomenon that surprising outcomes are associated only with {\em closely contested elections}. We compare standard voting rules based on their performance on surprise and show that they have different behavior for different parts of the population. It also hints at an impossibility that a single voting rule will be less surprising for {\em all} parts of a population. Finally, we experiment with the UK-EU referendum (a.k.a.\ Brexit) dataset that attest some of our theoretical predictions.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-562" tabindex="-1" role="dialog"
         aria-labelledby="modal-562-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-562-label">[Abstract] Pedagogical Value-Aligned Crowdsourcing: Inspiring the Wisdom of Crowds via Interactive Teaching</h4>
                </div>
                <div class="modal-body">
                    <p>Crowdsourcing offers an economical means to leverage human wisdom for large-scale data annotation. However, the crowdsourced labeled data often suffer from low quality and significant inconsistencies, since the low-cost crowd workers are commonly lacking in corresponding domain knowledge and might make cursory choices. Most research in this area emphasizes the post-processing of the obtained noisy labels, which cannot radically ameliorate the quality of crowdsourcing service. In this paper, we focus on improving the worker's reliability during the label collecting process. We propose a novel game-theoretical framework of crowdsourcing, which formulates the interaction between the annotation system and the crowd workers as an incentivized pedagogical process between the teacher and the students. In this framework, the system is able to infer the worker's belief or prior from their current answers, reward them by performance-contingent bonus, and instruct them accordingly via near-optimal examples. We develop an effective algorithm for the system to select examples, even when the worker's belief is unidentifiable. Also, our mathematical guarantees show that our framework not only ensures a fair payoff to crowd workers regardless of their initial priors but also facilitates value-alignment between the annotation system (requester) and the crowd workers. Our experiments further demonstrate the effectiveness and robustness of our approach among different worker populations and worker behavior in improving the crowd worker's reliability.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-506" tabindex="-1" role="dialog"
         aria-labelledby="modal-506-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-506-label">[Abstract] Adaptive Adjacency Kanerva Coding for Memory-Constrained Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9pt; font-family: NimbusRomNo9L;">When encountering continuous, or very large do-
mains, using a compact representation of the state space is prefer-
able for practical reinforcement learning (RL). This approach
can reduce the size of the state space and enable generalization
by relating similar or neighboring states. However, many state
abstraction techniques cannot achieve satisfactory approximation
quality in the presence of limited memory resources, while expert
state space shaping can be costly and usually does not scale
well. We have investigated the principle of Sparse Distributed
Memories (SDMs) and applied it as a function approximator to
learn good policies for RL.
</span></p>
					<p><span style="font-size: 9pt; font-family: NimbusRomNo9L;">This paper describes a new approach, adaptive adjacency
in SDMs, that is capable of representing very large continuous
state spaces with a very small collection of prototype states.
This algorithm enhances an SDMs architecture to allow on-
line, dynamically-adjusting generalization to assigned memory
resources to provide high-quality approximation. The memory
size and memory allocation no longer need to be manually
assigned before and during RL. Based on our results, this
approach performs well both in terms of approximation quality
and memory usage.
</span></p>
					<p><span style="font-size: 9pt; font-family: NimbusRomNo9L;">The superior performance of this approach over existing
SDMs and CMACs is demonstrated through a comprehensive
simulation study in two classic domains, Mountain Car with 2
dimensions and Hunter-Prey with </span><span style="font-size: 9.000000pt; font-family: 'CMR9'">5 </span><span style="font-size: 9pt; font-family: NimbusRomNo9L;">dimensions. Given equivalent
memory resources, our approach learns better policies over
existing SDMs and CMACs, revealing </span><span style="font-size: 9.000000pt; font-family: 'CMR9'">14</span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">.</span><span style="font-size: 9.000000pt; font-family: 'CMR9'">7% </span><span style="font-size: 9pt; font-family: NimbusRomNo9L;">to </span><span style="font-size: 9.000000pt; font-family: 'CMR9'">39</span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">.</span><span style="font-size: 9.000000pt; font-family: 'CMR9'">5% </span><span style="font-size: 9pt; font-family: NimbusRomNo9L;">and
</span><span style="font-size: 9.000000pt; font-family: 'CMR9'">32</span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">.</span><span style="font-size: 9.000000pt; font-family: 'CMR9'">8% </span><span style="font-size: 9pt; font-family: NimbusRomNo9L;">to </span><span style="font-size: 9.000000pt; font-family: 'CMR9'">73</span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">.</span><span style="font-size: 9.000000pt; font-family: 'CMR9'">2% </span><span style="font-size: 9pt; font-family: NimbusRomNo9L;">improvements on the learned average returns,
respectively, when applied to both domains’ tasks, while it can
also achieve similar or even better performance when using only
</span><span style="font-size: 9.000000pt; font-family: 'CMR9'">20% </span><span style="font-size: 9pt; font-family: NimbusRomNo9L;">of the memory used by CMACs in our experiments. We
conclude that the adaptive adjacency approach can be used to
efficiently approximate value functions with limited memories,
and that the approach scales well across tested domains with
continuous, large-scale state spaces.&nbsp;</span></p>
				</div>
			</div>
		</div>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-313" tabindex="-1" role="dialog"
         aria-labelledby="modal-313-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-313-label">[Abstract] Foresee: Attentive Future Projections of Chaotic Road Environments with Online Training</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we focus on anticipation of road environment which is highly dynamic and uncertain by projecting future from the raw camera images. Interaction among traffic participants make this anticipation very challenging as the motion of one affect another. On the other hand, humans are very effective in anticipating the environment. For example, irrespective of the number of traffic participants they are efficacious to drive on the chaotic roads. Proliferation in deep learning have shown the efficacy of neural networks in learning this human behavior. In that direction, we investigate recurrent neural networks to understand the chaotic road environment which is shared by pedestrians, vehicles (cars, trucks, bicycles etc.), and sometime animals as well. We propose Foresee, a unidirectional gated recurrent units (GRUs) with attention to foresee future locations of the objects in terms of the images itself.</p><p>We train foresee in an unsupervised way. We have collected several videos on Delhi roads consisting of various traffic participants, background and infrastructure differences (like 3D pedestrian crossing) at various times on various days. We also explore online training for \emph{Foresee} to project future for up to $0.5$ seconds. We compared our proposal with two state of the art methods and finally, we show that the our trained generalizes to a public dataset for future projections.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-72" tabindex="-1" role="dialog"
         aria-labelledby="modal-72-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-72-label">[Abstract] Maximizing Spread in Emerging Networks</h4>
                </div>
                <div class="modal-body">
                    <p>When investigating how phenomena spread in a network, we may wish to infer under what conditions the spread is maximized. Influence maximization enables us, for instance, to pick targets for advertising campaigns in a social network. The goal is to select seed nodes so as to maximize the overall number of influenced nodes. Previous work has treated the network as a static graph, whereas, in reality, networks of interest may still be going through a phase of rapid expansion, especially when a market is growing. In this work, we propose an algorithm for epidemic-motivated and game-motivated influence in networks of growing size, with favorable theoretical properties as well as significantly improved empirical results on a number of datasets.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-118" tabindex="-1" role="dialog"
         aria-labelledby="modal-118-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-118-label">[Abstract] Best of Both Worlds: Mitigating Imbalance of Crowd Worker Strategic Choices Without Budget</h4>
                </div>
                <div class="modal-body">
                    <p>Crowdsourcing has become a popular paradigm for requesters to hire ubiquitous crowd workers. The worker's selfish instinct of choosing the most profitable task can cause the imbalance of task completion: some tasks achieve a number of redundant worker choices, while others may achieve no worker choice. Although budget-based incentives can mitigate the imbalance of crowd workers' strategic choices, the extra budget makes them less attractive. To mitigate task completion imbalance without budget, a price mediation mechanism is proposed. This mechanism works by allowing the crowdsourcing platforms to adjust task price, thereby eliciting workers to balance their choices. The price adjustment is carefully designed to satisfy 1) task completion integrity, and 2) social welfare maximization. We prove that this optimization problem is NP-hard to solve. By designing bound function and pruning policies, we propose an optimal branch-and-bound algorithm for small-scale instances. To further improve the scalability for large-scale instances, we relax the optimal algorithm, and get an approximation performance. Experimental results on a real dataset show that compared with benchmarks, our approaches are effective on maximizing social welfare on realistic-sized applications.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-526" tabindex="-1" role="dialog"
         aria-labelledby="modal-526-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-526-label">[Abstract] Towards the use of Contextual Information in Lending Automated Negotiation Processes</h4>
                </div>
                <div class="modal-body">
                    <p class="p1">






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
  <o:PixelsPerInch>96</o:PixelsPerInch>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>PT-BR</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073786111 1 0 415 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
p.p1, li.p1, div.p1
	{mso-style-name:p1;
	mso-style-unhide:no;
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:7.0pt;
	font-family:"Helvetica",sans-serif;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
@page WordSection1
	{size:612.0pt 792.0pt;
	margin:70.85pt 3.0cm 70.85pt 3.0cm;
	mso-header-margin:36.0pt;
	mso-footer-margin:36.0pt;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Tabela normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin:0cm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-fareast-language:EN-US;}
</style>
<![endif]-->



<!--StartFragment-->



<!--EndFragment--></p><p class="p1" style="text-align:justify"><span lang="EN-US" style="font-size:14.0pt;
mso-bidi-font-size:7.0pt;mso-ansi-language:EN-US">In this work it is discussed
the incorporation of context information in Lending Automated Negotiation
processes, so that agents can be able to make amends on strategies purely based
on the negotiation object attributes. In this sense, it is presented, as the
main contribution, an efficient negotiation model that takes the borrower position
into account in order to mitigate risks while maximizing gains for the
financial institution. A solution model is introduced by adapting and extending
the so called Haleema optimized negotiation model to E-Commerce transactions.
Simulations involving the implementation of both the Haleema and the proposed
model show a more conservative behavior to the latter, but with the same profit
margin. For the financial institution, results may indicate that the model is a
feasible approach to improve automatic services in Lending processes by
regulating decisions accordingly to the context.<o:p></o:p></span></p><style type="text/css">
p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 9.0px Helvetica}
</style>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-472" tabindex="-1" role="dialog"
         aria-labelledby="modal-472-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-472-label">[Abstract] Question Generation for Conversational Agents</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper we evaluate current state-of-the-art Question Generation systems in the task of generating questions to populate the knowledge base of a domain-oriented conversational agent. Three Question Generation systems are considered. The first is a highly cited tool representing linguistically-based approaches. The second illustrates the family of recent Question Generation systems based in deep neural networks. We contribute with a third system in which patterns are created based on a small set of seeds, constituted by sentence/question pairs; in this system, questions are generated based in a pattern matching at the semantic role level. Contrary to the usual evaluations, in our study we consider three evaluation dimensions that we consider more appropriate to automatically evaluate generated questions for a domain-oriented conversational agent -- correction, usefulness, and coverage of the produced questions. In this context, we evaluate the different systems individually, but also as a whole, with a reference corpus hand-crafted by humans, which we make public. Results show that these Question Generation systems should be seen as complementary, as coverage, although poor, duplicates when using them combined. In addition, we show that these systems can also contribute with interesting questions that were not considered in the reference manually created.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-431" tabindex="-1" role="dialog"
         aria-labelledby="modal-431-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-431-label">[Abstract] Convention Formation during Conflict Resolution Process in Networked Agent Societies</h4>
                </div>
                <div class="modal-body">
                    <p>Social conventions have been used as an efficient mechanism to facilitate coordination among agents in networked agent societies. A convention is a situation where each agent adopts the same strategy on the choice of actions. When agents are performing tasks, such as manufacturing products and driving on the roads, the agents should not execute conflicting actions to avoid inefficiency or even danger. To try to make agents execute conflict-free actions in these tasks, current approaches focus on establishing conventions before agents start to perform tasks. These approaches may provide a sub-convention situation, where conflicting strategies among agents exist when agents start to perform tasks. However, there is no solution to the problem of how to resolve conflicts and form conventions at the same time when agents are performing tasks. To tackle this problem, in this paper, we propose an approach which forms conventions during a conflict resolution process. In this process, each agent interacts repeatedly with its neighbours. In each interaction, if conflicting strategies exist, the agents need to resolve the conflict. We proof that, when each agent applies the same multi-agent learning algorithm to resolve conflicts, a convention is guaranteed to be formed during the conflict resolution process. We also conduct empirical experiments to evaluate the proposed approach with respect to different kinds of social networks, number of agents, number of actions, influences of non-adaptive agents, and so on. Experimental results reveal significant insights into convention emergence in networked agent societies using the proposed approach.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-622" tabindex="-1" role="dialog"
         aria-labelledby="modal-622-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-622-label">[Abstract] Real-time Machine Learning Prediction of an Agent-Based Model for Urban Decision-making</h4>
                </div>
                <div class="modal-body">
                    <p><span id="docs-internal-guid-4f2e3f1a-a7c4-ac19-0634-be8a5cbbb7d6"><span style="font-size: 11pt; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">Cities are becoming bigger, more complex, and changing even more rapidly. Currently, community engagement of urban decision-making is ineffective, uninformed, and normally happens in late stages. To facilitate more collaborative and evidence-based urban decision-making process for both experts and non-experts, real-time feedback is essential. However, current tools for urban planning are not capable of quickly performing complex simulation. To address these challenges, machine learning techniques were applied to achieve real-time prediction of an agent-based model (ABM) of city traffic. An ABM capable of determining accumulated traffic volume and waiting time by location was developed on the GAMA Platform. 10,000 generated city configurations were simulated. These simulation results were then used to train a convolutional neural network (CNN) to predict the traffic performance of an unseen city configuration. Prediction with the CNN is more than 5000 times faster than the original ABM. Its R squared value relative to the ABM was 0.86. This machine learning approach was applied as a versatile, quick, accurate, and computationally efficient method for real-time feedback and optimization for urban decision-making in the CityMatrix project. Users had a better understanding of the embodied trade-offs of the city, and achieved their goals for the city faster.</span></span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-629" tabindex="-1" role="dialog"
         aria-labelledby="modal-629-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-629-label">[Abstract] A simple and efficient algorithm to compute epsilon-equilibria of discrete Colonel Blotto games</h4>
                </div>
                <div class="modal-body">
                    <p>The Colonel Blotto game is a famous game commonly used to model resource allocation problems in many domains ranging from security to advertising. Two players distribute a fixed budget of resources on multiple battlefields to maximize the aggregate value of battlefields they win, each battlefield being won by the player who allocates more resources to it. Since its introduction in 1921, the continuous version of the game---where players can choose any fractional allocation---has been extensively studied, albeit only with partial results to date. Only very recently, the discrete version---where allocations can only be integers---started to gain traction and algorithms were proposed to compute the equilibrium in polynomial time; but these remain computationally impractical for large (or even moderate) numbers of battlefields. In several important applications, meaningful models naturally have a large number of battlefields; the question of efficiently finding an equilibrium for such cases remains open.&nbsp;</p><p>In this paper, we propose an algorithm to compute very efficiently an <i>approximate </i>equilibrium for the discrete Colonel Blotto game with many battlefields. Specifically, we propose a strategy (the <i>discrete independently uniform</i> strategy) and show that it is an epsilon-equilibrium. We provide a theoretical bound on the approximation error, epsilon, as a function of the number of battlefields and players budgets. We also propose an efficient dynamic programming algorithm to compute the best response of a player against an arbitrary set of marginals of the opponent. Using this algorithm, we can then compute for each game instance the actual value of epsilon. We perform numerical experiments that show that the proposed <i>discrete independently uniform</i> strategy provides a good approximation to the equilibrium even for a relatively moderate number of battlefields.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-290" tabindex="-1" role="dialog"
         aria-labelledby="modal-290-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-290-label">[Abstract] New cloning approach to solve Distributed Constraint Optimization Problems</h4>
                </div>
                <div class="modal-body">
                    <p><b><span lang="EN-US" style="font-size:9.0pt;font-family:
&quot;Times New Roman&quot;,serif;mso-fareast-font-family:&quot;Times New Roman&quot;;mso-ansi-language:
EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">Geographical and
natural distributed problems such as distributed scheduling problems and
distributed allocation resources problems can be described as a Distributed
Optimization under Constraints Problems Maximum Relaxation. DOC-MaxRelax is a
version of the general framework DOC-BRelax dealing with Distributed Constraint
Optimization Problems where the goal is to find a set of variables assignments
that maximize the number of satisfied constraints among agents. However, when
the number of variable per agent is more and more important, then the time
resolution will be exponential and computational resources will be overloaded.
As solution to these problems, we introduce a new cloning approach. In this paper,
we provide an analysis of the circumstances under which agents should consider
cloning, and present experimental results on how cloning improves the
performance of our Multi-Agent System.</span></b><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-491" tabindex="-1" role="dialog"
         aria-labelledby="modal-491-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-491-label">[Abstract] ComPAS: Community Preserving Sampling for Streaming Graphs</h4>
                </div>
                <div class="modal-body">
                    <p>In the era of big data, graph sampling is indispensable in many&nbsp;<span style="line-height: 1.42857;">settings. Existing sampling methods are mostly designed for static&nbsp;</span><span style="line-height: 1.42857;">graphs, and aim to preserve basic structural properties of the original&nbsp;</span><span style="line-height: 1.42857;">graph (such as degree distribution, clustering coefficient etc.) in the&nbsp;</span><span style="line-height: 1.42857;">sample. We argue that for any sampling method it is impossible to&nbsp;</span><span style="line-height: 1.42857;">produce an universal representative sample which can preserve all&nbsp;</span><span style="line-height: 1.42857;">the properties of the original graph; rather sampling should be ap</span><span style="line-height: 1.42857;">plication specific (such as preserving hubs - needed for information&nbsp;</span><span style="line-height: 1.42857;">diffusion). Here we consider community detection as an application&nbsp;</span><span style="line-height: 1.42857;">scenario. We propose ComPAS, a novel sampling strategy that un</span><span style="line-height: 1.42857;">like previous methods, is not only designed for streaming graphs&nbsp;</span><span style="line-height: 1.42857;">(which is a more realistic representation of a real-world scenario) but&nbsp;</span><span style="line-height: 1.42857;">also preserves the community structure of the original graph in the&nbsp;</span><span style="line-height: 1.42857;">sample. Empirical results on both synthetic and different real-world&nbsp;</span><span style="line-height: 1.42857;">graphs show that ComPAS is the best to preserve the underlying&nbsp;</span><span style="line-height: 1.42857;">community structure with average performance reaching 73.2% of&nbsp;</span><span style="line-height: 1.42857;">the most informed algorithm for static graphs.</span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-624" tabindex="-1" role="dialog"
         aria-labelledby="modal-624-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-624-label">[Abstract] Analyzing the Effect of Information Stagnancy on the Distributed Stochastic Algorithm</h4>
                </div>
                <div class="modal-body">
                    <p style="margin-bottom: 0in; line-height: 100%" align="justify">


	
	
	
	<style type="text/css">p { margin-bottom: 0.1in; direction: ltr; line-height: 120%; text-align: left; }</style>


<font color="#000000"><font face="Times New Roman, serif"><font style="font-size: 12pt" size="3">Despite
the fact that many real world problems change over time, many
Distributed Constraint Optimization Problem (</font></font></font><font color="#000000"><font face="Times New Roman, serif"><font style="font-size: 12pt" size="3"><u>DCOP</u></font></font></font><font color="#000000"><font face="Times New Roman, serif"><font style="font-size: 12pt" size="3">)
algorithms assume that the problem is constant or changing at a
negligible rate. In addition, these algorithms also assume that
changes to the environment are instantaneously observable.  However,
in highly dynamic environments with communication delays, both of
these assumptions can be violated resulting in problem solving with
out-of-date information.  In this study, we explore the relationship
between environmental dynamics, information stagnancy, and solution
quality in Dynamic DCOP problems.  By using recent advances in the
analysis of dynamic, distributed problems, we show that information
stagnancy can be characterized and used to accurately predict the
behavior of a protocol.  To evaluate our finding, we use the
Distributed Stochastic Algorithm (</font></font></font><font color="#000000"><font face="Times New Roman, serif"><font style="font-size: 12pt" size="3"><u>DSA</u></font></font></font><font color="#000000"><font face="Times New Roman, serif"><font style="font-size: 12pt" size="3">)
as a basis. Through extensive empirical testing, we show that the
prediction function is accurate.</font></font></font></p><p>

<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-582" tabindex="-1" role="dialog"
         aria-labelledby="modal-582-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-582-label">[Abstract] Eligibility Traces for Options</h4>
                </div>
                <div class="modal-body">
                    <p>Temporally extended actions not only represent knowledge in the hierarchical setup in reinforcement learning, they also improve exploration while reducing the complexity of choosing actions. The option framework provides a concrete way to implement and reason about temporal abstraction. This work attempts to test the utility of eligibility traces with options and find good ways of doing multi-step intra-option updates. Three algorithms, based on off-policy methods - importance sampling, tree backup and retrace, are proposed for using eligibility traces with options.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-522" tabindex="-1" role="dialog"
         aria-labelledby="modal-522-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-522-label">[Abstract] Stability in Barter Exchange Markets</h4>
                </div>
                <div class="modal-body">
                    <p>The notion of stability is the foundation of several classic problems in economics and computer science that arise in a wide-variety of real-world situations, including Stable Marriage, Stable Roommate, Hospital Resident and Group Activity Selection. We study this notion in the context of barter exchange markets. The input of our problem of interest consists of a set of people offering goods/services, with each person subjectively assigning values to a subset of goods/services offered by other people. The goal is to find a <i>stable transaction</i>, a set of cycles that is <i>stable</i> in the following sense: there does not exist a cycle such that every person participating in that cycle prefers to his current “status”. For example, consider a market where families are seeking vacation rentals and offering their own homes for the same. Each family wishes to acquire a vacation home in exchange of its own home without any monetary exchange. We study such a market by analyzing a stable transaction of houses involving cycles of fixed length. The underlying rationale is that an entire trade/exchange fails if any of the participating agents cancels the agreement; as a result, shorter (trading) cycles are desirable.</p><p>We show that given a transaction, it can be verified whether or not it is stable in polynomial time, and that the problem of finding a stable transaction is NP-hard even if each person desires only a small number of other goods/services. Having established these results, we study the problem of finding a stable transaction in the framework of parameterized algorithms.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-269" tabindex="-1" role="dialog"
         aria-labelledby="modal-269-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-269-label">[Abstract] Stable Outcomes in Modified Fractional Hedonic Games</h4>
                </div>
                <div class="modal-body">
                    <p>In <i>coalition formation games</i> self-organized coalitions are created as a result of the strategic interactions of independent agents. For each couple of agents (i,j), weight w<sub>i,j</sub> = w<sub>j,i</sub> reflects how much agents i and j benefit from belonging to the same coalition. We consider the modified fractional hedonic game, that is a coalition formation game in which agents’ utilities are such that the total benefit of agent i belonging to a coalition (given by the sum of w<sub>i,j</sub> over all other agents j belonging to the same coalition) is averaged over all the other members of that coalition, i.e., excluding herself. Modified fractional hedonic games constitute a class of succinctly representable hedonic games.<br></p><p>We are interested in the scenario in which agents, individually or jointly, choose to form a new coalition or to join an existing one, until a stable outcome is reached. To this aim, we consider common stability notions, leading to strong Nash stable outcomes, Nash stable outcomes or core stable outcomes: we study their existence, complexity and performance, both in the case of general weights and in the case of 0-1 weights. In particular, we completely characterize the existence of the considered stable outcomes and show many tight or asymptotically tight results on the performance of these natural stable outcomes for modified fractional hedonic games, also highlighting the differences with respect to the model of fractional hedonic games, in which the total benefit of an agent in a coalition is averaged over all members of that coalition, i.e., including herself.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-537" tabindex="-1" role="dialog"
         aria-labelledby="modal-537-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-537-label">[Abstract] Learning Game-theoretic Models from Aggregate Behavioral Data with Applications to Vaccination Rates in Public Health</h4>
                </div>
                <div class="modal-body">
                    <p><span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: small;">A survey is a common method to elicit behavioral data. The collected data provides a noisy representation of the actions of a sampled population. Direct access to individual responses is rare, for many obvious reasons. Instead, most of us would only have access to aggregated information about the percentage of individuals who reportedly took certain actions. Public-health data on populations' vaccination rates collected by government officials is such example and will be the focus of this paper. Naturally, behavioral data capture implicit interdependencies governing the decision-making process of the sampled population. In this work, we undertake the challenging task of uncovering such independencies of the data and use computational game theory (CGT) to model data as the result of distributed decision-making at the reported granularity level (e.g., nations, states, districts, and towns). Indeed, CGT has increasingly gained popularity as both a formal and practical framework in which to study the potential effect of policy making of agents in a variety of settings, like the vaccination setting we study here. To achieve our task, in this paper, we posit the view of aggregated behavioral data as jointly&nbsp;</span><g class="gr_ gr_19 gr-alert gr_gramm gr_inline_cards gr_run_anim Punctuation only-del replaceWithoutSep" id="19" data-gr-id="19" style="display: inline; color: rgb(34, 34, 34); font-size: small; border-bottom: 2px solid transparent; background-repeat: no-repeat; background-position: -1px calc(100% + 3px); background-image: url(&quot;data:image/svg+xml;charset=utf8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='100%' height='100%'%3E%3Cline opacity='0.75' x1='4' y1='100%' x2='100%' y2='100%' transform='translate(-1.5, -2.5)' stroke-width='3' stroke-linecap='round' stroke='%23fc5454'/%3E%3C/svg%3E&quot;); background-size: calc(100% + 1px) 100%; animation: gr__appear_critical 0.4s ease forwards; font-family: arial, sans-serif;">randomized,</g><span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: small;">&nbsp;or mixed, strategies of multiple agents. We propose a novel general machine-learning approach to infer game-theoretic models from a potentially noisy dataset of mixed strategies. Our goal is to learn instantiations of game-theoretic models from the data that would best explain and compactly represent the global behavior of the population within a given hypothesis class of games. Ultimately, we want to employ the learned models for policy analysis on the underlying system as a whole, which cannot be achieved using other existing approaches. We illustrate our framework in a health-policy setting using publicly available data on vaccination rates in the continental USA.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-280" tabindex="-1" role="dialog"
         aria-labelledby="modal-280-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-280-label">[Abstract] Monte Carlo based Negotiation Strategy</h4>
                </div>
                <div class="modal-body">
                    <p>Automated negotiation is a rising topic in Artificial Intelligence. Recent advances in this domain have shown that opponent modeling as much as bidding strategy are crucial issues to improve agent performances. Several solutions have thus been proposed to handle them. This paper explores a Monte Carlo-base approach for automated negotiation. Monte Carlo has become a topic of great interest since its successes in AI for games, and particularly for Go. Indeed AlphaGo, which has won all its competitions so far, is based on this family of methods. In spite of this rising interest, &nbsp;Monte Carlo methods have not yet been explored in the domain of automated negotiation. In this paper, we formalize negotiation as a game and we introduce MoCaNA, an automated negotiation strategy based on Monte Carlo Tree Search. The latter is very adaptive and makes it possible to negotiate without any knowledge on the bound of the negotiation, which is not the case for traditional strategies. This adaptation may be important in several contexts such as e-commerce, where negotiation may not be bounded at all. Our approach also uses a model of the opoponent strategy, and a model of its utility.</p><p><br></p><p>We compare our Monte Carlo-base agent to the agents of ANAC 2014. Our agent is able to outperform some finalists of the ANAC 2014 on one of the domain they have been conceived for.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-433" tabindex="-1" role="dialog"
         aria-labelledby="modal-433-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-433-label">[Abstract] Probabilistic Coalition Structure Generation</h4>
                </div>
                <div class="modal-body">
                    <p>Computing an optimal coalition structure is an important problem in many multi-agent applications. In this paper this problem is investigated in the situation when some of the agents considered at start may be&nbsp; finally defective and a new coalition structure based on the agents who are present cannot be formed. When the uncertainty about the presence of the agents is given as a probability distribution, an optimal coalition structure is one with a maximal expected utility. We introduce a model for probabilistic coalition structure generation (PCSG) which generalizes the standard model for coalition structure generation (CSG). We present some of its properties, and focus on two policies which make precise how the utility of a coalition structure may evolve when some agents are missing. Two encoding schemes (one per policy) associating a PCSG instance with a MILP instance are also provided, and some empirical results are furnished.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-143" tabindex="-1" role="dialog"
         aria-labelledby="modal-143-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-143-label">[Abstract] Optimally Protecting Elections with Uncertainty about Voter Preferences</h4>
                </div>
                <div class="modal-body">
                    <p>Election control has always been an important issue of democratic institutions concerned. Considering that a voting rule is indeed susceptible to control, it is natural to seek ways to protect elections. Much of prior work has focused on complete voter preferences and approached the problem from the perspective of the computational complexity of election control. However, it is impractical for anybody to have complete voter preferences in real-world scenarios. In addition, when given a voting rule, such as plurality which is widely used in our lives, is easy to control, how to design protection strategies to prevent the occurrence of election control is ignored. In this paper, we model the problem, where the attacker can deploy a single attack such as a denial-of-service attack to convert the voting result through deleting some voter groups, and the defender allocates the limited protection resources to prevent attacks on specific voter groups, as a Stackelberg game. Then we first use the minimax regret decision criterion for uncertainty about voter preferences in the game.We also propose heuristic algorithms to speed up computing minimax regret for the Stackelberg game. Finally, we conduct detailed experiments on both synthetic and real data, which show that our algorithms lead to much better solution quality than other algorithms in the literature and can scale to realistic instances.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-330" tabindex="-1" role="dialog"
         aria-labelledby="modal-330-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-330-label">[Abstract] A Study of AI Population Dynamics with Million-agent Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p>We conduct an empirical study on discovering the ordered collective dynamics obtained by a population of artificial intelligence (AI) agents. Our intention is to put AI agents into a simulated natural context, and then understand their induced dynamics at the population level. In particular, we aim to verify if the principles developed in the real world could also be used in understanding an artificially-created intelligent population. To achieve this, we simulate a large-scale predator-prey world, where the laws of the world are designed by only the findings or logical equivalence that have been discovered in nature. We endow the agents with the intelligence based on deep reinforcement learning (DRL), and scale the population size up to millions. A large-scale DRL training platform with redesigned experience buffer is introduced. Our results show that the population dynamics of AI agents, driven only by each agent's individual self-interest, reveals an ordered pattern that is similar to the Lotka-Volterra model studied in population biology. We further discover the emergent behaviors of collective adaptations in studying how the agents' grouping behaviors will change &nbsp;with the environmental resources. Both of the two findings could be explained by the self-organization theory in nature.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-543" tabindex="-1" role="dialog"
         aria-labelledby="modal-543-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-543-label">[Abstract] Industry 4.0: Repurposing Manufacturing Lines On-the-fly with Multi-agent Systems for the Web of Things</h4>
                </div>
                <div class="modal-body">
                    <p>Multi-agent systems (MAS) have long been envisioned as a key enabling technology in manufacturing, but this promise is yet to be realized: the lack of proper models, architectures, tooling, and the high level of expertise required for designing and programming agent-based manufacturing systems hindered their large-scale acceptance. The emerging Web of Things now being standardized at W3C and IETF provides new research opportunities that can help MAS enter the mainstream and achieve their long-promised impact. In this paper, we integrate these new developments with MAS and automated planning in order to design scalable and flexible agent-based manufacturing systems that can be re-purposed on-the-fly: our agents synthesize production plans using semantic descriptions of Web-based artifacts and coordinate with one another via semantic organizations. The deployed systems use the Web as an application architecture (and not just a transport layer), which facilitates the seamless integration of geographically distributed production cells. Engineers can program and re-purpose the systems using an intuitive interface that runs in any standard Web browser and on any device. To demonstrate our approach, we implemented a prototypical production cell that integrates two industry-grade robots and an augmented reality interface for human workers. Together, these contributions demonstrate a means to achieve an intriguing vision for the forthcoming fourth industrial revolution: a global collective intelligence for manufacturing.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-679" tabindex="-1" role="dialog"
         aria-labelledby="modal-679-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-679-label">[Abstract] Monocular Vision Based Approach for Autonomous Taxi</h4>
                </div>
                <div class="modal-body">
                    <p>Intelligent public transport is an integral component of smart cities. In this paper, a simpler approach has been demonstrated for autonomous taxi navigation. A single front camera with 1920x1080 pixel resolution at 60 frames per second has been used for real-time object detection and path planning. Two hours of driving data has been used for training the proposed deep neural network. The duly trained network was then tested with 30 minutes of driving data, recorded and used separately. Two control parameters were derived viz. speed of the vehicle and the steering angle. An eight layered convolutional network with two gated recurrent and four dense layers was trained and tested on Nvidia Tesla K 40 GPU based system with Core i-7 processor. The mean squared error (MSE) for the target parameters viz. speed and steering angle were 1.79 and 2.69 percent, respectively, with 38 milli seconds of real-time response delay. An additional information on real-time perception module via semi-dense depth map interpolation usingerceptual loss function is provided for future integration with SLAM methods.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-142" tabindex="-1" role="dialog"
         aria-labelledby="modal-142-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-142-label">[Abstract] Game Theory for Adaptive Defensive Cyber Deception</h4>
                </div>
                <div class="modal-body">
                    <p>Based on prior work by others we seek to combine recent advances in game theory of both cyber defense and deception. In particular we have begun work on applying online learning and game theory to the task of advancing deception for cyber defense. Cyber deception games are generally modeled as non-cooperative, multi-turn, signaling games where the quality and authenticity of the signal is being manipulated. &nbsp;We will harness artificial intelligence techniques to allow our cyber deception to evolve over time, changing as attacks change, thus maintaining an enhanced defensive posture.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-61" tabindex="-1" role="dialog"
         aria-labelledby="modal-61-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-61-label">[Abstract] Swarm vs Swarm Adaptive Search and Tracking</h4>
                </div>
                <div class="modal-body">
                    <p style="margin-bottom: 0.14in; line-height: 115%">


	
	
	
	<style type="text/css">p { margin-bottom: 0.1in; direction: ltr; line-height: 120%; text-align: left; widows: 2; orphans: 2; }</style>


As the number of
commercial drones continue to increase there will be a need for
autonomous mechanisms that enable us to police these drones. This
paper introduces a novel approach for detecting and tracking “B”
teamed swarms of quadrotor unmanned aerial vehicles using a
corresponding “A” teamed swarm. The key goal is to produce
scalable, robust and flexible search &amp; tracking mechanisms, which
enable us to overcome confusing evasive tactics expressed by swarm
“B”. During the search process swarm “A” first scatter to
cover a region of interest, and then progress by searching for “B”
teamed swarm nodes. If one or more “B” nodes are detected, a
number of “A” nodes switch to tracking mode to pursue detected
nodes, while the remaining nodes continue the search process.
<font color="#000000"><span lang="en-US">Multi-objective optimization
(MOO) is used for the simulation. </span></font>The results show
multi-objective evolutionary algorithm by decomposition (<span lang="en-US">MOEA/D)
as the best algorithm for the most of “B” nodes detection,
non-dominated sorting genetic algorithm version 2 (NSGA2) for the
fastest first convergence, and multiple particle swarm optimization
(MPSO) for the least processing time.</span></p><p>

<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-723" tabindex="-1" role="dialog"
         aria-labelledby="modal-723-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-723-label">[Abstract] Online Multi-Robot Coverage: Evaluating Assumptions and Metrics</h4>
                </div>
                <div class="modal-body">
                    <p>When considering the use of multi-robot systems for exploration or coverage, it is important to carefully assess the assumptions made when designing the algorithms, and ensure that consistent metrics are used when comparing different systems. We provide an analysis of the common assumptions made and metrics used in multi-robot coverage and exploration algorithms. We then take three algorithms--the Rolling Dispersion Algorithm (RDA), the Multi-Robot Depth-First-Search (MR-DFS) algorithm, and the "BoB" algorithm--chosen for their different strengths and assumptions, and compare, using a set of common metrics, their performance in different environments in simulation. We also present two extensions to RDA--RDA-MS (multi-start) and RDA-EC (extended communication)--because it was the most constrained algorithm. These extensions preserve the original set of assumptions, but are able to perform as well as the less constrained algorithms, which makes them applicable to constrained settings, such as search and rescue. We show the performance of the extensions both in simulation and in experiments with physical robots.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-452" tabindex="-1" role="dialog"
         aria-labelledby="modal-452-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-452-label">[Abstract] Towards Cooperation in Sequential Prisoner’s Dilemmas: a Deep Multiagent Reinforcement-Learning Approach</h4>
                </div>
                <div class="modal-body">
                    <p>Matrix games like the Prisoner's Dilemma have guided research on social dilemmas for decades. However, they only distinguish two atomic actions: cooperate and defect. In real-world prisoner's dilemmas, these choices are temporally extended and different strategies may correspond to a sequence of actions. We introduce a Sequential Prisoner's Dilemma (SPD) game to better capture the aforementioned characteristics. In this work, we propose a deep multiagent reinforcement-learning framework that investigates the evolution of mutual cooperation in SPD games. Our framework consists of two phases. The first phase is offline: it synthesizes policies with different cooperation degrees and then trains a cooperation degree detection network. The second phase is online: an agent adaptively selects its policy based on the detected degree of opponent cooperation. The effectiveness of our approach is empirically demonstrated in two representative SPD 2-D games: the Apple-Pear game and the Fruit Gathering game. Experimental results show that our strategy can avoid being exploited by exploitative opponents and achieve cooperation against cooperative opponents.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-218" tabindex="-1" role="dialog"
         aria-labelledby="modal-218-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-218-label">[Abstract] Playing the Wrong Game: Bounding Negative Externalities in Diverse Populations of Agents</h4>
                </div>
                <div class="modal-body">
                    <p><span style="white-space:pre">	</span>The robustness of multiagent systems can be affected by mistakes or behavioral biases (e.g., risk-aversion, altruism, toll-sensitivity), with some agents playing the ``wrong game.'' This can change the set of equilibria, and may in turn harm or improve the social welfare of agents in the system. We are interested in bounding what we call the {\em biased price of anarchy} (BPoA) in populations with diverse agent behaviors, which is the ratio between welfare in the ``wrong'' equilibrium and optimal welfare.&nbsp;&nbsp;</p><p><span style="white-space:pre">	</span>We study nonatomic routing games, and derive an externality bound that depends on a key topological parameter of the underlying network.&nbsp;</p><p><span style="white-space:pre">	</span>We then prove two general BPoA bounds for games with diverse populations: one that relies on the network structure and the \emph{average bias} of all agents in the population, and one that is independent of the structure but depends on the \emph{maximal bias}. Both types of bounds can be combined with known results to derive concrete BPoA bounds for a variety of specific behaviors (e.g., varied levels of risk-aversion).&nbsp;</p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-265" tabindex="-1" role="dialog"
         aria-labelledby="modal-265-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-265-label">[Abstract] Prosocial learning agents solve generalized Stag Hunts better than selfish ones</h4>
                </div>
                <div class="modal-body">
                    <p>Deep reinforcement learning has become an important paradigm for constructing agents that can enter complex multi-agent situations and improve their policies through experience. One commonly used technique is reactive training - applying standard RL methods while treating other agents as a part of the learner's environment. It is known that in general-sum games reactive training can lead groups of agents to converge to inefficient outcomes. We focus on one such class of environments: Stag Hunt games. Here agents either choose a risky cooperative policy (which leads to high payoffs if both choose it but low payoffs to an agent who attempts it alone) or a safe one (which leads to a safe payoff no matter what). We ask how we can change the learning rule of a single agent to improve its outcomes in Stag Hunts that include other reactive learners. We extend existing work on reward-shaping in multi-agent reinforcement learning and show that that making a single agent prosocial, that is, making them care about the rewards of their partners can increase the probability that groups converge to good outcomes. Thus, even if we control a single agent in a group making that agent prosocial can increase our agent's long-run payoff. We show experimentally that this result carries over to a variety of more complex environments with Stag Hunt-like dynamics including ones where agents must learn from raw input pixels.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-619" tabindex="-1" role="dialog"
         aria-labelledby="modal-619-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-619-label">[Abstract] To Charge or not to Charge: Selfish Storage and Its Effect on Electricity Markets</h4>
                </div>
                <div class="modal-body">
                    <pre style="margin-bottom: 0px;"><span style=" color:#000000;">The volatility of prices in modern electricity markets, caused by fluctuations in generation and fast-changing demand, can be significantly reduced by the introduction of arbitrage-oriented storage suppliers. The behavior of selfish agents that provide storage is greatly influenced by both strategic considerations and by the physical constraints of storage systems, limiting their beneficial effect on the market. In this work we use agent-based modeling to examine the effect of both these factors on the agent's behavior and the subsequent market outcome. For a market in which a single monopolistic storage provider exists, we analyze the welfare loss caused by profit-maximizing behavior of the agent, showing that in case of linear demand and supply curves, the price of anarchy is 3/4, and the monopolist extracts 2/3 of the total welfare that it adds. For smaller-scale storage, we use Markov Decision Processes (</span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">MDPs</span><span style=" color:#000000;">) to realistically model the physical behavior of a storage system. We then utilize this model to provide an agent-based framework to derive the bidding strategies of storage agents, and use it to analyze the effect of multiple agents on the market, empirically showing the effect of physical specifications of storage on the market equilibrium and storage saturation. </span></pre>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-305" tabindex="-1" role="dialog"
         aria-labelledby="modal-305-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-305-label">[Abstract] Identifying Reusable Macros for Efficient Exploration via Policy Compression</h4>
                </div>
                <div class="modal-body">
                    <p>Reinforcement Learning agents often need to solve not a single <i>task</i>, but several tasks pertaining to a same <i>domain</i>; in particular, each task corresponds to an MDP drawn from a family of related MDPs (a domain). An agent learning in this setting should be able exploit policies it has learned in the past, for a given set of sample tasks, in order to more rapidly acquire policies for novel tasks. Consider, for instance, a navigation problem where an agent may have to learn to navigate different (but related) mazes. Even though these correspond to distinct tasks (since the goal and starting locations of the agent may change, as well as the maze configuration itself), their solutions do share common properties---e.g. in order to reach distant areas of the maze, an agent should not move in circles. After an agent has learned to solve a few sample tasks, it may be possible to leverage the acquired experience to facilitate solving novel tasks from the same domain.</p><p><br></p><p>Our work is motivated by the observation that trajectory samples from optimal policies for tasks belonging to a common domain, often reveal underlying useful patterns for solving novel tasks. We propose an optimization algorithm that characterizes the problem of learning reusable temporally extended actions (macros). We introduce a computationally tractable surrogate objective that is equivalent to finding macros that allow for maximal compression of a given set of sampled trajectories. We develop a compression-based approach for obtaining such macros and propose an exploration strategy that takes advantage of them. We show that meaningful behavioral patterns can be identified from sample policies over discrete and continuous action spaces, and present evidence that the proposed exploration strategy improves learning time on novel tasks.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-259" tabindex="-1" role="dialog"
         aria-labelledby="modal-259-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-259-label">[Abstract] Uniform Mixed Equilibria in Affine Congestion Games</h4>
                </div>
                <div class="modal-body">
                    <pre id="code" class="brush: ; plain-text" style="margin-bottom: 0px; padding: 10px; white-space: pre-wrap; color: rgb(0, 0, 0); font-size: 12px;">Motivated by possible applications in fault-tolerant systems, we introduce the notion of uniform mixed equilibria for resource selection games. Given an integer $\rho\geq 1$, a $\rho$-uniform mixed strategy is a mixed strategy in which a player plays exactly $\rho$ pairwise disjoint pure strategies with uniform probabilities, so that a $\rho$-uniform mixed equilibrium is a tuple of $\rho$-uniform mixed strategies, one for each player, in which no player can lower her cost by deviating to another $\rho$-uniform mixed strategy. We evaluate this solution concept within the well-studied class of congestion games with affine latency functions. For games with weighted players, we show existence of $\rho$-uniform mixed equilibria and provide a tight characterization of their price of anarchy. For games with unweighted players, instead, we extend the existential guarantee to any class of latency functions and, restricted to games with affine latencies, we derive a tight characterization of both the prices of anarchy and stability.</pre>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-81" tabindex="-1" role="dialog"
         aria-labelledby="modal-81-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-81-label">[Abstract] On a Flexible Representation for Defeasible Reasoning Variants</h4>
                </div>
                <div class="modal-body">
                    <p>We propose Statement Graphs (SG), a new logical formalism for defeasible reasoning based on argumentation. Using a flexible labeling function, SGs can capture the variants of defeasible reasoning (ambiguity blocking or propagating, with or without team defeat, and circular reasoning). We evaluate our approach with respect to human reasoning and propose a working first order defeasible reasoning tool that, compared to the state of the art, has richer expressivity at no added computational cost.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-266" tabindex="-1" role="dialog"
         aria-labelledby="modal-266-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-266-label">[Abstract] Strategic Monitor Placement against Malicious Flows</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal">Security Games have been widely adopted to model scenarios
in which one player, the Defender, has to decide how to deploy her resources to
minimize the loss that can be caused by an attack performed by another player,
the Attacker, aiming at maximizing such loss. In the present paper, we
focus on scenarios in which the Defender has lexicographic-like preferences on the targets, being primarily interested in defending the
integrity of a subset of the targets and, only secondarily, to reduce the amount
of the other damaged targets. Our central motivation for studying this problem
comes from the need to reduce the impact of malicious flows in networks. Such
networks can be either physical, like cities, or virtual, e.g., social
networks. In this work, we introduce a new class of security games to model
these scenarios, characterizing it and proving the NP-hardness of computing a
leader-follower equilibrium, which is the most appropriate solution concept for
this setting. To compute such an equilibrium, we provide an exact
exponential-time algorithm, capable of exploiting the topological properties of
the network. Finally, we show empirically that the number of instances in which
the algorithm requires exponential time turns out being very small, stating the
actual applicability to real-world scenarios of the algorithm we designed.<o:p></o:p></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-225" tabindex="-1" role="dialog"
         aria-labelledby="modal-225-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-225-label">[Abstract] Context-based and Explainable Decision Making with Argumentation</h4>
                </div>
                <div class="modal-body">
                    <p>Argumentation-based approaches to decision making have gained
considerable research interest, due to their ability to select and
justify decisions. In order to make better decisions, context is a key
piece of information that needs to be considered. However, most existing
argumentation-based models and frameworks have not modelled
or reasoned with context explicitly. In this paper, we present a
new argumentation-based approach for making context-based and
explainable decisions. We propose a graphical representation for
modelling decision problems involving varying contexts, Decision
Graph with Context (DGC), and a reasoning mechanism for making
context-based decisions which relies on the Assumption-based
Argumentation formalism. Based on these constructs, we introduce
two types of explanations, argument explanation and context explanation, identifying the reasons for the decisions made from an
argument-view and a context-view respectively.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-182" tabindex="-1" role="dialog"
         aria-labelledby="modal-182-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-182-label">[Abstract] An Axiomatic View of the Parimutuel Consensus Wagering Mechanism</h4>
                </div>
                <div class="modal-body">
                    <p>We consider an axiomatic view of the \emph{Parimutuel Consensus Mechanism} defined by Eisenberg and Gale (1959). The parimutuel consensus mechanism can be interpreted as a parimutuel market for wagering with a proxy that bets optimally on behalf of the agents, depending on the bets of the other agents.&nbsp; We show that the parimutuel consensus mechanism satisfies the desirable properties of Pareto optimality, individual rationality, budget balance and sybilproofness. While the parimutuel consensus mechanism does violate the key property of incentive compatibility, it is incentive compatible in the limit as the number of agents becomes large. Via simulations on real contest data, we show that violations of incentive compatibility are both rare and only minimally beneficial for the participants. This suggests that the parimutuel consensus mechanism is a reasonable mechanism for eliciting information in practice.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-728" tabindex="-1" role="dialog"
         aria-labelledby="modal-728-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-728-label">[Abstract] Approximation for Competitive Equilibria with Indivisible Goods and Generic Budgets</h4>
                </div>
                <div class="modal-body">
                    <p>We study the existence of Competitive Equilibria in Fisher market model but with generic budgets. We assume that the preferences of players are additive and the same for all players. Such equilibria do not exist for the simplest possible example of two players with equal budgets and a single item, thus, we study cases with unequal budgets. First, we prove existence of an approximation for Competitive Equilibria, then we represent a simple algorithm satisfying the same bound.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-576" tabindex="-1" role="dialog"
         aria-labelledby="modal-576-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-576-label">[Abstract] An Adaptive E-Learning System Based on Agents and Artifacts Metamodel</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we propose an adaptive e-learning system that supports personalization based on Agents and Artifacts (A{\&amp;}A) Metamodel. A{\&amp;}A Metamodel focuses on environment modeling in multi agent system (MAS) design and models entities in agents’ environments with artifacts as first class entities like the agents. From the perspective of MAS based E-Learning systems, learner models and learning resources are part of the environment of the agents and agents interact with them constantly. Thus, we propose an e-learning system that focuses on environment abstraction and models access to different learner models and learning resources with artifacts to support personalization. In MAS based e-learning systems with the same functionality, specific agents are responsible for modeling learner information and retrieving learning resources. However, in the proposed approach, by exploiting the A{\&amp;}A Metamodel, this operations are performed by artifacts to provide a more flexible and scalable solution. The proposed adaptive e-learning environment model is developed as a prototype with CArtAgO framework and a MAS based E-Learning system is also developed with Jason agent platform as a case study exploiting the proposed environment model. As part of the development of the proposed system, learning resources for Logic Design course are stored as learning objects in two learning object repositories and learners are modeled by using an ontology according to their learning styles. However, the proposed model can be extended to support various learning object repositories and different learning styles models. Finally, we present a discussion of current limitations and future directions for our approach.<br><br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-748" tabindex="-1" role="dialog"
         aria-labelledby="modal-748-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-748-label">[Abstract] Reinforcement Learning based on Limited Goal Selection for Multi-Agent Cooperation without Communication</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal"><span lang="EN-US">This paper focuses on reinforcement learning for multi-agent cooperation without communication among them and proposed the reinforcement learning which locally solves conflicts among agents to promote the local multi-agent cooperation without communication. Concretely, the proposed method extends Q-learning to employ internal reward for such a local cooperation instead of ordinary (external) reward. To guarantee the effectiveness of the proposed methods, we derived the mechanisms that can solve the following questions: (1) how the values of the cooperative behaviors types (i.e., the varieties of the cooperative behaviors of the agents) should be updated under the condition of no communication; and (2) how the optimal goal should be selected for cooperation among the agents (i.e., how to limit the cooperation). The intensive simulations on the maze problem for the agent-cooperation task have been revealed that our proposed method successfully enable the agents to acquire their cooperative behaviors even in no communication, while the conventional method (Q-learning) always fails to acquire such behaviors.<o:p></o:p></span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-349" tabindex="-1" role="dialog"
         aria-labelledby="modal-349-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-349-label">[Abstract] A Memory-based Multiagent Framework for Adaptive Decision Making</h4>
                </div>
                <div class="modal-body">
                    <p>Rapid adaptation to dynamically change one's policy based on a singular observation is a complex problem. This is especially difficult in multiagent systems where the global behavior is emergent from inter-agent interactions. In this paper, we introduce a memory-based learning framework called Distributed Gated Recurrent Unit with Memory Block (DGRU-MB) that enables rapid and adaptive decision making. Our framework builds on the Gated Recurrent Unit with Memory Block (GRU-MB) architecture, exploiting its modularity to define a flexible framework that can process multiple streams of sequential information; by using an external memory to identify and store dynamic features. The DGRU-MB framework combines multiagent learning with memory-based learning's ability to stitch together information across time. This enables DGRU-MB to rapidly assimilate useful features from a group of agents acting in parallel, consolidate it into a rapidly reconfigurable external memory and use it for adaptive decision making. We compare the performance of the DGRU-MB network on a simulated cybersecurity task with a traditional feedforward neural ensemble, and a centralized feedforward framework. Results demonstrate that DGRU-MB significantly outperforms the other methods and exhibits adaptive decision making to effectively solve this task.&nbsp;&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-192" tabindex="-1" role="dialog"
         aria-labelledby="modal-192-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-192-label">[Abstract] Applying Social Choice Theory to Multi-Objective Optimization</h4>
                </div>
                <div class="modal-body">
                    <p>Multi-objective optimization problems, for both discrete and continuous domains,&nbsp; often don't have a unique optimal solution. Furthermore, there are usually many possible available algorithms from which to chose for these problems, and one typically does not know in advance which one will be the most effective for a particular instance.&nbsp; Hyper-heuristics are&nbsp; often used as a means to solve this problem. In particular, the underlying idea of hyper-heuristics is to run several algorithms&nbsp; or heuristics and dynamically decide, based on different criteria, which problem or part of the problem should be solved by which algorithm or heuristic. In this paper, we explore the use of social choice theory in creating hyper-heuristics. Using hyper-heuristics created by using Borda, Copeland, and Kemeny-Young voting rules, we solve both continuous (WFG benchmark) and discrete (moTSP) multi-objective optimization problems, and the discuss the results obtained by each of these methods.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-732" tabindex="-1" role="dialog"
         aria-labelledby="modal-732-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-732-label">[Abstract] Bidding Strategies for Periodic Double Auctions Using Monte Carlo Tree Search</h4>
                </div>
                <div class="modal-body">
                    <p><span style="color: rgb(33, 33, 33); font-family: wf_segoe-ui_normal, &quot;Segoe UI&quot;, &quot;Segoe WP&quot;, Tahoma, Arial, sans-serif, serif, EmojiFont; font-size: 15px;">The Power Trading Agent Competition (TAC) game models a realistic smart grid energy trading scenario. It simulates multiple markets, including a day-ahead wholesale trading market based on a Periodic Double Auction (PDA) structure. &nbsp;Bidding strategies for PDAs are complicated by the need to make predictions and plan for bidding in future actions for the same good, which may affect the bidding strategy in the current auction. &nbsp;We present a general bidding strategy for PDAs based on forecasting clearing prices and using Monte Carlos Tree Search (MCTS) to plan a bidding strategy across multiple time periods. &nbsp;We developed a controlled simulator that isolates a version of the Power TAC wholesale market to evaluate bidding strategies in a realistic energy market PDA. We&nbsp;show that our MCTS bidding strategy cost-effective in buying energy comparing to other baselines and state-of-the-art strategies. The experiments also show that the performance of our strategy improves with a higher number of MCTS simulations, a more accurate price predictor, and action spaces with advanced action selection.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-691" tabindex="-1" role="dialog"
         aria-labelledby="modal-691-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-691-label">[Abstract] Maximum Likelihood approach for model-free Inverse Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal" style="margin-bottom:0in;margin-bottom:.0001pt;text-align:
justify;line-height:normal;mso-layout-grid-align:none;text-autospace:none"><span style="font-size: 12pt;">The problem of learning unknown reward function using a limited
number of demonstrations recorded from an expert’s behavior has been investigated
by researchers using different inverse reinforcement learning (IRL) approaches.
Most of the existing IRL algorithms either assume the availability of a transition
function or provide a complex inefficient approach to learn it. In this paper,
we present a model-free approach to IRL (learning without the knowledge of a transition
function), which casts IRL in the maximum likelihood framework. We use a
modification of Q-learning that replaces maximization with averaging to allow
computing the gradient of the Q-function. Our algorithm learns the reward
function of the expert represented as a linear combination of known features. We
use gradient ascent to update the feature weights to maximize the likelihood of
expert’s trajectories. We demonstrate on two problem domains that our approach improves
the likelihood compared to a previous method and converges in less number of
iterations.<o:p></o:p></span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-428" tabindex="-1" role="dialog"
         aria-labelledby="modal-428-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-428-label">[Abstract] Manipulating Rating Systems on Unknown Networks</h4>
                </div>
                <div class="modal-body">
                    <p>We study the effects of manipulation strategies on a network-based rating system, where the attacker, as often the case in real-world situations, does not have complete knowledge about the system's users and their connections.</p><p><br>Starting from a `personalised' rating model, in which individuals form their opinion looking at their influential peers, we analyse how a malicious service provider can take advantage of the underlying (social) network structure, even when the individuals' private evaluations and their connections are unknown, thereby lifting a number of constraining assumptions in the literature. </p><p>Specifically, we equip the attacker with the possibility of iterative manipulation and we identify how they can gain knowledge of the network and improve upon their final expected gain.</p><p><br>We look at several scenarios of increased generality, in particular whether or not existing users' types can be recognised, e.g. users that have already expressed an evaluation of the system, even if their precise evaluation cannot. </p><p><br>We present procedures yielding an optimal manipulation strategy, focussing on worst-case results, and then present computer simulations on a number of real-world inspired social networks.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-459" tabindex="-1" role="dialog"
         aria-labelledby="modal-459-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-459-label">[Abstract] Integrating Social Network Models with BDI-based simulations: An evacuation case study</h4>
                </div>
                <div class="modal-body">
                    <p>This paper presents an integration of Social Network modelling into an Agent Based Simulation framework that incorporates a cognitive and a physical model. We argue that social networks are an appropriate tool for modelling large scale macro-processes of diffusion of various kinds of content. These processes influence and interact with the cognitive processes of agents which in turn affect the agent behaviour in the (simulated) physical world. We consider it appropriate to integrate existing specialised subsystems into an overall architecture to achieve an integrated model. We present our implemented architecture for this, along with a case study which compares the results of a benchmark evacuation simulation, with simulations that integrate influence from a social network. We explore evacuation rates and travel time duration for comparison with the benchmark under 3 different configurations, with two different network structures. We observe that the social network, including its specific configuration does have a substantial effect on evacuation outcomes. We believe that the framework presented here provides a basis for modelling, exploring and understanding these interactions.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-551" tabindex="-1" role="dialog"
         aria-labelledby="modal-551-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-551-label">[Abstract] Learning with Opponent-Learning Awareness</h4>
                </div>
                <div class="modal-body">
                    <p>Multi-agent settings are quickly gathering importance in machine learning. Beyond a plethora of recent work on deep multi-agent reinforcement learning, hierarchical reinforcement learning, generative adversarial networks and decentralized optimization can all be seen as instances of this setting. However, the presence of multiple learning agents in these settings renders the training problem non-stationary and often leads to unstable training or undesired final results. We present Learning with Opponent-Learning Awareness (LOLA), a method that reasons about the anticipated learning of the other agents. The LOLA learning rule includes an additional term that accounts for the impact of the agent's policy on the anticipated parameter update of the other agents. We show that the LOLA update rule can be efficiently calculated using an extension of the likelihood ratio policy gradient update, making the method suitable for model-free reinforcement learning. This method thus scales to large parameter and input spaces and nonlinear function approximators. Preliminary results show that the encounter of two LOLA agents leads to the emergence of tit-for-tat and therefore cooperation in the infinitely iterated prisoners' dilemma, while independent learning does not. In this domain, LOLA also receives higher payouts compared to a naive learner, and is robust against exploitation by higher order gradient-based methods. Applied to infinitely repeated matching pennies, LOLA agents converge to the Nash equilibrium. In a round robin tournament we show that LOLA agents can successfully shape the learning of a range of multi-agent learning algorithms from literature, resulting in the highest average returns on the IPD. We also apply LOLA to a grid world task with an embedded social dilemma using deep recurrent policies. Again, by considering the learning of the other agent, LOLA agents learn to cooperate out of selfish interests.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-682" tabindex="-1" role="dialog"
         aria-labelledby="modal-682-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-682-label">[Abstract] Allocating Structured Tasks to Multiple Robots in Flooding Disaster Scenarios</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal"><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>PT-BR</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="true"
  DefSemiHidden="true" DefQFormat="false" DefPriority="99"
  LatentStyleCount="267">
  <w:LsdException Locked="false" Priority="0" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="59" SemiHidden="false"
   UnhideWhenUsed="false" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" QFormat="true" Name="TOC Heading"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin-top:0cm;
	mso-para-margin-right:0cm;
	mso-para-margin-bottom:10.0pt;
	mso-para-margin-left:0cm;
	line-height:115%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-fareast-language:EN-US;}
</style>
<![endif]-->Disasters such as flooding are dangerous for people in the affected areas and also for the rescue teams. Using multiple autonomous robots to support rescuers can minimise the risks. However, there are challenges in developing appropriate coordination strategies for multi-robots in such a way that robots perform their operations efficiently. Real-world scenarios, such rescue operations in flooding disasters, usually require the use of heterogeneous entities working on tasks with different structures, constraints, and degrees of complexity. In addition, dynamic changes in the environment and failures in robots during the mission may lead also to the need to reallocate previously allocated tasks. In this paper, we propose a dynamic, distributed, task allocation mechanism that considers different types of tasks for heterogeneous robots, where robots can play various different roles and carry out a limited number of tasks according to the roles they can play in order to support rescue teams. Furthermore, our task allocation mechanism can deal with dynamic task allocation. We have run several experiments in order to evaluate the proposed mechanism. The results demonstrate that the proposed mechanism performs reasonably fast and provides near-optimal allocations.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-395" tabindex="-1" role="dialog"
         aria-labelledby="modal-395-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-395-label">[Abstract] Solving the Synergistic Team Formation Problem</h4>
                </div>
                <div class="modal-body">
                    <p>The term co-operative learning is used to refer to learning procedures based on the organization of students into heterogeneous teams in which individual and team work are organized with the aim of achieving both completed academic tasks and co-learning. Key factors influencing team performance are competences, personality and gender of team members. Hence, we present a computational model to compose proficient and congenial teams based on individuals' personalities and gender, and their competences to perform tasks of different nature. Our model, called the synergistic team formation problem (STFP), extends Wilde's post-Jungian method for team composition, which solely employs individuals’ personalities and gender. In addition to presenting the synergistic team formation problem, we develop algorithms for solving the problem. The first one of these algorithms is based on an ILP formulation and its solution by a commercial ILP solver. While for small instances this approach is rather successful, this is not case for larger problem instances. Hence, we also develop a heuristic for the STFP that is meaningful for organizations and classrooms. Our computational results show that the heuristic approach underpins a powerful algorithm for the synergistic team composition problem.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-548" tabindex="-1" role="dialog"
         aria-labelledby="modal-548-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-548-label">[Abstract] Burn-In Demonstrations for Multi-Modal Imitation Learning</h4>
                </div>
                <div class="modal-body">
                    <p>Recent work on imitation learning has generated policies that reproduce expert behavior from multi-modal data. However, past approaches have focused only on recreating a small number of distinct, expert maneuvers, or have relied on supervised learning techniques that produce unstable policies. This work extends InfoGAIL, an algorithm for multi-modal imitation learning, to reproduce behavior over an extended period of time. Our approach involves reformulating the typical imitation learning setting to include ``burn-in demonstrations'' upon which policies are conditioned at test time. We demonstrate that our approach outperforms standard InfoGAIL in maximizing the mutual information between predicted and unseen style labels in road scene simulations, and we show that our method leads to policies that imitate expert autonomous driving systems over long time horizons.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-596" tabindex="-1" role="dialog"
         aria-labelledby="modal-596-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-596-label">[Abstract] A decomposition-based approach of global norms for hierarchical normative systems</h4>
                </div>
                <div class="modal-body">
                    <p>The norms concept (obligations, permissions and prohibitions) adapts well to the definition of Holonic Multiagent System (HMAS). HMAS forms a promising approach to software engineering for the modeling and development of hierarchical complex systems (Intelligent transportation systems, Smart city management systems, etc.). During the construction of these systems, different requirements can be considered: non-functional requirements&nbsp; and behavioral requirements. Norms are used as a mechanism to specify the requirements of these systems. However, most normative models for multi-agent systems do not take into account algorithms for norms coherence verification and theirs underlying complexities.&nbsp;</p><p>This paper proposes a Global Norms Decomposition (GND) approach for hierarchical normative systems. This approach allows the specification and verification of the requirements of hierarchical and critical intelligent systems. The requirements of these systems are specified by norms. Indeed, the GND approach allows (i) the specification of global norms in the abstract level of the studied system, (ii) the norms coherence checking for this level, and (iii) the successive refinement of these norms using a set of refinement rules that preserve properties of the system already proven in the highest level, in order to arrive finally at a concrete normative context which constitutes the behaviour model of the system. The GND approach allows the simplification of specification of norms, for an incrimental specification using a refinement process, and the reduction of complexity of checking the coherence of norms, building verification using refinement rules. Our approach is also illustrated by a case study describing the smart city management system.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-123" tabindex="-1" role="dialog"
         aria-labelledby="modal-123-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-123-label">[Abstract] Decentralised Inventory Routing in Dynamic, Adversarial and Partially Observable Environments</h4>
                </div>
                <div class="modal-body">
                    <p>We consider a dynamic inventory routing problem with multiple resource types, supply nodes, and autonomous vehicle agents (road, sea, and air) making decisions on where to collect and deliver resource in a decentralised manner. Sink nodes consume dynamically varying demands (whose timing and size are not known <i>a priori</i>). Network arcs, and vehicles, experience failures at times, and for durations, that are not known <i>a priori</i>. These dynamic events are caused by an intelligent adversary, seeking to disrupt the network. Our objective is to design policies for vehicle agents (indicating which resources to collect, and where to deliver those resources, over time) that minimise the likelihood of <i>stockout </i>events arising (where insufficient resource is present at a sink to meet demand). We present a series of policies to be applied by each vehicle agent in a decentralised fashion. We evaluate the performance of these policies across several scenarios with varying network topologies, and examine the impact of <i>partial observability</i>, where vehicles collect and spread state knowledge as they traverse the network.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-274" tabindex="-1" role="dialog"
         aria-labelledby="modal-274-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-274-label">[Abstract] Compositional Correctness in Multiagent Interactions</h4>
                </div>
                <div class="modal-body">
                    <p>&nbsp; An interaction protocol specifies the constraints on communication</p><p>&nbsp; between agents in a multiagent system.&nbsp; Ideally, we would like to be</p><p>&nbsp; able to treat protocols as modules and compose them in a declarative</p><p>&nbsp; manner to systematically build more complex protocols.&nbsp; Supporting</p><p>&nbsp; composition correctly requires taking into account the causal</p><p>&nbsp; dependencies between protocols.&nbsp; One particular problem that may</p><p>&nbsp; arise from inadequate consideration of causal dependencies is that</p><p>&nbsp; the enactment of a composite protocol may violate \emph{atomicity};</p><p>&nbsp; that is, some components may be initiated but prevented from</p><p>&nbsp; completing.&nbsp; We use this \emph{all or nothing} principle as the</p><p>&nbsp; basis for formalizing atomicity as a novel correctness property for</p><p>&nbsp; protocols.</p><p><br></p><p>&nbsp; Our contributions are the following.&nbsp; One, we motivate and formalize</p><p>&nbsp; atomicity and highlight its distinctiveness from related correctness</p><p>&nbsp; notions.&nbsp; Two, we give a decision procedure for verifying atomicity</p><p>&nbsp; and report results from an implementation.&nbsp; For concreteness of</p><p>&nbsp; exposition and technical development, we adopt BSPL as an exemplar</p><p>&nbsp; of information-based approaches.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-173" tabindex="-1" role="dialog"
         aria-labelledby="modal-173-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-173-label">[Abstract] Boundedly Rational Voters in Large(r) Networks</h4>
                </div>
                <div class="modal-body">
                    <p>In Iterative Voting, voters first cast their ballots but may change their minds upon observing the ballots of others.&nbsp; Previous models have extended Iterative Voting to the incomplete information domain of social networks, where voters only observe the ballots of their friends.&nbsp; However, these models are based on computationally-intensive calculations of expected utilities.&nbsp; We propose a framework of bounded rationality for voters situated in social networks.&nbsp; Using this framework, we propose and test a number of heuristics that reduce the computation required for optimal strategic reasoning by several orders of magnitude compared to previous work, while retaining similar qualitative behaviors.&nbsp; These heuristics enable us to conduct simulations on how the size of the voting population affects strategic behavior.&nbsp; To illustrate the effectiveness of our approach, we apply our heuristics to explore the Micromega rule –-- an observation in political science that large political parties favor small assemblies.&nbsp; We find that the size of electoral districts is a contributing factor to the Micromega rule in some networks. Fringe candidates retain more support in smaller districts, while larger parties dominate in larger districts.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-484" tabindex="-1" role="dialog"
         aria-labelledby="modal-484-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-484-label">[Abstract] Microservices as an Architectural Style for Multi-agent Systems</h4>
                </div>
                <div class="modal-body">
                    <p>This paper presents an empirical approach to implement multi-agent systems adopting microservices as an architectural style. First, we discuss the conceptual similarities between microservices and agents through a cross analysis of microservice tenets and the general characterization of agents. The analysis reveals that indeed just like agents, microservices can be thought of as autonomous software entities, driven by goals and</p><p>evolving within an environment and communicating with one another. Next, using a real-world application we follow established guidelines for developing applications using a microservice architecture. We document the key steps along the way. Finally, we show how the theoretical model within each agent in the system is being realized by the corresponding service(s).</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-493" tabindex="-1" role="dialog"
         aria-labelledby="modal-493-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-493-label">[Abstract] Bayesian Best-Arm Identification for Selecting Influenza Mitigation Strategies</h4>
                </div>
                <div class="modal-body">
                    <p>Pandemic influenza has the epidemic potential to kill millions of people. While various preventive measures exist (i.a., vaccination and school closures), deciding on strategies that lead to their most effective and efficient use, remains challenging. To this end, individual-based epidemiological models are essential to assist decision makers in determining the best strategy to curve epidemic spread. However, individual-based models are computationally intensive and therefore it is pivotal to identify the optimal strategy using a minimal amount of model evaluations. Additionally, as epidemiological modeling experiments need to be planned, a computational budget needs to be specified a priori. Consequently, we present a new sampling method to optimize the evaluation of preventive strategies using fixed budget best-arm identification algorithms. We use epidemiological modeling theory to derive knowledge about the reward distribution which we exploit using Bayesian best-arm identification algorithms (i.e., Top-two Thompson sampling and BayesGap). We evaluate these algorithms in a realistic experimental setting and demonstrate that it is possible to identify the optimal strategy using only a limited number of model evaluations, i.e., 2-to-3 times faster compared to the uniform sampling method, the predominant technique used for epidemiological decision making in the literature. Finally, we contribute and evaluate a statistic for Top-two Thompson sampling to inform the decision makers about the confidence of an arm recommendation.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-446" tabindex="-1" role="dialog"
         aria-labelledby="modal-446-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-446-label">[Abstract] Combining Prediction of Human Decisions with ISMCTS in Imperfect Information Games</h4>
                </div>
                <div class="modal-body">
                    <p>Monte Carlo Tree Search (MCTS) has been extended to many imperfect information games.</p><p>However, due to the added complexity that uncertainty introduces, these adaptations have not reached the same level of practical success as their perfect information counterparts. In this paper we consider the development of agents that perform well against humans in imperfect information games with partially observable actions. We introduce the Semi-Determinized-MCTS (SDMCTS), a variant of the Information Set MCTS algorithm (ISMCTS). More specifically, SDMCTS generates a predictive model of the unobservable portion of the opponent's actions from historical behavioral data. Next, SDMCTS performs simulations on an instance of the game where the unobservable portion of the opponent's actions are determined. Thereby, it facilitates the use of the predictive model in order to decrease uncertainty. We present an implementation of the SDMCTS applied to the Cheat Game, a well-known card game, with partially observable (and often deceptive) actions.</p><p>Results from experiments with 120 subjects playing a head-to-head Cheat Game against our SDMCTS agents suggest that SDMCTS performs well against humans, and its performance improves as the predictive model's accuracy increases.&nbsp;</p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-713" tabindex="-1" role="dialog"
         aria-labelledby="modal-713-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-713-label">[Abstract] Utility Decomposition with Deep Corrections for Scalable Planning under Uncertainty</h4>
                </div>
                <div class="modal-body">
                    <p>Decomposition methods have been proposed in the past to approximate solutions to large sequential decision making problems. In contexts where an agent interacts with multiple entities, utility decomposition can be used where each individual entity is considered independently. The individual utility functions are then combined in real time to solve the global problem. Although these techniques can perform well empirically, they sacrifice optimality. This paper proposes an approach inspired from multi-fidelity optimization to learn a correction term with a neural network representation. Learning this correction can significantly improve performance. We demonstrate this approach on a pedestrian avoidance problem for autonomous driving. By leveraging strategies to avoid a single pedestrian, the decomposition method can scale to avoid multiple pedestrians. We verify empirically that the proposed correction method leads to a significant improvement over the decomposition method alone and outperforms a policy trained on the full scale problem without utility decomposition.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-574" tabindex="-1" role="dialog"
         aria-labelledby="modal-574-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-574-label">[Abstract] Enhancing Social Experience via Context Sharing</h4>
                </div>
                <div class="modal-body">
                    <p>A socially intelligent personal agent understands and helps its user respect norms governing the user's interactions in a society. However, it is often appropriate for a user---and the user's agent---to deviate from a norm under certain context. We develop a framework wherein a personal agent deviating from a norm reveals the context to other agents in the society. We make two claims about the impact of such context revealing. First, revealing deviation context and reasoning about context revealed by others helps personal agents accurately learn applicable norms. Second, by acting according to such shared context-dependent norms, a personal agent can provide its user a more satisfying social experience than an agent who does not reason about context revealed by others. We demonstrate these claims via social simulations involving agent societies of varying sizes and diverse characteristics reflecting pragmatic, considerate, and selfish agents.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-559" tabindex="-1" role="dialog"
         aria-labelledby="modal-559-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-559-label">[Abstract] Training Dialogue Systems With Human Advices</h4>
                </div>
                <div class="modal-body">
                    <p>One major drawback of Reinforcement Learning (RL) Spoken Dialogue Systems is that they inherit from the general exploration requirements of RL which makes them hard to deploy from an industry perspective. On the other hand, industrial systems rely on human expertise and hand written rules so as to avoid irrelevant behavior to happen and maintain acceptable experience from the user point of view.&nbsp;&nbsp;</p><p>In this paper, we attempt to bridge the gap between those two worlds by providing an easy way to incorporate all kinds of human expertise in the training phase of a Reinforcement Learning Dialogue System. Our approach, based on the TAMER framework, enables safe and efficient policy learning by combining the traditional Reinforcement Learning reward signal with an additional reward, encoding expert advices.</p><p>Experimental results show that our method leads to substantial improvements over more traditional Reinforcement Learning methods.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-451" tabindex="-1" role="dialog"
         aria-labelledby="modal-451-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-451-label">[Abstract] On Designing Optimal Data Purchasing Strategies for Online Ad Auctions</h4>
                </div>
                <div class="modal-body">
                    <p>In online advertising, advertisers can purchase consumer relevant data from data marketplaces with a certain expenditure, and exploit the purchased data to guide the bidding process in ad auctions. One of the pressing problem faced by advertisers is to design the optimal data purchasing strategy (how much data to purchase to be competitive in bidding process) in online ad auctions. In this paper, we model the data purchasing strategy design as a convex optimization problem, jointly considering the expenditure paid during data purchasing and the benefits obtained from ad auctions. Using the techniques from Baysian game theory and convex analysis, we derive the optimal purchasing strategies for advertisers in different market scenarios. We also theoretically prove that the resulting strategy profile is the unique one that achieves Nash Equilibrium. Our analysis shows that the proposed data purchasing strategy can handle diverse ad auctions and valuation learning models. Our numerical results further confirm intuitions that the advertisers would typically purchase less data to avoid the risks of wasted purchasing under fiercer competition, and purchase more to extract huger profits when the website gains more popularity.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-643" tabindex="-1" role="dialog"
         aria-labelledby="modal-643-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-643-label">[Abstract] Nash equilibrium computation in resource allocation games</h4>
                </div>
                <div class="modal-body">
                    <p>We study Nash equilibrium (NE) computation in <i>resource allocation games</i>, where each player has a set of resources with exponentially many possibilities for allocation (exponentially many strategies), but with succinct payoff representation. Blotto is one such celebrated game between two players for devising war strategies. A recent series of works provided the first polynomial time algorithm for Blotto zero-sum games [Ahmadinejad et al. 2016]. Our first set of results extends this algorithm to multi-player Blotto game on a network (polymatrix game), where every node plays a two-player Blotto game with each of its neighbors in the network but has to choose a common strategy to play against all of them. The algorithm applies even when the game on each edge is not zero-sum, but the total payoff is zero. This captures situations where teams of players are competing against each other.&nbsp;</p><p>Given that general Blotto games are PPAD-hard, next we consider <i>coordination Blotto game</i>, where players are trying to "coordinate" resource allocation. We focus on the pure NE, since a coordination game is guaranteed to have one. We obtain a polynomial-time algorithm to find a best payoff NE for the case of two-players, and then extend it to polymatrix game with constantly many players. On the other hand, with arbitrarily many players, we show that finding a best payoff NE is NP-complete even in case of star graphs. Additionally, for the general polymatrix case, we show that finding an arbitrary NE is in PLS; PLS-hardness follows from [Cai, Daskalakis 2011].&nbsp;</p><p>Lastly, we consider a security-type <i>patrolling game</i> on a graph, where the first player (attacker) is trying to select paths to connect a set of sources to a set of destinations, while the second player (defender) is trying to block these paths by putting patrols on edges but is restricted by the number of patrols available. We show that even computing a best-response of the first player is NP-hard. Despite this we design efficient algorithms to compute a NE for two cases: <i>(i)</i> single path multiple edges, and <i>(ii)</i> multiple paths and single edge. The algorithms crucially uses a simple characterization of NE strategies through min-cuts.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-371" tabindex="-1" role="dialog"
         aria-labelledby="modal-371-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-371-label">[Abstract] Activating the &quot;Breakfast Club&quot;: Modeling Influence Spread in Natural-World Social Networks</h4>
                </div>
                <div class="modal-body">
                    <p>&nbsp; While reigning models of diffusion have privileged the structure of a given social network as the key to informational exchange, real human interactions do not appear to take place on a single graph of connections. Using data collected from a pilot study of the spread of HIV awareness in social networks of homeless youth, we show that health information did not diffuse in the field according to the processes outlined by dominant models. Since physical network diffusion scenarios often diverge from their more well-studied counterparts on digital networks, we propose an alternative Activation Jump Model (AJM) that describes information diffusion on physical networks from a multi-agent team perspective. Our model exhibits two main differentiating features from leading cascade and threshold models of influence spread: 1) The structural composition of a seed set team impacts each individual node's influencing behavior, and 2) an influencing node may spread information to non-neighbors. We show that the AJM significantly outperforms existing models in its fit to the observed node-level influence data on the youth networks. We then prove theoretical results, showing that the AJM exhibits many well-behaved properties shared by dominant models. Our results suggest that the AJM presents a flexible and more accurate model of network diffusion that may better inform influence maximization in the field.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-382" tabindex="-1" role="dialog"
         aria-labelledby="modal-382-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-382-label">[Abstract] A Game-theoretic Approach for Channel Security Against Active Time-Varying attacks Based on Artificial Noise.</h4>
                </div>
                <div class="modal-body">
                    <div>To penetrate sensitive communication systems, attackers can attack the channel using an Active Time-Varying(ATV) way, which will lead to a great information losses. The conventional way is to encrypt the original signal making it difficult for attackers to get information. However, this technology is restricted by the limited wireless terminal equipment. In this paper, we choose to insert artificial noises into the channel, which aims at disturbing the attackers and reducing the losses of system once attacks occur. But this technology would produce some side effects and there is a tradeoff between inserting artificial noise and minimizing information losses.</div><div><br></div><div>In this paper, we address this issue and propose a game-theoretic framework to minimize the total losses. We model the problem as a Stackelberg security game and propose a novel binary search based algorithm to efficiently compute the Strong Stackelberg Equilibrium which is the optimal defense strategy. This algorithm reduces a M-dimensional problem to M 1-dimensional problems so that the complexity is reduced. The simulation results show that our proposed algorithm significantly outperforms other non-strategic strategies in terms of decreasing the total losses against ATV attacks.</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-236" tabindex="-1" role="dialog"
         aria-labelledby="modal-236-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-236-label">[Abstract] Modeling dysfunctional and functional emotions in BDI agents</h4>
                </div>
                <div class="modal-body">
                    <p><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:
Calibri;mso-fareast-theme-font:minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;
mso-bidi-theme-font:minor-bidi;mso-ansi-language:EN-US;mso-fareast-language:
EN-US;mso-bidi-language:AR-SA">Emotional modeling in intelligent agents has had
an increasing development in recent years, so different types of emotions and several
aspects related to these have been modeled, seeking to achieve a realistic
human-like behavior. An interesting not yet modeled aspect related to emotions
is their dysfunctional/functional character which is essential as it is related
to the individual adaptation capability. In the present paper, we propose an
EBDI framework to model the dysfunctional/functional character of emotions and
its related conduct. The framework is based on a therapeutic model named ABC
that allows determining the irrational/rational nature of the
cognitive-affective process and its consequences. We have expanded the BDI belief
concept to classify the nature (irrational/rational) of the cognitive process,
that lead to emotional and behavioral consequences allowing the modeling of
negative and positive (dysfunctional/functional) emotions and the conduct
(maladaptive/adaptive) related to them. Moreover, the proposal opens the possibility
to model interesting disturbing humans’ states, very hard of modeling on
intelligent agents, and to reproduce real human behavior. Its potential through
an example scenario.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-533" tabindex="-1" role="dialog"
         aria-labelledby="modal-533-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-533-label">[Abstract] On the Role of Mobility, Adaptivity, and Interaction Topologies in Social Dilemmas</h4>
                </div>
                <div class="modal-body">
                    <p>Numerous studies have developed and analysed strategies for maximising utility in social dilemmas from both an individual agent's perspective and more generally from the viewpoint of a society. In this paper we bring this body of work together by investigating the success of a wide range of strategies in environments with varying characteristics, comparing their success. In particular we study within agent-based simulations, different interaction topologies, agents with and without mobility, and strategies with and without adaptation in the form of reinforcement learning, in both competitive and cooperative settings represented by the Prisoner's Dilemma and the Stag Hunt, respectively. The results of our experiments show that allowing agents mobility decreases the level of cooperation in the society of agents, due to singular interactions with individual opponents that limit the possibility for direct reciprocity. Unstructured environments similarly support a greater number of singular interactions and thus higher levels of defection in the Prisoner's Dilemma. In the Stag Hunt, strategies that prioritise risk taking show a greater level of success regardless of environment topology. As such, our range of experiments yield new insights into the role that mobility, adaptivity and interaction topologies all play in the study of co-operation&nbsp; in agent societies.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-597" tabindex="-1" role="dialog"
         aria-labelledby="modal-597-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-597-label">[Abstract] Poll-Confident Voters in Iterative Voting</h4>
                </div>
                <div class="modal-body">
                    <p>This article deals with strategic voting under incomplete information. The only indication available to a voter consists in the results of a public opinion poll and the vote intentions of her relatives, given by a social network, which is modeled as a graph over the agents. We assume a specific type of behaviour for the voters: they are confident in the poll and they update the results given by the poll with the information they get from their relatives. We consider an iterative voting model based on this behaviour type and study the associated “poll-confident” dynamics. Two configurations are investigated: an election with a single initial poll and one where several polls are performed and communicated all along the period. For both configurations, we analyse the convergence of the poll-confident dynamics regarding the structure of the social network. Moreover, we ask the natural question of manipulation from the polling institute.<br></p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-648" tabindex="-1" role="dialog"
         aria-labelledby="modal-648-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-648-label">[Abstract] Deceiving Cyber Adversaries: A Game Theoretic Approach</h4>
                </div>
                <div class="modal-body">
                    <p>An important way cyber adversaries find vulnerabilities in modern networks is through reconnaissance, in which they attempt to identify configuration specifics of network hosts. To increase uncertainty of adversarial reconnaissance, the network administrator (henceforth, defender) can introduce deception into responses to network scans, such as obscuring certain system characteristics.</p><p>We introduce a novel game theoretic model of deceptive interactions of this kind between a defender and a cyber attacker, which we call the Cyber Deception Game. We consider both a powerful (rational) attacker, who is knows the defender's exact deception strategy, and a naive attacker who is not. We show that the problem is NP-hard for both types of attackers. For the case with a powerful attacker, we provide a mixed-integer linear program solution, sped up with a novel cut generation method, as well as a fast and effective greedy algorithm. Similarly, we provide complexity results and propose exact and heuristic approaches when the attacker is naive. Our extensive experimental analysis demonstrates the effectiveness of our approaches.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-569" tabindex="-1" role="dialog"
         aria-labelledby="modal-569-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-569-label">[Abstract] Temporal Multiple-Plan Recognition and Failure Prediction for Ambient Assisted Living</h4>
                </div>
                <div class="modal-body">
                    <p>The process of inferring agent's plans/goals from their observed actions is known as plan recognition, which analyses how low-level observations about agents and environment can be associated with a high-level plan description. This work addresses the problems of recognising multiple plans in realistic environments, learning activity duration, and detecting anomalies in plan execution. We deal with problems related to disambiguation of multiple hypotheses and detecting anomalies in plan execution by exploiting both the inherent hierarchical organisation of activities and their expected time and duration, developing an efficient algorithm to filter hypotheses by applying temporal and path length constraints. We present a number of experimental results showing that, besides addressing limitations of traditional plan recognition algorithms, our filtering approach can significantly improve the precision of the underlying plan recognition algorithm. The experiments include synthetically generated plan libraries as well as plan libraries and observations obtained from real-world datasets relevant to the context of ambient assisted living.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-546" tabindex="-1" role="dialog"
         aria-labelledby="modal-546-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-546-label">[Abstract] Symbolic Dynamic Programming for Risk-sensitive Markov Decision Process with limited budget</h4>
                </div>
                <div class="modal-body">
                    <p>Risk-Sensitive Markov Decision Processes (RS-MDPs) set the optimization criterion as maximizing the probability of the cumulative cost not to be greater than an user-defined budget $\theta_u$,&nbsp; guaranteeing that worst executions of an MDP occur with the least possible probability. Solutions for these problems have a scalability issue when handling large cost intervals, since they require the enumeration of the costs and reasoning over the space of augmented states, i.e. a set of pairs $(state,budget)$. In this work, we propose the first&nbsp; symbolic dynamic programming algorithm for risk-sensitive MDPs that explores conditional independence of the transition structure over the augmented state space. We first define a factored RS-MDP and propose a new, sound and complete, Symbolic Value Iteration algorithm, called RS-SPUDD. The proposal algorithm also prunes invalid states and performs early termination.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-406" tabindex="-1" role="dialog"
         aria-labelledby="modal-406-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-406-label">[Abstract] Full Epistemic-entrenchment Characterization of Parikh’s Axiom</h4>
                </div>
                <div class="modal-body">
                    <p><span style="font-family: verdana, arial, helvetica; font-size: small;">In this article, we provide the full epistemic-entrenchment characterization of Parikh's relevance-sensitive axiom for belief revision — known as axiom (P). In short, axiom (P) states that, if a belief set K can be divided into two disjoint compartments (referring to different subject matters), and the new information φ relates only to the first compartment, then the revision of K by φ should not affect the second compartment. Accordingly, we define the subclass of epistemic entrenchments, that induce AGM revision functions, satisfying the strong version of axiom (P). Since the notions of relevance and local change are inherent in almost all intellectual activity, the results reported herein are significant for many domains of Artificial Intelligence.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-606" tabindex="-1" role="dialog"
         aria-labelledby="modal-606-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-606-label">[Abstract] Argumentation-based reasoning in BDI agents using the Toulmin model</h4>
                </div>
                <div class="modal-body">
                    <p>The theory of argumentation encompasses several fields of knowledge, gaining significant space in the community of multi-agent systems, since it can enable the agent to reason about its decisions, through perceptions about the environment or through dialogue with other agents. Toulmin has developed an argumentation model in the field of philosophy, which indicates six components to assemble the structure of an argument: data, warranty, claim, backing, qualifier and refutation. This work proposes an architecture for BDI agents for argumentation-based reasoning based on the Toulmin model. We have developed some examples in the AgentSpeak (L) language in order to validate the proposed architecture.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-241" tabindex="-1" role="dialog"
         aria-labelledby="modal-241-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-241-label">[Abstract] Outlook on Multi-agent Technology for Industrial Applications</h4>
                </div>
                <div class="modal-body">
                    <p><span lang="EN-US" style="font-size: 11pt; line-height: 115%; font-family: 'Times New Roman', serif;">For over a quarter of a century multi-agent systems
have been considered as one of the most promising technologies for
conceptualization and software implementation of complex distributed systems.
However, in practice, the situation is very different: the industry rarely uses
this technology, despite the appearing new classes of applications for which it
is the perfect match. The paper analyzes recent anticipations and real
achievements in the practical application of multi-agent systems at the
industrial level. It also identifies problems that, currently impede extensive
industrial implementation of multi-agent systems and technologies, as well as
ways to overcome them. Additionally the paper analyzes classes of applications,
for which multi-agent technologies have undeniable advantages. Finally,
prospects for development of these technologies are evaluated up to the level
of industrial application.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-126" tabindex="-1" role="dialog"
         aria-labelledby="modal-126-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-126-label">[Abstract] Efficient Auctions with Identity-Dependent Mixed Externalities</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-family: verdana, arial, helvetica; font-size: small;">We investigate a class of single-item multi-supply auctions with bidders who have identity-based mixed externalities. In such an auction, each bidder has a set of competitors and a set of friends (either set can be empty). Her private valuation from winning an item decreases with the number of her winning competitors while increases with the number of her winning friends.
</span><br style="font-family: verdana, arial, helvetica;"><span style="font-family: verdana, arial, helvetica; font-size: small;">Externalities are prevalent in many applications when the auctioned goods play a role in future interactions among the auction’s participants, such as patent licensing and sponsored search auctions. The development of auctions with externalities, however, is stymied by the computational difficulty of the underlying welfare maximization allocation problem; even without the consideration of truthfulness, the problem of social welfare maximization with only negative externalities is NP-hard and even hard to approximate within a constant factor (unless P=NP).
</span><br style="font-family: verdana, arial, helvetica;"><span style="font-family: verdana, arial, helvetica; font-size: small;">In this work, we design polynomial time and truthful mechanisms under different restrictions on the underlying competitor/friend graph structure. Our results can be summarized as follows.
</span><br style="font-family: verdana, arial, helvetica;"><span style="font-family: verdana, arial, helvetica; font-size: small;">1. When each bidder has only one competitor or one friend, we propose a truthful and welfare maximizing mechanism.
</span><br style="font-family: verdana, arial, helvetica;"><span style="font-family: verdana, arial, helvetica; font-size: small;">2. We design a truthful and 1+ε-approximationmechanism when the underlying graph is planar.
</span><br style="font-family: verdana, arial, helvetica;"><span style="font-family: verdana, arial, helvetica; font-size: small;">3. We give two truthful mechanisms when bidders have arbitrary mixed relations, with welfare approximation ratio n/ log n and ⌈(d + 1)/3⌉, respectively, where d is the maximum degree of the “undirected” graph.
</span><br style="font-family: verdana, arial, helvetica;"><span style="font-family: verdana, arial, helvetica; font-size: small;">Finally, we conduct experiments in a company-relation scenario and analyze the trade-off between social welfare and revenue obtained by our mechanism, item supply, and the degree of externality.</span><br></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-254" tabindex="-1" role="dialog"
         aria-labelledby="modal-254-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-254-label">[Abstract] Facing Multiple Attacks in Adversarial Patrolling Games with Alarmed Targets</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal">We study, to the best of our knowledge, the first security
game in which an Attacker can observe the movements of a patroller controlled
by a Defender on an arbitrary graph and, exploiting multiple resources, can
perform sequential attacks in a single (non-repeated) game against perfectly
alarmed targets. Our game model is in extensive form—allowing each player to
play multiple times—with perfect information and zero-sum utilities, and the
game tree is exponentially large both in the size of graph and in the number of
resources available to the Attacker. Nevertheless, we show that, fixed the
number of resources of the Attacker, the equilibrium path can be computed in
polynomial time in the size of the graph, while it is NP-hard otherwise.
Furthermore, we study the robustness of the Defender’s strategy when she makes
a wrong guess about the number of Attacker’s resources (that usually is
unknown), showing that even the error of just a single resource can lead to an
arbitrary loss. Finally, we investigate the performance of online algorithms when
no information about the Attacker’s resources is available.<o:p></o:p></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-191" tabindex="-1" role="dialog"
         aria-labelledby="modal-191-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-191-label">[Abstract] Finite Sample Analysis of LSTD($\lambda$) with Random Projections</h4>
                </div>
                <div class="modal-body">
                    <p>Policy evaluation (i.e., estimate the value function of a fixed policy which is the expected long-term accumulated reward an agent would receive) with linear function approximation is an important problem in reinforcement learning. When facing high-dimensional feature spaces, such a problem becomes extremely hard considering the computation efficiency and quality of approximations. We propose a new algorithm, LSTD($\lambda$)-RP, which leverages random projection techniques and takes eligibility traces into consideration to tackle the above two challenges. We carry out theoretical analysis of LSTD($\lambda$)-RP from two aspects: (1) deriving sufficient conditions to guarantee the uniqueness of sample-based LSTD($\lambda$)-RP solution with high probability; (2) providing meaningful upper bounds of the estimation error, approximation error and total generalization error.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-363" tabindex="-1" role="dialog"
         aria-labelledby="modal-363-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-363-label">[Abstract] Arbitrage-free Pricing in User-based Markets</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'CMR9'">Users have various attributes, and in user-based markets there are buyers who wish to
buy a target set of users with specific sets of attributes. The problem we address is that, given a set
of demand from the buyers, how to allocate users to buyers, and how to price the transactions. This
problem arises in online advertising, and is particularly relevant in advertising in social platforms like
Facebook, LinkedIn and others where users are represented with many attributes, and advertisers are
buyers with specific targets. This problem also arises more generally in selling data about online users,
in a variety of data markets.
</span></p>
					<p><span style="font-size: 9.000000pt; font-family: 'CMR9'">We introduce </span><span style="font-size: 9.000000pt; font-family: 'CMTI9'">arbitrage-free </span><span style="font-size: 9.000000pt; font-family: 'CMR9'">pricing, that is, pricing that prevents buyers from acquiring a lower unit
price for their true target by strategically choosing substitute targets and combining them suitably.
We show that </span><span style="font-size: 9.000000pt; font-family: 'CMTI9'">uniform </span><span style="font-size: 9.000000pt; font-family: 'CMR9'">pricing – pricing where all the targets have identical price – can be computed in
polynomial time, and while this is arbitrage-free, it is also a logarithmic approximation to the maximum
revenue arbitrage-free pricing solution. We also design a different arbitrage-free non-uniform pricing
– pricing where different targets have different prices – solution which has the same guarantee as the
arbitrage-free uniform pricing but is empirically more effective as we show through experiments. We
also study more general versions of this problem and present hardness and approximation results.&nbsp;</span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-583" tabindex="-1" role="dialog"
         aria-labelledby="modal-583-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-583-label">[Abstract] One-Shot Learning using Mixture of Variational Autoencoders: a Generalization Learning approach</h4>
                </div>
                <div class="modal-body">
                    <p>Deep learning, even if it is very successful nowadays, traditionally needs very large amounts of labeled data to perform excellent on the classification task. In an attempt to solve this problem, the one-shot learning paradigm, which makes use of just one labeled sample per class and prior knowledge, becomes increasingly important. In this paper, we propose a new one-shot learning method, dubbed MoVAE (Mixture of Variational AutoEncoders), to perform classification. Complementary to prior studies, MoVAE represents a shift of paradigm in comparison with the usual one-shot learning methods, as it does not use any prior knowledge. Instead, it starts from zero knowledge and one labeled sample per class. Afterward, by using unlabeled data and the generalization learning concept (in a way, more as humans do), it is capable to gradually improve by itself its performance. Even more, if there are no&nbsp; unlabeled data available MoVAE can still perform well in one-shot learning classification. We demonstrate empirically the efficiency of our proposed approach on three datasets, i.e. the handwritten digits (MNIST), fashion products (Fashion-MNIST), and handwritten characters (Omniglot), showing that MoVAE outperforms state-of-the-art one-shot learning algorithms.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-552" tabindex="-1" role="dialog"
         aria-labelledby="modal-552-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-552-label">[Abstract] A Conceptual Framework for the Design of Human-Agent Collectives Architectures Based on Consent Patterns</h4>
                </div>
                <div class="modal-body">
                    <p>Human-Agent Collectives (HAC) are systems in which humans and agents coalitions work together to take advantage of their collective intelligence in order to optimize the performance of tasks within scenarios that involve potentially high degrees of dynamism and uncertainty. This paper presents a contribution to design methodology to be used to implement systems that involve humans and agents. In particular, building upon patterns of consent for HACs, we &nbsp;formalize the main patterns of interaction and consent that exist in such HACs. We demonstrate the use of such patterns the case of an emergency response scenario where humans and agents are called upon to gather data and act on events in the real world.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-252" tabindex="-1" role="dialog"
         aria-labelledby="modal-252-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-252-label">[Abstract] Socially Motivated Partial Cooperation in Multi-agent Local Search</h4>
                </div>
                <div class="modal-body">
                    <p>Partial Cooperation is a paradigm and a corresponding model that was proposed to represent Multi-agent systems in which agents, like regular people in many realistic situations, are willing to cooperate to achieve a global goal, as long as some minimal threshold on their personal utility is satisfied. For example, a professor willing to take upon herself an additional teaching assignment for the benefit of the department and her students, as long as she has enough time left for her research. Distributed local search algorithms were proposed in order to solve asymmetric distributed constraint optimization problems (ADCOPs) in which agents are partially cooperative.</p><p><br></p><p>We contribute to the research on partial cooperative multi-agent local search by: 1) extending the partial cooperative model to allow it to represent dynamic cooperation intentions, affected by changes in agents wealth. Such changes in agents' intentions correspond to studies on human cooperation intentions in social studies literature. 2) proposing a novel local search algorithm in which agents receive indications of others' preferences on their actions (assignment selection) and thus, can perform actions that are socially beneficial. Our empirical study reveals the advantage of the proposed algorithm in multiple benchmarks. Specifically, on realistic meeting scheduling problems it overcomes limitations of standard local search algorithms.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-127" tabindex="-1" role="dialog"
         aria-labelledby="modal-127-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-127-label">[Abstract] An Efficient Auction with Variable Reserve Prices for Ridesourcing</h4>
                </div>
                <div class="modal-body">
                    <p><span style="font-family: verdana, arial, helvetica; font-size: small;">Ridesourcing refers to the service that matches passengers who need a car to personal drivers. In this work, we study an auction model for ridesourcing that sells multiple items to unit-demand single-parameter agents with variable reserve price constraints. In this model, there is an externally imposed reserve price set for every item, and the price is both item- and bidder-dependent. Such auctions can also find applications in a number of other traditional and online markets, such as ad auction or online laboring market. Our main result is a truthful, individually rational, and computationally efficient mechanism that respects the reserve price constraints and always achieves at least half of the optimal social benefit (i.e., the sum of the valuations of the winning agents). Furthermore, we show such efficiency approximation is tight by proving that even without any computational constraints, no truthful and individually rational mechanism can achieve better than 2-approximation for social benefit maximization. Finally, we evaluate the performance of our mechanism based on real taxi-trace data. The empirical results show that our mechanism outperforms other benchmark mechanisms in terms of both social benefit and revenue.&nbsp;</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-456" tabindex="-1" role="dialog"
         aria-labelledby="modal-456-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-456-label">[Abstract] Efficient Coalition Structure Generation via Approximately Equivalent Induced Subgraph Games</h4>
                </div>
                <div class="modal-body">
                    <p>We show that any characteristic function game (CFG) G can be always turned into an approximately equivalent game represented using the induced subgraph game (ISG) representation. Such a transformation incurs obvious benefits in terms of tractability of computing solution concepts for G. Our transformation approach, namely AE-ISG, is based on the solution of a norm approximation problem. We then propose a novel coalition structure generation (CSG) approach for ISGs that is based on graph clustering, which outperforms existing CSG approaches for ISGs by using state of the art optimisation solvers. Finally, we provide theoretical guarantees on the value of the optimal CSG solution of G wrt the optimal CSG solution of the approximately equivalent ISG. As a consequence, our approach allows one to compute approximate CSG solutions with quality guarantees for any CFG. Results on a realistic application domain (i.e., ridesharing) show that our approach outperforms the state of the art algorithm both in terms of quality of the solutions and theoretical quality guarantees.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-439" tabindex="-1" role="dialog"
         aria-labelledby="modal-439-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-439-label">[Abstract] Imbalance Management of an Autonomous Power Trading Agent to Exploit Balancing Market Incentives in a Smart Grid Ecosystem</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;font-family:
&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:minor-latin;
mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">Electricity
retailers have to take severe financial risks since they are responsible for
the power imbalance management. In case of an imbalance they are penalized by
system operators in the extent of their
harm to the grid. Therefore, imbalance management is one of the core objectives
of retailers. It helps to substantially reduce the overall costs and increases
the competitive power. This paper presents novel agent-based solutions for two
important aspects of imbalance management, namely for the forecast of
heterogeneous customer demand and for a smart strategical bidding in the
wholesale market that exploits the incentives in the balancing market. The
underlying algorithms were first deployed and tested in our broker agent</span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;
font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">&nbsp;that competed in the 2017 edition of the Power Trading Agent Competition (Power
TAC). This paper will first present the economic
motivation behind the algorithms. Then the algorithms are formalized and
explained in detail. Finally, we analyze the tournament data using several key
performance indicators. The post tournament analysis revealed that our broker</span><span class="FirstName"><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:
Calibri;mso-fareast-theme-font:minor-latin;border:none;mso-ansi-language:EN-US;
mso-fareast-language:EN-US;mso-bidi-language:AR-SA"><span style="border:none"><span style="border:none"><span style="border:none"><span style="border:none">&nbsp;</span></span></span></span></span></span><span lang="EN-US" style="font-size:9.0pt;mso-bidi-font-size:11.0pt;line-height:110%;
font-family:&quot;Linux Libertine&quot;;mso-fareast-font-family:Calibri;mso-fareast-theme-font:
minor-latin;mso-bidi-font-family:&quot;Times New Roman&quot;;mso-bidi-theme-font:minor-bidi;
mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA">successfully
generated revenues from its imbalance, having the highest
imbalance/distribution rate with the lowest penalty payments and procurement
costs among all broker agents.</span><br></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-281" tabindex="-1" role="dialog"
         aria-labelledby="modal-281-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-281-label">[Abstract] Asynchronous Co-Learning in Urban Traffic Systems: a microscopic approach</h4>
                </div>
                <div class="modal-body">
                    <p>A better use of the urban traffic infrastructure is key in the effort of mitigating the effects of traffic congestion. Popular approaches range from classical control and optimization to multiagent reinforcement learning (MARL). This paper follows the latter track. Challenges here are manifold. First, most of the literature assumes that either traffic lights learn (while drivers do not change their behaviors) or vice-versa. Second, no matter what kind of class of learning agents is considered, their actions are&nbsp; highly coupled (thus making the learning task harder). Third, when both classes of agents co-learn, these learning tasks are of different nature (from the point of view of MARL). Finally, a microscopic modeling and simulation of the this problem is not trivial as the pace of each agent is different. Therefore, this paper not only proposes a co-learning approach in which agents act in a shared environment, but also argues that this task needs to be formulated asynchronously. Besides, driver agents are able to update the value of the available actions by receiving information from other drivers. Results show that the co-learning approach outperforms other policies in terms of average travel time of all vehicles. Moreover, when co-learning is used, more vehicles can start and finish their trips as a consequence of a better distribution of the trips within the network.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-242" tabindex="-1" role="dialog"
         aria-labelledby="modal-242-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-242-label">[Abstract] Trifle: Information-oriented Normative Reasoning with Structured Argumentation</h4>
                </div>
                <div class="modal-body">
                    <p>Norms are used to regulate agents in a multi-agent system (MAS)</p><p>without compromising their autonomy, by specifying correct</p><p>behaviour, and rewards and punishments for non-compliance.</p><p>Often, such social facts are informational entities (i.e., belonging</p><p>to relational tables), comprising attributes and foreign-key relations,</p><p>and informational operations may be required to make inferences</p><p>(e.g., joining tables representing GP registration and immunisation</p><p>to infer whether a norm requiring both is violated). Orthogonally,</p><p>non-monotonicity and uncertainty is important, since some inferences</p><p>are provisionally true and subject to being proven false as new</p><p>or further information is considered. Trifle captures these concerns</p><p>with normative reasoning for information-oriented norms and</p><p>constitutive rules, founded on non-monotonic structured argumentation</p><p>to capture uncertainty. Trifle meets four rationality postulates,</p><p>including consistency in the face of contradictory information.</p><p>In short, Trifle bridges the gap between information-oriented and</p><p>structured argumentation approaches for normative reasoning.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-375" tabindex="-1" role="dialog"
         aria-labelledby="modal-375-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-375-label">[Abstract] Active Crowd Labeling: Improving Task Assignment with Online Variational Inference</h4>
                </div>
                <div class="modal-body">
                    <p>Crowd labeling improves label accuracy by assigning a same task to multiple workers. Since workers usually vary in quality, improper task assignment may significantly increase the number of labels needed for high accuracy. In this paper, we formulate a framework to improve task assignment with online variational inference. One distinct advantage is that it can flexibly incorporate different worker models. Another is its novel prediction-based task assignment strategy to select the assignment with the maximum accuracy increment. To improve accuracy growth rate, we keep the prediction optimistic but modulate the scope of task assignment according to the uncertainty measurement of online inference. To improve efficiency, we develop an approximation algorithm for variational inference. The extensive experiments on four popular worker models and four MTurk datasets show that our framework not only achieves the highest label accuracy but also the best computation efficiency.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-328" tabindex="-1" role="dialog"
         aria-labelledby="modal-328-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-328-label">[Abstract] Overlapping Coalition Formation via Probabilistic Topic Modeling</h4>
                </div>
                <div class="modal-body">
                    <p>Research in cooperative games often assumes that agents know the coalitional values with certainty, and that they can belong to one coalition only. By contrast, this work assumes that the value of a coalition is based on an underlying collaboration structure emerging due to existing but unknown relations among the agents; and that agents can form overlapping coalitions. Specifically, we first propose Relational Rules, a novel representation scheme for cooperative games with overlapping coalitions, which encodes the aforementioned relations, and which extends the well-known MC-nets representation to this setting. We then present a novel decision-making method for decentralized overlapping coalition formation, which exploits probabilistic topic modeling—and, in particular, online Latent Dirichlet Allocation. By interpreting formed coalitions as documents, agents can effectively learn topics that correspond to profitable collaboration structures.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-703" tabindex="-1" role="dialog"
         aria-labelledby="modal-703-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-703-label">[Abstract] Zero Shot Transfer Learning for Robot Soccer</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we present techniques for doing zero-shot transfer of<br>RoboCup robot soccer policies as the number of teammates, opponents,<br>and field size change. In real robot soccer matches, the number of<br>robots on the field can vary throughout a match due to breakages and<br>rule violations. Additionally, the field sizes played may vary<br>yearly. We show how to use deep reinforcement learning (DeepRL) for<br>the robot soccer domain, by using generated images as the state<br>space. The DeepRL is able to learn for different numbers of robots<br>on the field without affecting the input layers to the network. We<br>also show a method of using fully convolutional networks such that<br>the action space of the network can adapt to different field<br>sizes. Thus, allowing a single policy to be trained on one field<br>size and then run on a different field size, without retraining.<br>Finally, we present a method for different agents on the field to<br>share their decision making features, so that as teammates are added<br>and removed, no additional training is required. We demonstrate all<br>of these techniques on domains based on the sub-game of Keep-away,<br>where the goal is for the team to retain control of the ball for as<br>long as possible. Using these techniques we are able to learn a<br>Keep-away policy where the number of teammates, opponents, and field<br>size can vary with zero retraining and limited loss in performance.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-615" tabindex="-1" role="dialog"
         aria-labelledby="modal-615-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-615-label">[Abstract] Q-Learning Acceleration via State-space Partitioning</h4>
                </div>
                <div class="modal-body">
                    <p><font size="4" style="color: rgb(34, 34, 34); font-family: arial, sans-serif;">Recent work in Reinforcement Learning (RL) has focused on learning acceleration in order to overcome the method's slow convergence rate in large state spaces or with sparse rewards. In situations where multiple independent, cooperative agents are solving the same task, it has been shown that single-agent RL can be accelerated in a cooperative multi-agent scenario via information sharing. Efficient RL acceleration via information sharing among agents depends on how well the agents' information complements each other's. For example, a single agent's RL in a grid world is ideally accelerated when incorporating exploration information from other disjoint areas within the same environment.&nbsp;</font><span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: large;">In this work, we propose a single-agent RL acceleration approach by state space partitioning. We also define a "partition reward" as an external reward to demarcate partitions for agents to learn and decrease their overlap. The approach has two advantages: 1) agents' actions are not diminished and remain relatively independent from one another; 2) it can be used to accelerate learning in both structured state domains (where partitions can be pre-determined) and arbitrarily-structured state domains (where partitions may be developed dynamically by agent teams as they explore the environment). Finally, we validate the proposal's efficacy by comparing it to previous related work in a simplified soccer domain.&nbsp;</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-64" tabindex="-1" role="dialog"
         aria-labelledby="modal-64-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-64-label">[Abstract] Towards an Enthymeme-Based Communication Framework</h4>
                </div>
                <div class="modal-body">
                    <p>Communication is one of the most important aspects of multi-agent systems. Among the different communication techniques applied to multi-agent systems, argumentation-based approaches have received special interest from the community, because allowing agents to exchange arguments provides a rich form of communication. In contrast to the benefits that argumentation-based techniques provide to multi-agent communication, extra weight on the communication infrastructure results from the additional information exchanged by agents, which could restrict the practical use of such techniques. In this work, we propose an argumentation framework whereby agents are able to exchange fewer and shorter messages when engaging in dialogues by omitting information that is common knowledge (e.g., information about a shared multi-agent organisation). In particular, we focus on using<i> enthymemes</i>, shared argumentation schemes (i.e., reasoning patterns from which arguments are instantiated) and common organisational knowledge to build an enthymeme-based communication framework. We show that the approach makes argumentation-based communication more efficient in the sense that agents can exchange fewer messages with shorter content, yet without any loss in the intended arguments.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-633" tabindex="-1" role="dialog"
         aria-labelledby="modal-633-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-633-label">[Abstract] The Eigenoption-Critic Framework</h4>
                </div>
                <div class="modal-body">
                    <p>Eigenoptions (EOs) have been recently introduced as a promising idea for generating a diverse set of options through the graph Laplacian, having been shown to allow efficient exploration. Despite its first initial promising results, a couple of issues in current algorithms limit its application, namely: 1) EO methods require two separate steps (eigenoption discovery and reward maximization) to learn a control policy, which can incur a significant amount of storage and computation; 2) EOs are only defined for problems with discrete state-spaces and; 3) it is not easy to take the environment’s reward function into consideration when discovering EOs. In this paper we introduce an algorithm termed eigenoption-critic (EOC) that addresses these issues. It is based on the Option-critic (OC) architecture, a general hierarchical reinforcement learning algorithm that allows learning the intra-option policies simultaneously with the policy over options. We also propose a generalization of EOC to problems with continuous state-spaces through the Nystr\"{o}m approximation. EOC can also be seen as extending OC to nonstationary settings, where the discovered options are not tailored for a single task.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-758" tabindex="-1" role="dialog"
         aria-labelledby="modal-758-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-758-label">[Abstract] Abstractly Interpreting Argumentation Frameworks for Sharpening Extensions</h4>
                </div>
                <div class="modal-body">
                    <p style="margin-bottom: 0px; font-stretch: normal; font-size: 9px; line-height: normal; font-family: Helvetica;">Cycles of attacking arguments pose non-trivial issues in Dung style argumentation theory, apparent behavioural difference between odd and even length cycles being a notable one. While a few methods were proposed for treating them, to - in particular - enable selection of acceptable arguments in an odd-length cycle when Dung semantics could select none, so far the issues have been observed from a purely argument-graph-theoretic perspective. Per contra, we consider argument graphs together with a certain lattice like semantic structure over arguments e.g. ontology. As we show, the semantic-argumentgraphic hybrid theory allows us to apply abstract interpretation, a widely known methodology in static program analysis, to formal argumentation. With this, even where no arguments in a cycle could be selected sensibly, we could say more about arguments acceptability of an argument framework that contains it. In a certain sense, we can ‘verify’ Dung extensions with respect to a semantic structure in this hybrid theory, to consolidate our confidence in their suitedness. By defining the theory, and by making comparisons to existing approaches, we ultimately discover that whether Dung semantics, or an alternative semantics such as cf2, is adequate or problematic depends not just on an argument graph but also on the semantic relation among the arguments in the graph.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-462" tabindex="-1" role="dialog"
         aria-labelledby="modal-462-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-462-label">[Abstract] A Game-Theoretic Algorithm for Link Prediction</h4>
                </div>
                <div class="modal-body">
                    <p>Predicting edges in networks is a key problem in social network analysis and involves reasoning about the relationships between nodes based on the structural properties of a network. In particular, link prediction can be used to analyse how a network will develop or - given incomplete information about relationships - to discover "missing" links. Our approach to this problem is rooted in cooperative game theory, where we propose a new, quasi-local approach (i.e., one which considers nodes within some radius k) that combines generalised group closeness centrality and semivalue interaction indices. We develop fast algorithms for computing our measure and evaluate it on a number of real-world networks, where it outperforms a selection of other state-of-the-art methods from the literature. Importantly, choosing the optimal radius k for quasi-local methods is difficult, and there is no assurance that the choice is optimal. Additionally, when compared to other quasi-local methods, ours achieves very good results even when given a suboptimal radius k as a parameter.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-660" tabindex="-1" role="dialog"
         aria-labelledby="modal-660-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-660-label">[Abstract] Provenance Driven Trust Assessment</h4>
                </div>
                <div class="modal-body">
                    <p>Trust and reputation are typically assessed based on past interactions between individual agents. However, an individual encounter may be part of a complex overarching process involving many individual interactions. In supply chain management, for example, numerous agents may be involved in sourcing raw materials, delivering them to manufacturing centres, and dispatching the final product to consumers. Similarly, providers in service oriented computing offer various services that can be orchestrated into complex compositions. In such scenarios, the composition structure affects interactions and their utilities, as well as the individual agents and services involved. Existing reputation assessment methods typically focus on assessing individual agents and their capabilities, rather than compositions. Such complex interactions can be described using workflows, which define a series of tasks to be performed by agents. It is beneficial to estimate how a workflow will perform prior to execution, because it may be costly to execute or because a poorly designed workflow may have severe negative consequences. In this paper, we document past workflow executions as provenance records, which are directed acyclic graphs that describe the relationships between entities, activities, and agents in interactions. A workflow with several possible executions, therefore, is defined as a set of provenance records. We propose to record the executions of workflows and apply frequent subgraph mining and machine learning to learn a mapping from the provenance records to performance, which in turn is used to assess the trust in a workflow.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-52" tabindex="-1" role="dialog"
         aria-labelledby="modal-52-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-52-label">[Abstract] Unbiased Weighted Policy Learner</h4>
                </div>
                <div class="modal-body">
                    <p>Several multi-agent reward-based learning (MARL) algorithms have been proposed to optimize agents’ decisions. Despite many having unrealistic assumptions, the Weighted Policy Learner (WPL) algorithm has been shown to converge to Nash Equilibria (NE) in several challenging environments with minimum knowledge.</p><p>However, WPL is biased against pure NE, also known as deterministic strategies, and only converges in the limit, since the policy update rate approaches zero. Despite the authors claiming that this theoretical limitation is of no concern in practical scenarios, a noticeable delay in learning is observed in tasks where actions are dominated by other actions. We show how a trivial range clipping of the update function can remove this delay and still maintain the algorithm’s convergence properties.</p><p>We demonstrate this behavior with two separate variants of the algorithm, in several common game-theoretic environments (with stochastic equilibrium policies) and in some maze related games (where some actions dominate others in most states). We draw conclusions over the adequacy of our proposals and their advantages over the original algorithm.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-220" tabindex="-1" role="dialog"
         aria-labelledby="modal-220-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-220-label">[Abstract] An Oligopoly Two-Stage-Game Model for Investigating the Search Engine Market</h4>
                </div>
                <div class="modal-body">
                    <p class="15"><span style="font-family: 宋体; font-size: 12pt;">This paper shows that characteristics of competitive oligopoly exist in the search engine market by analyzing the market. An oligopoly two-stage-game(TSG) model </span><span style="font-family: 宋体; font-size: 12pt;">based on the Stackelberg and Cournot models</span><span style="font-family: 宋体; font-size: 12pt;">&nbsp;is proposed to maximize search engines</span><span style="font-family: Calibri; font-size: 12pt;">’</span><span style="font-family: 宋体; font-size: 12pt;">&nbsp;profit.Combining game theory and economic analysis, the strategies of optimal pricing and advertising quantity for search engines have been investigated at different costs.The model considers followers entering and price demand elasticity factors to infer the equilibrium of price and advertising quantity. We analyze the impact of price demand elasticity on the price and advertising quantity in the oligopoly two-stage-game model.Furthermore, the relationship between the demanded advertising quantity and the remaining adverting quantity in the second stage market is showed. Finally, the simulation results show that Nash equilibrium exists in the second stage market .</span><span style="font-family: 宋体; font-size: 12pt;"><o:p></o:p></span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-176" tabindex="-1" role="dialog"
         aria-labelledby="modal-176-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-176-label">[Abstract] Stackelberg Security Games with Multiple Uncoordinated Defenders</h4>
                </div>
                <div class="modal-body">
                    <p>Stackelberg security games have received much attention in recent years. While most existing work focuses on single-defender games, there are many real-world scenarios that involve multiple defenders (e.g., multi-national anti-crime actions in international waters and patrols of different security agencies in the same areas). It is therefore important to investigate security games with multiple defenders. In this paper, we focus on uncoordinated defenders who jointly protect a set of targets, but may have different valuations for these targets; each defender schedules her own resources and selfishly optimizes her own utility. We generalize the standard (single-defender) model of Stackelberg security games to this setting and formulate an equilibrium concept that captures the nature of strategic interaction among the players. We argue that an exact equilibrium may fail to exist, and, in fact, deciding whether it exists is NP-hard. However, under mild assumptions, every multi-defender security game admits an $\epsilon$-equilibrium for every $\epsilon&gt;0$, and the respective limit points can be efficiently approximated.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-705" tabindex="-1" role="dialog"
         aria-labelledby="modal-705-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-705-label">[Abstract] An Architecture for Supporting the Development of Ambient Intelligence Systems Managed by Cognitive Augmented Agents</h4>
                </div>
                <div class="modal-body">
                    <p>The development of ubiquitous systems for Ambient Intelligence (AmI) is a complex task since data communication, node synchronization, handover support, and inference mechanism for decision making based on context information and collaboration among system's devices is hard to deploy. The use of middleware plays an important role in collecting and managing context information for the development of ubiquitous systems covering devices in an Internet of Things (IoT) network. In this scenario, the management of such devices can be performed by employing intelligent and augmented agents capable of cognitive reasoning. In some cases, these agents can have limited resources or processing power and should be desirable to delegate some inference rules for a third part (e.g. middleware). Besides, it is also interesting that agents of a Multi-Agent System (MAS) embedded and responsible for a single device can communicate and interact sharing information with agents situated in a different MAS of another device using the IoT network. So, the objective of this paper is to propose an architecture for developing ubiquitous systems for AmI that uses embedded agents for interfacing with sensors and actuators and are able of communication and interacting with devices in IoT using a scalable middleware. For this purpose, ContextNet was used as middleware for the proposed architecture, the Jason framework was extended to allow communication between agents from different MAS, and an augmented agent extension for transferring inferring rules for the ContextNet middleware core solution was also proposed. As proof-of-concept solution, a real laboratory was assembled with several devices (using MAS or not) in an IoT for controlling some basic functions of the room. The proposed architecture shows to be a real option for the development of such kind of AmI systems.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-390" tabindex="-1" role="dialog"
         aria-labelledby="modal-390-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-390-label">[Abstract] A Unifying Framework for Manipulation Problems</h4>
                </div>
                <div class="modal-body">
                    <p>Manipulation models for electoral systems are a coreresearch theme in socialchoice theory;they&nbsp;include bribery (unweighted, weighted, swap, shift, ...), control (by adding or deleting voters or candidates), lobbying in referenda and others.<br>We develop a unifying framework for manipulation models with few types of people, one of the most commonly studied scenarios. A critical insight of our framework is to separate the descriptive complexity of the voting rule R from the number of types of people. This allows us to finally settle the computational complexity of R-Swap Bribery, one of the most fundamental manipulation problems. In particular, we prove that R-Swap Bribery is fixed-parameter tractable when R is Dodgson’s rule and Young’s rule, when parameterized by the number of candidates. This way, we resolve a long-standing open question from 2007 which was explicitly asked by Faliszewski et al. [JAIR 40, 2011].<br>Our algorithms reveal that the true hardness of bribery problems often stems from the complexity of the voting rules. On one hand, we give a fixed-parameter algorithm parameterized by number of types of people for complex voting rules. Thus, we reveal that R-Swap Bribery with Dodgson’s rule is much harder than with<br>Condorcet’s rule, which can be expressed by a conjunction of linear inequalities, while Dodson’s rule requires quantifier alternation and a bounded number of disjunctions of linear systems. On the other hand, we give an algorithm for quantifier-free voting rules which is parameterized only by the number of conjunctions of the<br>voting rule and runs in time polynomial in the number of types of people. This way, our framework explains why Shift Bribery is polynomial-time solvable for the plurality voting rule, making explicit that the rule is simple in that it can be expressed with a single linear inequality, and that the number of voter types is polynomial.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-409" tabindex="-1" role="dialog"
         aria-labelledby="modal-409-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-409-label">[Abstract] Dynamically Forming a Group of Human Forecasters and Machine Forecaster for Forecasting Economic Indicators</h4>
                </div>
                <div class="modal-body">
                    <p>How can human forecasts and a machine forecast be combined in inflation forecast tasks? A machine-learning-based forecaster makes a forecast based on a statistical model constructed from past time-series data, while humans take varied information such as economic policies into account. Combination methods for different forecasts have been studied such as ensemble and consensus methods. These methods, however, always use the same manner of combination regardless of the situation (input), which makes it difficult to use the advantages of different types of forecasters. To overcome this drawback, we propose an ensemble method for estimating the expected error of a machine forecast and dynamically determining the optimal number of humans included in the ensemble. We evaluated the proposed method by using the six datasets on U.S. inflation and confirmed that it attained the highest forecast accuracy for three datasets and the same accuracy as the highest one of traditional methods for two datasets.<br><br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-463" tabindex="-1" role="dialog"
         aria-labelledby="modal-463-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-463-label">[Abstract] Envy-Free Allocations Respecting Social Networks</h4>
                </div>
                <div class="modal-body">
                    <p>Finding an envy-free allocation of indivisible resources to agents is a central task in many multiagent systems. Often, non-trivial envy-free allocations do not exist, and finding them can be a computationally hard task. Classic envy-freeness requires that every agent likes the resources allocated to it at least as much as the resources allocated to any other agent. In many situations this assumption can be relaxed since agents often do not even know each other. We enrich the envy-freeness concept by taking into account (directed) social networks of the agents. Thus, we compare every agent’s resources with those of its (out)neighbors. This leads to a “more local” concept of envy-freeness. We also consider a strong variant where every agent must like its own allocations more than those of all its (out)neighbors.<br><br>We analyze the classic and the parameterized complexity of finding allocations that are envy-free with respect to one of the variants of our new concept, and that either are complete, are Pareto-efficient, or optimize the utilitarian social welfare. To this end, we study different restrictions of the agents’ preferences and of the social network structure. We identify cases that become easier (from Σ^2_p-hard or NP-hard to P) and cases that become harder (from P to NP-hard) when comparing classic envy-freeness with our graph-based envy-freeness. Furthermore, we spot cases where graph envy-freeness is easier to decide than strong graph envy-freeness, and vice versa.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-786" tabindex="-1" role="dialog"
         aria-labelledby="modal-786-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-786-label">[Abstract] Social mechanisms for collective ontology engineering</h4>
                </div>
                <div class="modal-body">
                    <p><font face="Helvetica"><span style="font-size: 12px;">Building ontologies&nbsp;</span></font><span style="font-size: 12px; font-family: Helvetica;">collaboratively presents the advantage of allowing practitioners to&nbsp; share their expertise in the modelling of a domain. However, collaborative ontology engineering, seen as a form of knowledge integration, is prone to inconsistencies. We propose two techniques to deal with this situation. First, we study how to repair an inconsistent&nbsp;</span><span style="font-size: 12px; font-family: Helvetica;">collective ontology that results from the views of heterogeneous experts, once they have been aggregated by means of voting. Second, we prevent the creation of any inconsistencies by letting the experts engage in a turn-based rational negotiation about the axioms to be added&nbsp;</span><span style="font-size: 12px; font-family: Helvetica;">to the collective ontology. We instantiate the two approaches using real-world ontologies and we compare them by measuring the level of satisfaction of the experts w.r.t. the collective ontology obtained by the two procedures and employing two alternative measures for `agent happiness'.</span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-557" tabindex="-1" role="dialog"
         aria-labelledby="modal-557-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-557-label">[Abstract] Of Mice and Mazes: Simulating Mice Behavior with Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p>Reinforcement learning (RL) algorithms are strongly motivated by biological systems.&nbsp; In this paper, we compare the output of RL agents against the observed behavior of real mice learning to navigate mazes as a way of exploring the extent to which instantiations of standard&nbsp; RL algorithms can approximate mouse learning.&nbsp; Using two similarity metrics, we found that certain parameterizations of Q-learning and SARSA were able to approximate the mice's behavior better than random- and optimal-behaving baselines. Furthermore, we identify trends in learning algorithms, reward functions, and parameterizations that cause RL agents to better approximate mouse learning. A main contribution of the paper is a novel methodology for comparing the learning processes of biological and RL agents.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-490" tabindex="-1" role="dialog"
         aria-labelledby="modal-490-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-490-label">[Abstract] Learning-Aware Human-Centered Collaborative Task Assignment in Open Environments</h4>
                </div>
                <div class="modal-body">
                    <p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:RelyOnVML/>
  <o:AllowPNG/>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>JA</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
   <w:UseFELayout/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="381">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1107305727 0 0 415 0;}
@font-face
	{font-family:SimSun;
	panose-1:2 1 6 0 3 1 1 1 1 1;
	mso-font-charset:134;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:3 680460288 22 0 262145 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	text-align:justify;
	text-justify:inter-ideograph;
	mso-pagination:widow-orphan;
	font-size:9.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:SimSun;}
h1
	{mso-style-priority:9;
	mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-link:"Heading 1 Char";
	mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	text-justify:inter-ideograph;
	mso-pagination:widow-orphan lines-together;
	page-break-after:avoid;
	mso-outline-level:1;
	font-size:16.0pt;
	font-family:Calibri;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:major-latin;
	mso-fareast-font-family:"ＭＳ ゴシック";
	mso-fareast-theme-font:major-fareast;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:major-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:major-bidi;
	color:#365F91;
	mso-themecolor:accent1;
	mso-themeshade:191;
	mso-font-kerning:0pt;
	font-weight:normal;}
p.Abstract, li.Abstract, div.Abstract
	{mso-style-name:Abstract;
	mso-style-unhide:no;
	mso-style-parent:"Heading 1";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	text-align:justify;
	text-justify:inter-ideograph;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	font-size:9.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:SimSun;
	mso-font-kerning:14.0pt;}
span.Heading1Char
	{mso-style-name:"Heading 1 Char";
	mso-style-priority:9;
	mso-style-unhide:no;
	mso-style-locked:yes;
	mso-style-link:"Heading 1";
	mso-ansi-font-size:16.0pt;
	mso-bidi-font-size:16.0pt;
	font-family:Calibri;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:major-latin;
	mso-fareast-font-family:"ＭＳ ゴシック";
	mso-fareast-theme-font:major-fareast;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:major-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:major-bidi;
	color:#365F91;
	mso-themecolor:accent1;
	mso-themeshade:191;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-size:10.0pt;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-fareast-font-family:SimSun;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman";}
</style>
<![endif]-->



<!--StartFragment-->



<!--EndFragment--></p><p class="Abstract">Intelligent agents provide useful interfaces between complex
systems and human users.<span style="mso-spacerun:yes">&nbsp; </span>For example,
agents can interact with people to discover their preferences, skills, and
expertise, then find tasks that are appropriate for the users’ abilities.<span style="mso-spacerun:yes">&nbsp; </span>Notably, human users benefit from
participating in tasks not only through rewards received (e.g., payments for
completing tasks) but also by learning through experience, which improves each
user’s expertise and skills required for future tasks. Human learning is
especially essential in open environments where both (1) people join and leave
the environment over time, potentially causing available expertise to disappear
and affect collaboration success, and (2) tasks available for assignment
change, potentially requiring new skills or greater expertise over time.<span style="mso-spacerun:yes">&nbsp;&nbsp; </span>Here, human learning enables users to adapt
with the open environment and positions users for greater future task
accomplishment.<span style="mso-spacerun:yes">&nbsp; </span>We contribute an
agent-based solution that models human learning to account for its benefit
during task selection, which is leveraged in a sequential decision making
process where personal assistant agents select and acquire tasks for their
users in order to maximize users’ cumulative task rewards in open
environments.<span style="mso-spacerun:yes">&nbsp; </span>Experimental results
demonstrate the benefits of reasoning about human learning: improved expertise
leading to increased cumulative rewards.<o:p></o:p></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-332" tabindex="-1" role="dialog"
         aria-labelledby="modal-332-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-332-label">[Abstract] A Dynamic Framework for Decentralized Norm Emergence in Open Multiagent Systems</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">Norms (social norms) are powerful tools to determine the standards
of agents’ behavior in multiagent systems as the agents interact
in pursuit of their respective goals. Norms are important as they
promote both autonomy (agents do not need to comply with a norm)
and heterogeneity (agents’ internal reasoning about norms are
speci c to each agent). Researchers have studied norm emergence
through the social learning technique in which agents interact (play
games) repeatedly in a closed system with  xed payo s de ned for
the behaviors.
</span></p>
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">We propose Cha, a framework for open multiagent systems, in
which member agents may enter and leave dynamically, and each
agent reasons individually about norms. Also, unlike previous stud-
ies, our normative framework can change dynamically based on
the continual changes of the environment. We evaluated Cha in a
simulated tra c-regulation case study. Our results showed that us-
ing the Cha framework, norms that promote con ict resolution and
fairness can emerge, and norms adapt to a changing environment
in a decentralized manner.&nbsp;</span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-480" tabindex="-1" role="dialog"
         aria-labelledby="modal-480-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-480-label">[Abstract] Fair resource allocation over time</h4>
                </div>
                <div class="modal-body">
                    <p>We consider the over-time version of the Max-Min Fair Allocation problem. In the usual (static) problem, given a set of resources and a set of agents, we have to allocate the resources to agents in such a way that the utility of the least happiest agent is maximized. In the over-time version there is a time horizon t=1,2,..., T, with at each time t a set of agents and a set of available resources that may change over the time defining instance I_t; we seek a sequence of allocations (S_1, S_2, ... , S_T) that&nbsp; (1) are near-optimal at each time t, and (2) are as stable as possible: we want to minimize transition costs induced by modification between allocations at time t and time (t+1). </p><p>We focus on the impact of the knowledge of the future on the quality and the stability of the returned solutions by distinguishing three settings: the off-line setting where the whole set of instances through the time horizon is known in advance, the online setting where no future instance is known, and the k-lookahead setting where at time t, the instances at times t+1,..., t+k are known.<br>We first consider the case without restrictions where the set of resources and the set of agents are the same for all instances and where every resource can be allocated to any agent.<br>For the off-line setting, we show that the over-time version of the problem is much harder than the static one, since it becomes NP-hard even for families of instances for which the static problem is trivial. Then, we provide a r/(r+1)-approximation algorithm for the off-line setting using as&nbsp; subroutine an r-approximation algorithm for the static version. We also give a r/(r+1)-competitive algorithm for the online setting using also as subroutine an r-approximation algorithm for the static version. </p><p>Furthermore, for the case with restrictions, we show that in the off-line setting it is possible to get a polynomial-time algorithm with the same approximation ratio as in the case without restrictions, while for the online setting, we prove that it is not possible to find an online algorithm with bounded competitive ratio. For the 1-lookahead setting however, we give a r/(4r+2)-approximation algorithm using as subroutine an r-approximation algorithm for the static version.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-741" tabindex="-1" role="dialog"
         aria-labelledby="modal-741-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-741-label">[Abstract] Modeling User Communications in Social Media</h4>
                </div>
                <div class="modal-body">
                    <p>With the sudden and significant growth of participation in social media, there has been a shift in need for intelligent agents to accommodate its users. One of the most salient aspects of social media is its conversational aspect, where users can interact to share and evolve their opinions and beliefs. The ``conversational context'' of social media posts has a large influence on their topics, and is usually even more influential than the characteristics of the community or other features. The nature of how topics may evolve in a conversation, or the ``topic flow'' of a conversation, is strongly dependent on the personality of users that participate in the conversation. Our work introduces a novel, unsupervised statistical model of topic flow on social networks, expanding from existing work on topic models. The Author-Aware Topic Flow Model (AATFM) learns distinct conversational behaviors with user and conversational information, which can discover human-interpretable topics and transition characteristics on corpora in an efficient manner. The AATFM is found to outperform other state-of-the-art topic models and topic flow models in prediction tasks on conversations.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-735" tabindex="-1" role="dialog"
         aria-labelledby="modal-735-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-735-label">[Abstract] Actively Learning from Demonstration with Diverse Query Types</h4>
                </div>
                <div class="modal-body">
                    <p><font face="Arial"><span style="font-size: 14.6667px; white-space: pre-wrap;">Task learning agents should be able to actively engage their human partners in order to generalize concepts relevant to the task being learned.  Towards that end, active learning literature has explored the selection of optimal candidate queries by a learning agent, with respect to a given utility function, but prior work has primarily focused on making one specific type of query towards generalization along that dimension of the task.  For example, repeatedly querying the oracle for class labels of unlabelled objects in the scene about which the learner is uncertain.  This work seeks to explore the scenario where a social learning agent has access to more than one type of active learning query it can make requests about, and the query types are not necessarily evaluated using the same utility functions.  In this case, it is important for the learner to have a way of selecting between the different query types, in order to decide which type of query is best to make at each turn in the learning interaction.  This work builds upon prior work in robot active learning which introduced a framework of three types of active learning queries explored in the literature: demonstration queries, label queries, and feature queries.  Given the three query types, we explore four rule-based strategies for enabling a learner to combine different types of queries in a learning episode.  We conducted experiments on two different tasks comparing 4 experimental strategies for combining the three AL query types against baselines of more traditional supervised learning, active learning, and random selection.  Our findings show it is more important the learner be enabled to elicit diverse types of information and be given an appropriate prioritization the question types than it is to focus on any one specific strategy for asking questions of the human teacher.</span></font><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-693" tabindex="-1" role="dialog"
         aria-labelledby="modal-693-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-693-label">[Abstract] Joint Attention for Context-Aware Camera Agents</h4>
                </div>
                <div class="modal-body">
                    <p>Joint attention refers to the idea of finding the focal points in an environment that are most salient to its occupants. In this work, we introduce the joint attention metric to an editing task for situated context-aware camera agents in corporate meetings. In a meeting room equipped with cameras from different viewpoints, the focal point of meeting participants is calculated using the extracted pose data and gaze direction. The automated editing algorithm then compiles the information from each agent to determine the joint attention of all the participants in the meeting, and select at each time point the camera viewpoint that best conveys joint attention. The editing also take into account basic filmmaking practices such as pacing and frame composition. The meeting videos are chosen from the AMI meeting corpus to represent 3 types of interactions: design and brainstorming, status update, and project planning. These videos provide a range of dynamics of the meetings in terms of conversational interaction, movement in the room, and focus shifts between objects and participants. The output of the agents is an editing plan for the meeting in Edit Description Language (EDL) format. We evaluate the output with a similarity metric against a baseline audio-based edit and an expert human-edited version.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-468" tabindex="-1" role="dialog"
         aria-labelledby="modal-468-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-468-label">[Abstract] Reputation as a barrier to entry – an agent based simulation</h4>
                </div>
                <div class="modal-body">
                    <p>Reputation systems are being widely used in online markets as a tool which prevents moral hazard and helps in dealing with the prevalent problem of asymmetric information. This research explores one of the challenges that comes with their implementation, a high barrier to entry for market newcomers. We implement an agent based simulation of a reputation system and by running a series of experiments try to analyze effects of sellers' reputation and experience aggregation on market structure. The simulation reveals that if experience is used as one of the criteria in deciding who to trade with, barriers to entry can appear for new sellers. Furthermore, there is a possibility that less quality traders with high experience drive out more quality ones with less experience. Results should be considered when building reputation systems.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-398" tabindex="-1" role="dialog"
         aria-labelledby="modal-398-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-398-label">[Abstract] Agent-Based Simulation of Offender Mobility: Integrating Activity Nodes from Location-Based Social Networks</h4>
                </div>
                <div class="modal-body">
                    <p class="Abstract"><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:RelyOnVML></o:RelyOnVML>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>IT</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
   <w:UseFELayout></w:UseFELayout>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="371">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" Priority="0" SemiHidden="true"
   UnhideWhenUsed="true" Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="0" SemiHidden="true"
   UnhideWhenUsed="true" Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if !supportAnnotations]--><!--[endif]--><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Calibri",sans-serif;
	mso-ansi-language:IT;
	mso-fareast-language:IT;}
</style>
<![endif]--> 



<!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="371">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" Priority="0" SemiHidden="true"
   UnhideWhenUsed="true" Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="0" SemiHidden="true"
   UnhideWhenUsed="true" Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>IT</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
   <w:UseFELayout></w:UseFELayout>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:RelyOnVML></o:RelyOnVML>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]-->



<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Calibri",sans-serif;
	mso-ansi-language:IT;
	mso-fareast-language:IT;}
</style>
<![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" LatentStyleCount="371">
  <w:LsdException Locked="false" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="line number"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="page number"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="No List"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   UnhideWhenUsed="true" Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>IT</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
   <w:UseFELayout></w:UseFELayout>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:RelyOnVML></o:RelyOnVML>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Calibri",sans-serif;
	mso-ansi-language:IT;
	mso-fareast-language:IT;}
</style>
<![endif]--></p><p class="Abstract"><span style="mso-ligatures:standard" lang="EN-US">In recent
years, simulation techniques have been applied to investigate the
spatio-temporal dynamics of crime. Researchers have instantiated mobile offenders
in agent-based simulations for theory testing, experimenting with prevention
strategies, and crime prediction purposes, despite facing challenges due to the
complex dynamics of crime and the lack of detailed information about offender
mobility. This paper presents an agent-based model to explore offender
mobility, focusing on the interplay between the agent’s awareness space and
activity nodes. To instantiate a realistic urban environment, we use open and location-based
social networks data to design the road network, and as proxy for human
activity we use activity nodes, respectively. 18 mobility strategies have been
tested, combining search distance strategies (e.g. Lévy flight, inspired by
insights in human dynamics literature) and target selection strategies
(enriched with Foursquare data). We analyze and compare the different mobility
strategies, and show the impact of using activity nodes extracted from social
networks to simulate offender mobility. This agent-based model provides a basis
for comparing offender mobility in crime simulations by inferring offender
mobility in urban areas from real world data.</span><span style="font-size:14.0pt;line-height:110%;mso-ligatures:standard" lang="EN-US"></span></p><p class="Abstract"><span style="mso-ligatures:standard" lang="EN-US"><br></span><span style="font-size:14.0pt;
line-height:110%;mso-ligatures:standard" lang="EN-US"></span></p><p class="Abstract"><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Calibri",sans-serif;
	mso-ansi-language:IT;
	mso-fareast-language:IT;}
</style>
<![endif]--></p><p class="Abstract"><span style="color:red;mso-ligatures:standard" lang="EN-US"><br></span><span style="color:red;mso-ligatures:
standard;mso-ansi-language:EN-GB;mso-fareast-language:JA" lang="EN-GB"></span></p><p>

</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-309" tabindex="-1" role="dialog"
         aria-labelledby="modal-309-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-309-label">[Abstract] Integrating Multi-Agent Systems with Mixed Reality: the Augmented World Approach</h4>
                </div>
                <div class="modal-body">
                    <div><div>In agent literature, a partially unexplored area is related to the integration of ever-wider opportunities offered by technologies such as Mixed Reality (MR) and Augmented Reality (AR). In this paper we present a framework called Augmented Worlds (AW), which provides a model and a technological support to develop a broad spectrum of agent-based AR/MR systems. Distinguishing key features of the approach include: bi-directional augmentation, support for existing cognitive agent technologies, support for developing open multi-user environments. In the paper, we describe first the conceptual model on which the framework is based, and then a concrete architecture and prototype implementation. Two case studies about real-world applications - an augmented museum and an augmented harbour - engineered with the framework are finally discussed.</div></div><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-642" tabindex="-1" role="dialog"
         aria-labelledby="modal-642-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-642-label">[Abstract] Algorithms to Manage Load Shedding Events in Developing Countries</h4>
                </div>
                <div class="modal-body">
                    <p>Due to the limited generation capacity of power stations, many developing countries frequently resort to disconnecting large parts of the power grid from supply, a process termed load shedding. This leaves homes in these parts without electricity, causing them discomfort and inconvenience. Because fairness is not a priority when shedding load, some homes bear the brunt of these effects. In this paper, we present a number of heuristic approaches that aim to make load shedding fair to homes. Because these heuristics depend on the prediction of household electricity consumption, we begin by developing a predictive model of consumer energy consumption. We show that our model produces results that are 30$\%$ more accurate than those of a standard approach. Then, we present algorithms that shed load at the household level. Finally, we evaluate these algorithms against standard fairness metrics and thus establish new benchmarks for fair load shedding schemes.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-300" tabindex="-1" role="dialog"
         aria-labelledby="modal-300-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-300-label">[Abstract] Non-parametric Fitted Relational Value Iteration: Unifying Relational and Propositional Discrete Domains</h4>
                </div>
                <div class="modal-body">
                    <p>We consider the problem of Approximate Dynamic Programming in relational domains. Inspired by the success of fitted value iteration methods in propositional settings, we develop the first relational fitted value iteration method by representing the value function as a linear combination of relational regression trees. We show how the two steps of Bellman operator application and projection steps can be performed using a gradient-boosting technique. Our proposed framework can be seen as a unified framework that can be effectively applied to both relational and propositional discrete domains.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-294" tabindex="-1" role="dialog"
         aria-labelledby="modal-294-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-294-label">[Abstract] Intolerance does not necessarily lead to segregation: a computer-aided analysis of the Schelling Segregation Model</h4>
                </div>
                <div class="modal-body">
                    <p>The Schelling Segregation Model is a spacial proximity model where individuals have preferences over their neighbours and can change their location according to a specific pecking order. We provide instances in which such order has an impact on the properties of the final outcome, in particular its segregation level, measured as a function of the number of clusters formed in the end.</p><p>Motivated by this finding, we introduce a tool for the systematic analysis of the starting scenarios, which handles the complexity of the problem with a randomised exploration module. We show a number of surprising findings which shed light on the relation between individuals' tolerance, neighbourhood size, and final level of segregation. In particular, challenging Schelling's claim that small preferences for local uniformity inevitably lead to higher levels of global segregation, we have been able to find instances of starting scenarios that, even when using the pecking order proposed by Schelling, display a reduced -- and at times, zero -- level of final segregation.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-467" tabindex="-1" role="dialog"
         aria-labelledby="modal-467-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-467-label">[Abstract] Rent Division Among Groups</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we extend the Rent Sharing problem for the case that every room must be allocated to a group of agents. In the classic Rent Sharing problem, there are $n$ agents and a house with $n$ rooms, and the goal is to allocate one room to each agent and assign a rent to each room, such that no agent envies any other option. Our setting deviates from the classic Rent Sharing problem in a sense that the rent determined for every room must be divided among the members of the resident group. <br></p><p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;">We define three notions to evaluate fairness, namely, weak envy-freeness, aggregate envy-freeness and strong envy-freeness. We also define three different policies to divide the cost among group members, namely, equal, proportional, and free cost-sharing policies. </p><p>
<br></p><p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;">We present several positive and negative results for different combinations of the fairness criteria and rent-division policies. Specifically, when the groups are pre-determined, we propose a strong envy-free solution that allocates the rooms to the agents, regarding free cost-sharing policy. In addition, for the case that the groups are not pre-determined, we propose a strong envy-free allocation algorithm with equal cost-sharing policy. In addition, we investigate on the problem of finding the maximum total rent that is possible to guarantee strong envy-freeness. We leverage our results to obtain an algorithm that determines the maximum total rent along with the proper allocation and rent-division method.</p><p><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-89" tabindex="-1" role="dialog"
         aria-labelledby="modal-89-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-89-label">[Abstract] Robustness to Model Uncertainty for Agent-Based Influencing of a Flock</h4>
                </div>
                <div class="modal-body">
                    <p>Many biological species exhibit flocking behavior whereby each animal bases its actions on the locations of nearby animals, leading to unchoreographed yet cohesive emergent flock behavior.&nbsp; Recent research has considered how controlled autonomous agents that are recognized by flock members as "one of their own" can exert a desired influence on the overall flock behavior.&nbsp; This past research has assumed that the underlying local behavior model of the flock is known.&nbsp; However in practice, these underlying behaviors are not known with certainty.&nbsp; This paper contributes the first detailed empirical study considering how well methods from the existing research on controllable agent behavior generalize to alternate flocking models when the true underlying flock model is unknown.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-136" tabindex="-1" role="dialog"
         aria-labelledby="modal-136-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-136-label">[Abstract] A Generic Domain Pruning Technique for GDL-based DCOP algorithms in Cooperative Multi-Agent Systems</h4>
                </div>
                <div class="modal-body">
                    <p><span class="fontstyle0">Generalized Distributive Law (GDL) based message passing algorithms, such as Max-Sum and Bounded Max-Sum, are often used to solve distributed constraint optimization problems in cooperative multi-agent systems (MAS). However, scalability becomes a challenge when these algorithms have to deal with constraint functions with high arity or variables with a large domain size. In either case, the ensuing exponential growth of search space can make such algorithms computationally infeasible in practice. To address this issue, we develop a generic domain pruning technique that enables these algorithms to be effectively applied to larger and more complex problems. We theoretically prove that the pruned search space obtained by our approach does not affect the outcome of the algorithms. Moreover, our empirical evaluation illustrates a significant reduction of the search space, ranging from </span><span class="fontstyle2">33% </span><span class="fontstyle0">to </span><span class="fontstyle2">81%</span><span class="fontstyle0">, without affecting the solution quality of the algorithms, compared to the state-of-the-art.</span>&nbsp;&nbsp;<br style="line-height: normal; text-align: -webkit-auto; text-size-adjust: auto;"></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-202" tabindex="-1" role="dialog"
         aria-labelledby="modal-202-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-202-label">[Abstract] Mitigating Strategic Attack Diffusion in Security Games</h4>
                </div>
                <div class="modal-body">
                    <p>One of the key problems studied by game theorists is the confrontation between a defender of a network of targets and an aggressor who attacks the network. In some cases, the attack spreads and therefore it can be modeled as a stochastic contagion. In this work we consider a setting in which the process of spreading is entirely strategic, sequential and under the control of the attacker. We define this problem as a Stackelberg game between two players, the defender and the attacker. We prove that finding an optimal strategy of the attacker is an NP-complete problem when the attack is strategic. To aid the defense efforts, we analyze possible strategies of protecting the network from different strategies of sequential attack.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-626" tabindex="-1" role="dialog"
         aria-labelledby="modal-626-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-626-label">[Abstract] A Combinatorial Market for Distributed Data</h4>
                </div>
                <div class="modal-body">
                    <p>Data is becoming more and more valuable, and there already exists an efficient technology for querying and combining data from distributed databases. However, this technology is very much underutilized. This happens mostly because of a lack of financial incentives for data providers to publish their data in a suitable format. The primary reason for this is that advertisement, the main source of income of data providers in the traditional Web, does not work in the domain of distributed databases where data is processed by machines rather than by humans. Enabling users to seamlessly combine data from different sources would allow them to automatically integrate and process distributed data, resulting in more efficient search processes. In this paper, we address this issue by designing a market for selling distributed data. We present a formal model for this problem, a market design solution, and we perform an economic analysis of the resulting market in equilibrium. Our results show that such a data market leads to high utility for buyers while data providers are guaranteed to recoup their costs for producing their databases.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-613" tabindex="-1" role="dialog"
         aria-labelledby="modal-613-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-613-label">[Abstract] Competition between Charging Stations: Queues, Capacities, Prices and Optimal Subsidies</h4>
                </div>
                <div class="modal-body">
                    <p>Electric vehicles (EVs) have a limited range and charging stations are required to ensure wide-spread adoption. However, limitations in charging capacity can result in significant queueing times. Charging stations are expensive to build and require careful planning of location, capacity as well as prices. We propose a game-theoretic model in which competing charging station investors strive to maximise individual net profit, while EV drivers strive to minimise travel costs and queueing at the stations. Existing literature largely considers monopolistic optimisation and either assumes fixed prices or disregards queues. In contrast, here we account for stochastic EV queuing times, driver behaviour, charging station investor behaviour, station capacities and prices, building and operational costs and extraneous competition. Our model is evaluated using a duopoly example and is used to examine subsidies as incentives to EV adoption. We calculate the rebate in utility for drivers and stations due to the subsidy, and determine optimal subsidy levels for system-wide and driver utility gain per pound spent on subsidy. Results show that subsidising the purchase of charging units for stations can have a significant beneficial effect for both EV drivers and station investors, with increasing benefit for drivers for increasing levels of subsidy, and increasing subsidy efficiency for increasing numbers of EV drivers. In contrast, subsidies on the energy price for stations can have a minor beneficial effect when subsidies are small and drivers are few, but can also incentivise stations to reduce capacities and increase prices. Last, subsidising only one station can result in most of the subsidy being absorbed by that station, with an adverse effect for the other station and little or no utility gain for the drivers.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-614" tabindex="-1" role="dialog"
         aria-labelledby="modal-614-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-614-label">[Abstract] Adversarial Regression for Stealthy Attacks in Cyber-Physical Systems</h4>
                </div>
                <div class="modal-body">
                    <p>Attacks manipulating the sensor measurements of a cyber-physical system (CPS) can be tuned by the attacker to cause a spectrum of damages. Attackers can attempt to remain undetected and hide their sensor manipulations by following the expected behavior of the system, while manipulating just enough sensor information that achieves their malicious goals. In this paper, we study the problem of adversarial regression in CPS. We consider a safety-critical CPS that is monitored by regression-based anomaly detectors. An adversary attempts to drive the system to an unsafe state by perturbing the values of a subset of sensors while remaining undetected. We solve the adversarial regression problem, considering linear regression- and neural network regression-based detectors. Then, we present a resilient detector that mitigates the impact of stealthy attacks through resilient configuration of detection thresholds. We numerically evaluate the adversarial regression problem, and demonstrate the effectiveness of the resilient detector using a case study of a process control system.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-443" tabindex="-1" role="dialog"
         aria-labelledby="modal-443-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-443-label">[Abstract] Efficient Convention Emergence through Decoupled Reinforcement Social Learning with Teacher-Student Mechanism</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we design reinforcement learning based (RL-based) strategies to promote convention emergence in multiagent systems (MASs) with large convention space. We apply our approaches to a language coordination problem in which agents need to coordinate on a dominant lexicon for efficient communication. By modeling each lexicon which maps each concept to a single word as a Markov strategy representation, the original single-state convention learning problem can be transformed into a muti-state multiagent coordination problem. The dynamics of lexicon evolutions during an interaction episode can be modeled as a Markov game, which allows agents to improve the action values of each concept separately and incrementally. Specifically we propose two learning strategies, multiple-Q and multiple-R, and also propose incorporating teacher-student mechanism on top of the learning strategies to accelerate lexicon convergence speed. Extensive experiments verify that our approaches outperform the state-of-the-art approaches in terms of convergence efficiency and convention quality.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-223" tabindex="-1" role="dialog"
         aria-labelledby="modal-223-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-223-label">[Abstract] An Imperfect Algorithm for Coalition Structure Generation</h4>
                </div>
                <div class="modal-body">
                    <p style="margin-bottom: 0px;">Optimal coalition structure generation (CSG) is a significant research problem in multi-agent systems that remains difficult to solve. The problem has many important applications such as in transportation, eCommerce, distributed sensor networks and others. The CSG problem is NP-complete and finding the optimal result for n agents needs to check O (n<sup>^</sup>n) possible partitions. The ODP-IP algorithm achieves the current lowest worst-case time complexity - O (3^n).</p><p>

</p><p style="margin-bottom: 0px;">In the light of its high computational time complexity, we devise an Imperfect Dynamic Programming (ImDP) algorithm for CSG problem with runtime O (n2^n) given n agents.<i> Imperfect algorithm</i> means, there are some contrived inputs for which the algorithm fails to give the optimal result. We benchmark our algorithm against the hybrid dynamic programming ODP-IP.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-427" tabindex="-1" role="dialog"
         aria-labelledby="modal-427-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-427-label">[Abstract] BelMan: Bayesian Bandits on the Belief--Reward Manifold</h4>
                </div>
                <div class="modal-body">
                    <p>We propose a generic, Bayesian, information geometric algorithm to the exploration--exploitation trade-off in multi-armed bandit problems. Our algorithm, BelMan, uniformly supports pure exploration, exploration--exploitation, and two-phase bandit problems. The knowledge on bandit arms and their reward distributions is summarised by the barycentre of the joint distributions of beliefs and rewards of the arms, the <i>pseudobelief--reward</i>, within the belief--reward manifold. BelMan alternates <i>information projection</i> and <i>reverse information projection</i>, i.e., projection of the pseudobelief--reward onto belief--reward distributions to choose the arm to play, and projection of the resulting belief--reward distributions onto the pseudobelief--reward. BelMan introduces a mechanism that infuses an exploitative bias by means of a <i>focal distribution</i>, i.e., a reward distribution that gradually concentrates on higher rewards. Comparative performance evaluation with state-of-the-art algorithms shows that BelMan is not only competitive but also outperforms other approaches in specific setups, for instance involving many arms and continuous rewards.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-756" tabindex="-1" role="dialog"
         aria-labelledby="modal-756-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-756-label">[Abstract] Defender Stackelberg Game with Inverse Geodesic Length as Utility Metric</h4>
                </div>
                <div class="modal-body">
                    <p><span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; text-size-adjust: auto;">The inverse geodesic length (IGL) is a well-known and widely used measure of network performance. It equals the sum of the inverse distances of all pairs of vertices in the network. A Stackelberg game is a strategic game in which one player commits to a strategy while taking into account that other players will respond accordingly. We propose a natural defender-attacker Stackelberg game on a network in which the defender wants to maximize the IGL level of the network and commits to protecting parts of the network while having knowledge of the strength of an attacker that wants to weaken the network. We present several algorithmic and complexity results concerning the problem of finding the optimal commitment for the defender. Some of our computational hardness results also answer open problems posed in prior work on IGL.&nbsp;</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-438" tabindex="-1" role="dialog"
         aria-labelledby="modal-438-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-438-label">[Abstract] Resolving Incompatibilities among Procedural Goals under Uncertainty</h4>
                </div>
                <div class="modal-body">
                    <p>By considering rational agents, we focus on the problem of selecting goals out of a set of incompatible ones.&nbsp; We consider the three forms of incompatibility introduced by Castelfranchi and Paglieri, namely the terminal incompatibility, the instrumental or resources incompatibility and the superfluity. We represent the plans associated with the goals by means of structured arguments whose premises are pervaded with uncertainty. Thus, we measure the strength of such arguments in order to determine the set of compatible goals. We propose two novel ways for calculating the strength of the arguments, depending on the kind of incompatibility that exists between goals. The logical strength value is represented by a three-dimensional vector determined from a probabilistic interval associated with each argument. These three dimensions represent the precision of the interval, the location of the interval and the combination of precision and location. This type of representation and treatment of the strength of a structured argument can be considered as a novelty in the study of structured arguments with uncertainty. The second way for calculating the strength of the argument is based on the cost of the plans (regarding the necessary resources) and the preference of the goals associated with the plans. Finally, the strategy for the selection of plans and goals is based on Dung's abstract argumentation theory.</p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-761" tabindex="-1" role="dialog"
         aria-labelledby="modal-761-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-761-label">[Abstract] Strategic Evasion of Centrality Measures</h4>
                </div>
                <div class="modal-body">
                    <p><span style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px;">Centrality measures – techniques that rank nodes in networks - belong to the fundamental tools of social network analysis. Similarly to other tools, they</span><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">&nbsp;were built around the assumption that individuals or groups in a network do not act strategically to evade&nbsp;</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">analysis</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">. Even&nbsp;</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">the centrality anal</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">ysis of</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">&nbsp;covert networks typically assume that the network under investigation is not strategic</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">ally</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">&nbsp;manipula</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">ted</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">.&nbsp;</font><font color="#000000" style="font-family: arial, sans-serif; font-size: 12.8px;">To circumvent this problem, a few recent studies attempted to understand how a member of a social network could try to mislead centrality measures. These models, however, were based on the assumption that the network analyser is oblivious to any evasion attempts. In this paper, we extend those models and present the first analysis of a strategic game between an analyser whose aim is to detect the leaders of the network, and the leaders whose aim is to evade such analysis.</font><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-235" tabindex="-1" role="dialog"
         aria-labelledby="modal-235-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-235-label">[Abstract] Making Room for Refugees: Agent-Based Simulation of West Asian Urban Dynamics</h4>
                </div>
                <div class="modal-body">
                    Rapid international migration of significant populations is generating profound implications for countries in West Asia, Europe, and other regions. Our motivation is to develop an agent-based model (ABM) to capture the existence of such migrant and refugee flows, and to explore their effects on urban dynamics. We leverage an extant agent-based model founded on the rent-gap theory, as a lens to study the effect of sizeable refugee migration upon a capital city in West Asia. In order to calibrate and validate the simulation model we construct indices for housing prices and other factors. Results from the model show the impact of migration shock on the housing market, and identify the relative efficacy of housing intervention policies. Our work progresses towards a tool for policy makers asking what-if questions about the urban environment in the context of migration.
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-697" tabindex="-1" role="dialog"
         aria-labelledby="modal-697-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-697-label">[Abstract] A Gibbs Sampling Approach to Argument-Based Inference of Attack Graphs</h4>
                </div>
                <div class="modal-body">
                    <p>Inferential analysis of discourse with computational argumentation is a new and potential approach to argumentation mining. This is interesting because one of the important tasks of argumentation mining is identification of an attack relation between arguments, and it is too optimistic to think that lexical analysis with natural language processing can provide a complete solution to the problem. In this paper, a Bayesian generative model characterizing Dung's abstract argumentation is extended so that it performs efficient approximate inference of attack interaction among arguments. A Gibbs sampling algorithm is implemented on the extended model to empirically show its reasonable estimation accuracy, sensitivity and time complexity. This model is applied to estimate customer review conflicts from rating scores of the individual reviews in Amazon.com. We demonstrate that reasonable consistency is observed between model's estimation and customers' conflict-judgement. This work will serve as an algorithmic foundation of the practical use of computational argumentation in argumentation mining.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-106" tabindex="-1" role="dialog"
         aria-labelledby="modal-106-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-106-label">[Abstract] Fair Knapsack</h4>
                </div>
                <div class="modal-body">
                    <p>We study the following multiagent variant of the knapsack problem. We are given a set of items, a set of voters, and a value of the budget; each item is endowed with a cost and each voter assigns to each item a certain value. The goal is to select a subset of items with the total cost not exceeding the budget, in a way that is consistent with the voters' preferences. Since the preferences of the voters over the items can vary significantly, we need a way of aggregating these preferences, in order to select the socially most preferred valid knapsack. We study three approaches to aggregating voters preferences, which are motivated by the literature on multiwinner elections and fair allocation. This way we introduce the concepts of individually best, diverse, and fair knapsack. We study computational complexity (including parameterized complexity, and complexity under restricted domains) of computing the aforementioned variants of multiagent knapsacks.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-299" tabindex="-1" role="dialog"
         aria-labelledby="modal-299-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-299-label">[Abstract] Positional Social Decision Schemes: Fair and Efficient Randomized Voting</h4>
                </div>
                <div class="modal-body">
                    <p>We introduce a new family of randomized voting rules, which is a probabilistic<br>counterpart of positional scoring rules. A rule in this family is defined by a<br>scoring vector associating a positive value with each rank in a vote, and an<br>aggregation function. We focus on two types of aggregation functions: those<br>corresponding to egalitarianism (min, and leximin) and the Nash product. We address the computation of the<br>rules and their normative properties. We argue that some these rules are<br>particularly useful for time-sharing in an efficient and fair manner.<br><br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-702" tabindex="-1" role="dialog"
         aria-labelledby="modal-702-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-702-label">[Abstract] Adaptive Bandit with Context-Dependent Embeddings</h4>
                </div>
                <div class="modal-body">
                    <p>We propose a technique for improving the performance of contextual bandit in non-stationary environments via adaptive, dynamic representation learning. Our approach combines off-line pre-training on unlabeled history of contexts (which, when available, can be exploited by our approach but not by the standard contextual bandit) with on-line choice and change of embedding functions facilitating representation learning. Our experiments on a variety of datasets consistently demonstrate advantages of our approaches over the standard contextual bandit approach. <br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-340" tabindex="-1" role="dialog"
         aria-labelledby="modal-340-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-340-label">[Abstract] Learning the Reward Function for a Misspecified Model</h4>
                </div>
                <div class="modal-body">
                    <p>In model-based reinforcement learning it is typical to treat the problems of learning the dynamics model and learning the reward function separately. However, when the dynamics model is flawed, it may generate erroneous states that would never occur in the true environment. A reward function trained only to map environment states to rewards (as is typical practice) would have little guidance in such states. This paper presents a novel error bound that accounts for the reward model's behavior in states sampled from the model. This bound is used to extend the existing Hallucinated DAgger-MC algorithm, which offers theoretical performance guarantees in deterministic MDPs that do not assume a perfect model can be learned. Empirically, this approach to learning a reward function can yield dramatic improvements in control performance when the dynamics model is flawed.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-417" tabindex="-1" role="dialog"
         aria-labelledby="modal-417-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-417-label">[Abstract] Parameter Design for Continuous Tasks based on Type Identification of Crowd Workers</h4>
                </div>
                <div class="modal-body">
                    <p>This paper proposes a method of task design based on type identification of crowd workers. Here, the task design means finding the values of task parameters that are suitable for individual workers. Multi-armed bandit techniques are promising, but if we consider continuous tasks, exploring various task settings for a single worker interferes with that worker, which deteriorates the quality of contributions. To solve this problem, we introduce the type identification test, i.e., we divide the entire period for a worker into a type identification phase and an execution phase and alternately handle the calculation at the individual worker level and at the aggregated workers level. Our method can find an appropriate task setting without exploring various settings for a worker, i.e., excessively interfering with the worker. Also, we provide a method of calculating the optimal type identification test to maximize the expected quality of contributions in the execution phase. Finally, we show the proposed method outperforms conventional multi-armed bandit algorithms such as Softmax and UCB1 with data we collected on the Amazon Mechanical Turk and with a simulation.<br><br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-197" tabindex="-1" role="dialog"
         aria-labelledby="modal-197-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-197-label">[Abstract] Multi-Agent Reinforcement Learning for Multi-Object Tracking</h4>
                </div>
                <div class="modal-body">
                    <p>We present a novel, multi-agent reinforcement learning formulation of multi-object tracking that treats creating, propagating, and terminating object tracks as actions in a sequential decision-making problem. In our formulation, each agent tracks a single object at a time by updating a Bayesian filter according to a discrete number of actions. At each timestep, the reward received is dependent on the joint actions taken by all agents and the ground truth object tracks. We optimize for different tracking metrics directly while propagating covariance information about each object's state. We use trust region policy optimization (TRPO) to train a shared policy across all agents, parameterized by a multi-layer neural network. Our experiments show an improvement in tracking accuracy over similar state-of-the-art, rule-based approaches on a popular multi-object tracking dataset.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-753" tabindex="-1" role="dialog"
         aria-labelledby="modal-753-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-753-label">[Abstract] Solving Dynamic Multi Objective Distributed Constraint Optimization Problems</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper we propose an algorithm for solving dynamic multi objective distributed constraint optimization problems (D-MODCOP) with Pareto solution. D-MODCOP is method for modeling problems in which the problems are modeled as a sequence of multi objective constraint optimization problems that must be solved decentralized. The dynamic nature of the problem is modeled with unpredictable random variables in the objective functions. Our algorithm searches the space of the problem point by point to find the Pareto frontier set in a decentralized manner in each time step. The D-MODCOP solver, solves a dynamic multi objective optimization(MODCOP) in each time step, computes a solution and uses the solution as the starting points for the next time step. In our experimental evaluation we show the convergence of our algorithm and its superiority in the number of message reduction over time steps in comparison with solving a new problem in each time step from scratch.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-525" tabindex="-1" role="dialog"
         aria-labelledby="modal-525-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-525-label">[Abstract] Efficient Influence Maximization Under Network Uncertainty</h4>
                </div>
                <div class="modal-body">
                    <p>We consider the influence maximization (IM) problem in a partially visible social network. In this problem, the aim is to design a decision-making framework for an autonomous agent to select a limited set of influential seed nodes in order to spread a belief or message as widely as possible across the network. Unlike most existing work, we consider the realistic case where the agent has to deal with uncertainty about parts of the network structure. Specifically, we assume that a partial section of the network is visible to the agent, while the rest is one of a finite set of known structures, each with a given realization probability. We show that solving the IM problem in this setting is NP-hard, and we provide analytical guarantees for the performance of a novel computationally-efficient seed-selection approximation algorithm for the agent. In empirical experiments on real-world social networks, we demonstrate the efficiency of our agent and show that it outperforms state-of-the-art approaches that do not model the uncertainty, reaching 14.9% more nodes in case of high uncertainty. Finally, we show that computationally more efficient heuristics, which considers uncertainty, do not perform well in this case.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-169" tabindex="-1" role="dialog"
         aria-labelledby="modal-169-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-169-label">[Abstract] Complexity of Scheduling Charging in the Smart Grid</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>In the smart grid, the intent is to use flexibility in demand, both to balance demand and supply as well as to resolve potential congestion. A first prominent example of such flexible demand is the charging of electric vehicles, which do not necessarily need to be charged as soon as they are plugged in. The problem of optimally scheduling the charging demand of electric vehicles within the constraints of the electricity infrastructure is called the charge scheduling problem. The models of the charging speed, horizon, and charging demand determine the computational complexity of the charge scheduling problem. For about 20 variants the problem is either in P or weakly NP-hard and dynamic programs exist to compute optimal solutions. About 10 other variants of the problem are strongly NP-hard, presenting a potentially significant obstacle to their use in practical situations of scale. An experimental study establishes up to what parameter values the dynamic programs can determine optimal solutions in a couple of minutes.</p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-415" tabindex="-1" role="dialog"
         aria-labelledby="modal-415-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-415-label">[Abstract] Moral values in norm decision making</h4>
                </div>
                <div class="modal-body">
                    <p>Most often, both agents and human societies use norms to coordinate their on-going activities. Nevertheless, choosing the 'right' set of norms to regulate these societies constitutes an open problem. Firstly, intrinsic norm relationships may lead to inconsistencies in the chosen set of norms. Secondly, and more importantly, there is an increasing demand of including ethical considerations in the decision making process. This paper focuses on choosing the 'right' norms by considering moral values together with society's partial preferences over these values and the extent to which candidate norms promote them. The resulting decision making problem can then be encoded as a linear program, and hence solved by state-of-the art solvers. Furthermore, we empirically test several optimisation scenarios so to determine the system's performance and the characteristics of the problem that affect its hardness.<br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-310" tabindex="-1" role="dialog"
         aria-labelledby="modal-310-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-310-label">[Abstract] Trial without Error: Towards Safe Reinforcement Learning via Human Intervention</h4>
                </div>
                <div class="modal-body">
                    <p><span style="font-family: &quot;Lucida Grande&quot;, helvetica, arial, verdana, sans-serif; font-size: 14.4px;">AI systems are increasingly applied to complex tasks that involve interaction with humans. During training, such systems are potentially dangerous, as they haven't yet learned to avoid actions that could cause serious harm. How can an AI system explore and learn without making a single mistake that harms humans or otherwise causes serious damage? For model-free reinforcement learning, having a human "in the loop" and ready to intervene is currently the only way to prevent all catastrophes. We formalize human intervention for RL and show how to reduce the human labor required by training a supervised learner to imitate the human's intervention decisions. We evaluate this scheme on Atari games, with a Deep RL agent being overseen by a human for four hours. When the class of catastrophes is simple, we are able to prevent all catastrophes without affecting the agent's learning (whereas an RL baseline fails due to catastrophic forgetting). However, this scheme is less successful when catastrophes are more complex: it reduces but does not eliminate catastrophes and the supervised learner fails on adversarial examples found by the agent. Extrapolating to more challenging environments, we show that our implementation would not scale (due to the infeasible amount of human labor required). We outline extensions of the scheme that are necessary if we are to train model-free agents without a single catastrophe.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-368" tabindex="-1" role="dialog"
         aria-labelledby="modal-368-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-368-label">[Abstract] Argumentation with Goals for Clinical Decision Support in Multimorbidity</h4>
                </div>
                <div class="modal-body">
                    <p>Decision-making in multimorbidity carries a complexity related with the multiple variables involved in the process. These variables reflect the concomitant health conditions that should be considered when defining a proper therapy. However, current Clinical Decision Support Systems (CDSSs) are not equipped to deal with such a setting. They do not go beyond the straightforward application of the rules that build their knowledge base and simple interpretation of Computer-Interpretable Guidelines (CIGs). The present work proposes a computational argumentation system equipped with goal seeking to combine independently generated CIG recommendations and enhance CDSSs to support physicians in these decisions.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-641" tabindex="-1" role="dialog"
         aria-labelledby="modal-641-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-641-label">[Abstract] Group Decision Making with Uncertain Subjective Preferences</h4>
                </div>
                <div class="modal-body">
                    <pre style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;"><!--StartFragment--><span style=" color:#000000;">Social choice theory, in particular voting, has been embraced by the AI community as it provides a principled framework for the aggregation of individuals' preferences in support of group decision-making and recommendation.  Much of this work, however, either assumes that individuals' subjective preferences (and thus, their votes) are correctly specified by the individuals themselves, or alternatively that the votes of individuals are  noisy estimates of some underlying ground truth over rankings of alternatives. We argue that neither model appropriately addresses some of the issues which arise in the context of group-recommendation domains where individuals have subjective preferences but for some reason (e.g., the high cognitive burden, </span><span style="color: rgb(0, 0, 0);">concerns about privacy, etc.) may instead vote using a noisy estimate of their subjective preferences. </span><span style="color: rgb(0, 0, 0);">In this paper we propose a general probabilistic framework for modeling noisy subjective preferences, and study the accuracy and reliability of four well-studied voting rules  (Plurality, </span><span style="color: rgb(0, 0, 0);">Borda</span><span style="color: rgb(0, 0, 0);">, </span><span style="color: rgb(0, 0, 0);">Kemeny</span><span style="color: rgb(0, 0, 0);"> and Copeland) in this context. We also propose and evaluate inference methods for recovering true subjective preferences given noisy ones. Our experiments confirm the efficacy of our proposed method in dealing with noisy preferences.</span></pre>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-362" tabindex="-1" role="dialog"
         aria-labelledby="modal-362-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-362-label">[Abstract] Large Scale Multi-Issue Multi-Lateral Negotiation</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we consider the problem of large scale multiissue negotiation. We assume that agents have different preferences over the negotiated issues and may be indifferent regarding some of the issues. They nevertheless have to make a collective choice that addresses all issues at stake. In practice,&nbsp; we consider an example of a joint purchase of energy where the concerned households have to define a collective energy contract. Given the complexity of the negotiation problem, we propose a multi-step negotiation process that involves iteratively partitioning the agents into subgroups according to their similarity over the issues they want to negotiate and negotiation outcomes. We don’t require the agents to reveal their preferences for the mechanism to work but we elicit these preferences through the negotiation steps. Furthermore, we design a negotiation protocol to support the creation of efficient outcomes. Our experimental results show that our negotiation algorithm allows the agents to reach agreements in limited numbers of rounds.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-134" tabindex="-1" role="dialog"
         aria-labelledby="modal-134-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-134-label">[Abstract] Classification with Costly Features using Deep Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p>We study a classification problem where each feature can be acquired for a cost and the goal is to optimize the trade-off between classification precision and the total feature cost. We frame the problem as a sequential decision-making problem, where we classify one sample in each episode. At each step, an agent can use values of acquired features to decide whether to purchase another one or whether to classify the sample. We use vanilla Double Deep Q-learning, a standard reinforcement learning technique, to find a classification policy. We show that this generic approach outperforms Adapt-Gbrt, currently the best-performing algorithm developed specifically for classification with costly features.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-329" tabindex="-1" role="dialog"
         aria-labelledby="modal-329-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-329-label">[Abstract] AgentSpeak(ER): An Extension of AgentSpeak(L) improving Encapsulation and Reasoning about Goals</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we introduce AgentSpeak(ER), an extension of the AgentSpeak(L) language tailored to support encapsulation. The AgentSpeak(ER) extention allows for significantly improving the style of BDI agent programming along relevant aspects, including program modularity and readability, failure handling, and reactive as well as goal-based reasoning. The paper introduces the novel language, formalises the changes in the usual semantics of AgentSpeak, illustrate the features of the language through examples, and shows results of experiments evaluating the proposed language.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-486" tabindex="-1" role="dialog"
         aria-labelledby="modal-486-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-486-label">[Abstract] Guiding Reinforcement Learning Exploration Using Natural Language</h4>
                </div>
                <div class="modal-body">
                    <p>In this work we present a technique to use natural language to help reinforcement learning generalize to unseen environments. This technique uses neural machine translation, specifically the use of encoder-decoder networks, to learn associations between natural language behavior descriptions and state-action information. We then use this learned model to guide agent exploration using a modified version of policy shaping to make it more effective at learning in unseen environments. We evaluate this technique using the popular arcade game, Frogger, under ideal and non-ideal conditions. This evaluation shows that our modified policy shaping algorithm improves over a Q-learning agent as well as a baseline version of policy shaping</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-49" tabindex="-1" role="dialog"
         aria-labelledby="modal-49-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-49-label">[Abstract] Agent-Based Modeling of Emergency Evacuations Considering Human Panic Behavior</h4>
                </div>
                <div class="modal-body">
                    <p>During mass evacuations, many psychological and physical factors are<br>responsible for stampedes and other life threatening<br>situations. Quantitative and qualitative analyses of these factors are<br>of high importance while devising optimal strategies for evacuations.<br>In this work we present an agent-based model that considers<br>psychological and physical factors that cause panic in such<br>situations.&nbsp; We have also simulated some simple evacuation scenarios<br>and presented a method to identify possible bottlenecks and<br>shortcomings in the environments during emergency evacuations.&nbsp; Our<br>method also helps in evaluation and analysis of different evacuation<br>strategies.&nbsp; To enable this analysis we have used a rule-based roadmap<br>approach, where critical nodes in the environment are identified by<br>the evacuation planner and each node has a special rule according to<br>the strategy of the planner.&nbsp; We evaluate different strategies on<br>parameters such as evacuation time and physical discomfort caused to<br>the agents.<br><br><br><p><br></p></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-425" tabindex="-1" role="dialog"
         aria-labelledby="modal-425-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-425-label">[Abstract] Social Convention Emergence in Systems where Agents have Conflict of Interest</h4>
                </div>
                <div class="modal-body">
                    <p>Recently, social conventions, a type of social norms, have attracted much attention in the multi-agent system literature. We here focus on the case that each agent specially prefers one convention and is indifferent to all the others. Therefore, agents have conflict in to which particular convention they should conform, although conformity is in their common interest. We formalize such kind of scenarios as <i>coordination games with conflict of interest</i>. In these games, an agent prefers choosing the same action as its opponent's, i.e., coordination, over discoordination. However, agents have different degrees of preference on by which action to achieve coordination. In our experimental study, we investigate if and how a social convention can emerge in systems where agents play coordination games with conflict of interest with their neighbours repeatedly. Moreover, we identify two key factors, the ratios of agents which prefer different conventions and the degree of such preference, and investigate their influences on the speed, dynamics and individual payoffs of convention emergence phenomena.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-348" tabindex="-1" role="dialog"
         aria-labelledby="modal-348-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-348-label">[Abstract] When less is more: Reducing agent noise with probabilistically learning agents</h4>
                </div>
                <div class="modal-body">
                    <p>Distributed agents concurrently learning to coordinate in a multiagent system can suffer from considerable amounts of agent noise. This is the noise that arises from the non-stationarity of the learning environment for each individual agent since other agents in the system are also constantly updating their policies, thereby continually shifting the goal posts for successful coordination. In this work, we propose a method to reduce agent noise by allowing individual agents to probabilistically determine whether or not to undergo policy updates based on their estimated impact on the team learning performance. We show that using this method to adapt the number of actively learning agents over time provides improvements to the convergence speed of the team as a whole without affecting the final converged learning performance.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-203" tabindex="-1" role="dialog"
         aria-labelledby="modal-203-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-203-label">[Abstract] Trust Network-based Spam Worker Identification in Crowdsourcing Environments</h4>
                </div>
                <div class="modal-body">
                    <p>Reputation-based defense models and trust network-based defense models have been widely investigated to defend against spammers in general online applications. In recent years, particularly targeting spam workers in crowdsourcing environments, several novel reputation-based models have also been proposed. However, the existing models overlook the fact that a spam worker can masquerade as an “honest” workers<br>by colluding with accomplices. In particular, a spam worker can obtain guises, such as a “good” reputation and trust links to honest requesters, via collusions. More importantly, the low or even free transaction fee and the availability of high-degree anonymity in crowdsourcing environments could allow spam workers to easily collude with accomplices to obtain guises.<br></p><p><br>In order to solve the challenging spam worker identification problem, in this paper, we propose a new model that is the first one to investigate trust network based features for identifying spam workers in crowdsourcing environments. In particular, we firstly propose a Crowdsourcing Trust Network (CTN). Based on it, we propose a novel worker trust representation called Worker Trust Matrix (WTM). A worker’s WTM is essentially a global trust feature set that consists of trust indicators measuring the extents to which the worker is trusted by different requesters in different sub-CTNs. Moreover, we prove that a WTM possesses the un-manipulable property and the usable property that are critical for effectively identifying a worker’s identity. Furthermore, we devise a learning-based algorithm to predict a worker’s identity with its WTM as input. Finally, we demonstrate the superior effectiveness of our proposed spam worker identification model in extensive experiments.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-94" tabindex="-1" role="dialog"
         aria-labelledby="modal-94-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-94-label">[Abstract] Modelling contingent modernisation of irrigation systems in farmer communities</h4>
                </div>
                <div class="modal-body">
                    <p>Of all the uses of water, agriculture is the one that
requires the greatest proportion of water resources worldwide and, consequently,
it is a salient subject for policy-making and modernisation of irrigation
systems is a key instrument to improve water use efficiency. Because of
economies of scale, farmer communities that share irrigation infrastructure are
natural candidates for innovations. In this paper we present an agent-based
model of the modernisation process of a farmer community. The phenomenon is
approached as a contingent innovation adoption: a first stage of collective
agreement followed by an individual adoption decision. The model is based on
historical data from two Spanish "irrigator communities" during the
period 1975-2010. Results suggest that individual profits and farm extension
(as proxy of social influence) are suitable assumptions when modelling the modernisation
of communities in regions where agriculture is strongly market-oriented and
water is scarce. These results point towards the interest of more sophisticated
socio-cognitive modelling within a more realistic socio-hydrologic context.<br></p><p class="MsoPlainText"><o:p></o:p></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-479" tabindex="-1" role="dialog"
         aria-labelledby="modal-479-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-479-label">[Abstract] Local Envy-Freeness with Indivisible Goods</h4>
                </div>
                <div class="modal-body">
                    <p>We study the fair division problem consisting in &nbsp;allocating one item per agent so as to avoid (or minimize) envy, in a setting where only agents connected in a given social network may experience envy. In a variant of the problem, agents themselves can be located on the network by the central authority. These problems turn out to be difficult even on very simple graph structures, but we identify several tractable cases. We further provide practical algorithms and experimental insights. &nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-567" tabindex="-1" role="dialog"
         aria-labelledby="modal-567-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-567-label">[Abstract] Dynamic fans economy: sequential all-pay auctions with proportional allocations</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we study an extensive-form game, coined sequential
all-pay auctions with proportional allocations (SAPAPA), in which
bidders submit their bids in a given order and each gets allocated a
fraction of the item that equals the proportion of his bid over the
sum of all bids while paying his own bid. This game models realistic
scenarios where fans dynamically donate to a host in the so-called
fans economy model, recently proposed by Tang et al. [14]. This
game can also be thought of as an extensive form Tullock contest,
which has not been well understood in the literature. In contrast,
the simultaneous form of this game, aka. all-pay auctions with
proportional allocations (APAPA), has been well studied and shown
to have good revenue and welfare properties.
We conduct a game-theoretical analysis of the SAPAPA game.
We obtain the closed-form solution of the unique subgame perfect
equilibrium (SPE) in the two-player complete information setting
and prove there could be infinite many SPEs for some general nplayer
cases. In addition, we show that, for the general n-player
cases, when the bidders are ordered in ascending order of their
values, there exists a unique SPE and its revenue is at least half
of that of the second highest value. For the case of incomplete
information, we also prove the uniqueness of perfect Bayesian
equilibrium (PBE) for the two-player case and give a monotonicity
characterization of the PBE strategies.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-774" tabindex="-1" role="dialog"
         aria-labelledby="modal-774-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-774-label">[Abstract] Toward a Misrepresentation Game with Ambiguous Preferences</h4>
                </div>
                <div class="modal-body">
                    <p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
  <o:PixelsPerInch>96</o:PixelsPerInch>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:DrawingGridVerticalSpacing>10 pt</w:DrawingGridVerticalSpacing>
  <w:DisplayHorizontalDrawingGridEvery>0</w:DisplayHorizontalDrawingGridEvery>
  <w:DisplayVerticalDrawingGridEvery>2</w:DisplayVerticalDrawingGridEvery>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>JA</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:SpaceForUL/>
   <w:BalanceSingleByteDoubleByteWidth/>
   <w:DoNotLeaveBackslashAlone/>
   <w:ULTrailSpace/>
   <w:DoNotExpandShiftReturn/>
   <w:AdjustLineHeightInTable/>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
   <w:UseFELayout/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"/>
 </w:LatentStyles>
</xml><![endif]-->

<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:標準の表;
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0mm 5.4pt 0mm 5.4pt;
	mso-para-margin:0mm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Yu Mincho";
	mso-ascii-font-family:"Yu Mincho";
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:"Yu Mincho";
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:"Yu Mincho";
	mso-hansi-theme-font:minor-latin;
	mso-font-kerning:1.0pt;}
</style>
<![endif]-->



<!--StartFragment-->



<!--EndFragment--></p><p class="MsoNormal"><span lang="EN-US">In this paper, we show an analysis on a Misrepresentation
Game with ambiguous preferences. A Misrepresentation Game is a game that sometimes
an agent obtains higher utility than truth-telling on a preference-elicitation
based fair division negotiation by misrepresenting their preferences while it
is still difficult to be noticed by the counterpart. We investigate whether we
can generate mechanisms for fair negotiations which avoids incentives to make
misrepresentations by using a way of automated design of mechanisms.<o:p></o:p></span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-497" tabindex="-1" role="dialog"
         aria-labelledby="modal-497-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-497-label">[Abstract] A framework for a dynamic inter-connection of collaborating agents with multi-layered application abstraction based on a software-bus system</h4>
                </div>
                <div class="modal-body">
                    <p>With the currently ongoing and necessary process to define standards for multi-agent systems, their potential for adaptation to specific underlying system requirements becomes increasingly challenging. Especially in applications, where MAS are coupled to hardware which has strict requirements to the logic-level controlling it, such as a specific response time, or quality-of-service. As a result, it is proposed to separate the high-level decision making process based on standardized MAS and the low-level control into two layers. In this paper, based on a publisher/subscriber software-bus system, we propose a framework which allows dynamic allocation and linking of agents to underlying low-level hardware control. The concept of the framework and its architecture is introduced as well as a proof-of-concept for dynamic agent linking.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-394" tabindex="-1" role="dialog"
         aria-labelledby="modal-394-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-394-label">[Abstract] Deep Recurrent Auto-encoder for Network Representation</h4>
                </div>
                <div class="modal-body">
                    <p>In the research of network, a key problem is how to represent the network reasonably. Most existing network representation methods do not fully consider local and global information of the network. In this paper, we In network representation, a key problem is how to learn the network structure information. To solve this problem, a traditional way is making use of matrix factorization. However, almost all of these methods adopt shallow models and cannot capture the complex network structure. In recent years, neural networks based methods have been applied to this task. Though these methods make a certain progress than MF-based methods, most of them still have not fully considered the network structure including global and local information.&nbsp;</p><p>In this paper, to solve the network representation problem, we first present the concept of a small structure unit and then propose a deep recurrent auto-encoder model. For each small structure unit, we construct several global-local node sequences. Then the proposed model can learn the local and global information of the network by these node sequences. Specifically, we learn the global information of each node by a multi-layer nonlinear neural network, and preserve the local information by a recurrent neural network. Besides, to solve the sparse problem, we design a penalty mechanism to enhance existing link information in network. Finally, we evaluate our model on three real datasets and conduct extensive experiments on visualization, parameter sensitivity and efficiency. The result demonstrates that the proposed model can preserve network structure well for network representation.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-195" tabindex="-1" role="dialog"
         aria-labelledby="modal-195-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-195-label">[Abstract] Action Categorization for Computationally Improved Task Learning and Planning</h4>
                </div>
                <div class="modal-body">
                    <p>This paper explores the problem of task learning and planning, contributing the <i>Action-Category Representation (ACR)</i> to improve computational performance of both Planning and Reinforcement Learning (RL). ACR is an algorithm-agnostic, abstract data representation that maps objects to action categories (groups of actions), inspired by the psychological concept of <i>action codes</i>. We validate our approach in StarCraft and Lightworld domains; our results demonstrate several benefits of ACR relating to improved computational performance of planning and RL, by reducing the action space for the agent.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-590" tabindex="-1" role="dialog"
         aria-labelledby="modal-590-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-590-label">[Abstract] Multiagent RL for Real-World Interdependent Congestion Problems</h4>
                </div>
                <div class="modal-body">
                    <div class="" style="font-family: Garamond; font-size: 15px; text-size-adjust: auto; margin: 0px;">In this article, we explore the computation of joint policies for autonomous agents to resolve multiple interdependent congestions.<span class="Apple-converted-space">&nbsp;</span></div><div class="" style="font-family: Garamond; font-size: 15px; text-size-adjust: auto; margin: 0px;">Agents have limited information about others' payoffs and preferences, and need to coordinate to achieve their tasks while adhering to operational constraints.&nbsp;</div><div class="" style="font-family: Garamond; font-size: 15px; text-size-adjust: auto; margin: 0px;">We formalize the generic problem as a multi-agent MDP, and instantiate it to a real-world problem: deciding required flight delays to resolve demand and capacity balance (DCB) problems in air traffic management (ATM).<span class="Apple-converted-space">&nbsp;</span></div><div class="" style="font-family: Garamond; font-size: 15px; text-size-adjust: auto; margin: 0px;">To this end, we present collaborative reinforcement learning methods that allow agents to interact and form own strategies in coordination with others.&nbsp;</div><div class="" style="font-family: Garamond; font-size: 15px; text-size-adjust: auto; margin: 0px;">We provide results on real-world ATM datasets, which confirm the effectiveness of our approach.</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-159" tabindex="-1" role="dialog"
         aria-labelledby="modal-159-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-159-label">[Abstract] Winners-Restricted Utility- and Revenue-Maximizing Equilibria for Size-Interchangeable Bidders</h4>
                </div>
                <div class="modal-body">
                    <p>A Walrasian equilibrium (WE) is a fundamental market outcome where all bidders are utility-maximizers (UM), and the market clears (MC), meaning that the price of unallocated goods is zero. However, a WE need not exist in combinatorial markets and, even if it exists, its revenue might be arbitrarily low. An Envy-Free Pricing (EFP) is one way to address the existence issue by dropping the MC condition. Although an EFP always exists, computing a revenue-maximizing EFP outcome remains computationally intractable even for simple combinatorial markets. In this paper, we propose a further relaxation of EFP, which we call Winners-Restricted Pricing (WiReP), which requires that only winners are UM. We show that a WiReP can be computed in polynomial time for some types of combinatorial markets, and develop methods to compute revenue-maximizing WiRePs for a fixed allocation. We embed these methods in a heuristic to search for revenue-maximizing outcomes over all feasible allocations, and show in extensive experiments that WiRePs&nbsp;are in fact close to WE while consistently achieving higher revenue and welfare than other algorithms in the literature.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-565" tabindex="-1" role="dialog"
         aria-labelledby="modal-565-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-565-label">[Abstract] Market making via reinforcement learning</h4>
                </div>
                <div class="modal-body">
                    <div>Market making is a fundamental trading problem in which an agent provides liquidity by continually offering to buy and sell a security. The problem is challenging due to inventory risk, the risk of accumulating an unfavourable position and ultimately losing money. In this paper, we develop a high-fidelity simulation of limit order book markets, and use it to design a market making agent using temporal-difference reinforcement learning. We use a linear combination of tile codings as a value function approximator, and design a custom reward function that controls inventory risk. We demonstrate the effectiveness of our approach by showing that our agent outperforms both simple benchmark strategies and a recent online learning approach from the literature.</div><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-688" tabindex="-1" role="dialog"
         aria-labelledby="modal-688-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-688-label">[Abstract] Inverse Reinforcement Learning with Nonparametric Behavior Clustering</h4>
                </div>
                <div class="modal-body">
                    <p>Inverse Reinforcement Learning (IRL) is the task of learning
a single reward function given a Markov Decision Process
(MDP) without defining the reward function, and a set
of demonstrations generated by humans/experts. However, in
practice, it may be unreasonable to assume that human behaviors
can be explained by one reward function since they
may be inherently inconsistent. Also, demonstrations may be
collected from various users and aggregated to infer and predict
users’ behaviors. In this paper, we introduce the Nonparametric
Behavior Clustering IRL algorithm to simultaneously
cluster demonstrations and learn multiple reward functions
from demonstrations that may be generated from more
than one behaviors. Our method is iterative: It alternates between
clustering demonstrations into different behavior clusters
and inverse learning the reward functions until convergence.
It is built upon the Expectation-Maximization formulation
and non-parametric clustering in the IRL setting. Further,
to improve the computation efficiency, we remove the
need of completely solving multiple IRL problems for multiple
clusters during the iteration steps and introduce a resampling
technique to avoid generating too many unlikely clusters.
We demonstrate the convergence and efficiency of the
proposed method through learning multiple driver behaviors
from demonstrations generated from a grid-world environment
and continuous trajectories collected from autonomous
robot cars using the Gazebo robot simulator.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-461" tabindex="-1" role="dialog"
         aria-labelledby="modal-461-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-461-label">[Abstract] Traffic Optimization Using an Online Social Network</h4>
                </div>
                <div class="modal-body">
                    <p>Traffic congestion is ubiquitous in cities across the globe and has great economic and environmental costs associated with it. Although real-time traffic updates are now available, the tendency of drivers to make uncoordinated routing decisions exacerbates the congestion problem. Existing solutions, both in private and public domains, do not provide efficient mechanisms for creating a socially optimal traffic distribution to overcome the congestion problem. In this paper, we present an online social network-based solution that enables drivers to coordinate about their route choices to overcome the congestion problem. We develop a route selection-based algorithm that favors a socially optimal distribution of traffic and reduces the average travel time of drivers. We study the effect of our approach on multiple networks, both synthetic and real. Extensive simulation results show that our approach is able to establish socially optimal traffic distribution in various networks as compared to existing road pricing-based techniques.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-158" tabindex="-1" role="dialog"
         aria-labelledby="modal-158-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-158-label">[Abstract] Fast Terminating Procedures for Equitable Stable Marriages</h4>
                </div>
                <div class="modal-body">
                    <p>The stable marriage problem calls for finding a perfect bipartite matching among agents in a two-sided market (e.g., women and men, or job applicants and employers). Each agent ranks members of the opposite side by strictly decreasing preference. The solution must be {\em stable}, meaning that no pair of agents prefer each other to their assigned matches. Gale and Shapley proposed an algorithm that yields a stable solution for any instance of the problem in polynomial time. However, out of all possible stable matchings, the Gale-Shapley algorithm yields the best possible (optimal) preference to each agent on the one side, and the worst possible (pessimal) to each on the other side. Accordingly, the {\em equitable stable marriage} (ESM) problem calls for minimizing the distance between average assigned preferences on the two sides as a measure of equality. Unfortunately, this problem is strongly NP-hard. Proposed heuristics run for an unpredictable and unbounded number of iterations with non-guaranteed termination. Thus, a cardinal question has remained open since 1962: is there an efficient procedure that achieves equitable stable matchings and is guaranteed to terminate?<br></p><p>This paper resolves this open question. We show that knowledge of a stable matching can guide a procedure towards a stable matching, from a &nbsp;random starting position, and study the monotonicity properties of procedures leading to stability. Armed with these results, we design a suite of agent strategies and associated procedures that provably terminate to stable and equitable matchings in low-polynomial time. A thorough experimental study with diverse preference distributions shows that our procedures stand out in terms of equality and other quality measures.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-639" tabindex="-1" role="dialog"
         aria-labelledby="modal-639-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-639-label">[Abstract] An Agent-Based Traffic Signal Timing System for Alleviating Urban Traffic Congestion</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal"><span style="background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;">In this paper we present a multi-agent
Traffic Signal Timing system (TST) for congestion reduction. The agent traffic
system is based on a real-world TST and intended to be deployed with minimal
changes to the infrastructure. As such, it considers attaching agents to
intersection controllers and using existing communication technologies. Our
fully decentralized agent TST has been validated on a simulated model of a city
comprising 128 intersections. The experimental results show that it outperforms
the conventional pre-timed and fully-actuated operation modes.</span><o:p></o:p></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-593" tabindex="-1" role="dialog"
         aria-labelledby="modal-593-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-593-label">[Abstract] Towards Online Goal Recognition Combining Goal Mirroring and Landmarks</h4>
                </div>
                <div class="modal-body">
                    <p>Online goal recognition is the problem of recognizing the goal of an agent based on an incomplete sequence of incrementally revealed observations as early along in the recognition process as possible.&nbsp;</p><p>Recognizing goals with minimal domain knowledge as an agent executes its plan requires efficient algorithms to sift through a large space of hypotheses.&nbsp;</p><p>We develop an online approach to goal recognition which operates in both continuous and discrete domains using a combination of Goal Mirroring and a generalized notion of landmarks adapted from the planning literature.&nbsp;</p><p>Extensive experiments demonstrate the approach is more efficient and substantially more accurate than the state-of-the-art.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-681" tabindex="-1" role="dialog"
         aria-labelledby="modal-681-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-681-label">[Abstract] Detecting miscomunication in dialogue with conversational agents</h4>
                </div>
                <div class="modal-body">
                    <p>During the process of mastering language for the purpose of communication, humans are able to successfully learn how to overcome issues in dialogue. We believe a similar process could be used in dialogue agents when dealing with miscommunication issues. We propose the creation of two models: a preventive one, which detects problematic dialogue turns before answering the user; and a reactive one, which marks previous interactions as problematic. These models can be used to prevent miscommunication during dialogue and to assist in the analysis of human-agent dialogue logs, in order to detect problems and potential improvements on the agent's strategies and Knowledge Base.<br><br>To evaluate our approach, we collected 
and annotated a corpus of interactions in European Portuguese (that will
 be freely available) with AGENT-X, a conversational agent that answers 
questions posed by PLACE-X visitors, and tested our approach achieving an F-Measure of 0.84 
with 0.93 True Negative rate, showing that is possible to use the 
training data to reduce the amount of dialogue turns an agent's developer 
has to review.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-508" tabindex="-1" role="dialog"
         aria-labelledby="modal-508-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-508-label">[Abstract] Establishing Relationships between Security and Efficiency: a Case Study in Airport Terminals</h4>
                </div>
                <div class="modal-body">
                    <p>Both security and efficiency are important performance areas of air transport systems. Several methods have been proposed in literature to assess security risks and estimate efficiency, but only few of these methods identify relationships between security risks and efficiency indicators. However, intuitively there is a relationship between security and efficiency. For example, removing the security checkpoint from the airport leads to lower waiting times for passengers, but reduces security. To identify and quantify such relationships, an agent-based methodology is proposed in this work. This methodology combines an agent-based security risk assessment approach with agent-based efficiency estimation. The methodology is applied to a case study that identifies relationships between security regarding an Improvised Explosive Device (IED) attack and different efficiency indicators in the aviation domain. Results show relationships between risks regarding an IED attack and efficiency indicators like queuing time for passengers and number of missed flights. The proposed methodology was showed to be useful to find and quantify relationships between security and efficiency and therefore forms a promising way to investigate different trade-offs in detail.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-424" tabindex="-1" role="dialog"
         aria-labelledby="modal-424-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-424-label">[Abstract] Adaptive Incentive Selection for Crowdsourcing Contests</h4>
                </div>
                <div class="modal-body">
                    <p>The success of crowdsourcing projects relies critically on motivating the crowd to contribute. One particularly effective method for incentivising participants to perform tasks is to run contests. However, there are numerous ways to implement such contests in specific projects (that vary in how performance is evaluated, how to reward, and the sizes of the prizes). Additionally, with a given financial budget and a time limit, choosing incentives that maximise the total outcome (e.g., the total number of completed tasks) is not trivial, as their effectiveness in a specific project is usually unknown in advance. Therefore, in this paper, we introduce algorithms to select such incentives effectively using budgeted multi-armed bandits. To do that, we first introduce the \kw{incentive selection problem}, then formalise it as a 2d-budgeted multi-armed bandit, where each arm corresponds to an incentive (i.e., a contest with a specific structure). We then propose the HAIS and Epsilon First algorithms to solve the incentive selection problem. The two algorithms are shown to be effective on both synthetic data and authentic data with a real microtask crowdsourcing project. Epsilon First performs well, but requires a situation-specific parameter to be tuned appropriately (which may be difficult in settings with little prior experience). In contrast to this, HAIS performs better in most cases without depending significantly on the parameter tuning.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-317" tabindex="-1" role="dialog"
         aria-labelledby="modal-317-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-317-label">[Abstract] PANO: Privacy Auctioning for Online Social Networks</h4>
                </div>
                <div class="modal-body">
                    <p>Online Social Networks (OSNs) enable their users to share content with their connections.&nbsp; Shared contents over OSNs raise privacy concerns, since they tend to contain personal information of users. More importantly, a single content, e.g, a photo of a group of people, can potentially contain private information of multiple users, which become available without their consent.&nbsp; Ensuring that all relevant users' privacy requirements are met is important but difficult since the requirements can easily be conflicting.&nbsp; Hence, mechanisms to resolve privacy disputes are needed.&nbsp; Accordingly, this paper proposes an agent-based collaborative privacy management model, where agents represent users and manage their privacy requirements.&nbsp; When an image is about to be shared, the relevant agents enter an auction and bid on behalf of their users about how private the considered image is. The bids are processed with a modified version of Clarke-Tax mechanism that achieves fair handling of privacy settings and taxes the agents whose privacy settings are chosen.&nbsp; We evaluate our approach over multi-agent simulations and show that it produces privacy policies efficiently and more accurately than existing approaches.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-367" tabindex="-1" role="dialog"
         aria-labelledby="modal-367-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-367-label">[Abstract] Practical Scalability for Stackelberg Security Games</h4>
                </div>
                <div class="modal-body">
                    <p>Stackelberg Security Games (SSGs) have been adopted widely for modeling adversarial interactions. With increasing size of the applications of SSGs, scalability of equilibrium computation is an important research problem. While prior research has made progress with regards to scalability, many real world problems cannot be solved satisfactorily yet as per current requirements; these include the deployed federal air marshals (FAMS) application and the threat screening (TSG) problem at airports. Further, scalability in these problem domains is inherently limited by NP hardness shown in prior literature. We initiate a principled study of approximations in zero-sum SSGs. Our contribution includes the following: (1) a unified model of SSGs called adversarial randomized allocation (ARA) games that allows studying most SSGs in one model, (2) hardness of approximation results for zero-sum ARA, as well as for the sub-problem of allocating federal air marshal (FAMS) and threat screening problem (TSG) at airports, (3) an approximation framework for zero-sum ARA with instantiations for FAMS and TSG using intelligent heuristics along with provable approximation guarantees and (4) experiments demonstrating the significant scalability of up to 1000x improvement in runtime with an acceptable 5% solution quality loss.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-393" tabindex="-1" role="dialog"
         aria-labelledby="modal-393-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-393-label">[Abstract] The Core of Hedonic Games under Enemies Aversion: Algorithms, Probabilities and Experiments</h4>
                </div>
                <div class="modal-body">
                    <p>We investigate hedonic games under enemies aversion when each agent considers other agents to be friends, enemies, or neutrals. The core's existence, its computation and other characteristics are fundamental issues in coalition formation games. The core can be empty and deciding core non-emptiness is intractable (i.e., $\Sigma_2^P$-complete). In this paper, we first obtain a new counter-example showing that the core can be empty even when the agent relations are symmetric. Secondly, we face the challenge of computing core-stable coalition structures, despite this problem's high intractability. It turns out that by column generation, our MILP formulation scales surprisingly well with respect to the number of agents. Thirdly, we prove formally that the core's expected size is at least an exponential of the number of agents. Finally, our experiments show that the core is very unlikely to be empty, despite the counter-examples, and we observe that on average the core's size is indeed exponential with respect to the number of agents.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-455" tabindex="-1" role="dialog"
         aria-labelledby="modal-455-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-455-label">[Abstract] Deep Multiagent Q-Learning for Autonomous Agents in Future Smart Grid</h4>
                </div>
                <div class="modal-body">
                    <p>Modern smart grid is an information-based electricity transmission and distribution system deployed with digital technologies to automatically manage electricity delivery and achieve sustainability, reliability, security, and efficiency of the electric grid. Broker mechanism is widely applied to serve for interested parties in smart grid. However, smart grid constitutes a complex, dynamic and real-time environment and raises great challenge for brokers, such as balancing demand and supply from customers and competing with other efficient brokers to gain profits. In this paper, we develop a pricing strategy for broker agents in local electricity retail market based on recurrent deep multiagent reinforcement learning. We introduce real data to simulate the retail market and evaluate the proposed broker pricing strategy. The experiments demonstrate the superior performance of deep reinforcement learning technique and highlight the effectiveness of the proposed pricing strategy with contribution value calculation in the context of complex environment.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-513" tabindex="-1" role="dialog"
         aria-labelledby="modal-513-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-513-label">[Abstract] Multi-player Flow Games</h4>
                </div>
                <div class="modal-body">
                    <p>
<style type="text/css">
p, li { white-space: pre-wrap; }
</style>
</p><pre style="margin-bottom: 0px;"><!--StartFragment--><span style=" color:#000000;">In the traditional maximum-flow problem, the goal is to transfer maximum flow in a network by directing, in each vertex in the network, incoming flow into outgoing edges. The problem corresponds to settings in which a central authority has control on all </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">vertices</span><span style=" color:#000000;"> of the network. Today's computing environment, however, involves systems with no central authority. In particular, in many applications of flow networks, the </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">vertices</span><span style=" color:#000000;"> correspond to decision-points controlled by different and selfish entities. For example, in communication networks, routers may belong to different companies, with different destination objectives. This suggests that the maximum-flow problem should be revisited, and redefined as a game.</span></pre><p>
</p><pre style="margin-bottom: 0px;"><br></pre><p>
</p><pre style="margin-bottom: 0px;"><span style=" color:#000000;">We introduce and study {</span><span style=" color:#800000;">\em</span><span style=" color:#000000;"> </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">multi</span><span style=" color:#000000;">-player flow games</span><span style=" color:#800000;">\/</span><span style=" color:#000000;">} (</span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">MFGs</span><span style=" color:#000000;">, for short). Essentially, the </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">vertices</span><span style=" color:#000000;"> of an MFG are partitioned among the players, and a player that owns a vertex directs the flow that reaches it. Each player has a different target vertex, and the objective of each player is to maximize the flow that reaches her target vertex. We study the stability of </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">MFGs</span><span style=" color:#000000;"> and show that, unfortunately, an MFG need not have a Nash Equilibrium. Moreover, the Price of Anarchy and even the Price of Stability of </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">MFGs</span><span style=" color:#000000;"> are unbounded. That is, the reduction in the flow due to selfish behavior is unbounded. We also study the problem of deciding whether a given MFG has a Nash Equilibrium and show that it is </span><span style=" color:#008000;">$\Sigma_2^P$</span><span style=" color:#000000;">-complete, as well as the problem of finding optimal strategies for the players, which we show to be NP-complete. We continue with some good news and consider a variant of </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">MFGs</span><span style=" color:#000000;"> in which flow may be swallowed. For example, when routers in a communication network may drop messages.​ We show that, surprisingly, while this model seems to </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">incentivize</span><span style=" color:#000000;"> selfish behavior, a Nash Equilibrium that achieves the maximum flow always exists, and can be found in polynomial time. Finally, we consider </span><span style="text-decoration-line: underline; color: rgb(0, 0, 0);">MFGs</span><span style=" color:#000000;"> in which the strategies of the players may use non-integral flows, which we show to be stronger.</span><!--EndFragment--></pre>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-389" tabindex="-1" role="dialog"
         aria-labelledby="modal-389-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-389-label">[Abstract] Matching domain to top level ontologies for enhancing agent interoperability</h4>
                </div>
                <div class="modal-body">
                    <p>Ontologies play a fundamental role in Multi-Agent systems, formalizing the knowledge from the agent's perception of the world. Ontology matching is a primary problem that has to be solved in order to allow agents with different backgrounds to adjust themselves before starting any form of cooperation or communication. In this task, top-level ontologies provide a well-founded common understanding that can be shared across knowledge domains and that acts as semantic bridges helping the matching task. However, most domain ontologies are not equipped with alignments to top-level ontologies and automatically finding such alignments is an open problem in the field. In this paper, we propose a background knowledge-based ontology matching approach for automatically matching domain and top-level ontologies. We run our experiments on two agent domain ontologies (SSN and CORA) and two well-known top-level ontologies (DOLCE and SUMO). Our approach outperforms state-of-the-art matching systems in this task.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-98" tabindex="-1" role="dialog"
         aria-labelledby="modal-98-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-98-label">[Abstract] Hypersequential Argumentation Frameworks: An Instantiation in the Modal Logic S5</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper we introduce hypersequent-based frameworks for the modeling of defeasible reasoning by means of logic-based argumentation. These frameworks are an extension of sequent-based argumentation frameworks, in which arguments are represented not only by sequents, but by more general expressions, called hypersequents. This generalization allows to incorporate, as the deductive-base of our formalism, some well-studied logics like the modal logic S5, the relevance logic RM, and Gödel-Dummett logic LC, to which no cut-free sequent calculi are known. In this paper we take S5 as the core logic and show that the hypersequent-based argumentation frameworks that are obtained in this case yield a robust defeasible variant of S5 with several desirable properties.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-177" tabindex="-1" role="dialog"
         aria-labelledby="modal-177-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-177-label">[Abstract] Rapid Randomized Restarts for Multi-Agent Path Finding Solvers</h4>
                </div>
                <div class="modal-body">
                    <p>Multi-Agent Path Finding (MAPF) is an NP-hard problem well studied in artificial intelligence and robotics. It has many real-world applications for which existing MAPF solvers use various heuristics. However, these solvers are deterministic and perform poorly on ``hard'' instances which are typically characterized by many agents interfering with each other in a small region of space. In this paper, we enhance MAPF solvers with randomization and observe that they exhibit heavy-tailed distributions of runtimes on hard instances. This leads us to develop simple rapid randomized restart (RRR) strategies with the intuition that, given a hard instance, multiple short runs will have a better chance of solving it than one long run. We validate this intuition through experiments, showing that our RRR strategies indeed boost the performance of state-of-the-art MAPF solvers such as iECBS, M* and CBS-CL.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-502" tabindex="-1" role="dialog"
         aria-labelledby="modal-502-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-502-label">[Abstract] Distributed bottom-up bus regulation mechanism in urban traffic</h4>
                </div>
                <div class="modal-body">
                    <p>For several decades, urban congestion has caused various nuisances for the inhabitants of the cities. There are several responses to this problem, including traffic regulation and the development of public transport, which helps mitigate the negative effects. The problem with public transport is that it is sometimes not reliable in terms of arriving time, especially for buses since they depend on the traffic condition. Developments in technology over the last few decades have improved the level of vehicle equipment, making it possible to offer new answers to the problems related to this issue.</p><p>Vehicles are now able to communicate and coordinate, and recent approaches are taking advantage of these advances to solve research problems that may be related to different requirements such as safety, comfort, energy efficiency or the one we are interested in more particularly in the context of this paper, namely the punctuality of buses. We propose in this paper a distributed coordination mechanism allowing intersections to anticipate to provide a clear path for the bus, allowing it to reach the bus stops in time.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-194" tabindex="-1" role="dialog"
         aria-labelledby="modal-194-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-194-label">[Abstract] Modeling Normative Multi-Agent Systems from a Kelsenian Perspective</h4>
                </div>
                <div class="modal-body">
                    <p>Standard Deontic Logic (SDL) has been used as the underlying logic to model and reason over Multi-Agent Systems governed by norms (NorMAS). It is known that SDL is not able to represent contrary-to-duty (CTD) scenarios in a consistent way. That is the case, for example, of the so-called Chisholm paradox, which models a situation in which a conditional obligation that specifies what must be done when a primary obligation is violated holds. In SDL, the set of sentences that represent the Chisholm paradox derives inconsistent sentences. Due to the <i>autonomy </i>of the software agents of a NorMAS, norms may be violated and the underlying logic used to model the NorMAS should be able to represent <i>violation scenarios</i>. The contribution of this paper is threefold: (i) we present how Kelsenian thinking, from his jurisprudence in the context of legal ontologies, and Intuitionist Hybrid Logic can be adopted in the modeling of NorMAS, (ii) discuss how this approach overcomes limitations of the SDL and (iii) present a discussion about normative conflict identification according to Hill's functional taxonomy, that generalizes from standard identification by impossibility-of-joint-compliance test.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-316" tabindex="-1" role="dialog"
         aria-labelledby="modal-316-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-316-label">[Abstract] Peer Prediction with Heterogeneous Tasks</h4>
                </div>
                <div class="modal-body">
                    <p>Peer prediction promotes contributions of useful information
by users in settings in which there is no way to verify the quality
of responses. This paper introduces the problem of peer
prediction with heterogeneous tasks, where each task is associated
with a different distribution on responses. The motivation
comes from eliciting user-generated content about places
in a city, where tasks vary because places and questions about
places vary. We extend the correlated agreement (CA) mechanism
((Shnayder et al. 2016a)) to this setting, aligning incentives
for investing effort without creating opportunities for coordinated
manipulations. We demonstrate in simulation much
better incentive properties than other mechanisms, using data
from user reports on a crowdsourcing platform.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-357" tabindex="-1" role="dialog"
         aria-labelledby="modal-357-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-357-label">[Abstract] A Robust Method for Inferring User Intention in a Dynamic Environment using Gaze</h4>
                </div>
                <div class="modal-body">
                    <p>The ability of an autonomous system to understand something about a human's intent is important to the success of many systems that involve both humans and autonomous agents. In this work, we consider the specific setting of a human passenger riding in an autonomous vehicle, where the passenger intends to go to or learn about a specific point of interest along the vehicle's route. In this setting, we seek to provide the vehicle with the ability to infer this point of interest using real-time gaze information. This is a difficult problem in that the inference must be designed in the context of the moving vehicle, i.e., in a dynamic environment with dynamic interest points. We propose here a solution to this problem via a novel methodology called Dynamic Interest Point Detection (DIPD) for inferring the point of interest corresponding to the human's intent using gaze tracking data and a dynamic Markov Random Field (MRF) model. The energy function we develop allows the algorithm to successfully filter out noise from the eye tracker, such as eye blinks, high-speed tracking misalignment, and other sources of error. We demonstrate the success of our DIPD technique experimentally, and show improvement over both nearest-neighbor and filtered-nearest-neighbor approaches.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-44" tabindex="-1" role="dialog"
         aria-labelledby="modal-44-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-44-label">[Abstract] Protecting Election from Bribery: New Approach and Computational Complexity Characterization</h4>
                </div>
                <div class="modal-body">
                    <p>Protecting election from bribery is an important problem that has received considerable attention, including many algorithmic and complexity results. In this paper, we initiate the study of a new approach to protecting election from bribery. The basic idea underlying the new approach is to "award some voters" for their honesty (i.e., an awarded voter cannot be bribed by the attacker). This approach naturally leads to the following bi-level decision problem: Is it possible for the defender with a given award budget to protect a proper subset of the voters such that no attacker with a fixed budget for bribing can manipulate the election? We give the first systematic characterization on the computational complexity of this "protection problem". Compared with many other studies in the field of voting systems, the computation complexity of our protection problem is, in general, very high. For example, the problem is $\Sigma_2^p$-complete even for very restricted special cases, in contrast to the NP-completeness of most problems studied before. Nevertheless, we characterize the parameter settings in which the protection problem is in P, NP or $\Sigma_2^p$, which can be used to guide the design and analysis of real-world elections.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-573" tabindex="-1" role="dialog"
         aria-labelledby="modal-573-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-573-label">[Abstract] CrowdEval: A Cost-Efficient Strategy to Evaluate Crowdsourced Workers’ Reliability</h4>
                </div>
                <div class="modal-body">
                    <p>Crowdsourcing platforms depend on the quality of work provided by a distributed workforce. Yet, it is challenging to dependably measure the reliability of these workers, particularly in the face of strategic or malicious behavior. In this paper, we present a dynamic and efficient solution to keep tracking workers’ reliability. In particular, we use both gold standard evaluation and peer consistency evaluation to measure each worker performance, and adjust the proportion of the two types of evaluation according to the estimated distribution of workers’ behavior (e.g., being reliable or malicious). Through experiments over real Amazon Mechanical Turk traces, we find that our approach has a significant gain in terms of accuracy and cost compared to state-of-the-art algorithms.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-163" tabindex="-1" role="dialog"
         aria-labelledby="modal-163-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-163-label">[Abstract] Personalized Peer Truth Serum for Crowdsourcing Multi-Attribute Personal Data</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>Recently, peer consistency based schemes have been proposed that incentivize crowd for investing effort and answering honestly. Such game theoretic schemes require that a group of peer agents evaluate a common object (such as an image) and report the labels independently. The reward is calculated based on statistical match in the reports provided by different agents.</p><p>In this paper, we formulate the problem of eliciting multi-attribute personal data from a crowd. Personal attributes of individuals are important in personalization algorithms and in other studies but are difficult to obtain. With attributes being personal in nature, there are no obvious peers in this case. We show how to extend an incentive scheme, the Peer Truth Serum, to settings where participants report combinations of individual data, by exploiting coherence of the different data items with what is reported by others. This new scheme applies, for example, to collecting personal health records or other multi-attribute measurements about personal properties such as smart homes. We provide a theoretical analysis of the incentive properties of the new scheme and show the performance of the scheme on several public datasets involving personal data, which further confirms the theoretical analysis.</p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-42" tabindex="-1" role="dialog"
         aria-labelledby="modal-42-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-42-label">[Abstract] A Ranking Semantics based on Subgraphs Analysis</h4>
                </div>
                <div class="modal-body">
                    <p style="margin-bottom: 0px;">In this paper we first propose a measure of the sensitivity of an argument in an abstract argumentation framework. The index is an indicator of how sensitive is the label assigned to the argument by an argumentation semantics. This numerical indicator is derived from the topology of the graph via a subgraphs analysis, coupled with the postulates of the chosen semantics. </p><p style="margin-bottom: 0px;">Using the total rank on arguments induced by such indicator, we propose two ranking-based semantics. We compare the behaviour of our ranking-semantics with recent proposals and a widespread set of properties identified in literature.</p><p style="margin-bottom: 0px;">A key feature of the semantics is that the attack relation between arguments keeps the same meaning as found in Dung' abstract semantics.</p><p>


</p><p style="margin-bottom: 0px;">By still relying on Dung' semantics we can soundly deal with any graph configuration, produce justified results, minimize the addition of ad-hoc postulates and provide a clear interpretation of the ranking of arguments.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-50" tabindex="-1" role="dialog"
         aria-labelledby="modal-50-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-50-label">[Abstract] Multilevel Holonification Model : Application to Road Traffic Simulation</h4>
                </div>
                <div class="modal-body">
                    <p>Organizational models and holonic multi-agent systems are growing as a powerful tool for modeling and developing large-scale complex system.&nbsp; The main issue in deploying holonic multiagent systems is the&nbsp; building of the holonic model called holarchy. This paper presents a novel density approach to cluster and hierarchize population in order to build the holarchy. The proposal extends DBSCAN algorithm. Moreover,&nbsp; multilevel indicators based on standard deviation&nbsp; are proposed in order to evaluate the consistency of the holonification process. The proposed model is&nbsp; tested in a road traffic modeling.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-625" tabindex="-1" role="dialog"
         aria-labelledby="modal-625-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-625-label">[Abstract] Database Aggregation</h4>
                </div>
                <div class="modal-body">
                    <p>Knowledge can be represented compactly in a multitude ways, from a set 
of propositional formulas, to a Kripke model, to a database. In this 
paper we study the aggregation of information coming from multiple 
sources, each source submitting a database modelled as a first-order 
relational structure. In the presence of an integrity constraint, we 
identify classes of aggregators that respect it in the aggregated 
database, provided all individual databases satisfy it. We also 
characterise languages for first-order queries on which the answer to 
queries on the aggregated database coincides with the aggregation of the
 answers to the query obtained on each individual database. This 
contribution is meant to be a first step on the application of 
techniques from rational choice theory to knowledge representation in databases.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-450" tabindex="-1" role="dialog"
         aria-labelledby="modal-450-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-450-label">[Abstract] Combine Abstract Algorithm and Midgame solving to Bulid Stronger Poker AI</h4>
                </div>
                <div class="modal-body">
                    Poker has been an ongoing challenge in artificial intelligence
for long time. The traditional approach for solving no-limit
poker is that first use abstract algorithm to produce an smaller
abstract game for the original game and then use
Counterfactual regret minimization to compute an Nash equilibrium
of the abstract game, finally map abstracted game
Nash equilibrium to the original game. But using action abstraction
causes the off-tree poblem that is part of reasons
why computer program Claudico lost to a team of top poker
players. Very recent work uses the midgame solving to
relieve this problem. Before the Midgame, we use the abstract
algorithm and CFR to produce precomputed strategies.
The midgame solver is produce the strategies in real time.
Midgame solve each round independently but needs hand
ranges of players including opponents as input. The previous
work assumes each hand of opponents has the same probability
or use the strategy of itself to compute the hand ranges
of opponents which is unreasonable. So in this paper, we
present an data-based model to predit the opponents’ range
while solving the Midgame, and we also use the modified
Effective hand strength to evaluate more exact payoff for
the Midgame than before. Finally, we make a change to the
Midgame solving that we always solve a midgame to product
a strategy for a new state every time it is our turn to take
actions while playing different from the previous work. Utilizing
our approaches we produce an stronger agent for no-limit
Texas Hold’em and win 3th in 2017 Annual Computer Poker
Competition .
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-535" tabindex="-1" role="dialog"
         aria-labelledby="modal-535-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-535-label">[Abstract] An FPTAS for Computing Nash Equilibrium in Resource Graph Games, with Applications to Security Games, Congestion Games, and Bilinear Games</h4>
                </div>
                <div class="modal-body">
                    <div style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: small;">We consider the computational complexity of computing a mixed-strategy Nash equilibrium (MSNE)&nbsp; in resource graph games (<g class="gr_ gr_12 gr-alert gr_spell gr_inline_cards gr_run_anim ContextualSpelling ins-del multiReplace" id="12" data-gr-id="12" style="display: inline; color: inherit !important; font-size: inherit !important; border-bottom: 2px solid transparent; background-repeat: no-repeat; background-position: -1px calc(100% + 3px); background-image: url(&quot;data:image/svg+xml;charset=utf8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='100%' height='100%'%3E%3Cline opacity='0.75' x1='4' y1='100%' x2='100%' y2='100%' transform='translate(-1.5, -2.5)' stroke-width='3' stroke-linecap='round' stroke='%23fc5454'/%3E%3C/svg%3E&quot;); background-size: calc(100% + 1px) 100%; animation: gr__appear_critical 0.4s ease forwards;">RGGs</g>), a compact representation for games with an exponential number of strategies. In an RGG, there are m resources and a directed graph of the resources, and each player's pure strategy set consists of subsets of resources. Each player's pure strategy is represented by a binary vector, and the pure strategy set is represented compactly using a rational polytope defined by a set of linear inequality constraints. Given the pure strategies of the players, each player's utility depends on the directed resource graph&nbsp;and the numbers of times the neighboring resources are used.&nbsp;</div><div style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: small;"><br></div><div style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: small;">In this paper, we provide the first FPTAS for computing an MSNE in any symmetric multilinear RGG&nbsp;</div><div style="color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: small;">where its constraint moralized resource graph (a graph formed between the moralized resource graph&nbsp;and the constraints defining the strategy polytope) has bounded treewidth. Our FPTAS can be generalized to a constant number of player types. As a consequence, our FPTAS provides the first and improved approximation results for domain-specific games such as general multiple-attack single-attacker and single-defender security&nbsp;games and congestion games, respectively. Finally, leveraging the RGG representation and our FPTAS result, we obtain an FPTAS to compute an MSNE for a large class of bilinear games.</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-319" tabindex="-1" role="dialog"
         aria-labelledby="modal-319-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-319-label">[Abstract] Automatic Generation of Multi-Agent Programs from Ontology Models</h4>
                </div>
                <div class="modal-body">
                    <p>This paper presents our proposal for the development of multi-agent systems designed as ontology models supporting code generation. The foundation of such work takes into consideration ontologies for agent-oriented software engineering aligned with the JaCaMo framework. These techniques are implemented in a tool that supports multi-agent systems core code generation for JaCaMo. The underlying ontology also allows for reasoning about the multi-agent systems models under development. Such comprehensive approach therefore spans through the modelling, programming, and verification of agent-oriented software.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-771" tabindex="-1" role="dialog"
         aria-labelledby="modal-771-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-771-label">[Abstract] Cost-Free Advertising for Selling Multiple Items in Social Networks</h4>
                </div>
                <div class="modal-body">
                    <p>
</p><pre style="margin-bottom: 0px;"><pre style="margin-bottom: 0px;"><span style=" color:#000000;">We consider a market where a seller sells multiple units of a commodity in a social network. Each node/buyer in the social network can only directly communicate with her neighbours, i.e. the seller can only directly sell the commodity to her neighbours without any advertising. In this paper, we design a cost-free advertising mechanism that </span><span style=" text-decoration: underline; color:#000000;">incentivizes</span><span style=" color:#000000;"> all buyers, who are aware of the sale, to invite all their neighbours to join the sale, even though there is no guarantee that their effort will be paid. While traditional prepaid sale promotions such as sponsored search auction cannot guarantee a positive return for the advertisers, our mechanism guarantees that the seller's revenue is greatly improved compared with </span><span style=" text-decoration: underline; color:#000000;">VCG</span><span style=" color:#000000;"> without advertising, and the seller does not need to pay if the advertising is not beneficial to the seller. </span><!--EndFragment--></pre><!--EndFragment--></pre>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-399" tabindex="-1" role="dialog"
         aria-labelledby="modal-399-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-399-label">[Abstract] Mitigating the Curse of Correlation in Security Games by Entropy Maximization</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">In Stackelberg security games, a defender seeks to randomly allocate limited security resources to protect critical targets from an
attack. In this paper, we study a fundamental, yet underexplored,
phenomenon in security games, which we term the </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineTI'">Curse of Correlation </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">(CoC). Specifically, we observe that there are </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineTI'">inevitable
</span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">correlations among the protection status of different targets. Such
correlation is a crucial concern, especially in </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineTI'">spatio-temporal </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">domains like conservation area patrolling, where attackers can surveil
patrollers at certain areas and then infer their patrolling routes
using such correlations. To mitigate this issue, we propose to design entropy-maximizing defending strategies for spatio-temporal
security games, which frequently suffer from CoC. We prove that
the problem is #P-hard in general. However, it admits efficient algorithms in well-motivated special settings. Our experiments show
significant advantages of max-entropy algorithms over previous
algorithms. A scalable implementation of our algorithm is currently
under pre-deployment testing for integration into FAMS software
to improve the scheduling of US federal air marshals.&nbsp;</span></p>
				</div>
			</div>
		</div>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-247" tabindex="-1" role="dialog"
         aria-labelledby="modal-247-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-247-label">[Abstract] A Prioritized Routing Agent for Flow of Traffic</h4>
                </div>
                <div class="modal-body">
                    <p>Traffic management during emergency evacuation presents an important set of challenges as compared to regular traffic management. We focus here on one particular challenge, namely prioritized routing. Prioritized routing may happen even during normal times, but it becomes even more important during emergencies, as emergency vehicles, police vehicles and large vehicles (such as buses) that carry a lot of people need to have a higher priority in terms of evacuation. It is also reasonable to assume that traffic police may need to perform a centralized control of traffic, since they typically have a global view of the emergency and have accurate real-time updates. The Ford-Fulkerson and other known algorithms which perform an efficient centralized planning of routes for evacuation in different conditions, do not handle this issue of prioritized routing. Hence, we focus on this problem and make the following contributions in this paper: (a) First, we develop an agent called Prioritized Routing Agent for Flow of Traffic (PRAFT) that can encode the notion of priority for vehicles as well as priority of routes for helping the traffic police perform a prioritized routing, while computing the maximum flow solution. Uniform Cost Search (UCS) is used as a key step in this procedure. (b) Through a series of experiments performed using the well-known traffic simulator SUMO, we establish that our solution maps higher priority vehicles to better quality routes and is monotonic in the sense that decreasing priority order of vehicles maps to a decreasing route quality.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-477" tabindex="-1" role="dialog"
         aria-labelledby="modal-477-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-477-label">[Abstract] Compact Preference Representation via Fuzzy Constraints in Stable Matching Problems: theoretical and experimental studies</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>The stable matching problem has many practical applications in two-sided markets, like those that assign doctors to hospitals or students to schools. Usually it is assumed that all agents in each side explicitly express a preference ordering over all those in the other side. This can be unfeasible and impractical when the set of agents is very big. However, usually this set has a combinatorial structure, since each agent is often described by some features. To tackle these scenarios, we define a framework for stable matching problems where agents are allowed to express their preferences over those of the other group in a compact way, via soft constraints over the features describing these agents. We focus on a special kind of soft constraints, namely fuzzy constraints. We provide a solving engine for this new kind of stable matching problems that does not increase the time complexity of the classical GS algorithm, while maintaining stability of the matching returned. We then evaluate the approach experimentally.<br></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-379" tabindex="-1" role="dialog"
         aria-labelledby="modal-379-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-379-label">[Abstract] Multi-armed bandit algorithms for  crowdsourcing systems with  online estimation of  workers&#39; ability</h4>
                </div>
                <div class="modal-body">
                    <p>Crowdsourcing systems have become a valuable solution for various organizations to outsource work on a temporary basis. &nbsp;Quality assurance in these systems remains a key issue due to the distributed setup of the crowdsourcing platforms and the absence of a priori information about the workers. Our work proposes a notion of Limited-information Crowdsourcing Systems (LCS), where the task master can assign the work &nbsp; based on some &nbsp;knowledge of the workers' ability acquired &nbsp; &nbsp;over time. The key challenges in this new setup are determining an efficient workers' selection policy and estimating the abilities of the workers. For the former challenge, we reduce the problem to an arm-limited, budget limited, multi-armed bandit (MAB) set-up and use the simplified bounded KUBE (B-KUBE) algorithm &nbsp;of \cite{tran2014efficient} &nbsp;as a solution. This algorithm has previously &nbsp;only been experimentally evaluated, and we provide provable performance guarantees, showing that it is order optimal. This work closes the gap in the literature of budget limited arm limited MAB by proving that expected regret of B-KUBE is $O(\log(B))$ where $B$ is the total budget of the task master. The latter challenge is solved by &nbsp;formalizing the notion of workers' ability mathematically, and proposing a strategy for the estimation of the workers' &nbsp;ability. Later, we experimentally evaluate B-KUBE in conjunction with this &nbsp;strategy, showing that it outperforms other state-of- the-art MAB algorithms when applied in the same setting.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-187" tabindex="-1" role="dialog"
         aria-labelledby="modal-187-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-187-label">[Abstract] Characterization of group behavior in crowd simulations using complex event processing</h4>
                </div>
                <div class="modal-body">
                    <p>Frequently, researchers in social sciences look for experiments where interacting individuals are expected to show some kind of emergent behavior. The multi-agent based simulation approach is relevant for conceiving such experiments, but, currently, there is a lack of conceptual tools to manage and validate the outcome of the simulation. Most works refer to particular variables, such as the ratio of evacuated people per minute or how much time it takes to empty a building. However, these variable means little if the behavior of the individuals is too much artificial. Researchers have proposed different means, most of them based on visual inspection by human users, but it is not an efficient solution if hours of simulations have to be reviewed. To address this issue, the recent advances and tools for Complex Event Processing provides new insights that are worth being studied. This paper uses this approach to computationally identify patterns of expected behavior of agents in a multi-agent based simulation and provide quantitative assessment of the behavior beyond individual and isolated variables. The contribution focuses precisely in the challenges associated to identifying group behaviors and other individual non-desirable traits, such as characters walking in perfectly straight unnatural lines. This work could be taken further to determine which behavior is the most intelligent, given a particular simulation. This permits too for a more serious testing and evaluation of the simulations, where not only the final outcome is important, but how one reaches such outcome too.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-30" tabindex="-1" role="dialog"
         aria-labelledby="modal-30-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-30-label">[Abstract] Why Bad Coffee? Explaining BDI Agent Behaviour with Valuings</h4>
                </div>
                <div class="modal-body">
                    <p>An important issue in deploying an autonomous system is how to enable human users and stakeholders to develop an appropriate level of trust in the system. It has been argued that a crucial mechanism to enable appropriate trust is the ability of a system to explain its behaviour. Obviously, such explanations need to be comprehensible to humans. We argue that it makes sense to build on the results of extensive research in social sciences that explores how humans explain their behaviour. Using similar concepts for explanation is argued to help with comprehensibility, since the concepts are familiar. Following work in the social sciences, we propose the use of a folk-psychological model that utilises beliefs, desires, and "valuings". We propose a formal framework for constructing explanations of the behaviour of an autonomous system, present an (implemented) algorithm for giving explanations, and present evaluation results.&nbsp;</p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-519" tabindex="-1" role="dialog"
         aria-labelledby="modal-519-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-519-label">[Abstract] Multi-agent Negotiation and Coordination Mechanisms to Manage User Satisfaction for SaaS</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal"><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>FR</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>AR-SA</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="true"
  DefSemiHidden="true" DefQFormat="false" DefPriority="99"
  LatentStyleCount="267">
  <w:LsdException Locked="false" Priority="0" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="59" SemiHidden="false"
   UnhideWhenUsed="false" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" QFormat="true" Name="TOC Heading"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Tableau Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin-top:0cm;
	mso-para-margin-right:0cm;
	mso-para-margin-bottom:10.0pt;
	mso-para-margin-left:0cm;
	line-height:115%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-fareast-language:EN-US;}
</style>
<![endif]-->

<span style="mso-ansi-language:EN-US" lang="EN-US">With the
rapid growth of personal and interactive applications on the cloud, end-user
satisfaction is becoming a key factor to ensure the prosperity of any Software
as a Service (SaaS). Elasticity management has been defined as a process
whereby the SaaS provider seeks to minimize the cost it pays to the cloud
provider while providing a satisfactory service to its users. Multi-agent
systems have been proposed as a platform to integrate the end-user satisfaction
into elasticity management. However, existing works rely on a binary vision of
end-user satisfaction. Recently, this vision has received growing criticism
from the theoretical and empirical research on Quality of Experience (QoE)
where it has been shown that the user's subjective satisfaction is a degree. In
the context of a multi-agent negotiation framework, this article proposes a
mechanism enabling the SaaS provider to undertake satisfaction management: <span style="mso-spacerun:yes">&nbsp;</span>to meet fine-grained user satisfaction goals
while still minimizing the cost paid to the cloud provider. This problem is
formulated as an optimization problem, for which a linear model is proposed.
For reference, a generic linear program solver is used to find the optimal
solution. An alternative heuristic algorithm is also devised in order to
improve responsiveness when the system has to scale up with fast growing number
of users. Both are implemented and their results are compared and analyzed.</span></p><p>

<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-128" tabindex="-1" role="dialog"
         aria-labelledby="modal-128-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-128-label">[Abstract] Gerrymandering Over Graphs</h4>
                </div>
                <div class="modal-body">
                    <p>In many real-life scenarios, voting problems consist of several phases: an overall set of voters is partitioned into subgroups, each subgroup chooses a preferred candidate, and the final winner is selected from among those candidates. The attempt to skew the outcome of such a voting system through strategic partitioning of the overall set of voters into subgroups is known as ``gerrymandering''. We investigate the problem of gerrymandering over a network structure; the voters are embedded in a social network, and the task is to divide the network into connected components such that a target candidate will win in a plurality of the components. We first show that the problem is NP-complete in the worst case. We then perform a series of simulations, using random graph models incorporating a homophily factor. In these simulations we show that a simple greedy algorithm can be quite successful in finding a partition in favor of a specific candidate.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-248" tabindex="-1" role="dialog"
         aria-labelledby="modal-248-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-248-label">[Abstract] Efficient Reciprocal Collision Avoidance between Heterogeneous Agents Using CTMAT</h4>
                </div>
                <div class="modal-body">
                    <p>We present a novel algorithm for reciprocal collision avoidance between heterogeneous agents of different shapes and sizes. We present a novel CTMAT representation based on medial axis transform to compute a tight fitting bounding shape for each agent. Each CTMAT is represented using tuples, which are composed of circular arcs and line segments. Based on the reciprocal velocity obstacle formulation, we reduce the problem to solving a low-dimensional linear programming between each pair of tuples belonging to adjacent agents. We precompute the Minkowski Sums of tuples to accelerate the runtime performance. Finally, we provide an efficient method to update the orientation of each agent in a local manner. We have implemented the algorithm and highlight its performance on benchmarks corresponding to road traffic scenarios and different vehicles. The overall runtime performance is comparable to prior multi-agent collision avoidance algorithms that use circular or elliptical agents. Our approach is less conservative and results in fewer false collisions.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-471" tabindex="-1" role="dialog"
         aria-labelledby="modal-471-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-471-label">[Abstract] Revenue Maximization for Electric Vehicle Charging Service Providers using Sequential Dynamic Pricing</h4>
                </div>
                <div class="modal-body">
                    With the rising penetration of electric vehicles (EVs), the provision of EV charging is becoming a standard commercial service. With this shift, EV charging service providers are looking for ways to make their business more profitable. Dynamic pricing is a proven technique to increase revenue in markets with time-variant, heterogeneous demand. In this paper, we propose a Markov Decision Process (MDP)-based approach to revenue-maximizing dynamic pricing for charging service providers. We implement the approach using an ensemble of policy iteration MDP solvers and evaluate it using a simulation based on real-world data. We show that our proposed method achieves significantly higher revenue than methods utilizing flat-based pricing. In addition to achieving higher revenue for charging service providers, the method also increases the efficiency of allocation measured in terms of the total utilization of the charging station.
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-664" tabindex="-1" role="dialog"
         aria-labelledby="modal-664-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-664-label">[Abstract] Super Altruistic Hedonic Games</h4>
                </div>
                <div class="modal-body">
                    <p>Hedonic games are coalition formation games in which agents’ utility depends only on their own coalition. However, the introduction of Altruistic Hedonic Games expanded the focus by considering the utility of agents’ friends within the coalition. We introduce Super Altruistic Hedonic Games, in which an agent’s utility may depend on the utility of all other agents in the coalition, weighted according to distance in the friendship graph. We establish the framework for this new model and investigate the complexity of multiple notions of stability.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-54" tabindex="-1" role="dialog"
         aria-labelledby="modal-54-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-54-label">[Abstract] On the Role of Abstract Argumentation in Belief Modelling</h4>
                </div>
                <div class="modal-body">
                    <p>The paper proposes a belief model based on abstract argumentation semantics and its probabilistic extensions. The model has been defined taking Smets’ TBM as the main reference, with further references to the original DS theory and the Bayesian update. The model represents possible worlds and evidence as defeasible propositions connected by a relation of attack. Degrees of believes are quantifying by evaluating abstract grounded semantics. When a decision-making is needed, a probability distribution over possible worlds is generated by computing the preferred semantics and applying the indifferent reason principle, in analogy with the pignisitc transformation of the TBM. We compare the behaviour of the model with TBM, DS and the Bayesian update in well-known critical situations, such as total ignorance, the so-called “Mr. Jones case”, Zadeh’s critical examples on combining highly conflicting belief. By relying on argumentation semantics, the model allows for a definition of complex relations among evidence, it is easily expandable with new evidence and it provides an undec label to deal with conflicting evidence in a more coherent and principled&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-58" tabindex="-1" role="dialog"
         aria-labelledby="modal-58-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-58-label">[Abstract] Corrupted Contextual Bandits</h4>
                </div>
                <div class="modal-body">
                    <p>We consider a novel variant of the contextual bandit problem (i.e., the multi-armed bandit with side-information, or context, available to a decision-maker) where the context used at each decision may be Corrupted (”Corrupted Context”). This new problem is motivated by certain on-line settings including clinical trial and ad recommendation applications. In order to address the Corrupted-context setting, we propose to combine the standard contextual bandit approach with a classical multi-armed bandit mechanism. Unlike standard contextual bandit methods, we are able to learn from all iteration, even those with corrupted context, by improving the expectation on the different arms. Promising empirical results are obtained on several real-life datasets.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-458" tabindex="-1" role="dialog"
         aria-labelledby="modal-458-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-458-label">[Abstract] On the Frequency of Decision Making in On-line Temporal Difference Learning</h4>
                </div>
                <div class="modal-body">
                    <p>The growth of Artificial Intelligence has been boosted by progress in allied fields such as computer architecture&nbsp; and communication engineering. An interesting fallout of the resulting technological acceleration is a notable increase in the \textit{frequency} with which agents can make decisions. It seems intuitive that a higher frequency of decision making will improve an agent's performance. We investigate if this intuition remains correct even if the agent's behaviour is to be \textit{learned} from experience. We anchor our study in the Sarsa family of algorithms for on-line Temporal Difference (TD) learning. On a deliberately-designed grid-world domain, and also the well-known Acrobot test bed, we find evidence in favour of performing decision making at a \textit{lower} frequency than maximum. We attribute this result to the use of function approximation, which is inevitable in&nbsp; most practical tasks. Interestingly, ``slowing down'' the standard Sarsa($\lambda$) algorithm also enables us to learn a competitive \textit{defense} strategy in the more complex Half Field Offense task. To the best of our knowledge, this is the first successful application of an on-line TD learning method to this task. At the heart of our contribution is a single ``decision interval'' parameter ``$d$'' to Sarsa, which we find significantly more effective in high-frequency settings than ``$n$'' and ``$\lambda$'', the usual parameters to control bootstrapping. In our experiments, we also demonstrate that $d$ can be tuned effectively by using the EXP3 algorithm.</p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-62" tabindex="-1" role="dialog"
         aria-labelledby="modal-62-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-62-label">[Abstract] Dealing with multiple intentions of cooperative ambient agents</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal">This paper presents a cooperative approach to deal with multiple intentions for a specific type of intelligent agents that interact with Ambient Intelligent environments, denominated ambient agent (AA). Since the environment provides contextual information subject to dynamic changes, it is desirable for the reasoning process used by an AA to be as adaptive and efficient as possible. At the same time, the AA must still achieve its goals. In order to address the planning adaptability, a formal context-based planning mechanism called Contextual Planning System (CPS) can be used to provide contextual guidance to an AA. The CPS proposes an optimal plan based on the current context that satisfies multiple intentions of the agent while preserving their consistency. It is, however, designed for a single agent. Different scenarios may require a cooperative approach, where AAs can be able to cooperate among themselves while achieving their individual goals. In these scenarios, benevolence cannot be assumed, and cooperation will be dependent on each of the agent's own intentions. We propose a mechanism denominated Collective CPS (CCPS) that allows an AA to partially delegate its own plans to other agents, or to collaborate with other agents' plans during their execution, while still using the CPS for its individual planning. An implementation of a working scenario for a simple and realistic Ambient Intelligence (AmI) environment is also discussed.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-284" tabindex="-1" role="dialog"
         aria-labelledby="modal-284-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-284-label">[Abstract] Prioritized Sequent-Based Argumentation</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper we integrate priorities in sequent-based argumentation. The former is a useful and extensively investigated tool in the context of non-monotonic reasoning, and the latter is a modular and general way of handling logical argumentation. Their combination offers a platform for representing and reasoning with maximally consistent subsets of prioritized knowledge bases. Moreover, many frameworks of the resulting formalisms satisfy common rationality postulates and other desirable properties, like conflict preservation.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-257" tabindex="-1" role="dialog"
         aria-labelledby="modal-257-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-257-label">[Abstract] Agents Interoperability via Conformance Modulo Mapping</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>In this work we present an algorithm for establishing a flexible conformance relation between two local agent interaction protocols (LAIPs) based on mappings involving agents and messages, respectively.&nbsp;</p><p>Conformance is in fact computed "modulo mapping": two LAIPs tau &nbsp;and tau' may involve different agents and use different syntax for messages, but may still be found to be conformant provided that a given map from entities appearing in tau to corresponding entities in tau' is applied. Also, LAIPs are modelled as trace expressions whose high expressive power allows for the design of protocols that could not be specified using finite state automata or equivalent formalisms. This expressive power makes the problem of stating if tau conforms to tau' undecidable. We cope with this problem by over-approximating trace expressions that may lead to infinite computations, obtaining a sound but not complete implementation of the proposed conformance check.&nbsp;</p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-278" tabindex="-1" role="dialog"
         aria-labelledby="modal-278-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-278-label">[Abstract] Learning Optimal Redistribution Mechanisms Through Neural Networks</h4>
                </div>
                <div class="modal-body">
                    <p>We consider a social setting where $p$ public resources/objects are to be allocated among $n$ competing and strategic agents so as to maximize social welfare (the objects should be allocated to those who value them the most). This is called allocative efficiency (AE). We need the agents to report their valuations&nbsp; for obtaining these resources, truthfully. This is called dominant strategy incentive compatibility (DSIC). Typically, we use auction based mechanisms to achieve AE and DSIC. However, due to Green-Laffont Impossibility Theorem, we cannot ensure budget balance in the system while ensuring AE and DSIC. That is, the net transfer of money cannot be zero. This problem has been addressed by designing a redistribution mechanism so as to ensure minimum surplus of money as well as AE and DSIC. The objective could be to minimize surplus in expectation or in worst case and these objects could be homogeneous or heterogeneous. The designing of such mechanisms is non-trivial and especially designing redistribution mechanisms which perform well in expectation becomes analytically challenging for heterogeneous settings.&nbsp;</p><p><br></p><p>In this paper, we take a completely different, data-driven approach. We train a neural network to determine an optimal redistribution mechanism based on given settings with both the objectives,&nbsp; optimal in expectation and optimal in worst case. We also propose a loss function to train neural network to optimize worst case. We design&nbsp; neural networks with underlying rebate functions to be linear as well as nonlinear in terms of bids of the agents. Our networks achieve the theoretical guarantees for the cases where it has been solved. We observe that a neural network based redistribution mechanism for homogeneous settings which uses nonlinear rebate functions, outperforms linear rebate functions when the objective is optimal in expectation. Our approach also yields an optimal in expectation redistribution mechanism for heterogeneous settings.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-114" tabindex="-1" role="dialog"
         aria-labelledby="modal-114-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-114-label">[Abstract] On Testing Preferential Domains by Sampling</h4>
                </div>
                <div class="modal-body">
                    <p>A preferential domain is a collection of sets of linear orders (called preferences) over a set of alternatives. It forms a core area of research in social choice theory due to both its practical importance and theoretical elegance. Example of some extensively studied preferential domains includes single peaked, single crossing, Euclidean, etc. In this paper, we study sample complexity of testing whether a given preference profile is close to some specific domain or far from the domain. We consider various notion of closeness, for example, deletion of alternatives, deletion of preferences, and simultaneous deletion of alternatives as well as preferences. We further explore the effect of assuming the deleted preferences to be random (instead of arbitrary) on the sample complexity of the testing problem. In most cases, we show that the above testing problem can be solved with high probability for all domains by observing a small (independent of the number n of preferences) number of samples. In the remaining few cases, we prove either impossibility results or Omega(n) lower bound on the sample complexity.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-355" tabindex="-1" role="dialog"
         aria-labelledby="modal-355-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-355-label">[Abstract] Self-Organizing Maps for Storage and Transfer of Knowledge in Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p>The idea of reusing or transferring information from previously learned tasks (source tasks) for the learning of new tasks (target tasks) has the potential to significantly improve the sample efficiency of a reinforcement learning agent. In this work, we describe an approach to reuse previously acquired knowledge by using it to guide the exploration of an agent while it learns new tasks. In order to do so, we use a measure of similarity that is defined directly in the space of the value function weight vectors. This similarity measure is also used as a basis for a&nbsp;variant of the growing self-organizing map algorithm, which is simultaneously used to enable the efficient storage of previously acquired task knowledge in an adaptive and scalable manner. We empirically validate our approach in a simulated navigation environment, and also demonstrate its utility through simple experiments using a mobile micro-robotics platform. Further, we discuss some of the possible improvements and extensions to this approach, as well as some potential applications where it could be particularly useful.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-579" tabindex="-1" role="dialog"
         aria-labelledby="modal-579-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-579-label">[Abstract] Inferring Commitment Semantics in Multi-Agent Interactions</h4>
                </div>
                <div class="modal-body">
                    <p>Commitments are a useful abstraction to specify the social semantics of multi-agent communication languages. To use them in open and heterogeneous systems, it is necessary to develop solutions to the problem of interoperability, an effort that has already provided methods to, for example, align commitments between interlocutors. In this paper we consider the problem of commitment semantics inference, which can be summarized as follows: how can an agent that arrives to a community with an established language discover its social semantics, only by observing interactions? We introduce a method based on simple learning techniques that tackles this problem. We show that the basic commitment semantics is not possible to infer, and discuss different ways of enriching it that make inference feasible. We show experimentally how our technique performs for each of these extensions. To the best of our knowledge, that is the first approach that tackles the problem of inferring commitment semantics.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-640" tabindex="-1" role="dialog"
         aria-labelledby="modal-640-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-640-label">[Abstract] Handling Disagreement in Ontologies-based Reasoning via Argumentation</h4>
                </div>
                <div class="modal-body">
                    <p>

	
		
		
	
	
		<br></p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">Ontologies play an important role in agent inter-communication via
providing formal definitions of the vocabularies used by agents to
describe their knowledge about the world. However, in practice, it
is often hard to have a confliction free ontology shared by differ-
ent agents, where disagreement occurs. Moreover, the information
from each agent can be uncertain due to her modeling choice or the
lack of confidence for a piece of ontological information. In this
paper, we present a </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'; font-style: italic">general </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">approach that makes use of argumen-
tation theory to deal with imperfect ontologies. It has the merits
that all inconsistency, incoherence and uncertainty can be handled
in a unified framework. Our approach spreads uncertainty degrees
throughout argumentation trees, where each argument is associated
with a label reflecting its justification status. We present different
labelling methods by taking account the structure of agents. The
enriched argument structure leads us to several interesting inference relations from imperfect ontological information. We further
present the properties of these inference relations and their relation-ships with other well-known inference ones.
</span></p>
				</div>
			</div>
		</div><p>
	
<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-53" tabindex="-1" role="dialog"
         aria-labelledby="modal-53-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-53-label">[Abstract] Competitive Equilibrium for almost All Incomes</h4>
                </div>
                <div class="modal-body">
                    <p>Competitive equilibrium from equal incomes (CEEI)&nbsp; is a well-known rule for fair allocation of resources among agents with different preferences. It has many advantages, among them is the fact that a CEEI allocation is both Pareto efficient and envy-free. However, when the resources are indivisible, a CEEI allocation might not exist even when there are two agents and a single item.<br><br>In contrast to this discouraging non-existence result, Babaioff and Nisan and Talgam-Cohen (2017) recently suggested a new and more encouraging approach to allocation of indivisible items: instead of insisting that the incomes be equal, they suggest to look at the entire space of possible incomes, and check whether there exists a competitive equilibrium for almost all income-vectors (CEFAI) --- all income-space except a subset of measure zero.<br><br>They show that a CEFAI exists when there at most 3 indivisible items, or when there are 4 indivisible items and two agents. They also show that when there are 5 items and two agents with arbitrary monotone preferences, there might not exist a CEFAI. They leave open the cases of 4 items with three or four agents.<br><br>This paper presents a new way to implement a CEFAI, as&nbsp; a subgame-perfect equilibrium of a sequential game.&nbsp;&nbsp; This new implementation allows us to both offer much simpler solutions to the known cases (at most 3 items, and 4 items with two agents), and to prove that a CEFAI exists even in the much more difficult case of 4 items and three agents.&nbsp; Moreover, we prove that a CEFAI might not exist with 4 items and four agents.&nbsp; Thus, this paper completes the characterization of CEFAI for monotone preferences.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-97" tabindex="-1" role="dialog"
         aria-labelledby="modal-97-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-97-label">[Abstract] Fair Allocation of Indivisible Goods Considering Contribution Diversity</h4>
                </div>
                <div class="modal-body">
                    <p>Fair allocation&nbsp; of a set of goods among several agents is a classic problem in economics and computer science. Although the problem has been extensively studied, the existing work usually assumes that each agent has the same contribution to the agent group and endows each agent with the equal entitlement. However, in real applications, different agents may have different contributions to the agent group, e.g., in a company, different project teams may have different profitability. Inspired by the max-min fairness, we can adopt generalized max-min fairness criterion, i.e., maximizing the minimum utility contribution ratio, to allocate the goods in the situation with contribution diversity. The utility contribution ratio of an agent is the ratio between the utility of the acquired goods of the agent and its contribution value. Nevertheless, the generalized max-min fairness may lead to serious wealth gap, especially when the variance of the contribution distribution is large. Serious wealth gap is harmful to the unity and cooperation of the agent group. Therefore, this paper considers how to make tradeoff between the generalized max-min fairness and wealth gap during the fair allocation of the goods. First, we propose an evaluation indicator of allocation strategy that is positively related to the minimum utility contribution ratio of the agents and that is inversely related to the wealth gap. Second, we present a branch-and-bound algorithm to compute the optimal allocation strategy that maximizes the evaluation indicator. Third, because finding the optimal allocation strategy is NP-hard, we propose a heuristic algorithm that can provide suboptimal allocation strategy in polynomial time and is a max{1.4, m-n+1} factor approximation algorithm for the case that all the agents have the same utility function, where m is the goods number and n is the agent number. The heuristic algorithm consists of three phases: i) we allocate some indivisible goods to the agents based on the generalized max-min fairness; ii) we adopt greedy idea to allocate the remaining goods to minimize the wealth gap; iii) we improve the allocation strategy based on hill climbing search. Experiments conducted on real data show that the heuristic algorithm produces near-optimal solutions.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-250" tabindex="-1" role="dialog"
         aria-labelledby="modal-250-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-250-label">[Abstract] Classification of Disruptive Trading Practices Through Support Vector Machines</h4>
                </div>
                <div class="modal-body">
                    <p>Disruptive Trading, defined by the U.S. Commodity Futures Trading Commission (CFTC) as "bidding or offering with the intent to cancel the bid or offer before execution", is an illegal trading strategy aimed to manipulate stock prices and gain profits, and is hard to detect and therefore to prosecute. This paper proposes the identification of these trading practices through Support Vector Machines (SVM) applied to reconstructed Limit Order Books. Our results show the SVM can predict the cancellation of large orders within a time-event horizon T, given properties of the existing order-flow within a particular time window. This is of great importance as the SVM reveals the events of relevance that should be considered to detect trading activities that could be associated with market manipulation. Consequently, financial regulatory bodies can apply procedures to real cases of manipulation as our model predicts the activity of the manipulators.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-595" tabindex="-1" role="dialog"
         aria-labelledby="modal-595-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-595-label">[Abstract] Deep Abstract Q-Networks</h4>
                </div>
                <div class="modal-body">
                    <p>We examine the problem of learning and planning on high-dimensional domains with long horizons and sparse rewards. Recent approaches have shown great successes in many Atari 2600 domains. However, domains with long horizons and sparse rewards, such as Montezuma’s Revenge and Venture, remain challenging for existing methods. Methods using abstraction (Dietterich 2000; Sutton, Precup, and Singh 1999) have shown to be useful in tackling long-horizon problems. We combine recent techniques of deep reinforcement learning with existing model-based approaches using an expert-provided state abstraction. We construct toy domains that elucidate the problem of long horizons, sparse rewards and high-dimensional inputs, and show that our algorithm significantly outperforms previous methods on these domains. Our abstraction-based approach outperforms Deep Q-Networks (Mnih et al. 2015) on Montezuma’s Revenge and Venture, and exhibits backtracking behavior that is absent from previous methods.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-224" tabindex="-1" role="dialog"
         aria-labelledby="modal-224-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-224-label">[Abstract] A tensor-based approach for the trust evaluation in web-based service-oriented environments</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal"><a name="OLE_LINK2"></a><span lang="EN-US"></span>Multi-agent technologies have been widely applied in many web-based applications such as the cloud computing, service-oriented environments, etc. In real applications, web-based service-oriented environments are open and dynamic, where loosely coupled agents interact to consume and provide services. How to select the most suitable provider for the requested service in such open and dynamic environments is a challenging issue in both theory and practice. In this paper, an innovative approach is proposed to evaluate the trusts of providers based on their historical performance. The proposed approach borrows the reference report mechanism of the certified reputation model so as to efficiently collect historical performance of providers. Based on the collected reference reports, the tensor based mechanism of the proposed approach can model the historical performance of providers by involving comprehensive information of service provision in a tensor. Based on the tensor, the CP decomposition based mechanism of the proposed approach can accurately evaluate the trusts of providers by considering the difference between services, the bias of consumers, and the timelines of reference reports. From the experiments, it can be seen that the proposed approach has better performance than current approaches on trust evaluation in open and dynamic environments, especially when the reference reports (i.e, historical performance) of providers are sparse.<br><span lang="EN-US"></span></p><p class="MsoNormal">

<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:普通表格;
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin:0cm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:等线;
	mso-ascii-font-family:等线;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:等线;
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:等线;
	mso-hansi-theme-font:minor-latin;
	mso-font-kerning:1.0pt;}
</style>
<![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="371">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:DrawingGridVerticalSpacing>7.8 磅</w:DrawingGridVerticalSpacing>
  <w:DisplayHorizontalDrawingGridEvery>0</w:DisplayHorizontalDrawingGridEvery>
  <w:DisplayVerticalDrawingGridEvery>2</w:DisplayVerticalDrawingGridEvery>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>ZH-CN</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:SpaceForUL></w:SpaceForUL>
   <w:BalanceSingleByteDoubleByteWidth></w:BalanceSingleByteDoubleByteWidth>
   <w:DoNotLeaveBackslashAlone></w:DoNotLeaveBackslashAlone>
   <w:ULTrailSpace></w:ULTrailSpace>
   <w:DoNotExpandShiftReturn></w:DoNotExpandShiftReturn>
   <w:AdjustLineHeightInTable></w:AdjustLineHeightInTable>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
   <w:UseFELayout></w:UseFELayout>
  </w:Compatibility>
  <w:DoNotOptimizeForBrowser></w:DoNotOptimizeForBrowser>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
 </o:OfficeDocumentSettings>
</xml><![endif]--><a name="OLE_LINK1"><span lang="EN-US"></span></a><span lang="EN-US"></span></p><p>

</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-352" tabindex="-1" role="dialog"
         aria-labelledby="modal-352-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-352-label">[Abstract] Moving Agents in Formation in Congested Environments</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we formalize and study the Moving Agents in Formation (MAiF) problem that combines the tasks of finding low-cost paths for multiple agents and keeping them in a desired formation as much as possible. Previous work focused on only one or the other of these tasks. We present a complete two-phase algorithm, called SWARM-MAPF, whose first phase is inspired by swarm-based approaches and whose second phase is inspired by multi-agent path-finding (MAPF) approaches. The first phase focuses on the selection of a leader and finds a path for it that is sufficiently away from the obstacles so that other agents can preserve the desired formation around it. The first phase also identifies the critical segments of the leader's path where other agents cannot preserve the formation and the refinement of which has to be thus delegated to the second phase. In the second phase, the combinatorial problem is similar to MAPF and is solved using algorithmic procedures that combine current MAPF techniques with our own novel contributions. We present experimental results to show several benefits of SWARM-MAPF in congested environments.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-150" tabindex="-1" role="dialog"
         aria-labelledby="modal-150-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-150-label">[Abstract] Equilibrium Behavior in Competing Dynamic Matching Markets</h4>
                </div>
                <div class="modal-body">
                    <p>Rival markets like rideshare services, universities, and organ exchanges compete to attract participants, seeking to maximize their own utility at potential cost to overall social welfare.&nbsp; Similarly, individual participants in such multi-market systems also seek to maximize their individual utility. If entry is costly, they should strategically enter only a subset of the available markets. All of this decision making---markets competitively adapting their matching strategies and participants arriving, choosing which market(s) to enter, and departing from the system---occurs dynamically over time. This paper provides the first analysis of equilibrium behavior in dynamic competing matching market systems---first from the points of view of individual participants when market policies are fixed, and then from the points of view of markets when agents are stochastic. When compared to single markets running social-welfare-maximizing matching policies, losses in overall social welfare in competitive systems manifest due to both market fragmentation and the use of non-optimal matching policies. We quantify such losses and provide policy recommendations to help alleviate them in fielded systems.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-185" tabindex="-1" role="dialog"
         aria-labelledby="modal-185-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-185-label">[Abstract] COMBIMA: Truthful, Budget Maintaining, Dynamic Combinatorial Market</h4>
                </div>
                <div class="modal-body">
                    <p style="margin-bottom: 0px;">Current interest in two-sided markets is motivated by examples of successful practical applications of market mechanisms in supply chain markets, online advertising exchanges, and pollution-rights markets. Many of these examples require markets where agents arrive dynamically and can trade multiple commodities. However, the known literature largely focuses on settings with single commodity unit demand.</p><p style="margin-bottom: 0px;">We present and evaluate a general solution that matches agents in a dynamic, two-sided combinatorial market. Multiple commodities, each with multiple units, are bought and sold in different bundles by agents that arrive over time.</p><p style="margin-bottom: 0px;"><br></p><p style="margin-bottom: 0px;">Our mechanism, COMBIMA, provides the first dynamic two-sided combinatorial market that allows truthful and individually-rational behavior for all agents, keeps the market budget balanced and approximates social welfare efficiency. We experimentally examine and compare the allocative efficiency of COMBIMA with respect to other known (dynamic and non-dynamic) two-sided markets under a variety of distributions of bids, market demand and market size. COMBIMA performs well by all benchmarks and improves on previous mechanisms.</p><p style="margin-bottom: 0px;"><!--EndFragment--></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-716" tabindex="-1" role="dialog"
         aria-labelledby="modal-716-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-716-label">[Abstract] Coalitional Permutation Manipulations in the Gale-Shapley Algorithm</h4>
                </div>
                <div class="modal-body">
                    <p class="p1">In this paper, we consider permutation manipulations by any subset of women, which is motivated by the college admissions process in China. Our result also answer the open problem on what can be achieved by permutation manipulations. We present an efficient algorithm to find a strategy profile such that the induced matching is stable and Pareto-optimal while the strategy profile itself is inconspicuous. Surprisingly, we show that such a strategy profile actually forms a Nash equilibrium of the manipulation game.</p><p class="p1"><br></p><p class="p1">




<style type="text/css">
p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 19.0px; font: 13.0px 'Helvetica Neue'}
p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 19.0px; font: 13.0px 'Helvetica Neue'; min-height: 15.0px}
</style>




</p><p class="p1">In the end, we show that it is NP-complete to find a manipulation that is strictly better for all members of the coalition. This result demonstrates a sharp contrast between weakly better off outcomes and strictly better off outcomes.</p><style type="text/css">
p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 19.0px; font: 13.0px 'Helvetica Neue'}
p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 19.0px; font: 13.0px 'Helvetica Neue'; min-height: 15.0px}
</style>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-91" tabindex="-1" role="dialog"
         aria-labelledby="modal-91-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-91-label">[Abstract] On the Design of Revenue-Enhancing Signal Structures in Common- and Interdependent-Value Second Price Auctions</h4>
                </div>
                <div class="modal-body">
                    <p>We consider the problem of designing the information environment for revenue maximization in a sealed-bid second price auction with two bidders. Much of the prior literature has focused on signal design in settings where bidders are symmetrically informed, or on the design of optimal mechanisms under fixed information structures. We study common- and interdependent-value settings where the mechanism is fixed (a second-price auction), but the auctioneer controls the signal structure for sellers. We show that in a standard common-value auction setting, there is no benefit to the auctioneer in terms of expected revenue from sharing information with the bidders, although there are effects on the distribution of revenues. In an interdependent-value model with mixed private- and common-value components, however, we show that asymmetric, information-revealing signals can increase revenue.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-119" tabindex="-1" role="dialog"
         aria-labelledby="modal-119-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-119-label">[Abstract] Human-Interactive Subgoal Supervision for Efficient Inverse Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p>Humans are able to understand and perform complex tasks&nbsp;</p><p>by strategically structuring tasks into incremental steps</p><p>or sub-goals. For a robot attempting to learn to perform&nbsp;</p><p>a sequential task with critical subgoal states, these&nbsp;</p><p>subgoal states can provide a natural opportunity for&nbsp;</p><p>interaction with a human expert. This paper&nbsp;</p><p>analyzes the benefit of incorporating a notion of subgoals</p><p>into Inverse Reinforcement Learning (IRL) with&nbsp;</p><p>a Human-In-The-Loop (HITL) framework. The learning process&nbsp;</p><p>is interactive, with a human expert first providing input&nbsp;</p><p>in the form of full demonstrations along with subgoal states. These</p><p>subgoal states defines a set of sub-tasks for the learning&nbsp;</p><p>agent to complete in order to achieve the final goal. The learning agent&nbsp;</p><p>queries for partial demonstrations corresponding to each sub-task</p><p>as needed when the learning agent struggles with individual&nbsp;</p><p>sub-tasks. The proposed Human Interactive IRL (HI-IRL) framework</p><p>is evaluated on several discrete path-planning tasks. We&nbsp;</p><p>demonstrate that subgoal-based interactive&nbsp;</p><p>structuring of the learning task results in significantly more&nbsp;</p><p>efficient learning, requiring only a fraction of the demonstration&nbsp;</p><p>data needed for learning the underlying reward function with a&nbsp;</p><p>baseline IRL model.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-228" tabindex="-1" role="dialog"
         aria-labelledby="modal-228-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-228-label">[Abstract] An Optimal Algorithm for the Bandits with Knowing Near-optimal Mean Reward</h4>
                </div>
                <div class="modal-body">
                    <p>This paper studies a variation of stochastic multi-armed bandit (MAB) problem where the learner knows a priori knowledge named Near-optimal Mean Reward (NoMR). This variation of bandit problem is seen in practical applications such as online web ad services, where a near-optimal average click rate of a user can be estimated from his/her demographic characteristics. A novel algorithm, NoMR-Bandit, is proposed to solve this bandit variation. It is proved that a proper NoMR can lead to an efficient exploration strategy and thereby the cumulative regret of NoMR-Bandit has a uniform upper bound of $O\left(\Delta\right)$, where $\Delta$ is the gap between the optimal and the second optimal mean reward. It is also proved that the cumulative regret of the bandit variation has a lower bound of $\Omega\left(1/\Delta\right)$, and hence NoMR-Bandit is optimal in terms of the order of regret bounds. For practical situations where a good NoMR is not directly available, NoMR-Bandit can be extended to obtain a NoMR from some arbitrarily poor estimation of the optimal mean reward. The extended algorithm, Cascade-Bandit, has a cumulative regret upper bound of $O\left(\Delta\log n\right)$, which is in the same order with state-of-the-art bandit solutions that are unaware of any priori knowledge. Extensive experiments show that the proposed NoMR-Bandit is also more efficient than all the other state-of-the-art bandit solutions, in the sense that NoMR-Bandit achieves 50\%-90\% less cumulative regret after sufficiently many iterations.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-314" tabindex="-1" role="dialog"
         aria-labelledby="modal-314-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-314-label">[Abstract] Modeling Consecutive Task Learning with Task Graph Agendas</h4>
                </div>
                <div class="modal-body">
                    <p>Recent advances in transfer, multi-task, and lifelong learning have demonstrated that agents can efficiently learn a challenging target task through a curriculum of simpler-to-harder tasks.<br>Yet relatively little work examines how learning can be self-directed, especially when there can be multiple underspecified targets, or when the environment combines their rewards, creating ambiguity.<br>We formalize this space of transfer among consecutive tasks as a task graph, where the inter-task similarity is measured based on high-level task descriptions.&nbsp; This framework permits us to define a learning agenda as a traversal on this task graph, generalizing the idea of curricula and unlocking a mechanism for describing (self-directed) learning as a path through the task graph.<br>We describe several task-graph traversal strategies that optimize knowledge acquisition, search for agent-specific optima in task space, and perform automatic curriculum generation. <br>Additionally, we identify the variance of the cumulative reward as a useful tool for disambiguating task descriptors, which may be incomparable otherwise. <br>Our empirical results suggest that agendas are beneficial in building on prior successes in transfer and curriculum learning, while providing a path forward for self-directed learning.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-273" tabindex="-1" role="dialog"
         aria-labelledby="modal-273-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-273-label">[Abstract] On the Impact of Buyers Preselection in Pricing Problems</h4>
                </div>
                <div class="modal-body">
                    <p>We investigate the problem of preselecting a subset of buyers participating in a market so as to optimize the performance of stable outcomes. We consider four scenarios arising from the combination of two stability notions, item and bundle envy-freeness, with the two classical objective functions, i.e., the social welfare and the seller’s revenue. When adopting the notion of item envy-freeness, we prove that, for both the two objective functions, the problem cannot be approximated within n<sup>1−ε</sup> for any ε &gt; 0, and provide tight or nearly tight approximation algorithms. We also prove that maximizing the seller’s revenue is NP-hard even for a single buyer, thus closing a longstanding open question. Under bundle envy-freeness, instead, we show how to transform in polynomial time any stable outcome for a market involving only a subset of buyers to a stable one for the whole market without worsening its performance, both for the social welfare and the seller’s revenue. This transformation implies that, although in this case buyers preselection cannot improve the performance, it can still be used as an algorithmic tool for computing good stable outcomes when preselection is not allowed. In fact, it can be first exploited to simplify the combinatorics of the problem, and then for mapping back the computed solution to one encompassing all the buyers. Finally, we consider multi-unit markets, where all items are of the same type and are assigned the same price. For this specific case, we show that buyers preselection can improve the performance of stable outcomes in all of the four considered scenarios, and design corresponding approximation algorithms.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-628" tabindex="-1" role="dialog"
         aria-labelledby="modal-628-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-628-label">[Abstract] Deep Reinforcement Learning of Behavior from Policy-Dependent Human Feedback</h4>
                </div>
                <div class="modal-body">
                    <p>To widen their accessibility and increase their utility, intelligent agents must be able to learn complex behaviors as specified by (non-expert) human users. Moreover, they will need to learn these behaviors within a reasonable amount of time while leveraging the low, sparse amount of feedback a human trainer is capable of providing, as efficiently as possible. Recent work has shown that human feedback can be characterized as a critique of an agent's current behavior rather than as an alternative reward signal to be maximized, culminating in the COnvergent Actor-Critic by Humans (COACH) algorithm for making direct policy updates based on human feedback. Our work builds on COACH, taking a further step in this direction, to a setting where the agent's policy is represented by a deep neural network. We employ a series of modifications on top of the original COACH algorithm that are critical for successfully learning behaviors from high-dimensional observations while also satisfying the constraint of minimal sample complexity. We demonstrate the effectiveness of our Deep COACH algorithm in the rich 3D world of Minecraft with an agent that learns to complete tasks by mapping from raw pixels to actions using only real-time human feedback and 10-15 minutes of interaction.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-302" tabindex="-1" role="dialog"
         aria-labelledby="modal-302-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-302-label">[Abstract] PELTE: Privacy Estimation of Images from Tags</h4>
                </div>
                <div class="modal-body">
                    <p>Image sharing is a service offered by many online social networks.&nbsp; In order to preserve privacy of images, users need to think through and set the privacy settings for each image that they upload.&nbsp; This is difficult for two main reasons: First, research shows that many times users do not know their own privacy preferences, but only become aware of them over time.&nbsp; Second, even when users know their privacy preferences, specifying these policies is cumbersome and requires too much effort, interfering with the quick sharing behavior expected on an social network. Accordingly, this paper proposes an agent-based approach, PELTE, that predicts the privacy setting of images using their content tags.&nbsp; Each user agent makes use of the privacy settings that its user have set for previous images to predict the privacy setting for a new uploaded one automatically.&nbsp; When in doubt, the agent analyzes the sharing behavior of other trusted agents to make a recommendation to its user about what is private.&nbsp; Contrary to existing approaches that assume a centralized online social network where privacy is set by accessing all the available images, our approach is distributed and thus each agent can only view the privacy settings of the images that it has shared or those that have been shared with it.&nbsp; Our simulations on a real-life dataset shows that PELTE can accurately predict privacy settings even when a user has shared a few images with others, the images have only a few tags or the user's friends have varying privacy preferences.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-46" tabindex="-1" role="dialog"
         aria-labelledby="modal-46-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-46-label">[Abstract] Methods for Joining and Leaving a Flock</h4>
                </div>
                <div class="modal-body">
                    <p>As autonomous agents become realizable in robotic forms that closely resemble biological agents, the possibility emerges to indirectly influence biological agents' behaviors through controlled interactions with autonomous agents.&nbsp; For example, birdstrikes - where one or more birds collide with a plane - are an expensive and dangerous problem at airports.&nbsp; Robot birds could potentially reduce birdstrikes by influencing flocks of natural birds to travel around an airport instead of over the airport.&nbsp; Prior research has considered how such robot birds should behave and where they should be placed within the flock. However, before robot birds can be used to influence flocks of real birds, we must consider how the robot birds could join and leave flocks of natural birds.&nbsp; Due to the influence the robot birds have once they become neighbors of birds in the flock, joining and leaving are not straightforward.&nbsp; In this paper, we introduce and evaluate several approaches for robot birds to use when joining and leaving flocks of natural birds.&nbsp; We introduce a variety of metrics to compare these approaches in the MASON simulator and present detailed experimental results.<br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-260" tabindex="-1" role="dialog"
         aria-labelledby="modal-260-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-260-label">[Abstract] Partial Verification as a Substitute for Money</h4>
                </div>
                <div class="modal-body">
                    <p>Recent work has shown that we can use partial verification instead of money to implement truthful mechanisms. In this paper we develop tools to answer the following question. Given an allocation rule that can be made truthful with payments, what is the minimal verification needed to make it truthful without them? Our techniques leverage the geometric relationship between the type space and the set of possible allocations.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-175" tabindex="-1" role="dialog"
         aria-labelledby="modal-175-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-175-label">[Abstract] Explore, Exploit or Listen: Combining Human Feedback and Policy Model to Speed up Deep Reinforcement Learning in 3D Worlds</h4>
                </div>
                <div class="modal-body">
                    <p>We describe a method to use discrete human feedback to enhance the performance of deep learning agents in virtual three-dimensional environments by extending deep-reinforcement learning to model the confidence and consistency of human feedback. This enables deep reinforcement learning algorithms to determine the most appropriate time to listen to the human feedback, exploit the current policy model, or explore the agent's environment. Managing the trade-off between these three strategies allows DRL agents to be robust to inconsistent or intermittent human feedback. Through experimentation using a synthetic oracle, we show that our technique improves the training speed and overall performance of deep reinforcement learning in navigating three-dimensional environments using Minecraft.We further show that our technique is robust to highly innacurate human feedback and can also operate when no human feedback is given.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-718" tabindex="-1" role="dialog"
         aria-labelledby="modal-718-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-718-label">[Abstract] Residential Energy Consumption Patterns in Urban and Rural Areas: A case study of Virginia, USA</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal">For improving energy efficiency, managing the demand side of the
energy equation is as important as managing the supply side. Demand response
and home energy management are important tools in curtailing demand and
shifting usage away from peak-time hours. For understanding the demand and
supply dynamics in urban versus rural areas of the U.S. we need to know the
detailed demand estimates of households in these areas along with their
physical characteristics. This information is lacking in the literature and so,
our research attempts to fill this gap. We use an agent-based model to build
disaggregated demand estimates for households during different seasons in both
urban and rural areas. These estimates are based on householders’ demographics,
user behavior, and ratings of appliances used in energy-related activities,
physical characteristics of the house and weather data. Using the US
Census-based classification of regions, we classify the population into urban
areas, urbanized clusters, and rural areas. An energy consumption demand
profile is created for each household based on household occupancy levels, size
of the dwelling, devices, and fuels used in undertaking energy-related
activities, and demographics of the household. Furthermore, this model is used
to perform a comparative analysis of energy demand for urban versus rural
households of Virginia. We believe that such detailed knowledge about energy
consumption profiles can help end-users adjust electricity consumption patterns
with respect to the time and level of energy used, in order to create an
optimal consumption profile that minimizes energy costs. Such profiles can also
help formulate energy policies for demand-side management.<o:p></o:p></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-131" tabindex="-1" role="dialog"
         aria-labelledby="modal-131-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-131-label">[Abstract] Proportionally Representative Participatory Budgeting: Axioms and Algorithms</h4>
                </div>
                <div class="modal-body">
                    <p>Participatory budgeting is one of the exciting developments in deliberative grassroots democracy. We concentrate on approval elections and propose proportional representation axioms in participatory budgeting, by generalizing relevant axioms for approval-based multi-winner elections. We observe a rich landscape with respect to the computational complexity of identifying proportional budgets and computing such, and present budgeting methods that satisfy these axioms by identifying budgets that are representative to the demands of vast segments of the voters.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-237" tabindex="-1" role="dialog"
         aria-labelledby="modal-237-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-237-label">[Abstract] Individual Security and Network Design with Malicious Nodes</h4>
                </div>
                <div class="modal-body">
                    <p>Networks are beneficial to those being connected but can also be used as carriers of contagious hostile attacks. These attacks are often facilitated by exploiting corrupt network users. To protect against the attacks, users can resort to costly defense. The decentralized nature of such protection is known to be inefficient but the inefficiencies can be mitigated by a careful network design. Is network design still effective when not all users can be trusted? We propose a model of network design and defense with byzantine nodes to address this question. We study the optimal defended networks in the case of centralized defense and, for the case of decentralized defense, we show that the inefficiencies due to decentralization can be fully mitigated, despite the presence of the byzantine nodes.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-487" tabindex="-1" role="dialog"
         aria-labelledby="modal-487-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-487-label">[Abstract] How Bad is Selfish Doodle Voting?</h4>
                </div>
                <div class="modal-body">
                    <p>Doodle polls allow people to schedule meetings or events based on the time preferences of participants.&nbsp; Each participant indicates on a web-based poll form which time slots they find acceptable and a time slot with the most votes is chosen. This is a social choice mechanism known as approval voting, in which a standard assumption is that all voters vote sincerely---no one votes no on a time slot they prefer to a time slot they have voted yes on. We take a game theoretical approach to understanding&nbsp; what happens in Doodle polls assuming participants vote sincerely. First we characterize Doodle poll instances where sincere pure Nash Equilibria (NE) exist, both under lexicographic tie-breaking and randomized tie-breaking.&nbsp; We then study the quality of such NE voting profiles in Doodle polls, showing that the price of anarchy and price of stability are both unbounded, even when a slot that many participants vote yes for is selected.&nbsp; Finally, we give some conditions under which the quality of the NE (and strong NE) are good.&nbsp;&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-707" tabindex="-1" role="dialog"
         aria-labelledby="modal-707-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-707-label">[Abstract] A unified auction for brand and performance advertising: revenue-optimal bidding proxy for brand advertisers</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we consider the revenue maximization problem of an advertising platform that contains both brand advertisers and performance advertisers. Traditionally, the two types of advertisers are handled separately by most platforms: the performance ads are sold via ad auctions that require the advertisers to submit bids while the brand ads are mostly sold via negotiated contracts (i.e., in the form of a certain number of clicks for a posted price, plus some implicit brand effects). In fact, most brand advertisers may not even have a valuation towards a single click on their ads. It therefore remains unclear whether the platform can design a unified mechanism to sell both types of ads, in order to maximize revenue.</p><p>It turns out that it is without loss of generality to assume that the mechanism includes a bidding proxy that places bids on the behalf of the brand advertiser. We then derive the revenue optimal mechanism of this sort.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-699" tabindex="-1" role="dialog"
         aria-labelledby="modal-699-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-699-label">[Abstract] Estimating Shared Autonomous Vehicle Fleet Size to Meet Urban Daily Travel Demand</h4>
                </div>
                <div class="modal-body">
                    <p>Shared autonomous vehicles (SAVs) present the possibility of greatly 
reducing the number of cars in use, and consequently the required 
parking space. We present a methodology to estimate the required SAV 
fleet size to meet travel demand for a region, and develop a detailed 
synthetic population model where we model every individual in a city, 
along with typical weekday activity patterns to estimate the travel 
demand. We combine this with a simulation of SAV routing to determine 
the fleet size needed to satisfy all trips with small waiting times. Our
 results show significant reductions in both the number of vehicles on 
roads and parking demand in cities, which would result in substantial 
savings.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-256" tabindex="-1" role="dialog"
         aria-labelledby="modal-256-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-256-label">[Abstract] When Are Two Gossips the Same? Types of Communication in Epistemic Gossip Protocols</h4>
                </div>
                <div class="modal-body">
                    <p>We provide an in-depth study of the knowledge-theoretic aspects of communication in so-called gossip protocols. Pairs of agents communicate by means of calls in order to spread information---so-called secrets---within the group. Depending on the nature of such calls knowledge spreads in different ways within the group. Systematizing existing literature, we identify 18 different types of communication, and model their epistemic effects through different indistinguishability relations. We then study these relations establishing results concerning the relative informativeness of the different types of communication identified.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-555" tabindex="-1" role="dialog"
         aria-labelledby="modal-555-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-555-label">[Abstract] When Can We Approximate Voting Rules from Truncated Ballots ?</h4>
                </div>
                <div class="modal-body">
                    <p>Classical voting rules assume that voters' ballots are complete preference orders over candidates. However, when the number of candidates is large enough, it is too costly to ask the voters to rank all candidates. We suggest to fix a rank k, to ask all voters to specify their k best alternatives, and then to consider "k-truncated approximations" of rules, which take only into account the top-k candidates of each ballot. The questions are then: Are these k-truncated approximations good predictors of the approximated rule? For which values of k and under which assumptions can we expect to output the correct winner with high probability? For different voting rules (Borda, Copeland, Maximin and Kemeny), we study these questions theoretically, by giving tight aprroximation ratios, and empirically, based on randomly generated profiles and on real data.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-408" tabindex="-1" role="dialog"
         aria-labelledby="modal-408-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-408-label">[Abstract] Recoverable Team Formation: Building Teams Resilient to Change</h4>
                </div>
                <div class="modal-body">
                    <p>Team formation consists in finding the least expensive team of agents such that a certain set of skills is covered. In this paper, we formally introduce recoverable team formation (RTF), a generalization of the above problem, by taking into account the dynamic nature of the environment, e.g. after a team has been formed, agents may unexpectedly become unavailable due to failure or illness. We analyze the computational complexity of RTF, provide both complete and heuristic algorithms, and empirically evaluate their performance. Furthermore, we demonstrate that RTF generalizes robust team formation, where the task is to build a team capable of covering all required skills even after any k agents are removed. Despite the high complexity of forming a recoverable team, we argue that recoverability is a crucial feature, and experimentally show that it is more appropriate for some applications than robustness.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-421" tabindex="-1" role="dialog"
         aria-labelledby="modal-421-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-421-label">[Abstract] Buyer-optimal distribution</h4>
                </div>
                <div class="modal-body">
                    <p>We consider the problem of how a buyer can optimize his utility if he is flexible to choose his own valuation distribution to attend a prior-dependent auction, such as the revenue-optimal auction. The problem is motivated by and equivalent to a variation of the market segmentation problem, where a principal tries to find a subset of agents (aka. a market segment) from the set of all agents, each with a constant valuation, to attend a posted price auction for selling M identical items (for some sufficiently large M), in order to maximize the total utilities from the agents who are selected into the segment. Our results are closed-form solutions in both the single buyer case and multi-buyer case where several buyers best response to each other. Interestingly, in the two-buyer case, essentially all commitments that satisfy a certain condition are equilibria.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-249" tabindex="-1" role="dialog"
         aria-labelledby="modal-249-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-249-label">[Abstract] Balancing Asymmetry in Max-sum using Split Constraint Factor Graphs</h4>
                </div>
                <div class="modal-body">
                    <p>Max-sum is a version of Belief Propagation, used for solving DCOPs.&nbsp; On tree-structured problems, Max-sum converges to the optimal solution in linear time. Unfortunately&nbsp; when the constraint graph representing the problem includes multiple cycles (as in many standard DCOP benchmarks), Max-sum does not converge and explores low quality solutions. Damping is a method that can be used for increasing the chances that Max-sum will converge, and was recently found to produce high quality solutions for DCOP when combined with an anytime framework. Another recent study revealed that Max-sum, in contrast to most DCOP algorithms, maintains its solution quality when applied to asymmetric problems.</p><p><br></p><p>In this paper we advance the research on incomplete inference DCOP algorithms by proposing a novel method for adjusting the level of asymmetry in the factor graph, in order to achieve a balance between exploitation and exploration, when using Max-sum for solving DCOPs. By converting a standard factor graph to an equivalent split constraint factor graph (SCFG), in which each function node is split to two function nodes, we can control the level of asymmetry for each constraint.</p><p>We prove that for a factor-graph with a single constraint, if this constraint is split symmetrically, Max-sum applied to the resulting cycle is guaranteed to converge to the optimal solution and demonstrate that for an asymmetric split, convergence is not guaranteed.&nbsp;</p><p>Our empirical results demonstrate that by combining damping and asymmetry we can find high quality solutions in a small number of iterations, even without using an anytime framework.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-55" tabindex="-1" role="dialog"
         aria-labelledby="modal-55-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-55-label">[Abstract] Graph theoretical properties of logic based argumentation frameworks</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">In this paper we present some graph theoretical properties of logic
based argumentation graphs obtained from an inconsistent knowledge base expressed using existential rules. We fully characterize
argumentation graphs obtained from knowledge bases composed of
factual knowledge and negative rules. Furthermore we provide some
structural properties for general existential rules induced argumentation graphs.&nbsp;</span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-267" tabindex="-1" role="dialog"
         aria-labelledby="modal-267-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-267-label">[Abstract] High-Multiplicity Election Problems</h4>
                </div>
                <div class="modal-body">
                    <p><span style="color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; display: inline !important; float: none;">The computational study of elections generally assumes that the preferences of the electorate come in as a list of votes. Depending on the context, it may be much more natural to represent the list succinctly, as the distinct votes of the electorate and their counts, i.e., high-multiplicity representation. We consider how this representation affects the complexity of election problems. High-multiplicity representation may be exponentially smaller than standard representation, and so many polynomial-time algorithms for election problems in standard representation become exponential. Surprisingly, for polynomial-time election problems, we are often able to either adapt the same approach or provide new algorithms to show that these problems remain polynomial-time in the high-multiplicity case; this is in sharp contrast to the case where each voter has a weight, where the complexity usually increases. In the process we explore the relationship between high-multiplicity scheduling and manipulation of high-multiplicity elections. And we show that for any fixed set of job lengths, high-multiplicity scheduling on uniform parallel machines is in P, which was previously known for only two job lengths. We did not find any natural case where a polynomial-time election problem does not remain in P when moving to high-multiplicity representation. However, we found one natural NP-hard election problem where the complexity does increase, namely</span><span style="color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"> winner determination for Kemeny elections.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-457" tabindex="-1" role="dialog"
         aria-labelledby="modal-457-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-457-label">[Abstract] Budget-feasible Procurement Mechanisms in Two-sided Markets</h4>
                </div>
                <div class="modal-body">
                    <p>This paper considers the mechanism design problem in two-sided markets where multiple strategic buyers come with budgets to procure as much value of items&nbsp; as possible from the strategic sellers. Sellers are allowed to untruthfully bid their costs and buyers could claim their budgets, not necessarily the true ones. The goal is to seek truthful budget-feasible mechanisms that ensure sellers are rewarded enough payment and buyers' budgets are not exceeded. Prior to this work, existing budget-feasible procurement mechanisms are limited in one-sided market with a single buyer and address only sellers' truthfulness.&nbsp; We study two models,&nbsp; one with homogeneous item values and the other with heterogeneous item values.&nbsp; Our main contributions are two budget-feasible mechanisms&nbsp; with various desired theoretical guarantees like, the truthfulness both on the sellers' side and the buyers' side, and constant approximation that the total procured value of buyers approximates the optimal solution within a constant factor.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-337" tabindex="-1" role="dialog"
         aria-labelledby="modal-337-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-337-label">[Abstract] Distributed Large Neighborhood Search for Solving Large-Scale DCOPs</h4>
                </div>
                <div class="modal-body">
                    <p>Distributed constraint reasoning has recently gained momentum due to its ability to handle many combinatorial problems that are naturally distributed over a set of agents. However, to date most approaches cannot handle large-scale optimization problems. On the other hand, while large neighborhood search (LNS) has been widely applied for such large-scale problems in the centralized case, little attention has been devoted to the application of LNS in a distributed setting. In this paper, we present a general anytime framework for solving distributed constraint optimization problems (DCOP) using LNS. Our approach does not make any assumption on the number of variables per agent nor the constraints of the problem. Our approach is an anytime iterative distributed incomplete&nbsp; algorithm. On each iteration, it explores multiple neighborhoods. It allows different mechanisms for selecting those neighborhoods, it supports concurrent exploration of them using different algorithms, and it allows different mechanisms for aggregating the outputs of these algorithms. Our empirical results show that large gains can be achieved through the proposed approach.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-482" tabindex="-1" role="dialog"
         aria-labelledby="modal-482-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-482-label">[Abstract] Addressing Concept Drift in Reputation Assessment</h4>
                </div>
                <div class="modal-body">
                    <div>Trust, reputation and stereotype models use past interactions to predict agents' future behaviour. Such behaviour may change over time, and forgetting factors or sliding windows are typically used to give higher importance to recent interactions and discount past records. However, tuning these parameters can result in losing relevant data or retaining too much old data. In this paper, we use established concept drift techniques to identify both gradual and sudden changes in behaviour, in environments where such changes may occur non-uniformly across the population. Using our method, agents are able to exclude irrelevant and unrepresentative past interactions from calculating trust, reputation and stereotypes.</div><div><br></div><div>Our results show that our method is robust against gradual and sudden behaviour change because it retains a higher proportion of relevant data, while previous methods take several iterations to remove data that is no longer representative. Stereotypes are more sensitive to behaviour change than trust and reputation because they rely on a larger amount of historical data. Our method is particularly beneficial when agent turnover is high, since when agents have less direct experience there is more emphasis on stereotypes.&nbsp;<br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-206" tabindex="-1" role="dialog"
         aria-labelledby="modal-206-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-206-label">[Abstract] Ranking mechanism design for price-setting agents in e-commerce</h4>
                </div>
                <div class="modal-body">
                    <pre style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;"><pre style="margin-bottom: 0px;"><pre style="margin-bottom: 0px;"><span style=" color:#000000;">Ranking algorithms of e-commerce sites take the buyer's search query and information <gs id="b0a041bf-857c-480d-bee5-57f07edc8a0e" ginger_software_uiphraseguid="5082b2cb-0b02-4d72-81b6-e95311a342fc" class="GINGER_SOFTWARE_mark">of</gs> the corresponding sellers' items as input, and output a ranking of sellers' items that maximizes sites' objectives. However, the conversion rate of each item (i.e., the probability of a completed transaction) not only depends on the ranking given by the site (which controls click-through rates), but also depends on the item price set by its seller(which controls the buyer's willingness to buy). As a result, a ranking algorithm is in fact a mechanism that deals with sellers who strategically set item prices.</span></pre><pre style="margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);">An interesting fact about this setting, at least </span><span style="color: rgb(0, 0, 0);">the </span><span style="color: rgb(0, 0, 0);">status</span><span style="color: rgb(0, 0, 0);"> </span><span style="color: rgb(0, 0, 0);">quo for the largest e-commerce sites such as Taobao, Amazon, and eBay, is that sellers are usually not given the option to report their private costs but can only communicate with the site by setting item prices. In terms of <gs id="04f088c5-5edc-4159-8219-26f3a770e83f" ginger_software_uiphraseguid="1fed0bfa-e84a-4abe-bbc3-a393998c771c" class="GINGER_SOFTWARE_mark">mechanism</gs> design, this is a setting where the designer is restricted to design a specific type of indirect mechanisms.</span></pre><pre style="margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);">We follow the framework of implementing optimal direct mechanisms by indirect mechanisms to tackle this optimal indirect ranking mechanism design problem. We firstly define a related optimal direct ranking mechanism design setting and use Myerson's characterization to optimize in that setting. We then characterize the class of direct mechanisms which could be implemented by indirect mechanisms, and construct a mapping that maps the mechanisms designed in the previous direct setting to indirect mechanisms in the original setting where sellers are allowed only to set item prices. We show that, using this technique, one can obtain mechanisms in the indirect setting that maximize expected total trading volume. We then present the mechanism employed by Taobao currently, get a Bayesian Nash Equilibrium of it and obtain the gap of the volume of Taobao and the optimal mechanism. Given real dataset from Taobao, we also simulate our optimal mechanism and Taobao's mechanism, and it shows that our mechanism outperforms Taobao's mechanism significantly.</span></pre></pre></pre>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-620" tabindex="-1" role="dialog"
         aria-labelledby="modal-620-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-620-label">[Abstract] Efficient Randomized Mechanisms for Matching Under Indifference Classes</h4>
                </div>
                <div class="modal-body">
                    <p>We study the problem of assigning a set of indivisible objects to self-interested agents in the absence of transferable utilities. Under strict ordinal preferences several well-known mechanisms, such as Random Serial Dictatorship and Probabilistic Serial rule, guarantee a desirable set of properties such as Pareto efficiency, strategyproofness, and non-bossiness. However, when agents are able to specify indifferences in their preferences, these mechanisms no longer satisfy these properties. We consider specialized sub-domains of preferences, in which agents can express indifferences, and develop easy-to-implement and efficient randomized algorithms to restore efficiency, strategyproofness, and non-bossiness requirements.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-386" tabindex="-1" role="dialog"
         aria-labelledby="modal-386-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-386-label">[Abstract] Fair Privacy Multilateral Closed Negotiation</h4>
                </div>
                <div class="modal-body">
                    <p>In multi-agent systems, a multilateral closed negotiation, where the opponent's strategy and utility are closed, is an important class of automated negotiation. Recently, stacked alternating offers protocols (SAOP) for multilateral negotiations have become an important negotiation protocol, such as in the automated negotiating agents competition (ANAC). However, most existing negotiation protocols (including SAOP) haven't addressed the privacy issues of agents. During negotiations, such private information as agents' preferences should be revealed fairly because each agent loses utility when doing so. </p><p>In this paper, we propose a negotiation protocol that addresses the fairness of revealing each agent's private information. First, we propose a new measure of revealing each agent's private information, which is based on the accuracy of the common estimating method of opponents' utility functions. Next, the negotiation protocol adjusts the number of offers by each agent based on a new measure. This adjustment encourages agents who reveal less private information than other agents to reveal more offers. In the experiments, we compare and investigate the fairness of revealing private information by tournaments among state-of-the-art agents in ANAC2016 using our proposed negotiation protocol. The experimental results demonstrate that our proposed negotiation protocol with the adjustment improves the fairness of the revealed private information.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-289" tabindex="-1" role="dialog"
         aria-labelledby="modal-289-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-289-label">[Abstract] Learning Others&#39; Intentional Models in Multi-Agent Settings Using Interactive POMDPs</h4>
                </div>
                <div class="modal-body">
                    <p>Interactive partially observable Markov decision processes (I-POMDPs) provide a principled framework for planning and acting in a partially observable, stochastic and multi-agent environment, extending POMDPs to multi-agent settings by including models of other agents in the state space and forming a hierarchical belief structure. In order to predict other agents' actions using I-POMDP, we propose an approach that effectively uses Bayesian inference and sequential Monte Carlo (SMC) sampling to learn others' intentional models which ascribe to them beliefs, preferences and rationality in action selection. Empirical results show that our algorithm accurately learns models of other agents and has superior performance when compared to other methods. Our approach serves as a generalized reinforcement learning algorithm that learns other agents' beliefs, and transition, observation and reward functions. It also effectively mitigates the belief space complexity due to the nested belief hierarchy.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-673" tabindex="-1" role="dialog"
         aria-labelledby="modal-673-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-673-label">[Abstract] The Cost of Diversity in Multiwinner Elections</h4>
                </div>
                <div class="modal-body">
                    <p>Multiwinner elections schemes typically focus on the goal of maximizing either excellence or representation. The goal of selecting a diverse winning set usually has a lower priority, or is not considered at all, because any improvement in diversity could come at the cost of excellence or representativeness of the winning set. Programs that increase diversity and inclusion have real-world benefits for organizations that implement them. However, methods such as quotas are sometimes controversial because they can elect candidates that are unqualified. We present a metaheuristic for increasing inclusion, and give experimental results for k-Approval, and k-Borda. Our results show that inclusion can be increased at a relatively low cost to in overall voter satisfaction.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-167" tabindex="-1" role="dialog"
         aria-labelledby="modal-167-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-167-label">[Abstract] District-Based Elections: Contrasting Current, Optimal, and Likely Outcomes</h4>
                </div>
                <div class="modal-body">
                    In many electoral systems, voters are divided into territorial subdivisions for electing members to a legislative body.  Naturally, different partitions may result in different outcomes; gerrymandering (i.e., strategic partitioning into districts) thus potentially affects election results, and has been used for many decades as an election manipulation technique by both major U.S.~political parties. Nevertheless, the United States Supreme Court has never struck down any redistricting plan, as it is difficult to distinguish accidental from intentional manipulation of district borders.

We propose an approach to evaluating likely and less likely results among different redistricting options, as a fundamental sub-problem within the broader goal of identifying remedies for this type of election control.  We examine data from two 2016 elections, for the United States House of Representatives in North Carolina and Ohio. Our analysis shows that while in North Carolina there is evidence that the current district partition is significantly better for the Republican Party, there is little evidence that either party has an advantage due to gerrymandering in Ohio.
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-109" tabindex="-1" role="dialog"
         aria-labelledby="modal-109-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-109-label">[Abstract] Stability and Pareto Optimality in Refugee Allocation Matchings</h4>
                </div>
                <div class="modal-body">
                    <p>We focus on the refugee matching problem---a general ``two-sided matching under preferences'' model with multi-dimensional feasibility constraints that was formalized by Delacretaz, Kominers, and Teytelboym (2016). We propose a taxonomy of stability concepts for the problem; identify relations between them; and show that even for two natural weakenings of the standard stability concept, &nbsp;non-existence and NP-hardness results persist. We then identify several natural weaker stability concepts for which we present a polynomial-time and strategy-proof algorithm that returns a stable matching. We also examine the complexity of computing and {testing} Pareto optimal matchings.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-157" tabindex="-1" role="dialog"
         aria-labelledby="modal-157-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-157-label">[Abstract] Determining acceptable points of view for ranking based argumentation semantics</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">In this paper we consider the following research question: “What are
acceptable points of view for ranking-based argumentation semantics?” To answer this question we introduce a new generic framework that considers a selection function, a ranking on arguments
and a lifting function as its input parameters. We study the different
combinations the instantiation of these parameters yield and thus
demonstrate the modularity of our framework. We introduce a set of
postulates and study their satisfaction for the framework’s different
classes of output.&nbsp;</span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-342" tabindex="-1" role="dialog"
         aria-labelledby="modal-342-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-342-label">[Abstract] Seasonal Goods and Spoiled Milk: Pricing for a Limited Shelf-Life</h4>
                </div>
                <div class="modal-body">
                    <p>We examine the case of items with a limited shelf-life where storing an item (before consumption) may carry a cost to a buyer (or distributor). For example, eggs, milk, or Groupon coupons have a fixed expiry date, and seasonal goods can suffer a decrease in value. We show how this setting contrasts with recent results by Berbeglia et al. for items with infinite shelf-life.</p><p>We prove tight bounds on the seller's profits showing how they relate to the items' shelf-life. We show, counterintuitively, that in our limited shelf-life setting, increasing storage costs can sometimes lead to less profit for the seller which cannot happen when items have unlimited shelf-life. We also provide an algorithm that calculates optimal prices.</p><p>Finally, we examine empirically the relationship between profits and buyer utility as the storage cost and shelf-life duration change, and observe properties, some of which are unique to the limited shelf-life setting.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-612" tabindex="-1" role="dialog"
         aria-labelledby="modal-612-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-612-label">[Abstract] Judgment Aggregation with Rationality and Feasibility Constraints</h4>
                </div>
                <div class="modal-body">
                    <p>I introduce a model of judgment aggregation that allows for an explicit distinction between rationality and feasibility constraints. The former are assumed to be satisfied by the individual agents; the latter must be met by the collective decision returned by the aggregation rule in use. Using this model, I characterise the class of combinations of rationality and feasibility constraints for which the majority rule can guarantee feasible outcomes and I propose several majoritarian aggregation rules that, in some sense, approximate the ideal of the majority when using the majority rule itself is not feasible. Finally, to illustrate the power and flexibility of the model, I show how it can be used to simulate several common voting rules in a simple and elegant manner. This includes the well-known Borda rule, for which finding a natural counterpart in judgment aggregation has long been an elusive quest.<br><br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-553" tabindex="-1" role="dialog"
         aria-labelledby="modal-553-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-553-label">[Abstract] From Individual Goals to Collective Decisions</h4>
                </div>
                <div class="modal-body">
                    <p>Classical rules for collective decision-making often require agents to fully specify their preference or opinion to compute the result. In particular, judgment aggregation rules require each agent to answer a yes/no question on a set of issues and they then output a collective judgment. In this paper we relax this assumption, by letting agents express their goals by means of propositional formulas on a finite set of binary issues. We propose a number of rules for aggregating individual goals into a decision for the group. We adapt axiomatic properties from the literature on Social Choice Theory to our setting, providing a full characterisation for one of our rules. We also study computationally the problem of determining the outcome for the defined rules (i.e., winner determination), showing that the generalisation from fully specified models to individual goals does significantly increase the complexity.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-75" tabindex="-1" role="dialog"
         aria-labelledby="modal-75-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-75-label">[Abstract] Generic Integration of Personality and Mood with Emotions: A Machine Learning Approach</h4>
                </div>
                <div class="modal-body">
                    <p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
  <o:PixelsPerInch>96</o:PixelsPerInch>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>EN-GB</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]-->

<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin:0cm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-fareast-language:EN-US;}
</style>
<![endif]-->



<!--StartFragment-->



<!--EndFragment--></p><p class="MsoNormal">Intelligence is not a self-contained characteristic of an
individual. This point needs to be considered when we design and develop artificially
intelligent agents. Researchers have found that emotion is a critical component
of general intelligence. An intelligent agent should be able to show different
emotional behaviours in different interaction situations. It is widely accepted
that personality and mood play an important role in modulating emotions.
However, current computational accounts of emotion for intelligent agents do not
effectively integrate the notions of personality and mood in the process of
emotion generation. Even if some attempts have been made, those are based on
designer assumptions and user-defined rules. In this paper, we present our
novel supervised machine learning approach to train a network of emotions
integrating the factors of personality and mood, that provides a high and
robust prediction accuracy. As a secondary contribution, we also present our data collection technique that can be utilised in the training and evaluation
of emotion models.<o:p></o:p></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-397" tabindex="-1" role="dialog"
         aria-labelledby="modal-397-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-397-label">[Abstract] Constraint Composite Graph-Based Lifted Message Passing for Distributed Constraint Optimization Problems</h4>
                </div>
                <div class="modal-body">
                    <p>The Distributed Constraint Optimization Problem (DCOP) offers a powerful approach for the description and resolution of cooperative multi-agent problems. In this model, a group of agents coordinates their actions to optimize a global objective function, taking into account their local preferences. <br>In the majority of the DCOP algorithms, agents operate onto three main graphical representations of the problem: (a) the constraint graph, (b) the pseudo-tree, or (c) the factor graph. In this paper, we introduce the&nbsp; Constraint Composite Graph (CCG) for DCOPs, an alternative graphical representation onto which agents can coordinate their assignment to solve the distributed problem. We propose a novel variant of Max-sum, called CCG-Max-sum which is applied to CCGs, and demonstrate the effectiveness of CCG-Max-sum on DCOP benchmarks based on several network topologies.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-376" tabindex="-1" role="dialog"
         aria-labelledby="modal-376-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-376-label">[Abstract] Surrogate Difference Evaluations with Limited Peer to Peer Communications</h4>
                </div>
                <div class="modal-body">
                    <p>Decentralized Multiagent Systems (MAS) have distinct advantages over single agent systems including robustness, scalability and error tolerance. Credit assignment is a key component in empowering MAS and techniques such as Difference Evaluations have been used successfully to train MAS in a wide variety of applications. This success depends on frequent, if not continuous, exchange of data in the system. However, what level of success occurs when communication is severely limited?&nbsp; This paper presents the effects of limited communication on system performance when agents learn using Difference Evaluations within a Cooperative Co-Evolutionary Algorithm (CCEA). For simulation and evaluation purposes, the CCEA utilizes a barrier free Underwater Multiagent Exploration Domain (UMED).&nbsp; Communication is limited below the surface of the water, but not above the surface. Our results show a system performance degradation of less than 10% when system training utilized Difference Evaluations experiencing limited communications (99.6% reduction in communication ability) when compared with full communication within the domain.&nbsp;&nbsp; Additionally, we show that system performance increased when the system is trained utilizing Global Evaluations under limited communications when compared with full communication within the domain.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-751" tabindex="-1" role="dialog"
         aria-labelledby="modal-751-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-751-label">[Abstract] Ex-post IR dynamic auctions with cost-per-action payments</h4>
                </div>
                <div class="modal-body">
                    <p>Consider a repeated auction between one seller and many buyers, where each buyer only has an estimation of her value in each period until she actually received the item in that period. The seller is allowed to conduct a dynamic auction to sell the items but must guarantee ex-post individual rationality. In other words, if the buyer realized that her value of the item she just received is zero, she does not need to pay anything. One important application of this model is the cost-per-action (or pay-per-action) auctions in online advertising, where the buyers (advertisers) are charged only when some user clicks their ads, goes to their websites, and makes some meaningful actions (e.g., buys something). Unlike the clicks on the ads, these actions are private information only observable by the buyers (advertisers). Hence they may have incentives to misreport the user actions, because they can pay less under cost-per-action payment schemes with ex-post individual rationality guarantees.&nbsp;</p><p>In this paper, we introduce a novel structure that we call credit accounts to enable a general reduction from any incentive compatible and ex-ante individually rational dynamic auction to an approximately incentive compatible and ex-post individually rational dynamic auction with credit accounts. Our reduction can obtain stronger individual rationality guarantees at of the cost of weaker incentive compatibility. Surprisingly, our reduction works without making any common knowledge assumptions. Finally, as a complement to our reduction, we prove that there is no non-trivial auction that is exactly incentive compatible and ex-post individually rational in this setting.&nbsp;</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-115" tabindex="-1" role="dialog"
         aria-labelledby="modal-115-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-115-label">[Abstract] Price-based Online Mechanisms for Settings with Uncertain Future Procurement Costs and Multi-Unit Demand</h4>
                </div>
                <div class="modal-body">
                    <p>We examine the use of online mechanism design in settings where consumers have multi-unit demand, goods are procured and allocated over time, and future procurement costs are uncertain and only become known at the time of allocation. An important application with such characteristics is demand response, where electricity wholesale prices depend on overall demand and the availability of renewables. We formulate this as a mechanism design problem and focus specifically on the property that the mechanism does not revoke any allocated items. For this setting, we characterise a class of price-based mechanisms that guarantee dominant-strategy incentive compatibility, individual rationality, and no cancellation. We present three specific such mechanisms in this domain and evaluate them in an electric vehicle charging setting. Using extensive numerical simulations, we show that a mechanism based on the first-come first-serve principle performs well in settings where future procurement costs can be estimated reliably or supply is very tight, while a responsive mechanism performs very well when the estimated procurement costs are highly uncertain and supply is not as tight. We moreover show that a well-defined price-based mechanism can lead to high profits for the operator of the mechanism in many real-world situations.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-638" tabindex="-1" role="dialog"
         aria-labelledby="modal-638-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-638-label">[Abstract] Truthful Mechanisms for Interval Scheduling with Applications to Cloud Computing</h4>
                </div>
                <div class="modal-body">
                    <p><font face="Times New Roman, serif"><span style="font-size: 16px;">Motivated by cloud computing, we study a market-based approach for job scheduling on multiple machines where users have hard deadlines and prefer earlier completion times. In our model, completing a job provides a benefit equal to its present value, i.e., the value discounted to the time when the job finishes. Users submit job requirements to the cloud provider who non-preemptively schedules jobs to maximize the social welfare, i.e., the sum of present values of completed jobs. Using a simple and fast greedy algorithm, we obtain a (2-b</span><span style="font-size: 16px;">)/(1-b) approximation to the optimal schedule, where 0 &lt; b &lt; 1 is the discount factor shared by all jobs. Building on our approximation algorithm, we construct a pricing rule to incentivize users to truthfully report all job requirements.</span></font></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-85" tabindex="-1" role="dialog"
         aria-labelledby="modal-85-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-85-label">[Abstract] Evaluating the Stability of Non-Adaptive Trading in Continuous Double Auctions</h4>
                </div>
                <div class="modal-body">
                    <p>The continuous double auction (CDA) is the predominant mechanism in modern securities markets. Despite much prior study of CDA strategies, fundamental questions about the CDA remain open, such as: (1) to what extent can outcomes in a CDA be accurately modeled by optimizing agent actions over only a simple, non-adaptive policy class; and (2) when and how can a policy that conditions its actions on market state deviate beneficially from an optimally parameterized, but simpler, policy like Zero Intelligence (ZI). To investigate these questions, we present an experimental comparison of the strategic stability of policies found by reinforcement learning (RL) over a massive space, or through empirical Nash-equilibrium solving over a smaller space of non-adaptive, ZI policies. Our findings indicate that in a plausible market environment, an adaptive trading policy can deviate beneficially from an equilibrium of ZI traders, by conditioning on signals of the likelihood a trade will execute or the favorability of the current bid and ask. Nevertheless, the surplus earned by well-calibrated ZI policies is empirically observed to be nearly as great as what a deviating reinforcement learner could earn, using a much larger policy space. This finding supports the idea that it is reasonable to use equilibrated ZI traders in studies of CDA market outcomes.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-147" tabindex="-1" role="dialog"
         aria-labelledby="modal-147-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-147-label">[Abstract] Max-min Fair Allocation for the Combination of Indivisible and Divisible Goods</h4>
                </div>
                <div class="modal-body">
                    <p>Fair allocation&nbsp; is a classic problem in economics and computer science. Its application scenarios include inheritance settlement, border dispute resolution, computing resource sharing and so on. Although the problem has attracted much attention, the existing work either only focuses on the fair allocation of indivisible goods or only focuses on the fair allocation of divisible goods, but not both. However, in real applications, the allocated goods set may simultaneously include indivisible goods and divisible goods, e.g., the allocated inheritance may include indivisible houses and divisible lands. The combination of indivisible goods and divisible goods requires us to consider how to coordinate the allocations of indivisible goods and divisible goods, which has not been discussed in the existing work. Therefore, this paper investigates the more general case of fair allocation problem, where the allocated goods set consists of both indivisible goods and divisible goods. In the study, we focus on the max-min fairness, i.e., maximizing the minimum utility of any agent. First, we present a mixed-integer linear programming formulation to compute the optimal allocation strategy. Second, because the problem is NP-hard, we propose an approximation algorithm that runs in polynomial time and has provable performance guarantee. The algorithm is composed of three phases: i) we divide the divisible goods into n equal-utility virtual goods, where n is the agent number; ii) we regard the virtual goods as indivisible and fairly allocate the indivisible goods and virtual goods; iii) we adjust the allocation of divisible goods to improve the allocation strategy. Experiments conducted on real data show that the approximation algorithm produces near-optimal solutions when the goods number or the agent number is large enough.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-32" tabindex="-1" role="dialog"
         aria-labelledby="modal-32-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-32-label">[Abstract] Autonomous Object-Oriented Curriculum Generation for Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <style type="text/css">
p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 14.0px; font: 12.0px Courier; color: #000000; -webkit-text-stroke: #000000}
span.s1 {font-kerning: none}
span.s2 {text-decoration: underline ; font-kerning: none}
</style>


<p class="MsoNormal">Autonomously learning a complex task takes a very long time for Reinforcement Learning (RL) agents.&nbsp;<span style="font-size: 12pt;">One way to learn faster is by dividing a complex task into several simple subtasks and organizing them in a Curriculum that guides Transfer Learning (TL) methods to reuse knowledge in a convenient &nbsp;sequence.&nbsp;</span><span style="font-size: 12pt;">&nbsp;However, previous works do not take into account the TL method to build specialized Curricula, leaving the burden of a careful subtask selection to a human.&nbsp;</span><span style="font-size: 12pt;">We here rely on Object-Oriented task descriptions to guide both the Curriculum generation and knowledge reuse procedures, autonomously building object-based Curricula.&nbsp;</span><span style="font-size: 12pt;">We also propose a novel procedure for autonomously dividing the target task into simpler ones under minimal human supervision.&nbsp;</span><span style="font-size: 12pt;">Our experiments show that our proposal achieves a better performance using both manually given and autonomously generated subtasks when compared to the state-of-the-art technique in two different domains.</span></p><p class="MsoNormal"><o:p></o:p></p><style>
<!--
 /* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073786111 1 0 415 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
@page WordSection1
	{size:595.0pt 842.0pt;
	margin:72.0pt 72.0pt 72.0pt 72.0pt;
	mso-header-margin:35.4pt;
	mso-footer-margin:35.4pt;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-632" tabindex="-1" role="dialog"
         aria-labelledby="modal-632-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-632-label">[Abstract] Multi-Agent Distributed Lifelong Learning for Collective Knowledge Acquisition</h4>
                </div>
                <div class="modal-body">
                    <p>Lifelong machine learning methods acquire knowledge over a series of consecutive tasks, continually building upon their experience.&nbsp; Current lifelong learning algorithms rely upon a single learning agent that has centralized access to all data. In this paper, we extend the idea of lifelong learning from a single agent to a network of multiple agents that collectively learn a series of tasks. Each agent faces some (potentially unique) set of tasks; the key idea is that knowledge learned from these tasks may benefit other agents trying to learn different (but related) tasks.&nbsp; Our Collective Lifelong Learning Algorithm (CoLLA) provides an efficient way for a network of agents to share their learned knowledge in a distributed and decentralized manner, while preserving the privacy of the locally observed data. We provide theoretical guarantees for robust performance&nbsp; of the algorithm and empirically demonstrate that CoLLA outperforms existing approaches for distributed multi-task learning on a variety of data sets.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-38" tabindex="-1" role="dialog"
         aria-labelledby="modal-38-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-38-label">[Abstract] Parallel Transfer Learning: Accelerating Reinforcement Learning in Multi-Agent Systems</h4>
                </div>
                <div class="modal-body">
                    <p>Many large-scale systems require autonomous control to manage their inherent complexity, scale and variability.&nbsp; Reinforcement Learning (RL) approaches are frequently used in such systems to learn the behaviours that best suit the system's operating environment. However, learning can take a significant amount of time during which an RL system's performance is necessarily suboptimal. To minimize the periods of suboptimal performance, learning experiences and interactions should be used as efficiently as possible.&nbsp;</p><p>Transfer learning (TL), a method of reusing knowledge which has been gained in one task to improve the performance in another, has been used to speed up learning in single RL agent systems. However, TL requires learning on a source task to complete before it can be transferred to a target task, i.e., transfer is done offline. In multi-agent RL, agents are learning simultaneously so any potentially useful transfers need to be done online, before learning has necessarily converged. Transfers should also be multi-directional, i.e., any agent should be able to act both as a source and as a target.</p><p>This paper presents Parallel Transfer Learning (PTL), a technique for online transfer of knowledge in multi-agent RL systems, which allows the source of learnt information and the target task to run concurrently. PTL proposes multiple methods for selecting the knowledge to be transferred, frequency and size of transfers, and multiple methods for knowledge integration into the target task. We evaluate PTL in three canonical RL examples: Cart Pole, Mountain Car, and Co-operative Predator Prey Pursuit.&nbsp;</p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-706" tabindex="-1" role="dialog"
         aria-labelledby="modal-706-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-706-label">[Abstract] A Closed-Form Characterization of Buyer Signaling Schemes in Monopoly Pricing</h4>
                </div>
                <div class="modal-body">
                    <p>We consider a setting where a revenue maximizing monopolist sells a single item to a buyer. A mediator first collects the buyer's value and can reveal extra information about the buyer's value by sending signals. Mathematically, a signal scheme can be thought of as a decomposition of the prior value distribution into a linear combination of posterior value distributions, and based on each of them, the monopolist separately posts a price. According to the theory of Bayesian persuasion, a well designed signal scheme can lead to utility improvements for both the monopolist and the buyer.</p><p>We put forward a novel technique to analyze the effects of signal schemes of the mediator. Using this technique, we are able to construct explicitly a closed-form solution, and thus characterize the set of seller-buyer utility pairs achievable by any signal scheme, for any prior type distribution. Our result generalizes a well-known result by Bergemann et. al., who derive a characterization for the same problem but only restricted to the discrete distribution case.<br></p><p>Similar to the result derived by Bergermann et. al., we show that the set of seller and buyer utility pairs achievable form a triangle: any point within the triangle can be achieved by an explicitly constructed signal scheme and any point outside the triangle cannot be achievable by any such scheme. Our result is obtained by establishing the endpoints of the triangle: one corresponds to the point where the buyer obtains the highest utility among all schemes, another corresponds to the point where the buyer obtains zero utility and the seller has the lowest possible revenue, and the third corresponds to the point where the buyer has zero utility while the seller extracts full social surplus. We then prove that the triangle described fully characterizes all possible&nbsp; signal schemes.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-279" tabindex="-1" role="dialog"
         aria-labelledby="modal-279-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-279-label">[Abstract] On the Weakness of Strong Stackelberg Equilibrium for Security Games</h4>
                </div>
                <div class="modal-body">
                    <p>Strong Stackelberg Equilibrium (SSE) has become a standard solution concept in various security game applications. SSE is built upon the optimistic tie-breaking rule that the follower breaks ties in favor of the leader. The intuition behind adopting SSE in security games is the widely acknowledged assumption that the defender can induce the attacker to choose a preferred action by making an infinitesimal adjustment to her strategy and achieve an expected utility that is arbitrarily close to the prescribed value in SSE. Unfortunately, in security games with resource assignment constraints, it is possible that the defender cannot induce the desired outcome, and hence the results claimed in the security game literature may be overly optimistic. To overcome this issue, this paper provides (i) a formal definition of the utility guarantee of a defender strategy, and examples showing that the guaranteed utility of an SSE strategy can be much lower than the expected utility of SSE (claimed to be guaranteed in the security game literature); (ii) a general algorithmic operationalization of Inducible Stackelberg Equilibrium (ISE) based on the notion of inducibility (von Stengel and Zamir, 2004), where we prove that ISE always exists and leads to the highest guaranteed utility for the defender; (iii) formal comparisons between ISE and SSE together with a polynomial-time reduction from computing an ISE to computing an SSE; (iv) a novel algorithm CHASE to compute ISE for realistic-sized instances with column generation and heuristic bounds; and (v) extensive experimental evaluation unveiling significant overoptimism and sub-optimality of SSE.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-485" tabindex="-1" role="dialog"
         aria-labelledby="modal-485-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-485-label">[Abstract] Lenient Multi-Agent Deep Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    Much of the success of single agent deep reinforcement learning (DRL) in recent years can be attributed to the use of experience replay memories (ERM), which allow Deep Q-Networks (DQNs) to be trained efficiently through sampling stored state transitions. However, care is required when using ERMs for multi-agent deep reinforcement learning (MA-DRL), as stored transitions can become outdated because agents update their policies in parallel (Foerster et al., 2017). In this work we apply leniency (Panait et al., 2006)  to MA-DRL. Lenient agents map state-action pairs to decaying temperature values that control the amount of leniency applied towards negative policy updates that are sampled from the ERM. This introduces optimism in the value-function update, and has been shown to facilitate cooperation in tabular fully-cooperative multi-agent reinforcement learning problems. We evaluate our Lenient-DQN (LDQN) empirically against the related Hysteretic-DQN (HDQN) algorithm (Omidshafiei et al., 2017) as well as a modified version we call scheduled-HDQN, that uses average reward learning near terminal states. Evaluations take place in extended variations of the Coordinated Multi-Agent Object Transportation Problem (CMOTP) (Busoniu et al., 2010) which include fully-cooperative sub-tasks and stochastic rewards. We find that LDQN agents are more likely to converge on the optimal policy in a stochastic reward CMOTP compared to standard and scheduled-HDQN agents.<br>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-168" tabindex="-1" role="dialog"
         aria-labelledby="modal-168-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-168-label">[Abstract] More complexity results about reasoning over (m)CP-nets</h4>
                </div>
                <div class="modal-body">
                    <p><span id="ctl00_cph_SubmissionSummary_AbstractText" style="font-size:Small;">Aggregating preferences over combinatorial domains has several applications in AI. Due to the exponential nature of combinatorial preferences, compact representations are needed, and (m)CP-nets are among the most studied formalisms. Unlike CP-nets, which received an extensive complexity analysis, mCP-nets, as mentioned several times in the literature, lacked such a thorough characterization. In fact, an initial complexity analysis for mCP-nets was carried out only recently. In this paper, we further investigate the complexity of mCP-nets. In particular, we prove the \Sigma^P_3-completeness of the existence of Max optimal outcomes. Furthermore, we prove that various tasks known to be feasible in polynomial time are actually P-complete. This shows that these problems are inherently sequential, and hence they cannot benefit from highly parallel computation.</span><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-116" tabindex="-1" role="dialog"
         aria-labelledby="modal-116-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-116-label">[Abstract] Multi-Objective Distributed Pseudo-tree Optimization</h4>
                </div>
                <div class="modal-body">
                    <p>Many real world optimization problems involve multiple criteria that should be considered separately and optimized simultaneously. Multi-Objective Distributed Constraint Optimization Problem (MO-DCOP) is a fundamental problem to formalize various multi-agent applications and is the extension of a mono-objective DCOP where the goal is to find the Pareto front. In MO-DCOPs, it is well known that the Pareto front is exponential in the size of the problem, leading to agents having to exchange an exponential amount of information. In this paper, we develop a novel MO-DCOP algorithm based on dynamic programming techniques which guarantees to find the complete Pareto front. Furthermore, we propose a bounded version of our algorithm which can reduce the size of the messages using an adjustable parameter. In our experiments, we propose a new benchmark for MO-DCOPs based on a sensor network problem and show that (i) our complete algorithm outperforms the state-of-the-art algorithm and (ii) the bounded version of our algorithm offers a significant reduction in the size of messages while still guaranteeing to find a subset of the Pareto front.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-353" tabindex="-1" role="dialog"
         aria-labelledby="modal-353-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-353-label">[Abstract] Multi-Agent Path Finding with Deadlines</h4>
                </div>
                <div class="modal-body">
                    <p>We study multi-agent path-planning problems in scenarios such as evacuation where agents have to reach their goal locations within a deadline. Specifically, we study the problem of multi-agent path finding with deadlines (MAPF-DL), where all agents try to move from their given start locations to their given goal locations within a given deadline, without colliding with each other. The task is to maximize the number of agents that can reach the goal locations within the deadline. We show that MAPF-DL and some of its generalizations are NP-hard to solve optimally. We present two classes of optimal MAPF-DL algorithms, one based on the reduction to network-flow problems and a subsequent compact ILP formulation of the multi-valued decision diagrams and one based on novel combinatorial search techniques. Our empirical results demonstrate that these solvers scale well and each performs the best in different scenarios.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-205" tabindex="-1" role="dialog"
         aria-labelledby="modal-205-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-205-label">[Abstract] Parameterized Complexity of Multiwinner Determination: An Effort Towards Fixed-Parameter Tractability</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">We study winner determination for the three prevalent </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-committee
selection rules Minimax approval, Proportional approval and Ap-
proval Chamberlin-Courant’s voting. It is known that winner de-
termination for these rules is NP-hard. Moreover, parameterized
complexity of the problem has also been studied with respect to
some natural parameters such as the number of candidates or the
number of votes. However, there are still numerous parameteriza-
tions that have not been considered. In this paper, we revisit the
parameterized complexity of winner determination for these three
rules by considering several important parameters. In addition, we
study various combinations of single parameters and structural pa-
rameters, aiming at detecting more parameterizations leading to
 xed-parameter tractable (FPT) results.&nbsp;</span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-172" tabindex="-1" role="dialog"
         aria-labelledby="modal-172-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-172-label">[Abstract] Proportionality and Strategyproofness in Multiwinner Elections</h4>
                </div>
                <div class="modal-body">
                    <p>Multiwinner voting rules can be used to select a fixed-size committee from a larger set of candidates.&nbsp;We consider approval-based committee rules, which allow voters to approve or disapprove candidates. In this setting, several voting rules such as Proportional Approval Voting (PAV) and Phragmén's rules have been shown to produce committees that are proportional, in the sense that they proportionally represent voters' preferences; all of these rules are strategically manipulable by voters. On the other hand, a generalisation of Approval Voting gives a non-proportional but strategyproof voting rule. We show that there is a fundamental tradeoff between these two properties: we prove that no multiwinner voting rule can simultaneously satisfy a weak form of proportionality (a weakening of justified representation) and a weak form of strategyproofness. Our impossibility is obtained using a formulation of the problem in propositional logic and applying SAT solvers; a human-readable version of the computer-generated proof is obtained by extracting a minimal unsatisfiable set (MUS). We also discuss several related axiomatic questions in the domain of committee elections.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-464" tabindex="-1" role="dialog"
         aria-labelledby="modal-464-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-464-label">[Abstract] Ravel: A Microservice-based Hybrid Platform for Multi-Party Chat-Oriented Conversations</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9pt; font-family: LinLibertineT;">This paper presents Ravel, a microservice-based hybrid platform
aimed to integrate natural language understanding components
with orchestration components of dialogues between human beings
and agents. Ravel enables the specification of&nbsp;</span><span style="font-family: LinLibertineT; font-size: 12px;">(social) conversations</span><span style="font-size: 9pt; font-family: LinLibertineT;">&nbsp;norms,&nbsp;</span><span style="font-family: LinLibertineT; font-size: 12px;">using deontic logic, for use in contexts where multiple agents and human users are conversing in natural language.</span><span style="font-size: 9pt; font-family: LinLibertineT;">&nbsp;We demonstrate the usefulness and versatility of
Ravel using the example of fi</span><span style="font-size: 9pt; font-family: LinLibertineTI;">nch</span><span style="font-size: 9pt; font-family: LinLibertineT;">, a real-time chat-based finance
adviser system designed as a chat group of five participants: four
collaborative chatbots with two different roles (mediator and expert)
and a human or chatbot user. To orchestrate fi</span><span style="font-size: 9pt; font-family: LinLibertineTI;">nch </span><span style="font-size: 9pt; font-family: LinLibertineT;">conversations
around 15&nbsp;</span><span style="font-size: 9pt; font-family: LinLibertineT;">conversation norms based on deontic modes are successfully applied by&nbsp;</span><span style="font-size: 9pt; font-family: LinLibertineTI;">Ravel&nbsp;</span><span style="font-size: 9pt; font-family: LinLibertineT;">even in the context of several simultaneous human users.&nbsp;</span><span style="font-size: 9pt; font-family: LinLibertineT;">&nbsp;</span><br></p></div></div></div>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-104" tabindex="-1" role="dialog"
         aria-labelledby="modal-104-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-104-label">[Abstract] Hybrid Evolutionary Search and Policy Transfer for Playing RoboCup Keep-Away</h4>
                </div>
                <div class="modal-body">
                    <p>This research evaluates comparative methods for the adaptation and transfer of multi-agent behaviors (policies) across increasingly complex RoboCup keep-away tasks.&nbsp; Reinforcement Learning (RL) and evolutionary search methods are comparatively evaluated for keep-away behavior adaptation and subsequent policy transfer to more complex tasks. Policy transfer is where keep-away behaviors are first evolved in&nbsp; a source task and then transferred for further adaptation in more complex target tasks.&nbsp; Policy transfer is coupled with keep-away behaviors adapted by HyperNEAT (directed by objective based search, novelty search or hybridized objective novelty search) or with the SARSA or Q-Learning RL methods.&nbsp; Results indicate that policy transfer coupled with HyperNEAT directed by hybridized objective-novelty is most effective across increasingly complex keep-away tasks.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-121" tabindex="-1" role="dialog"
         aria-labelledby="modal-121-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-121-label">[Abstract] A Deeper Look at Experience Replay</h4>
                </div>
                <div class="modal-body">
                    <p>Experience replay plays an important role in the success of deep reinforcement learning (RL) by helping stabilize the neural networks. It has become a new norm in deep RL algorithms. In this paper, however, we showcase that varying the size of the experience replay buffer can hurt the performance even in very simple tasks. The size of the replay buffer is actually a hyper-parameter which needs careful tuning. Moreover, our study of experience replay leads to the formulation of the Combined DQN algorithm, which can significantly outperform primitive DQN in some tasks.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-339" tabindex="-1" role="dialog"
         aria-labelledby="modal-339-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-339-label">[Abstract] Equilibrium Refinement in Security Games with Arbitrary Scheduling Constraints</h4>
                </div>
                <div class="modal-body">
                    <p>Significant research effort in security games has focused in devising strategies that perform well even when the attacker deviates from optimal (rational) behavior. In most of these frameworks, a price needs to be paid to ensure robustness against this unpredictability. However, equilibrium refinement is an attractive alternative to boost solution robustness at no cost even though it has not received as much attention in security game literature. In this framework, resources are strategically allocated to secure an optimal outcome against a rational adversary while simultaneously protecting other targets to ensure good outcomes against boundedly rational or constrained attackers. Unfortunately, existing approaches for equilibrium refinement in security games cannot effectively address scheduling constraints that arise frequently in real-world applications. In this paper, we aim to fill this gap and make several key contributions. First, we show that existing approaches for equilibrium refinement can fail in the presence of scheduling constraints. Second, we investigate the properties of the best response of the attacker. Third, we leverage these properties to devise novel iterative algorithms to compute the optimally refined equilibrium, with polynomially many calls to an LP oracle for zero-sum games. Finally, we conduct extensive experimental evaluations that showcase i) the superior performance of our approach in the face of a boundedly rational attacker and ii) the attractive scalability properties of our algorithm that can solve realistic-sized instances.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-344" tabindex="-1" role="dialog"
         aria-labelledby="modal-344-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-344-label">[Abstract] Pre-training Neural Networks with Human Demonstrations for Deep Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p>Deep reinforcement learning (deep RL) has achieved superior performance in complex sequential tasks by using a deep neural network as its function approximator and by learning directly from raw images. A drawback of using raw images is that deep RL must learn the state feature representation from the raw images in addition to learning a policy. As a result, deep RL can require a prohibitively large amount of training time and data to reach reasonable performance, making it difficult to use deep RL in real-world applications, especially when data is expensive. In this work, we speed up training by addressing half of what deep RL is trying to solve --- learning features. Our approach is to learn some of the important features by pre-training deep RL network's hidden layers via supervised learning using a small set of human demonstrations. We empirically evaluate our approach using deep Q-network (DQN) and asynchronous advantage actor-critic (A3C) algorithms on the Atari 2600 games of Pong, Freeway, and Beamrider. Our results show that initializing a deep RL network with a pre-trained model provides a significant improvement in training time even when pre-training from a small number of human demonstrations.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-162" tabindex="-1" role="dialog"
         aria-labelledby="modal-162-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-162-label">[Abstract] A Transitive Trust based Incentive Scheme for Crowdsourcing</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>Using gold standard tasks is a popular technique in crowdsourcing to incentivize the workers based on an estimate of the quality of their work. However, this approach is inefficient in large scale crowdsourcing because it requires an increasing number of gold tasks with known answers. Reusing gold tasks for many workers carries a risk that they are identified by colluding workers. Assigning gold tasks to workers also wastes the task budget of the requester.</p><p><br></p><p>Techniques based solely on consistency with peer reports, such as output agreement, do not require gold tasks but offer weaker incentive compatibility and are vulnerable to collusion. We propose a simple mechanism that combines the advantage of both these approaches by continuously expanding a small pool of initial gold tasks using a transitive notion of trust. The mechanism works in the common crowdsourcing settings where every worker solves multiple micro-tasks and guarantees dominant strategy incentive compatibility. We demonstrate the practical applicability of the mechanism in incentivizing the workers through simulations and experiments on Mechanical Turk.</p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-601" tabindex="-1" role="dialog"
         aria-labelledby="modal-601-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-601-label">[Abstract] Incrementally Grounding Expressions for Spatial Relations between Objects</h4>
                </div>
                <div class="modal-body">
                    <p>Recognizing, reasoning about, and providing understandable descriptions of spatial relations between domain objects is an important task for robots interacting with and assisting humans. Prepositions are often used to describe such spatial relations, but it is difficult to equip a robot with comprehensive representations of these prepositions. This paper describes an architecture for incrementally learning and revising the grounding of spatial relations between objects. Specifically, Answer Set Prolog, a declarative language, is used to represent and reason with incomplete knowledge that includes prepositional relations between objects in a scene. A generic grounding of prepositions corresponding to spatial relations, human input (when available), and non-monotonic logical inference with this knowledge, are used to infer spatial relations in 3D point clouds of given scenes, incrementally acquiring and revising a specialized grounding of spatial relations and learning the level of trust associated with the two groundings. This architecture is illustrated and evaluated on a benchmark dataset of tabletop images and on simulated scenes of furniture.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-110" tabindex="-1" role="dialog"
         aria-labelledby="modal-110-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-110-label">[Abstract] Generalizing Top Trading Cycles for Housing Markets with Fractional Endowments</h4>
                </div>
                <div class="modal-body">
                    <p>The housing market setting constitutes a fundamental model of exchange economies of goods. Most of the work concerning housing markets does not cater for randomized assignments or allocation of time-shares. Recently, house allocation with fractional endowment of houses was considered by Athanassoglou and Sethuraman (2011) who posed the open problem of generalizing Gale's Top Trading Cycles (TTC) algorithm for fractional endowments. In this paper, we present a generalization of TTC called FTTC that is polynomial-time as well as core stable and Pareto optimal with respect to stochastic dominance. For the standard setting in which each agent owns one discrete house, FTTC coincides with a state of the art strategyproof mechanism for housing markets with discrete endowments and weak preferences. We show that FTTC satisfies a maximal set of desirable properties by proving two impossibility theorems. One of the theorems implies several impossibility results in the literature.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-635" tabindex="-1" role="dialog"
         aria-labelledby="modal-635-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-635-label">[Abstract] Voting with Ties: Strong Impossibilities via SAT Solving</h4>
                </div>
                <div class="modal-body">
                    <div>Voting rules allow groups of agents to aggregate their preferences in order to reach joint decisions. The Gibbard-Satterthwaite theorem, a seminal result in social choice theory, implies that, when agents have <i>strict</i> preferences, all anonymous, Pareto-optimal, and <i>single-valued</i> voting rules can be strategically manipulated. In this paper, we consider multi-agent voting when there can be ties in the preferences as well as in the outcomes. These assumptions are extremely natural--especially when there are large numbers of alternatives--and enable us to prove much stronger results than in the overly restrictive setting of strict preferences. In particular, we show that <i>(i)</i> all anonymous Pareto-optimal rules where ties are broken according to the preferences of a chairman or by means of even-chance lotteries are manipulable, and that <i>(ii)</i> all pairwise Pareto-optimal rules are manipulable, no matter how ties are broken. These results are proved by reducing the statements to finite--yet very large--problems, which are encoded as formulas in propositional logic and then shown to be unsatisfiable by a SAT solver. We also extracted human-readable proofs from minimal unsatisfiable cores of the formulas in question, which were in turn verified by an interactive higher-order theorem prover.</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-736" tabindex="-1" role="dialog"
         aria-labelledby="modal-736-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-736-label">[Abstract] Learning Curriculum Policies for Reinforcement Learning</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">Curriculum learning in reinforcement learning is a training methodology that seeks to speed up learning of a difficult target task, by
first training on a series of simpler tasks and transferring the knowledge acquired to the target task. Automatically choosing a sequence
of such tasks (i.e. a </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineTI'"><i>curriculum</i></span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">) is an open problem that has been the
subject of much recent work in this area. Most existing approaches
for automated curriculum design have typically relied on heuristics
to guide the selection of source tasks. In this paper, we explore a
principled method for curriculum design that learns a more general
representation of a curriculum: a </span><span style="font-size: 9.000000pt; font-family: 'LinLibertineTI'"><i>curriculum policy</i></span><span style="font-size: 9.000000pt; font-family: 'LinLibertineT'">. We show that
learning a curriculum policy has several advantages over simply
learning a curriculum, and examine different ways of representing
such a policy. Finally, we evaluate the effectiveness of these curriculum policies for producing curricula for multiple agents in a
gridworld testbed domain.&nbsp;</span></p>
				</div>
			</div>
		</div>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-414" tabindex="-1" role="dialog"
         aria-labelledby="modal-414-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-414-label">[Abstract] Feasible Negotiation Procedures for Multiple Interdependent Negotiations</h4>
                </div>
                <div class="modal-body">
                    <p>In an agent society, agents usually have different knowledge and goals and perform differently in order to achieve their individual or joint goals. Agent negotiation provides an effective solution to help agents reach agreements on their future behaviours in the society to guarantee their goals can be achieved successfully. In an agent society, agents may need to conduct Multiple Interdependent Negotiations (MIN), with different opponents and for different purposes, in order to achieve a goal. By considering the complexity of negotiation environments, interdependencies, opponents and issues in the agent society, to efficiently conduct MIN is a challenging research issue. To the best of authors' knowledge, most of the state-of-art work primarily focuses on the single negotiation scenario and tries to propose sophisticated negotiation protocols and strategies to help individual agents to succeed in the single negotiation. However, very little work has been done with consideration of interdependencies and trade-offs among multiple negotiations, so as to help both individual agents as well as the agent society, to increase their welfare. This paper promotes the research on agent negotiations from the single negotiation level to the multiple negotiations level. To effectively conduct MIN in an agent society, this paper proposes three feasible negotiation procedures, which attempt to conduct MIN in a successive way, in a concurrent way, and in a clustered way by considering different negotiation situations, respectively. A simulated agent society is built to test the proposed negotiation procedures with random experimental settings. According to the experimental results, the successive negotiation procedure produces the highest time efficiency, the concurrent negotiation procedure promises the highest profits and success rates, and the clustered negotiation procedure provides a well-balanced solution between the negotiation efficiency and effectiveness.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-549" tabindex="-1" role="dialog"
         aria-labelledby="modal-549-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-549-label">[Abstract] Conflict-Based Search with Optimal Task Assignment</h4>
                </div>
                <div class="modal-body">
                    <p>We consider a variant of the Multi-Agent Path-Finding problem that seeks both task assignments and collision-free paths for a set of agents navigating on a graph, while minimizing the sum of costs of all agents. Our approach extends Conflict-Based Search (CBS), a framework that has been previously used to find collision-free paths for a given fixed task assignment. Our key ideas are to operate on a search forest rather than a search tree and to create the forest on demand, avoiding the factorial explosion of all possible task assignments. We show that our new algorithm, CBS-TA, is complete and optimal. The CBS framework allows us to extend our method to ECBS-TA, a bounded suboptimal version. We provide extensive empirical results comparing CBS-TA to task assignment followed by CBS, Conflict-Based Min-Cost-Flow (CBM), and an integer linear program (ILP) solution, demonstrating the advantages of our algorithm. Our results highlight a significant advantage in jointly optimizing the task assignment and path planning for very dense cases compared to the traditional method of solving those two problems independently. For large environments with many robots we show that the traditional approach is reasonable, but that we can achieve similar results with the same runtime but stronger suboptimality guarantees.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-500" tabindex="-1" role="dialog"
         aria-labelledby="modal-500-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-500-label">[Abstract] Trend-Following Trading Strategies and Financial Market Stability</h4>
                </div>
                <div class="modal-body">
                    <p>We describe an approach to studying financial market stability, through a combination of agent-based modeling and game-theoretic reasoning. We employ a high-fidelity simulator of financial market environments to generate data about candidate strategy profiles, and identify equilibria over heuristic trading strategies from a game model induced from that data. This approach has been employed in studies of various issues in algorithmic trading, but qualitative extensions are required to address questions of market stability. The key idea is to incorporate incomplete information about common components of value, so that agents are incentivized to learn from market information. This provides a transmission path for market shocks, which we demonstrate through a scenario in trend following. The presence of trend followers, agents that continue price trends rather than oppose them, is an economic consequence of delayed market access for background traders. We find that trend following improves price discovery and reduces volatility, metrics often associated with stable markets, but counterproductively makes the market less stable.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-510" tabindex="-1" role="dialog"
         aria-labelledby="modal-510-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-510-label">[Abstract] Complexity of Shift Bribery in Iterative Elections</h4>
                </div>
                <div class="modal-body">
                    <p>In iterative voting systems, candidates are eliminated in consecutive rounds until either a fixed number of rounds is reached or the set of remaining candidates does not change anymore. We focus on iterative voting systems based on the positional scoring rules plurality, veto, and Borda and study their resistance against shift bribery attacks. In constructive shift bribery, an attacker seeks to make a designated candidate win the election by bribing voters to shift this candidate in their preferences; in destructive shift bribery, the briber’s goal is to prevent this candidate’s victory. We show that many iterative voting systems, including those due to Hare (a.k.a. single transferable vote, instant-runoff voting, or alternative vote), Coombs, Baldwin, and Nanson, are resistant to these types of attack.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-200" tabindex="-1" role="dialog"
         aria-labelledby="modal-200-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-200-label">[Abstract] Two-sided Markets: Mapping Social Welfare to Gain from Trade</h4>
                </div>
                <div class="modal-body">
                    <p>Though the definition of gain from trade is an extension of social welfare from auctions to markets, from a mathematical point of view the additional dimension added by gain from trade makes it much more difficult to design a gain from trade maximizing mechanism. This paper provides a means to understand when a market designer can choose the easier path of maximizing social welfare rather than maximizing gain from trade.  

More specifically we provide and prove the first formula to convert a social welfare approximation bound to a gain from trade approximation bound that maintains the original quality of approximation, making it possible to compare solutions that approximate gain from trade with those that approximate social welfare. We evaluate the performance of our formula by using it to convert known social welfare approximation solutions to gain from trade approximation solutions.  We then compare the performance of all known two-sided markets solutions (that implement truthfulness, IR, BB, and approximate efficiency) according to the theoretical approximation bound as well as in practice.  
Surprisingly, we found that some social welfare solutions achieve a better gain from trade than other solutions designed to approximate gain from trade.
<br></p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-667" tabindex="-1" role="dialog"
         aria-labelledby="modal-667-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-667-label">[Abstract] A Cloaking Mechanism to Mitigate Market Manipulation</h4>
                </div>
                <div class="modal-body">
                    <p>We propose <i>a cloaking mechanism</i> to deter <i>spoofing</i>, a specific form of market manipulation designed to deceive investors by artificially affecting supply or demand with spurious orders. The cloaking mechanism works by hiding a specified number of price levels in the order book, starting from the most competitive ones, throughout the trading period. Our agent-based model includes background traders following two representative bidding strategies: the non-spoofable <i>zero intelligence</i> (ZI), which trades based on fundamental and private values, and the manipulable <i>heuristic belief learning</i> (HBL), which uses the order book to predict price outcomes. We also model an exploiter who strategically chooses to spoof and seeks to profit through buying at lower prices and later selling at higher ones. Simulation results show that the proposed cloaking mechanisms can effectively diminish spoofing in terms of price distortions and exploitation profits, but at the expense of a lower proportion of HBL traders and reduced surplus in equilibrium. By conducting <i>empirical mechanism design</i> and <i>game-theoretic analysis</i> across a variety of parametrically distinct environments, we find in markets with low or medium shocks, the benefit of cloaking in mitigating spoofing outweighs its social costs.&nbsp;In addition, we explore more sophisticated spoofing strategies which use probing to reveal cloaked information, and demonstrate the effort and risk associated with the probing may dominate the gains.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-170" tabindex="-1" role="dialog"
         aria-labelledby="modal-170-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-170-label">[Abstract] Heterogeneous Facility Location Games</h4>
                </div>
                <div class="modal-body">
                    <p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"><!--StartFragment-->We study heterogeneous $k$-facility location games on a line segment. In this model there are $k$ facilities to be placed on a line segment where each facility serves a different purpose. Thus, the preferences of the agents over the facilities can vary arbitrarily. Our goal is to design strategy proof mechanisms that locate the facilities in a way to maximize the minimum utility among the agents. For $k=1$, if the agents' locations are known, we prove that the mechanism that locates the facility on an optimal location is strategy proof. For $k \geq 2$, we prove that there is no optimal strategy proof mechanism, deterministic or randomized, even when $k=2$ and there are only two agents with known locations. We derive inapproximability bounds for deterministic and randomized strategy proof mechanisms. Finally, we provide strategy proof mechanisms that achieve constant approximation. All of our mechanisms are simple and communication efficient. As a byproduct we show that some of our mechanisms can be used for other objectives as the social welfare and the happiness and achieve constant approximation.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-520" tabindex="-1" role="dialog"
         aria-labelledby="modal-520-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-520-label">[Abstract] Probabilistic Verification for Obviously Strategyproof Mechanisms</h4>
                </div>
                <div class="modal-body">
                    <p>Obviously strategyproof (OSP) mechanisms maintain the incentive compatibility of agents that are not fully rational. They have been object of a number of studies since their recent definition. We are motivated by the result showing that OSP mechanisms without money cannot return good approximations, even if the designer monitors the agents during the execution of the mechanism, that is, she enforces the agents' utilities to be tied to their reported bids [Ferraioli&amp;Ventre, AAAI 2017].</p><p><br>We ask whether there are different (harsher) forms of punishments and novel ways for the designer to exert control over the agents that can overcome this impossibility. We define a model of probabilistic verification wherein agents are caught misbehaving with a certain probability and show how OSP mechanisms without money can return optimal solutions at the cost of either imposing very large fines for lying or verifying a linear number of agents.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-599" tabindex="-1" role="dialog"
         aria-labelledby="modal-599-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-599-label">[Abstract] Deep Learning for Revenue-Optimal Auctions with Budgets</h4>
                </div>
                <div class="modal-body">
                    <p>The design of revenue-maximizing auctions for settings with private budgets is a hard task. Even the single-item case is not fully understood, and there are no known optimal auctions, or even characterization results, for multi-item settings. In this work, we model a mechanism as a neural network, and use machine learning for the automated design of optimal auctions.&nbsp; We extend the {\em RegretNet} framework~\cite{deep-auction} to handle private budget constraints and&nbsp; Bayesian incentive compatibility.&nbsp; We discover new auctions with very close approximations to incentive-compatibility and high revenue for multi-unit auctions with private budgets, including problems with unit-demand bidders. For benchmarking purposes, we also illustrate that {\em RegretNet} can obtain essentially optimal designs for simpler settings where analytical solutions are available~\cite{CHE2000,Malakhov2008,PAI2014}.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-232" tabindex="-1" role="dialog"
         aria-labelledby="modal-232-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-232-label">[Abstract] On the Complexity of Optimal Correlated Auctions and Reverse Auctions</h4>
                </div>
                <div class="modal-body">
                    <p>&nbsp;&nbsp; We investigate the problem of finding a revenue-optimal auction with correlated bidders. We give an algorithm for the exact solution for two bidders, and for a 5/3-approximation for many bidders, improving from O(n^6) runtime to O(n^3) for both problems by exploiting structural properties of this problem directly. We show that for correlated bidders, reverse auctions behave differently from auctions. For two bidders we discuss a constant-factor reduction in complexity. For k &gt;= 3 bidders, we show that the optimal reverse auction must sometimes buy k copies of the item.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-542" tabindex="-1" role="dialog"
         aria-labelledby="modal-542-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-542-label">[Abstract] Behavior Model Calibration for Epidemic Simulations</h4>
                </div>
                <div class="modal-body">
                    <p><font color="#222222" face="arial, sans-serif"><span style="font-size: 12.8px;">Computational epidemiologists frequently employ large-scale agent-based simulations of human populations to study disease outbreaks and assess intervention strategies. The agents used in such simulations rarely capture the real-world decision-making of human beings. An absence of realistic agent behavior can undermine the reliability of insights generated by such simulations and might make them ill-suited for informing public health policies. In this paper, we address this problem by developing a methodology to create and calibrate an agent decision making model for a large multi-agent simulation, using survey data. Our method optimizes a cost vector associated with the various behaviors to match the behavior distributions observed in a detailed survey of human behaviors during influenza outbreaks. Our approach is a data driven way of incorporating decision making for agents in large-scale epidemic simulations.</span></font><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-285" tabindex="-1" role="dialog"
         aria-labelledby="modal-285-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-285-label">[Abstract] Solving Hard Stable Matching Problems Involving Groups of Similar Agents</h4>
                </div>
                <div class="modal-body">
                    <p>Many important stable matching problems are known to be NP-hard, even when strong restrictions are placed on the input.&nbsp; In this paper we seek to identify simple structural properties of instances of stable matching problems which will allow the design of efficient algorithms.&nbsp; We focus on the setting in which all agents involved in some matching problem can be partitioned into k different <i>types</i>, where the type of an agent determines his or her preferences, and agents have preferences over types (which may be refined by more detailed preferences within a single type).&nbsp; This situation could arise in practice if agents form preferences based on some small collection of agents' attributes. The notion of types could also be used if we are interested in a relaxation of stability, in which agents will only form a private arrangement if it allows them to be matched with a partner who differs from the current partner in some particularly important characteristic. We show that, in this setting, many well-studied NP-hard stable matching problems (such as MAX SMTI, MAX SRTI, and MAX SIZE MIN BP SMTI) belong to the parameterised complexity class FPT when parameterised by the number of different types of agents, and so admit efficient algorithms when this number of types is small.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-689" tabindex="-1" role="dialog"
         aria-labelledby="modal-689-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-689-label">[Abstract] Adversary models account for imperfect crime data: Forecasting and planning against real-world poachers</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
  <o:PixelsPerInch>96</o:PixelsPerInch>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1107305727 0 0 415 0;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073786111 1 0 415 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;}
</style>
<![endif]-->



<!--StartFragment-->



<!--EndFragment--></p>






<!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
  <o:PixelsPerInch>96</o:PixelsPerInch>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="382">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1107305727 0 0 415 0;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073786111 1 0 415 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;}
</style>
<![endif]-->



<!--StartFragment-->

<p class="MsoNormal" style="text-align:justify"><span style="font-family:&quot;Times New Roman&quot;,serif;
mso-fareast-font-family:&quot;Times New Roman&quot;">Poachers are engaged in extinction
level wholesale slaughter, so it is critical to harness historical data for
predicting poachers' behavior. However, in these domains, data collected about
adversarial actions are remarkably imperfect, where reported negative instances
of crime may be mislabeled or uncertain. Unfortunately, past attempts to
develop predictive and prescriptive models to address this problem suffer from
shortcomings from a modeling perspective as well as in the implementability of
their techniques. Most notably these models i) neglect the uncertainty in crime
data, leading to inaccurate and biased predictions of adversary behavior, ii)
use coarse-grained crime analysis and iii) do not provide a convincing
evaluation as they only look at a single protected area. Additionally, they iv)
proposed time-consuming techniques which cannot be directly integrated into low
resource outposts. In this innovative application paper, we (I) introduce
iWare-E a novel imperfect-observation aWare Ensemble (iWare-E) technique, which
is designed to handle the uncertainty in crime information efficiently. This
approach leads to superior accuracy for adversary behavior prediction (up to 34%
increase in AUC) compared to the previous state-of-the-art. We also demonstrate
the country-wide efficiency of the models and are the first to (II) evaluate
our adversary behavioral model across different protected areas in Uganda,
i.e., Murchison Fall and Queen Elizabeth National, (totaling about 7500 km2) as
well as (III) on fine-grained temporal resolutions. Lastly, (IV) we provide a
scalable planning algorithm to design fine-grained patrol routes for the rangers,
which achieves up to 150% improvement in number of predicted attacks detected.</span><o:p></o:p></p>

<!--EndFragment-->
				</div>
			</div>
		</div>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-550" tabindex="-1" role="dialog"
         aria-labelledby="modal-550-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-550-label">[Abstract] Faster Reinforcement Learning Using Active Task Selection</h4>
                </div>
                <div class="modal-body">
                    <p>In this work, we propose several online methods to build a <i>learning curriculum</i> from a given set of target-task-specific training tasks in order to speed up reinforcement learning (RL). These methods can decrease the total training time needed by an RL agent compared to training on the target task from scratch. Unlike traditional transfer learning, we consider creating a sequence from several training tasks in order to provide the most benefit in terms of reducing the total time to train. Our methods utilize the learning trajectory of the agent on the curriculum tasks seen so far to decide which tasks to train on next. An attractive feature of our methods is that they are weakly coupled to the choice of the RL algorithm as well as the transfer learning method. Further, when there is domain information available, our methods can incorporate such knowledge to further speed up the learning. We experimentally show that these methods can be used to obtain suitable learning curricula that speed up the overall training time on discrete and continuous task domains.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-82" tabindex="-1" role="dialog"
         aria-labelledby="modal-82-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-82-label">[Abstract] Introspective Reinforcement Learning and Learning from Demonstration</h4>
                </div>
                <div class="modal-body">
                    <p>Reinforcement learning is a paradigm to model how an autonomous agent learns to maximize its cumulative reward by interacting with the environment. One challenge faced by reinforcement learning is that in many environments the reward signal is sparse, leading to slow improvement of the agent's performance in early learning episodes. Potential-based reward shaping is a technique to resolve the aforementioned issue of sparse reward by incorporating an expert's domain knowledge in the learning via a potential function. Past work on reinforcement learning from demonstration directly mapped (sub-optimal) human expert demonstration to a potential function, which can speed up reinforcement learning. In this paper we propose an introspective reinforcement learning agent that significantly speeds up the learning further. An introspective Reinforcement learning agent records its state-action decisions and experience during learning in a priority queue. Good quality decisions will be kept in the queue, while poorer decisions will be rejected. The queue is then used as demonstration to speed up reinforcement learning via reward shaping. A human expert's demonstration can be used to initialise the priority queue before the learning process starts. Experimental validations in the 4-dimensional CartPole domain and the 27-dimensional Super Mario AI domain show that our approach significantly outperforms state-of-the-art approaches to reinforcement learning from demonstration in both domains.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-768" tabindex="-1" role="dialog"
         aria-labelledby="modal-768-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-768-label">[Abstract] Feature Learning and Transfer Performance Predicting for Video Reinforcement Learning Tasks via Siamese Convolutional Neural Network</h4>
                </div>
                <div class="modal-body">
                    <p>In this paper, we handle the negative transfer problem by a deep learning method to predict the transfer performance (positive transfer/negative transfer) between two reinforcement learning tasks. Our method directly trains a neural network from raw task descriptions without any other prior knowledge such as samples from the target task and models of tasks. We consider video reinforccement learning tasks such as video games which can be perceived by the agent with visual ability and described as iamges. The architecture of our neural network consists of two parts: a siamese convolutional neural network to learn the features of each pair of tasks and a softmax layer to predict the binary transfer performance. When the features of a pair of task images are obtained, the difference between the tasks is computed based on the feature vectors. Before passed to the softmax layer, the difference feature is mapped to a new feature by a fully-connected layer with a ReLU activation function to realize nonlinear classification. We conduct extensive experiments in two video reinforcement learning domains, the maze domain and the Ms. Pacman domain, to evaluate the performance of our method. The results show that our proposed method can accurately predict the transfer performance with around 90% accuracy and outperform the baseline methods in both domains. Especially in the Ms. Pacman domain, our method can achieve an accuracy of 94.2% and significantly outperform the methods with hand-crafted features by more than 10%.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-383" tabindex="-1" role="dialog"
         aria-labelledby="modal-383-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-383-label">[Abstract] Neither dumb nor optimal: plausible wayfinding in pedestrian agent-based models</h4>
                </div>
                <div class="modal-body">
                    <p>Extending the range of pedestrian decision making activities represented in a simulation model represents a serious challenge: different decisions are taken at distinct levels of abstraction, employing different types of information and knowledge about the environment, from path planning to the regulation of distance from other pedestrians and obstacles present in the environment. Pedestrians, moreover, are not robots: although empirical observations show that they consider congestion when planning, there are evidences that their decisions are not always optimal (even in normal situations). We present a model integrating and improving consolidated results mitigating the optimization effects of congestion aware path planning by making commonsense estimations of the effects of perceivable congestion, also embedding an imitation mechanism stimulating changes in planned decisions whenever another nearby pedestrian did the same. The model is formally described and experimented both in a validation scenario as well as in a real-world situation: an interesting counterintuitive result, in which reducing available choices and exits actually reduces overall egress time, is also presented and discussed.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-201" tabindex="-1" role="dialog"
         aria-labelledby="modal-201-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-201-label">[Abstract] Complexity of Controlling Nearly Single-Peaked Elections Revisited</h4>
                </div>
                <div class="modal-body">
                    <p>
		
	
	
		</p><div class="page" title="Page 1">
			<div class="layoutArea">
				<div class="column">
					<p><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">We investigate the complexity of C</span><span style="font-size: 7.000000pt; font-family: 'NimbusRomNo9L'">ONSTRUCTIVE </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">C</span><span style="font-size: 7.000000pt; font-family: 'NimbusRomNo9L'">ONTROL BY
</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">A</span><span style="font-size: 7.000000pt; font-family: 'NimbusRomNo9L'">DDING</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">/D</span><span style="font-size: 7.000000pt; font-family: 'NimbusRomNo9L'">ELETING </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">V</span><span style="font-size: 7.000000pt; font-family: 'NimbusRomNo9L'">OTES </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">(CCAV/CCDV) for </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">r</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-approval, Con-
dorcet, Maximin and Copeland</span><span style="font-size: 6.000000pt; font-family: 'CMMI6'; vertical-align: 4.000000pt">α </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">in </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-axes and </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-candidate partition
single-peaked elections. In general, we prove that CCAV and CCDV
for most of the voting correspondences mentioned above are NP-
hard even when </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k </span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">is a very small constant. Exceptions are CCAV
and CCDV for Condorcet and CCAV for </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">r</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-approval in </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-axes single-
peaked elections, which we show to be fixed-parameter tractable
with respect to </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">. Whether CCDV for </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">r</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-approval in </span><span style="font-size: 9.000000pt; font-family: 'CMMI9'">k</span><span style="font-size: 9.000000pt; font-family: 'NimbusRomNo9L'">-axes single-
peaked elections is  xed-parameter tractable remains open. Finally,
we give a polynomial-time algorithm to recognize 2-axes elections,
resolving an open problem.&nbsp;</span></p>
				</div>
			</div>
		</div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-504" tabindex="-1" role="dialog"
         aria-labelledby="modal-504-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-504-label">[Abstract] Sequential Allocation Rules are Separable: Refuting a Conjecture on Scoring-Based Allocation of Indivisible Goods</h4>
                </div>
                <div class="modal-body">
                    <p>Baumeister et al. [2] introduced scoring allocation correspondences and rules, parameterized by an aggregation function ⋆ (such as + and min) and a scoring vector s. Among the properties they studied is separability, a.k.a. consistency [16], a central property important in many social decision contexts. Baumeister et al. [2] show that some common scoring allocation rules fail to be separable and conjecture that “(perhaps under mild conditions on s and ⋆), no positional scoring allocation rule is separable.” We refute this conjecture by showing that (1) the family of sequential allocation rules—an elicitation-free protocol for allocating indivisible goods based on picking sequences [10]—is separable for each coherent collection of picking sequences, and (2) every sequential allocation rule can be expressed as a scoring allocation rule for a suitable choice of scoring vector and social welfare ordering.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-214" tabindex="-1" role="dialog"
         aria-labelledby="modal-214-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-214-label">[Abstract] A Condorcet-Consistent Participatory Budgeting Algorithm</h4>
                </div>
                <div class="modal-body">
                    <p>The budget is the key means for effecting policy in democracies, yet its preparation is typically an opaque and arcane process. Participatory budgeting is making inroads in municipalities, but is usually limited to a small fraction of the total budget and the produced budgets usually do not provide axiomatic guarantees.</p><p>Here we apply the Condorcet principle to a general participatory budgeting scenario that includes a budget proposal, a vote profile, and a budget limit. We devise a polynomial-time budgeting algorithm that, given such a scenario,&nbsp; produces the Condorcet winner if it exists, else a member of the Smith set. (A caveat -- our definition of dominance employs strict rather than relative majority.) Furthermore, we argue that if there is no Condorcet winner for this scenario, then the resulting budget would often be close to a weak Condorcet winner for a slightly smaller budget limit.&nbsp;</p><p>Our algorithm allows items to be quantitative, indivisible, and have arbitrary costs and allows voters to specify weak orders as their preferences. Furthermore, our algorithm supports hierarchical budget construction, thus may be applied to entire high-stakes budgets.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-474" tabindex="-1" role="dialog"
         aria-labelledby="modal-474-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-474-label">[Abstract] The Impact of Antagonistic Concepts on Influence Manipulation</h4>
                </div>
                <div class="modal-body">
                    <p>The propagation of concepts in a population of agents is a form of influence spread, which can be modelled as a cascade from an initial set of individuals. In real-world environments there may be many concepts spreading and interacting. Previous work that investigates the spread of multiple concepts is typically limited to two concepts. In this paper, we consider the problem of indirect influence manipulation and the effect of introducing an additional concept, in the form of an antagonistic concept. Antagonistic concepts manipulate the target concept in a way that is adverse to our goal of maximising or minimising spread. We evaluate the impact of antagonistic concepts on current strategies for indirect influence manipulation. A recently established heuristic for indirectly manipulating concept spread in the presence of two concepts, MPG, is evaluated against an adaptation that accounts for the existence of antagonistic concepts. Through this evaluation, we demonstrate the resilience of MPG in multi-concept environments. <br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-571" tabindex="-1" role="dialog"
         aria-labelledby="modal-571-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-571-label">[Abstract] Interactive Reinforcement Learning with Dynamic Reuse of Prior Knowledge</h4>
                </div>
                <div class="modal-body">
                    <p>Reinforcement learning has enjoyed multiple successes in recent years. However, these successes typically require very large amounts of data before an agent achieves acceptable performance. This paper introduces a novel way of combating such requirements by leveraging existing (human or agent) knowledge. In particular, this paper uses demonstrations from agents and humans, allowing an untrained agent to quickly achieve high performance. We empirically compare with, and highlight the weakness of, HAT and CHAT, methods of transferring knowledge from a source agent/human to a target agent. We highlight a weakness of CHAT: its confidence measurement on transferred knowledge is focused on the source demonstration dataset. This paper introduces an effective transfer approach, DRoP, combining the offline knowledge (demonstrations recorded before learning) with online confidence-based performance analysis. DRoP dynamically involves the demonstrator's knowledge, integrating it into the reinforcement learning agent's online learning loop to achieve efficient and robust learning.<br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-539" tabindex="-1" role="dialog"
         aria-labelledby="modal-539-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-539-label">[Abstract] On Revenue-Maximizing Mechanisms assuming Convex Costs</h4>
                </div>
                <div class="modal-body">
                    <p><font color="#222222" face="arial, sans-serif"><span style="font-size: 12.8px;">We investigate revenue-maximizing mechanisms in settings where bidders' utility functions are characterized by convex costs.&nbsp; Such costs arise, for instance, in procurement auctions for energy.&nbsp; We provide a constant-factor approximation guarantee for a prior-free randomized mechanism.&nbsp; Additionally, we propose two heuristics that allocate proportionally, using either value or virtual value.&nbsp; We describe experiments which show that for randomly drawn monotone hazard rate distributions, our mechanisms can achieve near optimal performance.&nbsp;&nbsp;Perhaps surprisingly, in the convex cost setting, it is preferable to allocate to multiple relatively high bidders, rather than only to bidders with the highest (virtual) value, as is optimal in the traditional quasi-linear utility setting.</span></font><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-322" tabindex="-1" role="dialog"
         aria-labelledby="modal-322-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-322-label">[Abstract] On the Distance Between CP-nets</h4>
                </div>
                <div class="modal-body">
                    <p>Preferences play a key role in decision making, whether such decision are made by a single individual or a group. In a multi-agent context, it is also important to know how to aggregate preferences to reach a collective decision. Moreover, being able to measure the distance between the preference of two individuals is important to identify the amount of disagreement and possibly reach consensus. In this paper we define a notion of distance between CP-nets, a formalism that can compactly encode conditional qualitative preferences. We consider the Kendall-tau distance between the partial orders induced by CP-nets, and we define two tractable approximations of that distance, which can be computed in time polynomial in the number of features of the CP-nets. We then perform experiments to demonstrate the quality of these approximations compared to the Kendall-tau distance. We also relate our two notions of distance to the distance rationalizability of sequential plurality voting for CP-nets.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-135" tabindex="-1" role="dialog"
         aria-labelledby="modal-135-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-135-label">[Abstract] Optimization-Based Voting Rule Design: The Closer to Utopia the Better</h4>
                </div>
                <div class="modal-body">
                    <p>In certain situations, such as elections in the Euclidean domain, it is possible to specify clear requirements for the operation of a multiwinner voting rule, for it to provide committees that correspond to some desirable intuitive notions (such as individual excellence of committee members or their diversity). We formally describe several such requirements, which we refer to as ``utopias''. Supplied with such utopias, we develop an optimization-based mechanism for constructing committee scoring rules that provide results as close to these utopias as possible; we test our mechanism on weakly separable and OWA-based rules. Using our method we recovered some believed connections between known multiwinner voting rules and certain applications and got other interesting insights.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-331" tabindex="-1" role="dialog"
         aria-labelledby="modal-331-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-331-label">[Abstract] Robust Multi-Agent Path Finding</h4>
                </div>
                <div class="modal-body">
                    <p>In a multi-agent path-finding (MAPF) problem, the task is to find a plan for moving a set of agents from their initial locations to their goals without collisions. Following this plan, however, may not be possible due to unexpected events that delay some of the agents. We explore the notion of \emph{robust} MAPF, where the task is to find a plan that can be followed even if a limited number of such delays occur. Two novel forms of robust MAPF are defined. The first is called k-robust MAPF (kR-MAPF), where we seek a plan that is robust to k unexpected delays per agent.&nbsp;</p><p>This form of robustness is especially suitable for agents with a control mechanism that guarantees each agent is at most k steps from its pre-defined plan. We propose sufficient and required conditions for finding a k-robust plan, and show how to convert several MAPF solvers to find a k-robust plan with minimal cost. The second form of robust MAPF we define is called p-likely robust MAPF (pR-MAPF), where we seek a plan in which the probability that no collisions will occur is greater than a given p.&nbsp;</p><p>This form of robustness is suitable for cases where the probability of the unexpected delays is known or can be approximated.&nbsp; Finding an optimal p-likely robust solution is significantly more difficult than finding an optimal k-robust solution. As a practical solution, we propose a greedy algorithm based on the Conflict-Based Search framework. We evaluate all the proposed solvers and the two forms of robustness experimentally, showing that it is possible to find robust plans, the resulting increase in plan cost is not large, and having a robust plan indeed results in fewer re-plans during execution.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-435" tabindex="-1" role="dialog"
         aria-labelledby="modal-435-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-435-label">[Abstract] Truthfulness on a Budget: Trading Money for Approximation through Monitoring</h4>
                </div>
                <div class="modal-body">
                    <p>In a budget-feasible mechanism, the total payments used by the designer to enforce incentive compatibility must be within a given budget. This is a quite realistic desideratum that we here study for generic utilitarian problems. Specifically, we aim at characterizing the minimum budget needed to truthfully implement utilitarian problems. Towards this goal, we connect two streams of work on mechanism design and look at monitoring — a novel paradigm wherein agents’ declarations are tied to their actual costs [13]. In this setting, we prove that the social cost is always a sufficient budget, even for collusion-resistant mechanisms, and, under mild conditions,a necessary budget for a large class of utilitarian problems that encompass set system problems. Furthermore, for two well-studied problem outside of this class, namely facility location and obnoxious facility location, we draw a novel picture about the relationship between approximation and frugality. While for optimal mechanisms we prove that the social cost is always a sufficient and necessary budget in both cases, for approximate mechanisms we do have a dichotomy: for the facility location problem (i.e., agents want to be close to the facilities) we show that “good” approximations still need a budget equal to the social cost; on the contrary, for obnoxious facility location (i.e. agents want to be as far away from the facilities as possible), we show that it is possible to trade approximation for a smaller budget, thus obtaining more frugal truthfulness.</p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-650" tabindex="-1" role="dialog"
         aria-labelledby="modal-650-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-650-label">[Abstract] A Resilient Agent-Based Re-Organizing Traffic Environment for Urban Evacuations</h4>
                </div>
                <div class="modal-body">
                    <p class="MsoNormal"><span style="font-size: 10.5pt; line-height: 107%; font-family: Helvetica, sans-serif; background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;">Implementing effective
traffic road reversals is a complex problem: it requires clearing roads from
traffic before implementing safe road reversal operations and often results in
anomalies in the network topology. Road reversals are further complicated when,
due to unexpected events (e.g., torrential rains), roads are suddenly closed.
Current traffic road reversal approaches are based on the execution of
mathematical models which identify upfront, optimal reversal configurations for
the entire traffic network. These approaches assume that the traffic network
structure is static, and as such do not allow for dynamic road closures. In
this paper, we present a <i>resilient</i> agent-based re-organizing traffic
model for urban evacuations. Resilience refers to the traffic network's ability
to regain its evacuation function quickly and efficiently after severe
perturbations. The proposed model integrates <i>road reversal</i> and <i>zoning</i>
strategies. Experimental results show that: a) the model improves the evacuation
effort, and b) the evacuation function is able to cope quickly and effectively
with&nbsp;</span>dynamic road closures.<o:p></o:p></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-112" tabindex="-1" role="dialog"
         aria-labelledby="modal-112-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-112-label">[Abstract] Simple Truthful Mechanisms for Broker’s Profit in Two-Sided Markets</h4>
                </div>
                <div class="modal-body">
                    <!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG></o:AllowPNG>
  <o:PixelsPerInch>96</o:PixelsPerInch>
 </o:OfficeDocumentSettings>
</xml><![endif]-->

<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves></w:TrackMoves>
  <w:TrackFormatting></w:TrackFormatting>
  <w:PunctuationKerning></w:PunctuationKerning>
  <w:ValidateAgainstSchemas></w:ValidateAgainstSchemas>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF></w:DoNotPromoteQF>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>ZH-CN</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables></w:BreakWrappedTables>
   <w:SnapToGridInCell></w:SnapToGridInCell>
   <w:WrapTextWithPunct></w:WrapTextWithPunct>
   <w:UseAsianBreakRules></w:UseAsianBreakRules>
   <w:DontGrowAutofit></w:DontGrowAutofit>
   <w:SplitPgBreakAndParaMark></w:SplitPgBreakAndParaMark>
   <w:EnableOpenTypeKerning></w:EnableOpenTypeKerning>
   <w:DontFlipMirrorIndents></w:DontFlipMirrorIndents>
   <w:OverrideTableStyleHps></w:OverrideTableStyleHps>
   <w:UseFELayout></w:UseFELayout>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"></m:mathFont>
   <m:brkBin m:val="before"></m:brkBin>
   <m:brkBinSub m:val="&#45;-"></m:brkBinSub>
   <m:smallFrac m:val="off"></m:smallFrac>
   <m:dispDef></m:dispDef>
   <m:lMargin m:val="0"></m:lMargin>
   <m:rMargin m:val="0"></m:rMargin>
   <m:defJc m:val="centerGroup"></m:defJc>
   <m:wrapIndent m:val="1440"></m:wrapIndent>
   <m:intLim m:val="subSup"></m:intLim>
   <m:naryLim m:val="undOvr"></m:naryLim>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="380">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"></w:LsdException>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"></w:LsdException>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"></w:LsdException>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 2"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 3"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 4"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 5"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 6"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 7"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 8"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Level 9"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"></w:LsdException>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"></w:LsdException>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"></w:LsdException>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"></w:LsdException>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"></w:LsdException>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"></w:LsdException>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"></w:LsdException>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"></w:LsdException>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"></w:LsdException>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"></w:LsdException>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"></w:LsdException>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"></w:LsdException>
 </w:LatentStyles>
</xml><![endif]-->

<!--[if gte mso 10]>
<style>
 /* Style Definitions */
table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:Calibri;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;}
</style>
<![endif]-->



<!--StartFragment-->

<p class="MsoNormal" style="text-align:justify;text-justify:inter-ideograph">We
study how to maximize the broker’s (expected) profit in a two-sided market,
where he buys items from a set of sellers and resells them to a set of buyers.
Each seller has a single item to sell and holds a private value (or
equivalently, a private cost) on her item. The buyers have additive valuations
over all sellers’ items. We consider the Bayesian setting where the players’
values are independently drawn from prior distributions, and aim at designing
dominant-strategy incentive-compatible (DSIC) mechanisms that are approximately
optimal.<o:p></o:p></p><p class="MsoNormal" style="text-align:justify;text-justify:inter-ideograph">Production-cost
markets, where each item has a publicly-known cost for it to be produced,
provide a platform for us to study two-sided markets. Briefly, we show how to
covert a mechanism for production-cost markets into a mechanism for the broker,
whenever the former satisfies cost-monotonicity. This reduction holds for general
combinatorial valuation functions of buyers. When the buyers’ valuations are
additive, we generalize an existing auction mechanism to production-cost
markets in an approximation-preserving way. We then show that the resulting
mechanism is cost-monotone and thus can be converted into an 8-approximation
mechanism for two-sided markets via our reduction.</p><p class="MsoNormal" style="text-align:justify;text-justify:inter-ideograph"><o:p></o:p></p>

<!--EndFragment-->
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-130" tabindex="-1" role="dialog"
         aria-labelledby="modal-130-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-130-label">[Abstract] Between Proportionality and Diversity: Balancing District Sizes under the Chamberlin–Courant Rule</h4>
                </div>
                <div class="modal-body">
                    <p>The Monroe and Chamberlin–Courant (CC) multiwinner rules pro<span style="line-height: 1.42857;">ceed by partitioning the voters into virtual districts and assigning a&nbsp;</span><span style="line-height: 1.42857;">unique committee member to each district, so that the voters are as&nbsp;</span><span style="line-height: 1.42857;">satisfied with the assignment as possible. The difference between&nbsp;</span><span style="line-height: 1.42857;">Monroe and CC is that the former creates equal-sized districts, and&nbsp;</span><span style="line-height: 1.42857;">the latter has no constraints. We generalize these rules by requir</span><span style="line-height: 1.42857;">ing that the largest district can be at most X times larger than the&nbsp;</span><span style="line-height: 1.42857;">smallest one (where X is a parameter). We show that our new rules&nbsp;</span><span style="line-height: 1.42857;">inherit worst-case computational properties from their ancestors,&nbsp;</span><span style="line-height: 1.42857;">evaluate the rules experimentally (in particular, we provide their&nbsp;</span><span style="line-height: 1.42857;">visualizations, we analyze actual district sizes, and we analyze voter&nbsp;</span><span style="line-height: 1.42857;">satisfaction), and we analyze their approximability.</span></p><div><br></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-196" tabindex="-1" role="dialog"
         aria-labelledby="modal-196-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-196-label">[Abstract] Efficient allocation mechanism with endowments and distributional constraints</h4>
                </div>
                <div class="modal-body">
                    <p>We consider an allocation problem of multiple types objects to agents, where each type of an object has multiple copies (e.g., multiple seats of a school), each agent is endowed with an object, and some distributional constraints are imposed on the allocation (e.g., minimum/maximum quotas). We develop a mechanism that is based on the Top Trading Cycles mechanism, which is strategy-proof, feasible (always satisfies distributional constraints), Pareto efficient, and individually rational, assuming the distributional constraints are represented as an M-convex set.&nbsp; The class of distributional constraints we consider contains many situations raised from realistic matching problems, including individual minimum/maximum quotas, regional maximum quotas, type-specific maximum quotas, and distance constraints.&nbsp; To the best of our knowledge, we are the first to develop a mechanism with these desirable properties.<br><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-291" tabindex="-1" role="dialog"
         aria-labelledby="modal-291-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-291-label">[Abstract] Hierarchical Agent Supervision</h4>
                </div>
                <div class="modal-body">
                    <p>Agent supervision is a form of control/customization where</p><p>a supervisor restricts the behavior of an agent to enforce certain</p><p>requirements, while leaving the agent as much autonomy</p><p>as possible. To facilitate supervision, it is often of interest</p><p>to consider hierarchical models where a high level abstracts</p><p>over low-level behavior details. We study hierarchical agent</p><p>supervision in the context of the situation calculus and the</p><p>ConGolog agent programming language, where we have a</p><p>rich first-order representation of the agent state. We define</p><p>the constraints that ensure that the controllability of individual</p><p>actions at the high level in fact captures the controllability</p><p>of their implementation at the low level. On the basis of</p><p>this, we show that we can obtain the maximally permissive</p><p>supervisor by first considering only the high-level model and</p><p>obtaining a high-level supervisor and then refining its actions</p><p>locally, thus greatly simplifying the supervisor synthesis task.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-215" tabindex="-1" role="dialog"
         aria-labelledby="modal-215-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-215-label">[Abstract] Inter-task Super-state Mapping for Autonomous Policy Transfer</h4>
                </div>
                <div class="modal-body">
                    <p>Transfer learning (TL) is used to improve the learning speed in reinforcement learning tasks with large state spaces. Many TL  approaches  use  inter-task  mappings  between  source  and target tasks. The main drawback of existing approaches based on  autonomous  inter-task  mappings  (either  state-based  or state-variable  based  mappings),  is  that  one  can  either  guarantee maximal transfer efficacy or minimal mapping search time, but not both. In this paper, we present “inter-task super-state mappings” to solve this problem. We prove that (i) our approach obtains maximum transfer efficacy, and that (ii) our inter-task  super-state  mapping  approach  requires  minimum search time, given no meta-data or task-specific information of the target task.</p><p><br></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-283" tabindex="-1" role="dialog"
         aria-labelledby="modal-283-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-283-label">[Abstract] A Large Neighboring Search Schema for Multi-Agent Optimization</h4>
                </div>
                <div class="modal-body">
                    <p class="p1"><span class="s1">The Distributed Constraint Optimization Problem (DCOP) is an elegant paradigm for modeling and solving multi-agent problems which are distributed in nature, and where agents cooperate to optimize a global objective within the confines of localized communication.</span></p><p class="p1"><span class="s1">Since solving DCOPs optimally is NP-hard, recent effort in the development of DCOP algorithms has focused on incomplete methods. Unfortunately, many of such proposals do not provide quality guarantees or provide a loose quality assessment.</span></p><p class="p1"><span class="s1">Thus, this paper proposes DLNS, a novel iterative local search framework to solve DCOPs, which is anytime, it provides guarantees on solution quality, refining upper and lower bounds during the iterative process.</span></p><p>




<style type="text/css">
p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; -webkit-text-stroke: #000000}
span.s1 {font-kerning: none}
</style>





</p><p class="p1"><span class="s1">We demonstrate the effectiveness of DLNS on several DCOP benchmarks on structured and unstructured domains.</span></p>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="modal-416" tabindex="-1" role="dialog"
         aria-labelledby="modal-416-label">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                    <h4 class="modal-title" id="modal-416-label">[Abstract] Strategyproof and fair matching mechanism for ratio constraints</h4>
                </div>
                <div class="modal-body">
                    <p>We introduce a new type of distributional constraints called ratio</p><p>constraints, which explicitly specify the required balance among schools in</p><p>two-sided matching.&nbsp;</p><p>Since ratio constraints do not belong to the known well-behaved class of&nbsp;</p><p>constraints called M-convex set, developing a fair and strategyproof</p><p>mechanism that can handle them is challenging.&nbsp;</p><p>We develop a novel mechanism called</p><p>Quota Reduction Deferred Acceptance (QRDA),&nbsp;</p><p>which repeatedly applies the standard DA&nbsp;</p><p>by sequentially reducing artificially introduced maximum</p><p>quotas. As well as being fair and strategyproof,</p><p>QRDA always obtains a weakly better matching for</p><p>students compared to a baseline mechanism called&nbsp;</p><p>Artificial Cap Deferred Acceptance (ACDA), which&nbsp;</p><p>uses predetermined artificial maximum quotas.&nbsp;</p><p>Experimentally, QRDA performs better in terms of student welfare</p><p>and nonwastefulness than ACDA and another fair and strategyproof</p><p>mechanism called Extended Seat Deferred Acceptance (ESDA), in which&nbsp;</p><p>ratio constraints are transformed into minimum/maximum quotas.</p>
                </div>
            </div>
        </div>
    </div>


    

    <hr>
</div>

<div class="container-fluid">
    <div class="row">
        <div class="col-lg-12">
            <div class="col-sm-5">
                <a href="http://confmaster.net">
                    <img id="logo-cm" src="https://cdn.confmaster.net/images/confmaster-logo.png" alt="Confmaster.net"
                         width="170"/>
                </a>
            </div>
            <div class="col-sm-2">
                
                    &nbsp;
                
            </div>
            <div class="col-sm-5">
                <p class="muted pull-right">
                    Copyright &copy; 2013 - 2017 <a href="http://coniant.net">coniant gmbh</a> All rights
                    reserved.
                </p>
            </div>
        </div>
    </div>
</div>


    <script src="//netdna.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>


    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/select2/4.0.3/js/select2.min.js"></script>
<script type="text/javascript" src="https://cdn.confmaster.net/django_select2/django_select2.js"></script>
    
        <script src="//cdnjs.cloudflare.com/ajax/libs/x-editable/1.5.0/bootstrap3-editable/js/bootstrap-editable.min.js">
        </script>
    
    <script type="application/javascript">
        $('.editable_bid').editable({
            type: 'select',
            title: "Bid on Paper",
            params: {csrfmiddlewaretoken: '0lW6D7unp3nmx2xktkcV8Rik0aewyskXbUqSV48CdhLPtM7lKjZRV1n0VXvbqcOy'},
            display: false, 
            showbuttons: false, 
            source: [{"text": "Top Choice", "value": 50}, {"text": "Very Interested", "value": 45}, {"text": "Interested", "value": 40}, {"text": "Neutral", "value": 35}, {"text": "No Bid", "value": 30}, {"text": "Not Interested", "value": 25}, {"text": "Conflict of Interest", "value": 20}], 
            success: function (response, newValue) {
                // Decrement old counter
                bid_type_id = '#bid_type_' + $(this).attr('data-value');
                ctr = parseInt($(bid_type_id).attr('data-ctr')) - 1;
                $(bid_type_id).html(ctr);
                $(bid_type_id).attr('data-ctr', ctr);

                // increment new counter
                bid_type_id = '#bid_type_' + newValue;
                ctr = parseInt($(bid_type_id).attr('data-ctr')) + 1;
                $(bid_type_id).html(ctr);
                $(bid_type_id).attr('data-ctr', ctr);
                $(this).attr('data-value', newValue);

                $(this).html(response);
                
            }
        });
    </script>

</body>
</html>
