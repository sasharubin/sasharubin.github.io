\section{OLD --- The model}


	
		\begin{definition}[CCGS]
		A \emph{$d$-dimensional Cost Concurrent Game Arena} (\CCGA) is a
		tuple $A=\tpl{\Ag, \Stt, \Act,\iota,\kappa,d}$
		\begin{enumerate} \item $\Ag$ is a finite non-empty set of \emph{agents} (we write 
			$\NElm			= \card{\Ag}$);
			\item $\Act$ is a set of the actions;
			\item $\Stt$ is a finite non-empty set of \emph{states} and $\iota$
						is the \emph{initial state};
			\item $\trn: \Stt \times \Act^{\Ag} \rightarrow \Stt$ is
						a \emph{transition function} mapping each pair consisting of a
						state and an action for each agent to a state,
			\item $d \in \nat$ is the {\em dimension} and $\kappa: \Ag \to (\Stt \times \Act^{\Ag} \rightarrow \mathbb{Z}^d)$ is a \emph{cost function}.
		\end{enumerate}
		\end{definition}


An \emph{execution} $\pi$ is an infinite sequence over $\Stt \times \Act^{\Ag}$ that
respects the transition function.  Let $\exec$ denote the set of all
executions. 

A {\em payoff function} is a function $\mu: \Ag \to (\exec \to \mathbb{R})$, i.e., it
assigns a payoff/utility to each agent.  The payoff may depend on the costs and
the states along the execution. Each agent is trying to maximise its payoff.
A \emph{$d$-dimensional Cost Concurrent Game Structure} (\CCGS) is a tuple $G = (A,\mu)$ where $A$ is a \CCGA and $\mu$ is a payoff function.
In case the payoffs are always in the set $\{0,1\}$ such games are called ``win-lose''.

A \emph{strategy profile} is a strategy for each agent. We write these as $\sigma: \Ag \to (\hist \to \Act)$ where $\hist$ is the set of finite sequences of states.
\todo{Note: we do not include actions in histories... this seems a reasonable choice for discussing NE in distributed systems}
A strategy profile $\sigma$ induces a unique execution $\pi_\sigma$.

\todo{todo: define turn-based game as a special case}

\subsection{Payoff functions}

In order to define concrete payoff functions we typically aggreggate the costs incurred for each player. 
Each execution $\pi$ induces, for each agent $i$, a sequence of costs
$c_i(\pi) \in (\mathbb{Z}^d)^\omega$. Write $c_i^j(\pi) \in \mathbb{Z}^\omega$ for the sequence of costs
for player $i$ in dimension $j \leq d$.




In what follows, the name of the classes of games (mean-payoff, parity, LTL) should really be prefixed by 
``multi-player'' so as not to cause confusion with the two-player zero-sum case.
For $\alpha \in \mathbb{Z}^\omega$, define $mp(\alpha)$ to be the long-term average of the sequence $\alpha$, i.e.,
the lim-inf of the the average of the first $n$ terms of $\alpha$.


\begin{example}[Mean-payoff games]
Let $d = 1$, and let $\mu(i)(\pi) = mp(c_i(\pi))$ be the long term average of
$c_i(\pi)$. Call these {\em mean-payoff games}.
\end{example}

  \begin{example}[$F$-mean payoff games]
  Fix a function $F:\mathbb{R}^d \to \mathbb{R}$ and define $\mu(i)(\pi) = F(mp(c_i^1(\pi)), \cdots, mp(c_i^d(\pi)))$,
  i.e., the payoff for player $i$ is the value of $F$ on the long-term averages of its costs. 
  Call such games {\em $F$-mean payoff games}. Here are some illustrative examples of functions $F$:
\begin{enumerate}
\item $F$ is a threshold function. For instance, if $d = 1$ and $F(x) = 1$ if $x > 0$ and $0$ otherwise.
Let us call these \emph{Threshold Mean-Payoff games}.
\item $F$ is the average of its arguments, 
\item $F$ is the max of its arguments,
\item $F$ counts the number of arguments that are positive,
\item $F$ is the lexicographic. For instance, if $d = 2$, define $F(x,y) = 0$ if $x \leq 0$, $1$ if $x \geq 0$, and $2$ if $x \geq 0$ and $y \geq 0$.
Call these \emph{lexicographic threshold mean-payoff games}. 
\end{enumerate}

\end{example}

We give some more examples with $d = 1$.


\begin{example}[Parity-games]
Let $d = 1$, and let $\mu(i)(\pi)$ equal $1$ if the largest cost of player $i$ seen infinitely often on $\pi$ is even, and equal to $0$ otherwise. 
Call such games {\em parity-games}. 
\end{example}

\begin{example}[Generalised Muller games]
 Let $d = 1$, and let $\mu(i)(\pi)$ depend only on the set of states that occur infinitely often in $\pi$. Call such games {\em generalised Muller-games} after that fact
 that a Muller-game is such a game in which the payoffs are from $\{0,1\}$.
\end{example}

\begin{example}[LTL-games and $\omega$-regular games]
A \emph{LTL-game} is one in which each player has an LTL objective that it is trying to satisfy. 
Formally, replace the cost function in CGCS's by state-labelings $\lambda:\Stt \to 2^{\Ap}$ over some fixed set of atoms $\Ap$.
Given $N$ LTL formulas $\phi_i, i \leq N$, the payoff for player $i$ is $1$ if $\pi \models \phi_i$ and $0$ otherwise.

More generally, if $\phi_i$ is an $\omega$-regular language (i.e., $\phi_i \subseteq (2^{\Ap})^*$) then we have \emph{$\omega$-regular games}.
\end{example}

\begin{example}[Oxford Games]
Let $d = 1$ and suppose every weight is positive. Let $\phi_i$ be \LTL formulas, one for each agent. 
An \emph{Oxford} game (because we discussed some variation of this in Oxford)
has payoff that maps a play $\pi$ to $0$ if $\pi \models \neg \phi_i$ and to $mp(c_i(\pi))$ otherwise. The goal is to maximise the payoff.
\end{example}

\note{Can we capture zero-sum mean-payoff games in which one player maximises and the other minimises?}

\section{The decision problems}

Let $\C$ be a set of games. We define two decision problems.
\begin{definition}
 \emph{E-NASH($\C$)}: Decide if a given game from $\C$ has a Nash-Equilibrium.
\end{definition}

\begin{definition}
 Memoryless-E-NASH($\C$): Decide if a given game from $\C$ has a Nash-Equilibrium made of memoryless strategies.
\end{definition}


We now discuss the relationship between some of the games.

\begin{definition}[Equivalent games]
Call two games $G,G'$ \emph{(memoryless-)equivalent} 
if for every strategy profile $\sigma$ (of memoryless strategies) in $G$ there exists a strategy profile 
$\sigma'$ (of memoryless strategies) in $G'$, and vice versa, such that $\mu(i)(\pi_\sigma) = \mu'(i)(\pi_{\sigma'})$ for each agent $i$. Here $\pi_\sigma$ and $\pi_{\sigma'}$
are the plays induced by the strategy profiles $\sigma$ and $\sigma'$ respectively.
\end{definition}

It is useful to have effective transformations of games from one class into games of another class. Indeed, if $\C,\C'$ are two classes of games for which 
there is an effective transformation of games in $\C$ into equivalent games in $\C'$ then E-NASH($\C$) can be reduced to E-NASH($\C'$). A similar statement holds for the memoryless case.

For instance, it is immediate from the definitions that every parity-game is (trivially) equivalent to a Muller game (i.e., itself), 
and every Muller game is (trivially) equivalent to an $\omega$-regular game (i.e., itself). 

Here are some more interesting equivalences. 

\begin{theorem}\label{thm:LTL to parity}
Every LTL-game can be effectively translated into an equivalent parity-game with $2$-exponential blowup. \todo{This should also work for objective-LTL games.}
\end{theorem}

\begin{proof}[Sketch]
Let $G$ be an LTL-game.
The idea (which is standard for two-player zero-sum games) 
is to convert the LTL formulas into deterministic parity-word automata (DPW), and then form the product of the original game with these automata. 
Being deterministic, the automata
simply annotate the game $G$. 

Here are some details. Translate each LTL formula $\phi_i$ into a deterministic parity-word automaton $A_i$ in which priorities are on edges 
(instead of, as usual, states). Say $A_i$ has state set $Q_i$. 
Then form the parity-game $G'$ as the product of $G$ and $\prod Q_i$. The cost for player $i$ of transition of $G'$ is defined to be the priority of the corresponding 
transition in $A_i$. Then $G$ and $G'$ are equivalent.
\end{proof}


\begin{theorem} \label{thm:PG-MP}
Every parity-game can be effectively translated into a memoryless-equivalent threshold mean-payoff game with no blowup.
\end{theorem}

\begin{proof}[Sketch]
Let $G$ be a parity-game. The idea (cf. e.g., \cite{Jurd98}) is to replace each priority $p$ by the cost $(-m)^p$ where $m$ is 
the number of states of $G$. Then, if $\pi$ is the play resulting from a memoryless-strategy profile in $G$ then the highest priority for player $i$ on $\pi$ is even 
if and only if $mp(c_i(\pi)) > 0$.
\end{proof}

%\todo{Similarly, the lexicographic payoff is a special case of $F$-mean payoff games.}

\begin{corollary}
 For every LTL-game there is a memoryless-equivalent threshold mean-payoff game with $2$-exponential blowup.
\end{corollary}

\todo{Question. Is this same true if we drop ``memoryless''?}

\begin{conjecture} \label{conj:oxford-mp}
Oxford games are memoryless-equivalent to lexicographic threshold mean-payoff games with $2$-exponential blowup.
\end{conjecture}
\begin{proof}[Sketch]
 Let $G$ be an Oxford game. Replace the LTL formulas by DPW, as in Theorem~\ref{thm:LTL to parity}. Then replace DPWs by mean-payoff condition, as in Theorem~\ref{thm:PG-MP}.
\end{proof}


%The following property is useful: a payoff function is \emph{prefix-independent} if $\mu(i)(\pi) = \mu(i)(\pi')$ for every suffix $\pi'$ of $\pi$.
%All the payoff functions above are prefix-independent, except some LTL and $\omega$-regular games.


\section{Related Work and Conjectures}

We now state some known results and sketch their proofs. For the sake of the draft, we also
conjecture some results and sketch proof-ideas.

\subsection{Concurrent Setting}
The authors in \cite{DBLP:journals/corr/BouyerBMU15} give a general reduction from multiplayer concurrent games with preference relations to two-player zero-sum games such that the former has a NE
iff the later has a winning strategy. In their words:

\begin{verbatim}
We propose a novel transformation of the multi-player
concurrent game (with a preference relation for each player) 
into a two-player zero-sum turn-based game, which we call 
the suspect game. Intuitively, in the suspect game, one of 
the players suggests a global move (one action per player 
of the original game), with the aim to progressively build 
a Nash equilibrium; while the second player aims at proving 
that what the first player proposes is not a Nash equilibrium.
This transformation can be applied to arbitrary concurrent games 
(even those with infinitely many states) and preference relations
for the players, and it has the property that there is a 
correspondence between Nash equilibria in the original game and 
winning strategies in the transformed two-player turn-based 
game. The winning condition in the suspect game of course depends 
on the preference relations of the various players in the 
original game. 
\end{verbatim}

The paper then gives the exact complexity of ENASH for many $\omega$-regular 
objectives, and semi-quantitative versions of these (like counting or 
lexicographic). E.g., 
\begin{theorem}[\cite{DBLP:journals/corr/BouyerBMU15}]
The complexity of ENASH for:
\begin{enumerate}
 \item reachability- and safety-games are $\np$-complete, 
 \item Buchi-games are $\ptime$-complete,
 \item parity-games is ${\sf P}^\np_{||}$-complete,
 \item Muller-games is $\pspace$-complete,
 \item lexicographic Buchi-games are in $\np$.
\end{enumerate}
\end{theorem}



\begin{conjecture} \label{conj:ENASH-mpgs}
E-NASH for threshold mean-payoff games is decidable in \expspace.
Memoryless E-NASH for threshold mean-payoff games is decidable in \exptime. The same statements hold for lexicographic mean-payoff games.
\end{conjecture}
\begin{proof}[Idea]
% Perhaps the suspect game can be applied, or GP's idea of reducing E-NASH to synthesis and satisfiability can be applied.
 We first sketch the proof for threshold mean-payoff games (i.e., not lexicographic).
 Given a game $G$, let $\phi_a$ denote the condition that the mean-payoff of the costs of a play for agent $a$ is greater than $0$. 
 Guess the set of losers $L \subseteq \Ag$ and consider the following turn-based two-player zero-sum game $G_L$ played on the states of $G$
 between $E$ and $A$, who alternate turns, with $E$ going first. $E$ plays tuples of actions $m$, one for each player,  
 and $A$ plays states.  There are $|\Ag|+1$ modes the game can be in: neutral or $a$-deviating for $a \in \Ag$. Before any of his moves, $A$ can decide to switch modes from neutral to $a$-deviating for some $a \in \Ag$, and once in $a$-deviating mode, the play stays in $a$-deviating mode.  Play starts from the initial state, in neutral mode. The modes are used as follows. Suppose the current state is $q$ and $E$ has chosen the tuple $m$. 
In the neutral mode $A$ plays $q' = \delta(q,m)$. In $a$-deviating mode $A$ may play $q' = \delta(q,m')$ where $m'$ agrees with $m$ except possibly on $a$'s action. A play $\pi$ is won by $E$ iff 
 $\pi \models \bigwedge_{a \in L} \neg \phi_a \wedge \bigwedge_{a \in \Ag \setminus L} \phi_a$. Then: $E$ has a (finite-memory) winning strategy in $G_L$ iff $G$ has a (finite-memory)  Nash Equilibrium whose losers are $L$.
 
 Thus, we have reduced the (memoryless) ENASH problem to solving (in memoryless strategies) exponentially-many polynomially-sized two-player zero-sum games $H$ with objective that is a boolean combination of mean-payoff thresholds. Each game $H$ is solvable for arbitrary strategies \expspace (using Petri-Nets). So the whole procedure can be done in \expspace.
 Each game $H$ is solvable for memoryless strategies in \exptime (just run through all the memoryless strategies, and look for a lasso satisfying the winning condition). So the whole procedure can be done in \exptime.
 
 To get the result for the lexicographic case, adapt the formula that $E$ needs to satisfy to reflect the lexicographic order on the threshold objectives.
\end{proof}
The complexity can probably be improved. Use nondeterminism to guess $L$, and then solve a single game $H$. It is known that if the boolean combination of the objectives is a conjunction of ``greater-than'' conditions, then the complexity is co-\np-complete for finite-strategies, and \np-complete for memoryless strategies~\cite{DBLP:conf/fsttcs/ChatterjeeDHR10}. 

 \begin{conjecture}
  Memoryless-ENASH for Oxford-games is decidable in 3\exptime.
 \end{conjecture}
\begin{proof}[Sketch]
 By Conjecture~\ref{conj:oxford-mp}, we can reduce the problem to Memoryless-ENASH of lexicographic threshold mean-payoff games. By Conjecture~\ref{conj:ENASH-mpgs}
 these can be solved in \exptime.
\end{proof}

\todo{Q: What about a lower bound? See \cite{DBLP:journals/corr/BouyerBMU15}}


% The following is folklore: one can decide if a given player in a two-player 
% concurrent game has a winning strategy by reducing to a turn-based game in which 
% that player always moves first.

\subsection{Turn-based Setting}

The first paper studies mean-payoff games.

\begin{theorem}[\cite{Alpe91}] \label{thm:turnbased:MP}
In turn-based mean-payoff games:
\begin{enumerate}
 \item Memoryless NE may not exist if $N > 2$, \todo{Q: what about $N \leq 2$?}
 \item Finite-state NE exist, and the number of states may be taken to be $|\Stt|!$. \todo{Q: can this be improved to memoryless?}
\end{enumerate}
\end{theorem}
\begin{proof}[Sketch]
The main part of the proof of 2. is to show that such games are equivalent to certain 
finite-duration games: play as usual, but stop once a state is repeated and a 
simple cycle is formed, and define the utility of the play for agent $i$ to be 
mean-payoff costs of the cycle.  Given this, use backward induction (i.e., 
Zermelo-Kuhn theorem) to deduce that the finite duration game (and hence the 
original CCGS) admits a NE. Each strategy needs to remember at most the ordering 
of the states as they are encountered, i.e., $|\St|!$ memory is enough. This 
bound on the strategies of the finite-duration game transfers to the original 
game. 
\end{proof}

The next paper studies multi-player stochastic games with $\omega$-regular objectives.
Deterministic games are a special case.

\begin{theorem}[special case of \cite{CJM04}]
Turn-based games with prefix-independent $\omega$-regular objectives have
finite-state NE. \todo{Check if for parity objectives memoryless strategies suffice}
\todo{Check if paper mentions prefix-independent}
\end{theorem}
\begin{proof}[Sketch] 
The idea is that a NE is one where the players play to try and achieve their 
own 
objectives, but the moment a player deviates all the others punish that player 
by ensuring she still can't achieve her objective if she couldn't in the first 
place.

In more detail, let $W_i$ be the 
winning region of the game in which player $i$ tries to achieve its objective 
and all the others form an adversarial-coalition. This is a two-player zero-sum 
game (i.e., player $i$ vs a single player representing all the other players, 
called the adversarial coalition) with $\omega$-regular objective. These games 
are determined, and thus the states $L_i$ not in $W_i$ are won by the 
adversarial coalition. Let $\sigma_i$ be a strategy for player $i$ that wins 
from $W_i$, and let $\sigma_i^j$ be a strategy for players $j \neq i$ such that 
they, collectively, ensure that player $i$ loses on $L_i$. Define a strategy 
$\rho_i$ for player $i$ as follows: as long as all other players $j \neq i$ 
behave according to $\sigma_j$, then $\rho_i$ behaves like $\sigma_i$. However, 
the moment some player $j \neq i$ deviates from $\sigma_j$ then $\rho_i$ 
punishes player $j$ by playing $\sigma_j^i$. The strategy profile $\tpl{\rho_1, 
\cdots, \rho_n}$ is a NE.
Thus each $\rho_i$
just needs to remember whether or not it is in normal behaviour or punishing 
behaviour. Thus if the $\sigma_i$ and $\sigma_i^j$ were finite-state 
then the $\rho_i$ are finite-state.
But two-player zero-sum games with $\omega$-regular objectives admit finite-state strategies.
\end{proof}

The next paper studies generalised Muller games. Here the payoff is a function that depends only on the set of states seen infinitely often on a play. 
\begin{theorem}[\cite{DBLP:conf/fsttcs/PaulS09}]
Every turn-based generalised Muller game admits finite-state NE.
\end{theorem}
The proof does not go via threat-strategies, but via backward induction. The 
authors also prove that one can decide if such a game has a subgame-perfect 
equilibrium.

\begin{conjecture}
In turn-based $F$-mean-payoff games, finite-state NE exist, and the number of states may be taken to be $|\Stt|!$. 
\end{conjecture}
\begin{proof}[Idea]
Proof should follow that of Theorem~\ref{thm:turnbased:MP}. One could also adapt the proof in \cite{AmRu14}.
\end{proof}








  



%The fact that one-player mean-payoff games can be solved in \ptime\ (Karp 1978) 
%means that one can compute a NE in \expspace.

	

%\begin{theorem}[Ehrenfeuct + Mycielski, 1979]
%Two player zero-sum mean-payoff games are memoryless determined, i.e., exactly 
%one of the players has a winning strategy, and that strategy may be taken to be 
%memoryless.
%\end{theorem}











\subsection{Other related work that should be checked}

\begin{enumerate}
 \item \url{http://arxiv.org/abs/1210.3539} covers synthesis of specifications written in LTL with mean-payoff weights. Reduced to parity games.
\item Rational synthesis, e.g., \cite{CFRR16}

\end{enumerate}








\bibliographystyle{plain}

\bibliography{refs}


\end{document}