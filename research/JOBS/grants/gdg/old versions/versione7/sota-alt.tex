This part of the proposal should be read in conjunction with Part B1,
which introduces the project providing its vision. 


\section{State-of-the-art and objectives}

%\vspace{-1ex}

The overarching objective of \project is:

\begin{quote}\textit{
\project aims at laying the theoretical foundations and practical
methodologies of a science and engineering of \textbf{white-box self-programming mechanisms}. 
}
\end{quote}


Towards the goal of building \textbf{white-box self-programming mechanisms}, \project will address the following objectives: %challenges.
\begin{enumerate}

\item \textbf{Make white-box self-programming mechanisms comprehensible to
    humans} 

\item \textbf{Make white-box self-programming mechanisms verifiable}

\item \textbf{Equip mechanisms with general self-programming abilities}

\item \textbf{Make self-programming abilities available while in operation} 

\item \textbf{Make self-programming mechanisms data-aware}


\item 
\textbf{Allow learning and stochastic decisions, while remaining within safe bounds}

\item \textbf{Favor component-based approaches}  
\end{enumerate}

We discuss each of them in details below.



\subsection{Addressing objective 1: Make white-box self-programming mechanisms
  comprehensible to humans.}

The key property of white-box self-programming mechanisms is the
ability of describing their specification, the programs they generate
and the relationship between the two in human terms.

To do so the domain where the mechanism operates, the structure of the
mechanism itself, its capabilities and limitations, as well as
possible goals need to be formally described in terms of concepts that
can be shared with humans.

\project will base
\textbf{Knowledge Representation} (KR) stems from a deep
tradition in logic. In particular, it aims at building systems that
know about their world and are able to act in an informed way in it,
as humans do.

A crucial part of the system it that knowledge is represented
symbolically, and that reasoning procedures are able to extract
consequences of such knowledge as new symbolic representations. Such
an ability is used to deliberate in an informed fashion the course of
actions to take.

This very idea is radically new in human history [Leve14]. It comes
about after a long gestation, stemming from Aristotle, who developed
the initial notion of logic though unrelated to notion of computation;
continued by Leibniz, who brought forward a notion of “thinking as
computation”, though not yet symbolic; and later by Frege, who
developed the notion of symbolic logic, though unrelated to
computation; and finally by the breakthrough in human thinking of the
early part of last century with Church, Godel, and Turing, who set the
bases for symbolic logic bound together with computation and
ultimately for Computer Science, though even them did not think about
logic as a way of representing knowledge. The KR idea can only be
traced back to McCarthy work in 1959 [McCa59], which gave rise to the
area of Artificial Intelligence.

In KR, a first-person view of an agent reasoning on its knowledge of
the world to deliberate its action has been studied in depth through
comprehensive frameworks, such as that of Situation Calculus [McHa69,
Reit01, LRLL97, DeLL00, DeLP06]. 

In state- of-the art MAS, mental states are assigned to other agents
when designing the MAS, but then they are compiled away from the
single agents when in operation. We may call such an approach a
third-person view (or designer view) of agents, to be contrasted to
first-person view, where agents at runtime have a model of the world
in which they are immersed in (which possibly includes other agents),
and use such a model to deliberate about what to do next. In fact a
first-person view of agents has long be advocated in reasoning about
action in Knowledge Representation [McHa69, Reit01].


Restricted forms of representations
(essentially propositional) have been put forward to study efficient
action deliberation or planning which in these years is producing a
vast array of particularly fruitful results [GeBo13, DePS10, DFPS10,
CaDH11, FeDL12, DePS13, DeVa13, GeTh14, DeDM14, DDGM14].

Recently this work has been complemented by a set of novel results
that shows the effective computability of expressive variants of the
original full-fledged (predicate based) Situation Calculus [DeLP12,
DLPV14, DeLV14]. Such results are being complemented by the
possibility of combining action theories with ontological
representations in description logics [CDLL13, CDMP13,
HCMD14]. Moreover, the techniques for applying belief revision to
transition systems based on dynamic logic of assignments proposed
recently [HMDW14], open up the possibility of grounding
computationally the notion of “behavior revision”.

However virtually in all the works adopting a first-person view of
agent in KR, the agent does not ascribe explicitly behaviors of other
agents acting in the same world. To be more precise, such behaviors
are blurred together with contingencies and exogenous events occurring
in the environment the agent is immersed in.


\subsection{Addressing objective 2: Make white-box self-programming mechanisms verifiable.}

The translation from LTL to automata is exponential in the worst case, but exponential blow-up is rarely seen in practice and many optimizing compilers have been developed [46, 50, 60, 70, 76, 74, 71, 73, 144, 140, 146].




% [46] J.-M. Couvreur. On-the-fly verification of linear temporal logic. In Proc. World Congress on Formal Methods, pages 253–271, 1999.

% [50] N. Daniele, F. Guinchiglia, and M. Vardi. Improved automata generation for linear temporal logic. In Computer Aided Verification, Proc. 11th International Conference, volume 1633 of Lecture Notes in Computer Science, pages 249–260. Springer-Verlag, 1999.

% [60] K. Etessami and G. Holzmann. Optimizing bu ̈chi automata. In Proc. 11th Int’l Conf. on Concurrency Theory, Lecture Notes in Computer Science 1877, pages 153–167. Springer-Verlag, 2000.

% [76] S. Gurumurthy, R. Bloem, and F. Somenzi. Fair simulation minimization. In Computer Aided Ver- ification, Proc. 14th International Conference, volume 2404 of Lecture Notes in Computer Science, pages 610–623. Springer-Verlag, 2002.

% [74] D. Giannakopoulou and F. Lerda. From states to transitions: Improving translation of ltl formulae to bu ̈chi automata. In Proc. 22nd IFIP Int’l Conf. on Formal Techniques for Networked and Distributed Systems, pages 308–326, 2002.

% [71] P. Gastin and D. Oddoux. Fast LTL to bu ̈chi automata translation. In Computer Aided Verification, Proc. 13th International Conference, volume 2102 of Lecture Notes in Computer Science, pages 53– 65. Springer-Verlag, 2001.

% [146] X. Thirioux. Simple and efficient translation from ltl formulas to Bu ̈chi automata. Electr. Notes Theor. Comput. Sci., 66(2), 2002.

% [144] F. Somenzi and R. Bloem. Efficient Bu ̈chi automata from LTL formulae. In Computer Aided Veri- fication, Proc. 12th International Conference, volume 1855 of Lecture Notes in Computer Science, pages 248–263. Springer-Verlag, 2000.

% [140] R. Sebastiani and S. Tonetta. “more deterministic” vs. “smaller” bu ̈chi automata for efficient ltl model checking. In 12th Advanced Research Working Conference on Correct Hardware Design and Verification Methods, volume 2860 of Lecture Notes in Computer Science, pages 126–140. Springer- Verlag, 2003.


% [73] R.Gerth, D.Peled, M.Vardi, and P.Wolper. Simple on-the-fly automatic verification of linear temporal logic. In P. Dembiski and M. Sredniawa, editors, Protocol Specification, Testing, and Verification, pages 3–18. Chapman \& Hall, August 1995.


We need to go, however, beyond LTL. It is fairly clear that LTL is is not expressive enough for complex behavior over complex planning domains. Since the proposal in [125] to apply LTL to the specification and verification of reactive systems, the role of LTL as a feasible approach to that task has been widely studied. Over the past two decades an extensive research has been carried out concerning various aspects of using LTL to specify and verify reactive systems, cf. [55, 126, 153]. One of the conclusions of this research is that LTL, which consists of the temporal connectives next and until is not expressive enough for its task [113]. 

More recently, there has been a major emphasis recently in the semiconductor industry on designing industrial-strength temporal property specification languages. Two major languages are ForSpec [5] and Sugar [10], developed by Intel and IBM, respectively, which are both extensions of Pnueli’s LTL. A recent industry standard (PSL 1.1) resulted from merging features of ForSpec and Sugar (see www.accellera.org). All these languages extend LTL significantly. Many of additional constructs of these languages reflect current semiconductor design methodology. The most basic extension, however, is the addition of regular-event construct. For example, in ForSpec one can write e1 triggers e2, where e1 and e2 are regular expressions, which asserts that a behavior matching a word in e1, should be followed by a behavior matching a word in e2. One one hand, it is shown in [5] that such extension remedies well-known deficiencies of LTL [113, 159]. On the other hand, this extension is extremely easy to use; validation engineers prefer using regular expressions to using nested expressions of next’s and until’s. The extension of LTL with regular expression is known as RELTL. While the automata-theoretic approach has been extended to RELTL [4], there is no published work on optimized compilation of RELTL to automata. We plan to ex- plore the applicability of RELTL to specifying complex behaviors in planning settings. If RELTL is found to be appropriate for such settings, then we need to extend optimized compilation techniques from LTL to RELTL


% [125] A. Pnueli. The temporal logic of programs. In Proc. 18th IEEE Symp. on Foundation of Computer Science, pages 46–57, 1977.

% [55] E. Emerson. Temporal and modal logic. In J. V. Leeuwen, editor, Handbook of Theoretical Computer Science, volume B, chapter 16, pages 997–1072. Elsevier, MIT Press, 1990.

% [126] A. Pnueli. Applications of temporal logic to the specification and verification of reactive systems: A survey of current trends. In Proc. Advanced School on Current Trends in Concurrency, pages 510–584, Berlin, 1985. Volume 224, LNCS, Springer-Verlag.

% [153] M. Vardi. Branching vs. linear time: Final showdown. In Proc. Tools and Algorithms for the Con- struction and Analysis of Systems (TACAS), volume 2031 of Lecture Notes in Computer Science, pages 1–22. Springer-Verlag, 2001.

% [113] O. Lichtenstein, A. Pnueli, and L. Zuck. The glory of the past. In Logics of Programs, volume 193 of Lecture Notes in Computer Science, pages 196–218, Brooklyn, June 1985. Springer-Verlag.

% [5] R. Armoni, L. Fix, A. Flaisher, R. Gerth, B. Ginsburg, T. Kanza, A. Landver, S. Mador-Haim, E. Singerman, A. Tiemeyer, M. Vardi, and Y. Zbar. The ForSpec temporal logic: A new tempo- ral property-specification logic. In Proc. 8th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, Lecture Notes in Computer Science 2280, pages 296–211. Springer-Verlag, 2002.

% [10] I. Beer, S. Ben-David, C. Eisner, D. Fisman, A. Gringauze, and Y. Rodeh. The temporal logic sugar. In Proc. Conf. on Computer-Aided Verification, LNCS 2102, pages 363–367, 2001.

% [159] P. Wolper. Temporal logic can be more expressive. Information and Control, 56(1–2):72–99, 1983.

% [4] R. Armoni, D. Bustan, . Kupferman, and M. Vardi. Resets vs. aborts in linear temporal logic. In 9th Int’l Conf. on Tools and Algorithms for the Construction and Analysis of Systems, pages 65–80, 2003.




\subsection{Addressing objective 3: Equip mechanisms with general self-programming abilities.}


The recent advances in synthesis algorithms and methodology have resulted in promising case studies generating a lot of excitement in programming languages and embedded software research communities. The goal of \project is to build on the momentum of these recent developments to bring together ideas in these various point solutions into a transformative paradigm of self-programming mechanisms engineering. In this vision of synthesis-centric software design, instead of viewing synthesis as a problem of automatically mapping a high-level specification to a low-level implementation, we focus on the problem of consistently integrating distinct artifacts describing different views of the design via a collaborative effort between the mechanism execution and the synthesizer.



In our view of computer-augmented program engineering, the problem of synthesis gets formalized in a variety of ways: deriving an executable implementation from a declarative specification; completing a partial implementation guided either by logical assertions or by example behaviors; refining an implementation to satisfy additional functional and/or optimality requirements; and deriving and/or combining interface specifications from legacy components and libraries. A key ingredient in all these problems is the adversarial interaction between the uncontrolled aspects of the system (such as the environment, already specified parts, libraries to be used) and the controlled aspects to be designed (such as program components and parameters) which can be formally modeled as quantifier alternation: the synthesis question is whether there exists a control strategy such that for all system behaviors, the completed (or “closed-loop”) system satisfies the specification. This game-theoretic perspective distinguishes synthesis from post-facto verification, where we check if every behavior of the implementation satisfies the specification.


The algorithmic foundations necessary to solve the synthesis problem are rooted in game theory, logic, automata theory, program analysis, and control theory. While formal verification has been considered by many an impossible dream, it has recently become an industrial reality [6], driven by the synergy between theory and practice, where several practical algorithmic advances arose out of theoretical research results. For example, the automata-theoretic framework for model checking [67] is used in industrial hardware model checking [24], the timed-automaton framework and associated analysis [3] led to efficient tools for verifying real-time systems [9], and the abstraction-refinement framework [18], driven by decision procedures for expressive theories [7], is used in industrial software model checking [6]. We strongly believe that progress in computer-augmented program engineering will similarly be driven by, and drive, algorithmic foundational problems.

Recent advances in computer-augmented program engineering have used a variety of computational engines including decision procedures for constraint-satisfaction problems, computing winning strategies in games for temporal specifications, computational-learning algorithms, scalable static-analysis techniques, abstraction techniques for reducing state-spaces, and numerical simulation and optimization. Advances in these core computational engines can be shared by different synthesis algorithms in the context of different applications. With this motivation, we outline a few representative directions for future research.

Specifications for reactive systems such as protocols, are usually given in a temporal logic: a logic that express properties of ongoing behaviors. The synthesis problem for reactive systems goes back to work in the 1960’s [15], with finite automata on infinite words and trees providing the crucial algorithmic apparatus, with some recent efforts to translate these results into practice [12, 42]. There are a number of challenging open theoretical questions relating to reactive synthesis, such as the complexity of solving parity games on graphs and the complexity of solving stochastic games [23]. We also propose to develop theoretical foundations for synthesis in presence of quantitative objectives to allow selection, by users, among alternative implementations using the degree to which they satisfy the specification and perform trade-off analysis between how well the specification is satisfied and the complexity of the implementation. Finally, there is a clear need for developing practical heuristics to address the high computational complexity of reactive synthesis problems, just as the state-explosion problem in model checking was mitigated by a host of heuristics [16]. Potential directions include the combination of symbolic techniques with learning algorithms, and incremental synthesis algorithms to process evolving requirements.


\textbf{Robustness and automated exception handling.} In many application domains, such as the robotic systems and automotive control software, robustness is as important as correctness. By robustness we mean the capability of a program to perform “adequately”, even when the assumptions made at design time do not hold, for example, due to limited knowledge about the environment. The key challenge is how to define what constitutes adequate behavior. By drawing inspiration from the well established area of robust control, the PIs [49] have recently shown that it is possible to synthesize software that is robust against unspecified disturbances. This is a significant advance since existing techniques ensuring fault tolerance, or other types of robustness against disturbances, require the explicit modeling of all the faults that can occur in the system. Unfortunately, such explicit adversarial modeling of disturbances leads to a game that is computationally expensive to solve. In contrast, the results in [49] lead to games of polynomial complexity to construct programs that are robust against unmodeled disturbances of bounded power. The key insight is to use the programmer knowledge to derive a metric on program states that can be used to quantify the effect of disturbances of bounded power. In this expedition we will start from these recent advances and build the foundations of robust programming by synergistically drawing inspiration in control theory, and robust control in particular.

\subsection{Addressing objective 4: Make self-programming abilities available while in operation.} 

The automata-theoretic constructions studied in the literature all operate at the propositional level; that is, the temporal logics studied are propositional. An issue that has not been studied is the cost of “Booleanization”. Taking, for example, block-world planning problems [87], the number of Boolean variables tend to grow superlinearly (n3) with the number of blocks. Thus, just generating goal formulas becomes computationally challenging for a block world with 20 blocks. (It may seen that a cubic blow-up is rather benign, but one needs to remember that this blow-up occurs before we even start temporal reasoning, and therefore may have heavy computational cost.) In contrast, TLPLAN [8], which uses “formula decomposition”, avoids Booleanization, and can handle 20-blocks problems easily. The key insight in TLPLAN is that one can express control information in first-order LTL, search for a plan by simple depth-first forward chaining, and use formula-decomposition techniques to dynamically check formula on that component of the search space that we have generated “on-the-fly”.

In contrast, TLPLAN [8], which uses “formula decomposition”, avoids Booleanization, and can handle 20-blocks problems easily. The key insight in TLPLAN is that one can express control information in first-order LTL, search for a plan by simple depth-first forward chaining, and use formula-decomposition techniques to dynamically check formula on that component of the search space that we have generated “on-the-fly”.
This seems to imply that a major benefit is using LTL to specify control knowledge. 

Thus, to adapt automata-theoretic technique to planning we need on-the-fly techniques that combine on- the-fly compilation of temporal connectives, as in [45, 50, 73], which are significantly more sophisticated that the somewhat ad-hoc formula-decomposition technique used in TLPLAN, with on-the-fly variable- instantiation techniques used in TLPLAN. The key is to avoid prior Booleanization. We also need to compare the techniques used in TLPLAN with techniques used in temporal databases for processing non- propositional temporal integrity constraints [33, 34].

% [8] F. Bacchus and F. Kabanza. Using temporal logics to express search control knowledge for planning. AI J., 116(1–2):123–191, 2000.

% [87] H. Kautz and B. Selman. Unifying sat-based and graph-based planning. In Proc. 16th Int’l Joint Conf. on Artificial Intelligence, pages 318–325. Morgan Kaufmann, 1999.

% [45] C. Courcoubetis, M. Vardi, P. Wolper, and M. Yannakakis. Memory efficient algorithms for the verification of temporal properties. Formal Methods in System Design, 1:275–288, 1992.

% [50] N. Daniele, F. Guinchiglia, and M. Vardi. Improved automata generation for linear temporal logic. In Computer Aided Verification, Proc. 11th International Conference, volume 1633 of Lecture Notes in Computer Science, pages 249–260. Springer-Verlag, 1999.

% [73] R.Gerth,D.Peled,M.Vardi,andP.Wolper.Simpleon-the-flyautomaticverificationoflineartempo- ral logic. In P. Dembiski and M. Sredniawa, editors, Protocol Specification, Testing, and Verification, pages 3–18. Chapman & Hall, August 1995.

% [33] J. Chomicki. Efficient checking of temporal integrity constraints using bounded history encoding. ACM Trans. Database Syst., 20(2):149–186, 1995.

% [34] J.Chomicki and D.Niwinski. On the feasibility of checking temporal integrity constraints. J. Comput. Syst. Sci., 51(3):523–535, 1995.

Many real-world planning domains are inherently nondeterministic, that is, the result of actions are not fully predictable. For example, a robot trying to pick up a block may fail to grip the block. Formally, we need to consider a set-valued transition function $R : W \times Act \rightarrow 2^W$ , which assigns to each state and action a set of possible successor states. One can still can search for sequential condition plans, but in general the solution to the planning problem in such settings require universal plans [121, 137]. We consider here the most general universal plans, where the action selected depends not only on the current observations but on the sequence of observations made so far. This means that the plan should be viewed as a general reactive program [79], engaged in an ongoing interaction with the system it is trying to control. A correct plan should be able to handle arbitrary behavior of the system.

% [121] M. Peot and D. Smith. Conditional nonlinear planning. In Proc. of 1st Int. Conf. on AI Planning Systems (AIPS’92), pages 189–197. Morgan Kaufmann Publisher, 1992.

% [137] M. Schoppers. Universal plan for reactive robots in unpredictable environments. In Proc. Int. Joint Conf. on Artificial Intelligence, 1987.

% [79] D. Harel and A. Pnueli. On the development of reactive systems. In K. Apt, editor, Logics and Models of Concurrent Systems, volume F-13 of NATO Advanced Summer Institutes, pages 477–498. Springer-Verlag, 1985.


In its full generality, a plan is a mapping $p : Obs^∗ \rightarrow Act$, which selects an action based on the full history of observations. The plan $p$ realizes a specification $\varphi$  if all traces of $p$ satisfy $\varphi$. 
It turns out that the problem of synthesizing universal plans in nondeterministic domains has a long history in mathematical logic, going back to the 1960s [35, 18, 130]. More recently, it has been studied by computer scientists [6, 1, 52, 80, 104, 127, 128, 149, 151], as well as by control theorists [3, 132, 147]. The automata-theoretic approach is the key to modern algorithmic approaches to this problem. 

% [35] A. Church. Logic, arithmetics, and automata. In Proc. International Congress of Mathematicians, 1962, pages 23–35. institut Mittag-Leffler, 1963.

% [18] J. Bu ̈chi and L. Landweber. Solving sequential conditions by finite-state strategies. Trans. AMS, 138:295–311, 1969.

% [130] M. Rabin. Automata on infinite objects and Church’s problem. Amer. Mathematical Society, 1972.

% [6] A. Arora, P. Attie, and E. Emerson. Synthesis of fault-tolerant concurrent programs. In Proc. 17th ACM Symposium on Principles of Distributed Computing, pages 173–182, 1998.

% [1] M. Abadi, L. Lamport, and P. Wolper. Realizable and unrealizable concurrent program specifications. In Proc. 16th International Colloquium on Automata, Languages and Programming, volume 372, pages 1–17. Lecture Notes in Computer Science, Springer-Verlag, July 1989.

% [52] D. Dill. Trace theory for automatic hierarchical verification of speed independent circuits. MIT Press, 1989.

% [80] T. Henzinger, S. Krishnan, O. Kupferman, and F. Mang. Synthesis of uninitialized systems. In Proc. 29th Colloq. on Automata, Programming, and Languages, volume 2380 of Lecture Notes in Computer Science, pages 644–656. Springer-Verlag, 2002.

% [104] O. Kupferman and M. Vardi. Synthesis with incomplete informatio. In Advances in Temporal Logic, pages 109–127. Kluwer Academic Publishers, January 2000.

% [127] A. Pnueli and R. Rosner. On the synthesis of a reactive module. In Proc. 16th ACM Symp. on Principles of Programming Languages, pages 179–190, Austin, January 1989.

% [128] A. Pnueli and R. Rosner. On the synthesis of an asynchronous reactive module. In Proc. 16th International Colloquium on Automata, Languages and Programming, volume 372, pages 652–671. Lecture Notes in Computer Science, Springer-Verlag, July 1989.

% [149] W. Thomas. On the synthesis of strategies in infinite games. In E. Mayr and C. Puech, editors, Proc. 12th Symp. on Theoretical Aspects of Computer Science, volume 900 of Lecture Notes in Computer Science, pages 1–13. Springer-Verlag, 1995.

% [151] M. Vardi. An automata-theoretic approach to fair realizability and synthesis. In P. Wolper, editor, Computer Aided Verification, Proc. 7th International Conference, volume 939 of Lecture Notes in Computer Science, pages 267–292. Springer-Verlag, Berlin, 1995.

% [3] M. Antoniotti. Synthesis and verification of discrete controllers for robotics and manufacturing de- vices with temporal logic and the Control-D system. PhD thesis, New York University, New York, 1995.

% [132] P. Ramadge and W. Wonham. The control of discrete event systems. IEEE Transactions on Control Theory, 77:81–98, 1989.

% [147] J. Thistle. Control of infinite behavior of discrete-event systems. PhD thesis, University of Toronto, 1991.

While the standard automata-theoretic approach to universal planning yielded theoretically optimal upper bound, cf. [99, 104, 90, 127], it has proved to be not too amenable to implementation. First, Safra’s construction proved quite resistant to efficient implementation [145]. Second, the best-known algorithms for alternating tree-automata emptiness are exponential [84]. Thus, while highly optimized software packages for automata on finite words and finite trees have been developed over the last few years [53], no such software has been developed for automata on infinite trees.

Thus, to date, research in the model-checking community on program synthesis has not had much of an external impact, especially in comparison to model checking. We believe that conditions are now right for significant progress on the topic of synthesis. Basic factors underlying successful synthesis methods include the complexity of the decision procedures, and overcoming the combinatorial state-explosion problem. 

% [99] O. Kupferman and M. Vardi. Church’s problem revisited. The Bulletin of Symbolic Logic, 5(2):245 – 263, June 1999.

% [104] O. Kupferman and M. Vardi. Synthesis with incomplete informatio. In Advances in Temporal Logic, pages 109–127. Kluwer Academic Publishers, January 2000.

% [90] P. Kolaitis and M. Vardi. Conjunctive-query containment and constraint satisfaction. Journal of Computer and System Sciences, pages 302–332, 2000. Earlier version in: Proc. 17th ACM Symp. on Principles of Database Systems (PODS ’98).

% [127] A. Pnueli and R. Rosner. On the synthesis of a reactive module. In Proc. 16th ACM Symp. on Principles of Programming Languages, pages 179–190, Austin, January 1989.

% [145] S. Tasiran, R. Hojati, and R. Brayton. Language containment using non-deterministic omega- automata. In Proc. of 8th CHARME: Advanced Research Working Conference on Correct Hardware Design and Verification Methods, volume 987 of Lecture Notes in Computer Science, pages 261–277, Frankfurt, October 1995. Springer-Verlag.

% [84] M. Jurdzinski. Small progress measures for solving parity games. In 17th Annual Symposium on Theoretical Aspects of Computer Science, volume 1770 of Lecture Notes in Computer Science, pages 290–301. Springer-Verlag, 2000.

% [53] J. Elgaard, N. Klarlund, and A.Moeller. Mona1.x: new techniques for WS1S and WS2S. In Computer Aided Verification, Proc. 10th International Conference, volume 1427 of Lecture Notes in Computer Science, pages 516–520. Springer-Verlag, Berlin, 1998.



\subsection{Addressing objective 5: Make self-programming mechanisms data-aware.}

\textbf{Automated abstraction and refinement.} The appeal of abstraction lies in building sound abstract models from complex systems (often using automated logic engines such as SMT solvers), and subjecting the resulting models to efficient search and analysis [20]. One primary foundational goal is to find theories of abstraction for synthesis. Can we synthesize systems by synthesizing in the abstract and combine it with synthesis of refinements to build a concrete system? Can the synthesized systems be refined automatically depending on their quality? How can users improve the abstraction process? Answering the preceding questions will immediately make the powerful search-based techniques and SMT solvers come to bear on the synthesis problem.


\subsection{Addressing objective 6: Allow learning and stochastic decisions, while remaining within safe bounds.}


\textbf{Learning from examples.} While classical formal verification and synthesis relies on deductive reasoning and decision procedures for constraint-satisfaction problems, our view of synthesis also involves inference of program components from example behaviors, both positive and negative, using computational learning. While there is a wealth of literature on learning theory (see, for instance, [37]), we plan to explore how it can be adopted and advanced in the context of program synthesis. As an illustrative example, consider the recent interactive add-in for Microsoft Excel spreadsheet software based on the concept of “programming by examples” [30]. In this system, the user demonstrates the desired transformation task (for example, rewriting all names to a uniform format such as first-name followed by a single space, followed by last-name) using a few examples, and the synthesis tool automatically generates the “best” program (in the form of an Excel Macro) that is consistent with all the examples. The synthesized program is then used to transform all the entries in the spreadsheet, and if this synthesized transformation does not match the user’s intent, the user can guide the synthesizer by highlighting the incorrect updates, thus, providing negative examples for the subsequent iteration. While this tool is exemplary of the envisioned ExCAPE methodology, and has the potential of enormous impact by facilitating intuitive programming by millions of end users, the theoretical foundations of learning the desired program from examples are not yet understood. A suitable theoretical abstraction for the desired program is a “string-to-string” transducer. While there is a well developed theory of minimization and learning for the class of sequential transducers [51], sequential transducers are not expressive enough to capture the typical transformations that involve swapping of substrings. The recently proposed model of streaming string transducers [1] has appealing theoretical properties, such as well characterized expressiveness. Since this model can capture the desired Excel transformations, algorithms for minimization and learning—a topic for proposed research, can lead to efficient synthesis procedure with guarantees of convergence.


\subsection{Addressing objective 7: Favor component-based approaches.}  



\textbf{Interface-based synthesis and composition.} Interfaces capture essential properties of components while hiding irrelevant details. Interface theories [26] provide composition operators, compatibility notions (is the composition of a set of components legal?), and conditions for substitutability (when can one component be replaced by another without compromising the properties of the overall system?) that enable component-based design and alleviate state explosion. Compositionality and incrementality raise a number of questions in the context of synthesis: How to separately synthesize controllers for individual components, or for the same component but with respect to different properties, and then combine them into a single controller? How to derive the component interfaces? Because components take different forms depending on the application domain (they can be pieces of hardware, of software, or of models written in a high-level language such as Simulink or UML), there is no unique, “one-size-fits-all” interface model. For instance, interfaces carry different information in synchronous vs. dataflow components, or when reasoning about I/O dependencies vs.!correctness vs. timing and performance properties [46, 45, 66, ?]. In this expedition, domain knowledge of the human in the loop will be key in identifying the right level of abstraction and information content of the interfaces. In conjunction with this, we will develop methods to derive composite interfaces from basic interfaces automatically, thus maximizing the synergy of human and synthesizer.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "PartB2"
%%% TeX-PDF-mode: t
%%% End:
