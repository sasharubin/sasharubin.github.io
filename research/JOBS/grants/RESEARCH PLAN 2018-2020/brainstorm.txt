WHAT IS THE PROBLEM BEING SOLVED? 
WHY IS IT IMPORTANT? what does it have to do with the real world?
 INTERESTING? RELEVANT? TIMELY?
WHY IS THE PROPOSED DIRECTION FEASIBLE?


ML = DATA --> INFORMATION 
DATA --> PROCESSES

Q: 
- what are rewards used for? soft goals...
- convert soft goal into rewards? See Sadigh/Seshia et al. http://ieeexplore.ieee.org/abstract/document/7039527/?reload=true
that translate LTL synthesis into reward maximisation problem.
- how can FM interface with ML or simulations?
- how can one make ML more declarative?
- what is the MEANING of usual automata constructions? 
e.g., LTL --> AFW: states of the AFW are subformula
AFW --> NFW: states of the NFW are sets of subformula. i.e., the current obligations (e.g., S = {Xp, qUr, p})
nondeterminism comes from guess the future formulas that hold
NFW --> DFW: states of the DFW are sets of sets of subformula. i.e., possible sets of obligations

Planning
- Need incomplete models
- Models are generated automatically from experience
- How can one integrate synthesis and reinforcement learning?


Tricks
- make things bounded (e.g., quantification)

BPM:
- process mining --> process analysis (turnover, flexibility, complexity) --> redesign --> execution, tracking and monitoring 
flexibility = degree to which users can make local decisions... maximally permissive!
- THESIS: the more succinct a specification of a process, the more readable it is to humans, assuming that the basic operations for 
building processes are understandable.... 
- global spec is conjunction of local specs (relating a small subset of the events)
- given a trace, useful to know which constraints it does satisfy, which it may satisfy in the future, which it did in the past, avg number of times it has satisfied 
a given constraint in the past, which it can never satisfy in the future, etc.
- given a set of traces, find the smallest automaton (DFW, NFW, AFW, C-AFW, ... depending on the allowed operations) that contains the log.
- use quantitative measures to define "interestingness". e.g., take avg number of activations vs total number?

RL:
- Reinforcement learning is the problem faced by an agent that must learn behavior
through trial-and-error interactions with a dynamic environment.
- State space of environment is fixed. Transitions are unknown BUT FIXED. Agent receive observations (= reinforcement signal).
- cf. SL where you are told the optimal/correct action at every step.
- RL on large state spaces, i.e., assume state space is too large to store in memory. then what? 
- e.g., k-armed bandit problem. k machines, machine i has prob p_i of giving money. p_is are unknown.
 have H many turns. strategy?

Importance of formal methods in running systems
If every functional module has an associated formal description of its normal behavior, it
is easy to provide added value services that
1. Monitor its performance and alerts of any abnormal situation,
2. Improve the model based on actual experience,
3. Verifies controllers that combine existing modules, and provides information about their
probably effects,
4. Combines existing modules automatically.

Poker:
It therefore
makes sense to adopt a Nash strategy until an opponent
model can be learned. Then the best means of exploit-
ing that model can be tried.

==FMAI==
\emph{planning} in AI and \emph{reactive synthesis} in formal methods 
- same basic idea... model-based controller design
- central to both are succinct representations of the systems: STRIPS, PDDL, in planning and LTL/LTLf in synthesis.
but for different reasons! planning typically deals with reachability goals on compact domains; synthesis with LTL goals on explicit domains.
- both understood early on the computational complexity of the problem PSPACE-complete ... 2EXPTIME-complete
- planning responded by finding ways to treat the "easy but large cases", e.g., heuristic search
- reactive synthesis responded by studying the theory of the problem (e.g., fragments, extensions), and providing algorithms based on logic and automata theory (antichain).
- some work (Sheilah...) has studied translations between these, i.e., LTL --> AFW/NFW --> planning domain

What's missing from within this picture?

1. formal connections between the two fields: e.g., reducing synthesis to planning (cf Sheilah's work).
2. formal connections within planning problems: e.g., reduce LTLf planning to reachability planning...
3. clear idea of how one can exploit modern planners and heuristic methods to solve problems in automata in practice, e.g., do domain-independent 
heuristics work LTLf/LDLf/LTL...? perhaps "LTL-dependent heuristics" should be studied...
4. clear connections between DEL/epistemic programs/GDLIII (Thieschler) and synthesis framework/algorithms.

What's missing from the outside?
1. Richer models of the environment! 
Both consider the environment as being either co-operative (helps the agent achieve the goal), adversarial (tries to prevent 
the player from achieving the goal), or indifferent (e.g., probabilistic). However, environments should be treated as 
first-class objects and include a physical-component that supports the agents physically (e.g., physical roads, net-
work links); a communication-component that supports agent communication (e.g.,
rules and protocols, pheromones); and a social-component that reflects organisational
structure in terms of roles, groups, etc

Thus it is too simplistic to say that an environment is co-operative, adversarial, or indifferent.
E.G. consider a single artificial agent/robot interacting with a single human. In most scenarios one can think of 
(e.g., teaching a language, service) the agent is neither purely co-operative nor purely adversarial nor purely indifferent.

\begin{example}[Card Games]\label{bridge}
 Multiplayer trick-based card-games can be modeled as a MAS. For example, in one way to model Bridge\footnote{As usual, there is more than one way to model things, and one can argue the strengths, weaknesses, and suitability for different purposes of various modeling choices.}, the environment deals the cards so that no human agent can see the cards held by the other agents (physical).
 %, and thus agents have incomplete information about the cards of the other players.
 Opposite players form teams (social) and a team's objective is to win more tricks than the opponent. By viewing the environment as non-deterministic (rather than probabilistic) one can make worst-case analyses. Finally, in the bidding stage, agents are required to talk publicly
 (and thus learn more information about what cards other agents may have), while private talking is prohibited (communication).
\end{example}

\begin{example}[Mobile agents]
Mobile agents can be modeled as a MAS. The physical environment consists of the common space such as a grid or a graph in which the agents move. The communication environment may enforce that agents only have line of sight, or they may have RDF-sensors, etc. The social environment may include teams (e.g., for finding a missing person), or adversarial individuals (e.g., get to the finish line first).
\end{example}

This leads one to consider multiplayer games in which agents may have overlapping objectives, i.e., non-zero sum games.
However, while such games have begun to be addressed, the deficiencies in modeling the environment remain: 
whereas various communities (especially in MAS) have established that it is both essential
and natural to treat the {environment as a first-class citizen} (see for
example the highly cited papers~\cite{DBLP:journals/aamas/WeynsOO07,Odell2003}),
{this was mainly explored in the context of MAS architectures, with no
formal methods or rigorous mathematical results.} 
For instance, it is common to treat the environment as
another agent. This may suggest that the environment is being given first class status, 
however it still ignores the fact that the environment has very different characteristics 
then a rational agent: it need not behave
strategically; it need not have goals; modeling natural aspects of it, such as
incomplete information of the agents regarding the environment, is very
cumbersome.


THUS: I propose to develop richer models of the environment and study both theoretical and practical aspects of the 
planning with TEG (i.e., compact representations of domain and specs).

This separation of indidivual characteristics of the environment (into physical, communication, and social) will provide the 
leverage to develop decidable and tractable variations of the planning and synthesis problems.

In particular, I plan to isolate and exploit:
a) the spatial/topological infrastructure, a central component of the physical-environment, e.g., a computer-network's interlinks layout, or
the physical space in which physical agents move: such as roads, rooms and corridors, trails, etc. --- we call this the \emph{physical-network}, 
b) the communication component, specifically the communication rules and protocols, 
c) the social component by finding middle-grounds between co-operative and adversarial environments, e.g., peers.


We have already made preliminary studies of some of these directions:
a) the physical component has been isolated and exploited in my recent Marie-Curie COFUND project on verification of mobile agents in discrete but partially known environments~\cite{RZMA15,AMRZ16AAMAS, PRIMA} and in foundational aspects of generalised planning ~\cite{IJCAIPLANNINGx2}.
b) the communication component has been exploited in a deep and broad study of the effects of communication primitives in the study of verification of distributed 
computing~\cite{DBLP:conf/lpar/AminofRZ15,DBLP:journals/sigact/BloemJKKRVW16,AJKR14,DBLP:conf/icalp/AminofRZS15,RZMA15,DBLP:journals/sigact/BloemJKKRVW16} and in MAS 
\cite{AAMASPA, IJCAIPA}.
c) the social component has been touched on in recent studies of epistemic extensions of strategic logics~\cite{IJCAIPA, LICS}.


Relation with other work
- In fact a first-person view of agents has long be advocated in reasoning
about action in Knowledge Representation [McHa69, Reit01].
- many architectures used in robotics to capture mental states are not formal enough to admit to formal methods \cite{PeterDunney}, 
although some recent work at UNSW aims to address this.
- to deal with the social component I plan to use notions of "contexts" that defined expected behaviours to other agents that is used to reason 
about them. 

- situation awareness, incomplete information,
information classification and actions ontologies, reasoning about others’ expected behaviors and violations,
strategic action deliberation, and synthesis and refinement of execution plans.

Potential future directions
- E. Asarin, R. Chane-Yack-Fa, and D. Varacca, “Fair adversaries and
randomization in two-player games,” in Proceedings of FoSSaCS 2010,
ser. LNCS, vol. 6014. Springer, 2010, pp. 64–78.

- How Good Is a Strategy in a Game With Nature?
- Paying cost for resolving observation (Natasha,Blaise).

How can I complement research at UNSW.
1. Theoretical foundations of strategic epistemic reasoning in complex environments.
MIT: Strategic Reasoning and Planning for General Game-Playing Robots (Australia-Germany Joint Research Cooperation Scheme 2016-2017)
MIT: Universal Game-Playing Systems for Randomised and Imperfect-Information Games (ARC-DP 2012-2015)

2. Theory of distributed synthesis (information forks, automata theory for controller synthesis) 
could be used to analyse the cognitive meta-hierarchy of 
David Rajaratnam
Bernhard Hengst
Maurice Pagnucco
Claude Sammut
Michael Thielscher



How my work can be complemented by work at UNSW:
1. *unstructured* and incomplete environments are central to many robotic applications (e.g., rescue robots). Adapting definitions and results in reactive synthesis to such a setting is a clear and present challenge.

2. Insights from information flow in security of distributed system (CC Morgan) could yield insights into how strategies of different agents in the distributed synthesis problem signal private information to other agents. Note that the latter is in some sense the dual problem: how can one define strategies that *do* leak enough private information that the distributed players can co-ordinate and achieve a joint objective.

3. Toby Walsh, Haris Aziz?



Project Offers
==============



???
When faced with a dynamical sys-
tem that you want to simulate, control, analyze, or otherwise investigate, first axiomatize
it in a suitable logic. Through logical entailment, all else will follow, including system
control, simulation, and analysis.



- games of incomplete information, imperfect information
- epistemic planning

concretely:
probabilistic DEL with public announcements
PATL* on broadcast iCGS

Quantitative SL: add weights to the arena (e.g., to actions or to
states), and add atomic formulas to the logic of the form "the
mean-payoff for player i is at least c".

Question: is model-checking decidable if we add these to ATL? ATL*? SL?

--
controller manages a collection of programmable mechanisms
- monitors and responds to events
(e.g., shifts in load, certain specifications fail, ...)

- reprogram mechanisms on the fly
(e.g., change ???


controller is centralised (1 agent vs 1 environment)

FSMs (1) intuitively and concisely capture control dynamics in response to network events; and (2) their structure makes them amenable to verification.

what are the external events?
timing, 

what is the current way to solve the problems that whitemech would solve.


